[
    {
        "id": "2007_hignette_an",
        "added": "",
        "year": 2007,
        "firstAuthor": "Hignette",
        "authors": [
            "Gaëlle Hignette",
            "Patrice Buche",
            "Juliette Dibie-Barthélemy",
            "Ollivier Haemmerlé"
        ],
        "title": "An Ontology-Driven Annotation of Data Tables",
        "venue": {
            "type": "workshop",
            "acronym": "WISE"
        },
        "nameOfApproach": "",
        "techniqueTags": [
            "rule-based",
            "ontology-driven"
        ],
        "coreTasks": {
            "cta": true,
            "cpa": true,
            "cea": false,
            "cnea": false
        },
        "supportTasks": {
            "dataPreparation": {
                "description": "Uses a domain ontology with stopwords, units, value ranges and a list of 'no-result' indicators to normalise and interpret table content.",
                "spellChecker": "",
                "unitsOfMeasurements": "Ontology units for numeric types (e.g., °C, °F)."
            },
            "columnClassification": "Rule-based detection of numeric vs symbolic columns using numbers, units and 'no-result' indicators.",
            "subjectDetection": "",
            "datatypeAnnotation": "",
            "typeAnnotation": "Assigns numeric/symbolic ontology types to columns by combining title similarity with units/ranges (numeric) and taxonomy term similarity (symbolic).",
            "predicateAnnotation": "Identifies n-ary relations from the ontology by combining table title similarity with recognised column types.",
            "nilAnnotation": "",
            "entityLinking": {
                "description": "",
                "candidateGeneration": "",
                "entityDisambiguation": ""
            }
        },
        "mainMethod": {
            "type": "unsupervised",
            "technique": "rule-based"
        },
        "revision": {
            "type": "fully automated",
            "description": "Fully automatic scoring with thresholds for column typing and relation selection; no manual post-editing is required."
        },
        "domain": {
            "domain": "dependent",
            "type": "food microbiology"
        },
        "validation": {
            "goldStandard": "60 tables (349 columns) from scientific publications in food microbiology; 16 relations annotated.",
            "metrics": [
                "Precision",
                "Recall",
                "F1"
            ]
        },
        "code": "",
        "license": "Not Specified",
        "inputs": {
            "typeOfTable": "Web tables",
            "tableSources": [
                "web",
                "scientific"
            ]
        },
        "kg": {
            "tripleStore": "Domain ontology for food microbiology (numeric/symbolic types and relations)",
            "index": ""
        },
        "output": "XML",
        "applicationPurpose": "Ontology-driven annotation of scientific web tables to integrate and query data in an XML warehouse.",
        "userInterfaceTool": "",
        "checkedByAuthor": false,
        "checkedByAi": true,
        "doi": "https://doi.org/10.1007/978-3-540-77010-7_4",
        "citations": [
            {
                "ref": "2005_buche_fuzzy",
                "title": "Fuzzy querying of incomplete, imprecise, and heterogeneously structured data in the relational model using ontologies and rules"
            },
            {
                "ref": "2004_zanibbi_a",
                "title": "A survey of table recognition: Models, observations, transformations, and inferences"
            },
            {
                "ref": "2004_pivk_from",
                "title": "From tables to frames"
            },
            {
                "ref": "2006_tenier_instantiation",
                "title": "Instantiation of relations for semantic annotation"
            },
            {
                "ref": "2002_embley_automatically",
                "title": "Automatically extracting ontologically specified data from html tables of unknown structure"
            },
            {
                "ref": "2000_freitag_boosted",
                "title": "Boosted wrapper induction"
            },
            {
                "ref": "2001_baumgartner_visual",
                "title": "Visual web information extraction with Lixto"
            },
            {
                "ref": "2005_gagliardi_an",
                "title": "An automatic ontology-based approach to enrich tables semantically"
            },
            {
                "ref": "1998_lin_an",
                "title": "An information-theoretic definition of similarity"
            },
            {
                "ref": "2006_hignette_fuzzy",
                "title": "Fuzzy semantic approach for data integration applied to risk in food: an example about the cold chain"
            },
            {
                "ref": "1979_vanrijsbergen_information",
                "title": "Information Retrieval, 2nd edition"
            },
            {
                "ref": "2002_yangarber_unsupervised",
                "title": "Unsupervised learning of generalized names"
            },
            {
                "ref": "1999_platt_fast",
                "title": "Fast training of support vector machines using sequential minimal optimization"
            },
            {
                "ref": "1965_zadeh_fuzzy",
                "title": "Fuzzy sets"
            }
        ],
        "uncertainFields": [
            {
                "field": "doi",
                "reason": "DOI is not stated in the paper text; external lookup would be required. "
            },
            {
                "field": "venue.acronym",
                "reason": "The publication appears in 'WISE 2007 Workshops (LNCS 4832)'; using 'WISE' may conflate workshop vs conference branding. "
            },
            {
                "field": "output",
                "reason": "XML is inferred from the stated goal of building an XML data warehouse; the annotation export format is not formally specified. "
            },
            {
                "field": "kg.tripleStore",
                "reason": "A domain ontology is used but no specific KG/triplestore name is given; represented generically. "
            }
        ]
    },
    {
        "id": "2009_cafarella_data",
        "added": "",
        "year": 2009,
        "firstAuthor": "Cafarella",
        "authors": [
            "Michael J. Cafarella",
            "Alon Halevy",
            "Nodira Khoussainova"
        ],
        "title": "Data Integration for the Relational Web",
        "venue": {
            "type": "conference",
            "acronym": "VLDB"
        },
        "nameOfApproach": "Octopus",
        "techniqueTags": [
            "clustering"
        ],
        "coreTasks": {
            "cta": false,
            "cpa": false,
            "cea": false,
            "cnea": false
        },
        "supportTasks": {
            "dataPreparation": {
                "description": "",
                "spellChecker": "",
                "unitsOfMeasurements": ""
            },
            "columnClassification": "",
            "subjectDetection": "",
            "datatypeAnnotation": "",
            "typeAnnotation": "",
            "predicateAnnotation": "",
            "nilAnnotation": "",
            "entityLinking": {
                "description": "",
                "candidateGeneration": "",
                "entityDisambiguation": ""
            }
        },
        "mainMethod": {
            "type": "unsupervised",
            "technique": "clustering"
        },
        "revision": {
            "type": "semi automated",
            "description": "System executes best-effort operators and lets the user review, correct errors, and adjust tables (e.g., select/union/split/rename) during integration."
        },
        "domain": {
            "domain": "independent",
            "type": "generic web data"
        },
        "validation": {
            "goldStandard": "52-query workload gathered via Amazon Mechanical Turk; relevance judged by two independent annotators",
            "metrics": [
                "Hits@k",
                "Top-k Accuracy"
            ]
        },
        "code": "",
        "license": "Not Specified",
        "inputs": {
            "typeOfTable": "HTML tables and HTML lists",
            "tableSources": [
                "web"
            ]
        },
        "kg": {
            "tripleStore": "",
            "index": ""
        },
        "output": "",
        "applicationPurpose": "Interactive creation and integration of structured Web data sources into new datasets.",
        "userInterfaceTool": "Web UI",
        "checkedByAuthor": false,
        "checkedByAi": true,
        "doi": "https://doi.org/10.14778/1687627.1687750",
        "citations": [
            {
                "ref": "2003_bernstein_applying",
                "title": "Applying Model Management to Classical Meta Data Problems"
            },
            {
                "ref": "1970_bloom_spacetime",
                "title": "Space/Time Trade-offs in Hash Coding with Allowable Errors"
            },
            {
                "ref": "2008_cafarella_uncovering",
                "title": "Uncovering the Relational Web"
            },
            {
                "ref": "2008_cafarella_webtables",
                "title": "WebTables: Exploring the Power of Tables on the Web"
            },
            {
                "ref": "1999_dasilva_a",
                "title": "A Local Maxima Method and a Fair Dispersion Normalization for Extracting Multi-Word Units from Corpora"
            },
            {
                "ref": "2007_derose_building",
                "title": "Building Structured Web Community Portals: A Top-Down, Compositional, and Incremental Approach"
            },
            {
                "ref": "2001_doan_reconciling",
                "title": "Reconciling Schemas of Disparate Data Sources: A Machine-Learning Approach"
            },
            {
                "ref": "2005_dong_reference",
                "title": "Reference Reconciliation in Complex Information Spaces"
            },
            {
                "ref": "2009_elmeleegy_harvesting",
                "title": "Harvesting Relational Tables from Lists on the Web"
            },
            {
                "ref": "2004_etzioni_web",
                "title": "Web-scale Information Extraction in KnowItAll: (Preliminary Results)"
            },
            {
                "ref": "1999_friedman_navigational",
                "title": "Navigational Plans for Data Integration"
            },
            {
                "ref": "2001_galhardas_declarative",
                "title": "Declarative Data Cleaning: Language, Model, and Algorithms"
            },
            {
                "ref": "2008_kok_extracting",
                "title": "Extracting Semantic Networks from Text Via Relational Clustering"
            },
            {
                "ref": "",
                "title": "Microsoft Popfly"
            },
            {
                "ref": "2001_rahm_a",
                "title": "A Survey of Approaches to Automatic Schema Matching"
            },
            {
                "ref": "2001_raman_potters",
                "title": "Potter’s Wheel: An Interactive Data Cleaning System"
            },
            {
                "ref": "2004_sarawagi_semi",
                "title": "Semi-Markov Conditional Random Fields for Information Extraction"
            },
            {
                "ref": "2007_tuchinda_building",
                "title": "Building Data Integration Queries by Demonstration"
            },
            {
                "ref": "2002_turney_mining",
                "title": "Mining the Web for Synonyms: PMI-IR versus LSA on TOEFL"
            },
            {
                "ref": "2007_wong_making",
                "title": "Making Mashups with Marmite: Towards End-User Programming for the Web"
            },
            {
                "ref": "",
                "title": "Yahoo Pipes"
            }
        ],
        "uncertainFields": [
            {
                "field": "doi",
                "reason": "A DOI is not visible in the provided PDF; one may exist in digital libraries."
            },
            {
                "field": "kg.tripleStore",
                "reason": "The system does not rely on a knowledge graph; no triple store is mentioned."
            },
            {
                "field": "output",
                "reason": "The paper does not specify a serialisation format for outputs (e.g., CSV, RDF)."
            },
            {
                "field": "validation.metrics",
                "reason": "Reported results are percentages of relevant tables in top-k; mapped to Hits@k/Top-k Accuracy."
            },
            {
                "field": "userInterfaceTool",
                "reason": "Screenshots suggest an interactive interface; the exact tool type/name is not formally specified."
            }
        ]
    },
    {
        "id": "2009_hignette_fuzzy",
        "added": "",
        "year": 2009,
        "firstAuthor": "Hignette",
        "authors": [
            "Gaëlle Hignette",
            "Patrice Buche",
            "Juliette Dibie-Barthélemy",
            "Ollivier Haemmerlé"
        ],
        "title": "Fuzzy Annotation of Web Data Tables Driven by a Domain Ontology",
        "venue": {
            "type": "conference",
            "acronym": "ESWC"
        },
        "nameOfApproach": "@Web",
        "techniqueTags": [
            "rule-based",
            "ontology-driven"
        ],
        "coreTasks": {
            "cta": true,
            "cpa": true,
            "cea": true,
            "cnea": false
        },
        "supportTasks": {
            "dataPreparation": {
                "description": "Tables are extracted from the Web, stored in a common XML model, and lemmatised/normalised; numeric vs symbolic columns are segregated and units detected before annotation.",
                "spellChecker": "",
                "unitsOfMeasurements": "Ontology defines allowed units and numeric ranges (e.g., °C/°F for Temperature) used to filter and score numeric columns."
            },
            "columnClassification": "Distinguishes numeric vs symbolic columns using ontology units; classifies symbolic columns to ontology symbolic types via cosine similarity over titles and cell contents.",
            "subjectDetection": "",
            "datatypeAnnotation": "Assigns numeric columns to ontology numeric types using units and value-range constraints; builds fuzzy sets (e.g., intervals, mean±SE).",
            "typeAnnotation": "Assigns symbolic columns to ontology symbolic types by combining title/content similarity and taxonomy matches.",
            "predicateAnnotation": "Recognises relations by comparing the table's typed-column signature to n-ary relation signatures in the ontology and combining with title similarity.",
            "nilAnnotation": "",
            "entityLinking": {
                "description": "Links cells to ontology taxonomy terms using cosine similarity and proportional-advantage thresholds; keeps fuzzy membership over multiple candidates.",
                "candidateGeneration": "Lookup against all terms in the relevant type's taxonomy derived from the ontology.",
                "entityDisambiguation": "Selects best type per cell if advantage over second-best exceeds a threshold; retains a fuzzy set of candidates with membership scores."
            }
        },
        "mainMethod": {
            "type": "unsupervised",
            "technique": "rule-based"
        },
        "revision": {
            "type": "fully automated",
            "description": "Annotation pipeline runs automatically; fuzzy memberships enable optional later human validation without changing the core outputs."
        },
        "domain": {
            "domain": "dependent",
            "type": "food microbiology; chemical risk in food; aeronautics"
        },
        "validation": {
            "goldStandard": "Manually annotated scientific tables (e.g., 60 tables with 123 relations; additional corpora and column-level evaluations).",
            "metrics": [
                "Precision",
                "Recall"
            ]
        },
        "code": "",
        "license": "Not Specified",
        "inputs": {
            "typeOfTable": "Web tables",
            "tableSources": [
                "web",
                "pdf",
                "scientific"
            ]
        },
        "kg": {
            "tripleStore": "",
            "index": ""
        },
        "output": "RDF",
        "applicationPurpose": "Data enrichment and integration into the MIEL querying ecosystem.",
        "userInterfaceTool": "@Web",
        "checkedByAuthor": false,
        "checkedByAi": true,
        "doi": "https://doi.org/10.1007/978-3-642-02121-3_47",
        "citations": [
            {
                "ref": "2001_rahm_a",
                "title": "A survey of approaches to automatic schema matching"
            },
            {
                "ref": "2008_buche_flexible",
                "title": "Flexible querying of fuzzy rdf annotations using fuzzy conceptual graphs"
            },
            {
                "ref": "2003_doan_learning",
                "title": "Learning to match the schemas of data sources: A multistrategy approach"
            },
            {
                "ref": "2007_liu_tableseer",
                "title": "Tableseer: automatic table metadata extraction and searching in digital libraries"
            },
            {
                "ref": "2008_cafarella_uncovering",
                "title": "Uncovering the relational web"
            },
            {
                "ref": "2008_cafarella_webtables",
                "title": "Webtables: exploring the power of tables on the web"
            },
            {
                "ref": "2004_pivk_from",
                "title": "From tables to frames"
            },
            {
                "ref": "2006_tenier_instantiation",
                "title": "Instantiation of relations for semantic annotation"
            },
            {
                "ref": "2002_embley_automatically",
                "title": "Automatically extracting ontologically specified data from HTML tables of unknown structure"
            },
            {
                "ref": "2006_noy_defining",
                "title": "Defining n-ary relations on the semantic web"
            },
            {
                "ref": "2007_hignette_an",
                "title": "An ontology-driven annotation of data tables"
            },
            {
                "ref": "1979_vanrijsbergen_information",
                "title": "Information Retrieval (2nd ed.)"
            },
            {
                "ref": "1999_platt_fast",
                "title": "Fast training of support vector machines using sequential minimal optimization"
            },
            {
                "ref": "2005_gagliardi_an",
                "title": "An automatic ontology-based approach to enrich tables semantically"
            },
            {
                "ref": "1965_zadeh_fuzzy",
                "title": "Fuzzy sets"
            },
            {
                "ref": "1978_zadeh_fuzzy",
                "title": "Fuzzy sets as a basis for a theory of possibility"
            },
            {
                "ref": "1997_dubois_the",
                "title": "The three semantics of fuzzy sets"
            },
            {
                "ref": "2004_cliver_foodborne",
                "title": "Foodborne infections and intoxications"
            }
        ],
        "uncertainFields": [
            {
                "field": "nameOfApproach",
                "reason": "The annotation component is implemented within the @Web software, while MIEL is the querying system; the paper does not brand the annotator separately."
            },
            {
                "field": "coreTasks.cea",
                "reason": "Cell-level linking is to ontology taxonomy terms rather than to a public KG; mapping to CEA is inferred from description rather than explicit task naming."
            },
            {
                "field": "inputs.tableSources[1]",
                "reason": "Tables are said to come from publications and the Web; PDFs are likely but not always explicitly stated for every corpus."
            },
            {
                "field": "kg.tripleStore",
                "reason": "An OWL domain ontology is used, but no specific triple store or public KG (e.g., DBpedia) is named."
            },
            {
                "field": "userInterfaceTool",
                "reason": "@Web is a software platform; the existence of a dedicated end-user GUI for annotation is implied but not detailed."
            },
            {
                "field": "doi",
                "reason": "The DOI is not provided in the paper text available; leaving it empty to avoid inventing information."
            }
        ]
    },
    {
        "id": "2009_tao_automatic",
        "added": "",
        "year": 2009,
        "firstAuthor": "Tao",
        "authors": [
            "Cui Tao",
            "David W. Embley"
        ],
        "title": "Automatic hidden-web table interpretation, conceptualization, and semantic annotation",
        "venue": {
            "type": "journal",
            "acronym": "DKE"
        },
        "nameOfApproach": "TISP++ (built on TISP)",
        "techniqueTags": [
            "rule-based",
            "ontology-driven"
        ],
        "coreTasks": {
            "cta": false,
            "cpa": false,
            "cea": false,
            "cnea": false
        },
        "supportTasks": {
            "dataPreparation": {
                "description": "Parses HTML, unnests nested tables, filters layout tables, and derives structure patterns via sibling-page comparison. ",
                "spellChecker": "",
                "unitsOfMeasurements": ""
            },
            "columnClassification": "",
            "subjectDetection": "",
            "datatypeAnnotation": "Generates OWL datatype properties for labels and records and annotates values accordingly. ",
            "typeAnnotation": "",
            "predicateAnnotation": "",
            "nilAnnotation": "",
            "entityLinking": {
                "description": "",
                "candidateGeneration": "",
                "entityDisambiguation": ""
            }
        },
        "mainMethod": {
            "type": "unsupervised",
            "technique": "rule-based"
        },
        "revision": {
            "type": "fully automated",
            "description": "Fully automatic pipeline with dynamic pattern adjustment when encountering structural variations; no user-in-the-loop. "
        },
        "domain": {
            "domain": "independent",
            "type": "generic"
        },
        "validation": {
            "goldStandard": "Evaluated on >2000 tables from 275 sibling pages across 35 websites (car ads, molecular biology, geopolitical); overall F-measure for interpretation 94.5%. ",
            "metrics": [
                "Precision",
                "Recall",
                "F1"
            ]
        },
        "code": "",
        "license": "Not Specified",
        "inputs": {
            "typeOfTable": "HTML tables",
            "tableSources": [
                "web",
                "scientific",
                "gov-open-data"
            ]
        },
        "kg": {
            "tripleStore": "Generated OWL ontology queried via a SPARQL-capable store (implemented with Jena). ",
            "index": ""
        },
        "output": "RDF",
        "applicationPurpose": "Make hidden-web table data interpretable, semantically annotated, and queriable via standard SPARQL engines. ",
        "userInterfaceTool": "SPARQL query interface with source-page value highlighting",
        "checkedByAuthor": false,
        "checkedByAi": true,
        "doi": "https://doi.org/10.1016/j.datak.2009.02.010",
        "citations": [
            {
                "ref": "2003_arasu_extracting",
                "title": "Extracting structured data from web pages"
            },
            {
                "ref": "crescenz i2001roadrunner",
                "title": "RoadRunner: towards automatic data extraction from large web sites"
            },
            {
                "ref": "2005_zhai_web",
                "title": "Web data extraction based on partial tree alignment"
            },
            {
                "ref": "1979_tai_the",
                "title": "The tree-to-tree correction problem"
            },
            {
                "ref": "1991_yang_identifying",
                "title": "Identifying syntactic differences between two programs"
            },
            {
                "ref": "1996_wang_tabular",
                "title": "Tabular Abstraction, Editing, and Formatting"
            },
            {
                "ref": "2007_gatterbauer_towards",
                "title": "Towards domain-independent information extraction from web tables"
            },
            {
                "ref": "2002_cohen_a",
                "title": "A flexible learning system for wrapping tables and lists in HTML documents"
            },
            {
                "ref": "2004_lerman_using",
                "title": "Using the structure of web sites for automatic segmentation of tables"
            },
            {
                "ref": "2004_tengli_learning",
                "title": "Learning table extraction from examples"
            },
            {
                "ref": "2004_pivk_from",
                "title": "From tables to frames"
            },
            {
                "ref": "2006_embley_table",
                "title": "Table processing paradigms: a research survey"
            },
            {
                "ref": "2002_embley_automatically",
                "title": "Automatically extracting ontologically specified data from HTML tables with unknown structure"
            },
            {
                "ref": "2005_embley_automating",
                "title": "Automating the extraction of data from HTML tables with unknown structure"
            },
            {
                "ref": "2000_chen_mining",
                "title": "Mining tables from large scale HTML texts"
            },
            {
                "ref": "2006_gatterbauer_table",
                "title": "Table extraction using spatial reasoning on the CSS2 visual box model"
            }
        ],
        "uncertainFields": [
            {
                "field": "nameOfApproach",
                "reason": "Paper introduces both TISP and its extension TISP++; opted to name TISP++ as the approach encompassing ontology and annotation."
            },
            {
                "field": "techniqueTags",
                "reason": "No ML models (SVM/CRF/transformer) are used; classification as rule-based/ontology-driven inferred from pattern rules and OWL generation."
            },
            {
                "field": "coreTasks.cta",
                "reason": "CTA as later formalised is not explicitly targeted; interpretation/annotation are ontology-specific rather than KG class prediction."
            },
            {
                "field": "coreTasks.cpa",
                "reason": "Relationships are represented in the generated ontology but not framed as CPA over an external KG."
            },
            {
                "field": "coreTasks.cea",
                "reason": "Annotations link to a generated ontology rather than disambiguating against a public KG; mapping to CEA is unclear."
            },
            {
                "field": "kg.tripleStore",
                "reason": "They use Jena to output OWL and query via SPARQL, but no specific triple store (e.g., Virtuoso) is named."
            },
            {
                "field": "userInterfaceTool",
                "reason": "A query UI with highlighting is described but not formally named."
            },
            {
                "field": "inputs.tableSources[1]",
                "reason": "‘scientific’ added based on WormBase/NCBI examples; not enumerated explicitly as a source type by the authors."
            },
            {
                "field": "inputs.tableSources[2]",
                "reason": "‘gov-open-data’ added based on CIA Factbook/USGS examples; inferred rather than explicitly categorised."
            },
            {
                "field": "venue.acronym",
                "reason": "Acronym ‘DKE’ assumed for Data & Knowledge Engineering; not explicitly printed as an acronym in the paper."
            }
        ]
    },
    {
        "id": "2010_limaye_annotating",
        "added": "",
        "year": 2010,
        "firstAuthor": "Limaye",
        "authors": [
            "Girija Limaye",
            "Sunita Sarawagi",
            "Soumen Chakrabarti"
        ],
        "title": "Annotating and Searching Web Tables Using Entities, Types and Relationships",
        "venue": {
            "type": "journal",
            "acronym": "PVLDB"
        },
        "nameOfApproach": "",
        "techniqueTags": [
            "SVM",
            "ontology-driven"
        ],
        "coreTasks": {
            "cta": true,
            "cpa": true,
            "cea": true,
            "cnea": false
        },
        "supportTasks": {
            "dataPreparation": {
                "description": "Screen out formatting tables, capture table context and headers, and build text/lemma indices to propose candidates.",
                "spellChecker": "",
                "unitsOfMeasurements": ""
            },
            "columnClassification": "",
            "subjectDetection": "",
            "datatypeAnnotation": "",
            "typeAnnotation": "Assign KG types to columns using features over headers and collective signals.",
            "predicateAnnotation": "Assign KG relations to column pairs using compatibility between types and entity pairs.",
            "nilAnnotation": "",
            "entityLinking": {
                "description": "Link cells to KG entities using candidate lookup and collective disambiguation.",
                "candidateGeneration": "Retrieve candidates via text similarity between cell strings and entity lemmas using a text index.",
                "entityDisambiguation": "Joint probabilistic graphical model with message passing over entities, types, and relations."
            }
        },
        "mainMethod": {
            "type": "supervised",
            "technique": "SVM",
            "supervision": {
                "type": "supervised"
            }
        },
        "revision": {
            "type": "fully automated",
            "description": "Annotations are produced automatically by the trained model without manual post-editing."
        },
        "domain": {
            "domain": "independent",
            "type": "generic"
        },
        "validation": {
            "goldStandard": "Manual labels for Wiki Manual (36 tables), Web Manual (371 tables) and Web Relations; Wiki Link with 131k linked cells; catalog-derived ground truth from YAGO/DBpedia.",
            "metrics": [
                "Accuracy",
                "F1",
                "MAP"
            ]
        },
        "code": "",
        "license": "Not Specified",
        "inputs": {
            "typeOfTable": "Web tables",
            "tableSources": [
                "web",
                "wiki"
            ]
        },
        "kg": {
            "tripleStore": "YAGO; DBpedia",
            "index": "Lemma/text index (Lucene) for candidate retrieval"
        },
        "output": "",
        "applicationPurpose": "Relational Web search over annotated tables (select-project/join queries).",
        "userInterfaceTool": "Prototype relational Web search tool",
        "checkedByAuthor": false,
        "checkedByAi": true,
        "doi": "https://doi.org/10.14778/1920841.1921005",
        "citations": [
            {
                "ref": "2008_cafarella_webtables",
                "title": "WebTables: exploring the power of tables on the Web"
            },
            {
                "ref": "2008_cafarella_uncovering",
                "title": "Uncovering the relational Web"
            },
            {
                "ref": "2007_suchanek_yago",
                "title": "YAGO: A core of semantic knowledge unifying WordNet and Wikipedia"
            },
            {
                "ref": "2007_cucerzan_large",
                "title": "Large-scale named entity disambiguation based on Wikipedia data"
            },
            {
                "ref": "2008_milne_learning",
                "title": "Learning to link with Wikipedia"
            },
            {
                "ref": "2009_kulkarni_collective",
                "title": "Collective annotation of Wikipedia entities in Web text"
            },
            {
                "ref": "2009_gupta_answering",
                "title": "Answering table augmentation queries from unstructured lists on the Web"
            },
            {
                "ref": "2009_singh_curating",
                "title": "Curating and searching the annotated web"
            },
            {
                "ref": "2009_koller_probabilistic",
                "title": "Probabilistic Graphical Models: Principles and Techniques"
            },
            {
                "ref": "1983_salton_introduction",
                "title": "Introduction to Modern Information Retrieval"
            },
            {
                "ref": "2008_sarawagi_information",
                "title": "Information extraction"
            },
            {
                "ref": "2005_tsochantaridis_large",
                "title": "Large margin methods for structured and interdependent output variables"
            },
            {
                "ref": "2003_dill_semtag",
                "title": "SemTag and Seeker: Bootstrapping the semantic Web via automated semantic annotation"
            }
        ],
        "uncertainFields": [
            {
                "field": "venue.type",
                "reason": "The article appears in PVLDB (a journal) but is also presented at VLDB 2010; some bibliographies list it as a conference paper."
            },
            {
                "field": "venue.acronym",
                "reason": "Could be recorded as VLDB(conference) or PVLDB (journal); chosen PVLDB."
            },
            {
                "field": "kg.tripleStore",
                "reason": "Paper uses YAGO as the main catalog and also leverages DBpedia/Wikipedia; field expects a single store name."
            },
            {
                "field": "userInterfaceTool",
                "reason": "A prototype relational Web search tool is described but not formally named."
            },
            {
                "field": "output",
                "reason": "No explicit export format (e.g., RDF/CSV) is specified; outputs are annotations used for search."
            },
            {
                "field": "techniqueTags[1]",
                "reason": "Marked as ontology-driven because it leverages a catalog (YAGO/DBpedia); the paper does not explicitly use this label."
            },
            {
                "field": "inputs.tableSources[1]",
                "reason": "Wikipedia tables are used for training/evaluation; treating this as a separate source (wiki) may be seen as a subset of web."
            },
            {
                "field": "applicationPurpose",
                "reason": "Summarised from the search application section; phrasing may vary."
            }
        ]
    },
    {
        "id": "2010_mulwad_t2ld",
        "added": "",
        "year": 2010,
        "firstAuthor": "Mulwad",
        "authors": [
            "Varish Mulwad",
            "Tim Finin",
            "Zareen Syed",
            "Anupam Joshi"
        ],
        "title": "T2LD: Interpreting and Representing Tables as Linked Data?",
        "venue": {
            "type": "conference",
            "acronym": "ISWC"
        },
        "nameOfApproach": "T2LD",
        "techniqueTags": [
            "SVM",
            "ontology-driven"
        ],
        "coreTasks": {
            "cta": true,
            "cpa": true,
            "cea": true,
            "cnea": true
        },
        "supportTasks": {
            "dataPreparation": {
                "description": "Queries KBs with headers and cell strings and computes ranking features (e.g., PageRank, page length, and string similarities). Basic normalisation of strings is implied by lookup and feature computation.",
                "spellChecker": "",
                "unitsOfMeasurements": ""
            },
            "columnClassification": "Assigns a KG class label to each column via KB queries and scoring.",
            "subjectDetection": "",
            "datatypeAnnotation": "",
            "typeAnnotation": "Predicts KG class labels for columns (CTA) using DBpedia/Freebase/WordNet/YAGO evidence.",
            "predicateAnnotation": "Selects relations between column pairs from KB-derived candidates using a scoring procedure.",
            "nilAnnotation": "Flags cells as NIL/new entities when confidence is low, enabling discovery of entities absent from the KG.",
            "entityLinking": {
                "description": "Links cell strings to KG entities using a two-stage SVM pipeline.",
                "candidateGeneration": "Retrieves top-N entity candidates from KB lookups using header/context-enhanced queries.",
                "entityDisambiguation": "Ranks candidates with SVM-Rank using KB score, page length, PageRank, Levenshtein and Dice; a second SVM accepts/rejects based on rank score and margin."
            }
        },
        "mainMethod": {
            "type": "supervised",
            "technique": "SVM",
            "supervision": {
                "type": "supervised"
            }
        },
        "revision": {
            "type": "fully automated",
            "description": "Annotations are produced automatically; human judgements are used only for offline evaluation."
        },
        "domain": {
            "domain": "independent",
            "type": "generic"
        },
        "validation": {
            "goldStandard": "15 tables (52 columns, 611 entities) from Google Squared, Wikipedia and the Web; 23 columns used for relation evaluation.",
            "metrics": [
                "MAP",
                "Recall",
                "Accuracy"
            ]
        },
        "code": "",
        "license": "Not Specified",
        "inputs": {
            "typeOfTable": "HTML tables",
            "tableSources": [
                "web",
                "wiki"
            ]
        },
        "kg": {
            "tripleStore": "DBpedia",
            "index": ""
        },
        "output": "RDF (N3)",
        "applicationPurpose": "Generate linked data from tables and enrich/extend KGs.",
        "userInterfaceTool": "",
        "checkedByAuthor": false,
        "checkedByAi": true,
        "doi": "",
        "citations": [
            {
                "ref": "2010_finin_creating",
                "title": "Creating and Exploiting a Web of Semantic Data"
            },
            {
                "ref": "2008_cafarella_webtables",
                "title": "Webtables: exploring the power of tables on the web"
            },
            {
                "ref": "2010_mulwad_t2ld",
                "title": "T2LD - An automatic framework for extracting, interpreting and representing tables as Linked Data"
            },
            {
                "ref": "2009_sahoo_a",
                "title": "A survey of current approaches for mapping of relational databases to rdf"
            },
            {
                "ref": "2008_han_rdf123",
                "title": "RDF123: from Spreadsheets to RDF"
            },
            {
                "ref": "2010_syed_exploiting",
                "title": "Exploiting a Web of Semantic Data for Interpreting Tables"
            },
            {
                "ref": "2010_mulwad_using",
                "title": "Using linked data to interpret tables"
            }
        ],
        "uncertainFields": [
            {
                "field": "venue.acronym",
                "reason": "The paper appears in the ISWC 2010 Posters/Demos track; using 'ISWC' may omit the track specificity."
            },
            {
                "field": "doi",
                "reason": "No DOI is visible; CEUR-WS poster/demo papers often lack DOIs."
            },
            {
                "field": "kg.tripleStore",
                "reason": "DBpedia is used, but additional KBs (e.g., Wikitology, Freebase, YAGO) support typing; the primary store is not explicitly singled out."
            },
            {
                "field": "inputs.typeOfTable",
                "reason": "Evaluation uses web/Wikipedia tables; broader claims reference spreadsheets and databases, which may not be in-scope for the prototype."
            },
            {
                "field": "supportTasks.columnClassification",
                "reason": "The method assigns KG class labels to columns; it is unclear whether it also performs NE vs literal column detection as a separate step."
            },
            {
                "field": "userInterfaceTool",
                "reason": "A prototype is mentioned but no explicit UI or CLI is described."
            },
            {
                "field": "validation.goldStandard",
                "reason": "The evaluation uses a small curated set of tables rather than a named public gold standard."
            }
        ]
    },
    {
        "id": "2010_syed_exploiting",
        "added": "",
        "year": 2010,
        "firstAuthor": "Syed",
        "authors": [
            "Zareen Syed",
            "Tim Finin",
            "Varish Mulwad",
            "Anupam Joshi"
        ],
        "title": "Exploiting a Web of Semantic Data for Interpreting Tables",
        "venue": {
            "type": "conference",
            "acronym": "WebSci"
        },
        "nameOfApproach": "Wikitology",
        "techniqueTags": [
            "ontology-driven"
        ],
        "coreTasks": {
            "cta": true,
            "cpa": true,
            "cea": true,
            "cnea": false
        },
        "supportTasks": {
            "dataPreparation": {
                "description": "",
                "spellChecker": "",
                "unitsOfMeasurements": ""
            },
            "columnClassification": "",
            "subjectDetection": "",
            "datatypeAnnotation": "",
            "typeAnnotation": "Predicts column classes by voting over types returned from Wikitology/DBpedia using headers and cell values.",
            "predicateAnnotation": "Enumerates DBpedia relations between linked entity pairs across columns and selects the most frequent relation.",
            "nilAnnotation": "",
            "entityLinking": {
                "description": "Generates top-N candidates from Wikitology for each cell and re-ranks using predicted types.",
                "candidateGeneration": "Queries Wikitology IR index fields (title, redirects, firstSentence, linkedConcepts, propertiesValues) to retrieve candidates.",
                "entityDisambiguation": "Constrains candidates by predicted types and selects the highest-scoring match."
            }
        },
        "mainMethod": {
            "type": "unsupervised",
            "technique": "ontology-driven"
        },
        "revision": {
            "type": "fully automated",
            "description": "Prototype runs automatically without human-in-the-loop validation."
        },
        "domain": {
            "domain": "independent",
            "type": ""
        },
        "validation": {
            "goldStandard": "5 tables from Google Squared",
            "metrics": [
                "Accuracy"
            ]
        },
        "code": "",
        "license": "Not Specified",
        "inputs": {
            "typeOfTable": "Web tables",
            "tableSources": [
                "web"
            ]
        },
        "kg": {
            "tripleStore": "DBpedia; Wikitology",
            "index": "Wikitology IR index over Wikipedia/DBpedia (title, redirects, firstSentence, types, linkedConcepts, propertiesValues)"
        },
        "output": "RDF",
        "applicationPurpose": "Interpret web tables and export them as linked data.",
        "userInterfaceTool": "",
        "checkedByAuthor": false,
        "checkedByAi": true,
        "doi": "https://doi.org/10.1145/1935826.1935904",
        "citations": [],
        "uncertainFields": [
            {
                "field": "venue.acronym",
                "reason": "Acronym is not explicitly printed in the PDF; assumed to be WebSci for the Web Science Conference."
            },
            {
                "field": "doi",
                "reason": "No DOI is shown in the paper; left empty as it may not exist for this venue/year."
            },
            {
                "field": "kg.tripleStore",
                "reason": "Paper uses Wikitology (hybrid KB) and queries DBpedia relations; listing both may conflate KB and triple store."
            },
            {
                "field": "supportTasks.typeAnnotation",
                "reason": "They predict classes for columns, which aligns with CTA; exact procedure naming may differ from later STI task taxonomies."
            },
            {
                "field": "supportTasks.predicateAnnotation",
                "reason": "Relation selection is described heuristically; mapping it directly to CPA may oversimplify their approach."
            },
            {
                "field": "revision.type",
                "reason": "No explicit statement about user-in-the-loop post-processing; assumed fully automated based on prototype description."
            }
        ]
    },
    {
        "id": "2011_crestan_web-scale",
        "added": "",
        "year": 2011,
        "firstAuthor": "Crestan",
        "authors": [
            "Eric Crestan",
            "Patrick Pantel"
        ],
        "title": "Web-Scale Table Census and Classification",
        "venue": {
            "type": "conference",
            "acronym": "WSDM"
        },
        "nameOfApproach": "TabEx",
        "techniqueTags": [],
        "coreTasks": {
            "cta": false,
            "cpa": false,
            "cea": false,
            "cnea": false
        },
        "supportTasks": {
            "dataPreparation": {
                "description": "",
                "spellChecker": "",
                "unitsOfMeasurements": ""
            },
            "columnClassification": "",
            "subjectDetection": "",
            "datatypeAnnotation": "",
            "typeAnnotation": "",
            "predicateAnnotation": "",
            "nilAnnotation": "",
            "entityLinking": {
                "description": "",
                "candidateGeneration": "",
                "entityDisambiguation": ""
            }
        },
        "mainMethod": {
            "type": "supervised",
            "technique": "Gradient Boosted Decision Trees (GBDT)",
            "supervision": {
                "type": "supervised"
            }
        },
        "revision": {
            "type": "fully automated",
            "description": "Classification is fully automatic with evaluation on manually annotated samples; no user post-editing described."
        },
        "domain": {
            "domain": "independent",
            "type": ""
        },
        "validation": {
            "goldStandard": "Manually annotated random samples of web tables (e.g., 5,000 tables) used as gold data.",
            "metrics": [
                "Accuracy",
                "Precision",
                "Recall",
                "F1"
            ]
        },
        "code": "",
        "license": "Not Specified",
        "inputs": {
            "typeOfTable": "HTML tables",
            "tableSources": [
                "web"
            ]
        },
        "output": "",
        "applicationPurpose": "Classify HTML tables by type to support knowledge extraction.",
        "userInterfaceTool": "",
        "checkedByAuthor": false,
        "checkedByAi": true,
        "doi": "",
        "citations": [
            {
                "ref": "2008_cafarella_webtables",
                "title": "WebTables: Exploring the Power of Tables on the Web"
            },
            {
                "ref": "2008_cafarella_uncovering",
                "title": "Uncovering the Relational Web"
            },
            {
                "ref": "2009_chang_towards",
                "title": "Towards intent-driven bidterm suggestion"
            },
            {
                "ref": "2000_chen_mining",
                "title": "Mining Tables from Large-Scale HTML Texts"
            },
            {
                "ref": "2009_elmeleegy_harvesting",
                "title": "Harvesting Relational Tables from Lists on the Web"
            },
            {
                "ref": "2006_gazen_overview",
                "title": "Overview of Autofeed: An Unsupervised Learning System for Generating Webfeeds"
            },
            {
                "ref": "2008_huanhuan_context",
                "title": "Context-aware query suggestion by mining click-through and session data"
            },
            {
                "ref": "2001_friedman_greedy",
                "title": "Greedy function approximation: A gradient boosting machine"
            },
            {
                "ref": "2006_friedman_recent",
                "title": "Recent advances in predictive (machine) learning"
            },
            {
                "ref": "2007_gatterbauer_towards",
                "title": "Towards Domain-Independent Information Extraction from Web Tables"
            },
            {
                "ref": "2003_lin_identifying",
                "title": "Identifying Synonyms among Distributionally Similar Words"
            },
            {
                "ref": "2001_penn_flexible",
                "title": "Flexible Web Document Analysis for Delivery to Narrow-Bandwidth Devices"
            },
            {
                "ref": "2002_wang_a",
                "title": "A Machine Learning Based Approach for Table Detection on the Web"
            },
            {
                "ref": "2001_yoshida_a",
                "title": "A Method to Integrate Tables of the World Wide Web"
            }
        ],
        "uncertainFields": [
            {
                "field": "techniqueTags",
                "reason": "The approach uses GBDT, which is not among the allowed tags; therefore the list is left empty."
            },
            {
                "field": "output",
                "reason": "The paper does not specify any output serialisation format for results."
            },
            {
                "field": "userInterfaceTool",
                "reason": "No user interface or tool is described."
            },
            {
                "field": "code",
                "reason": "No code repository or download link is provided."
            },
            {
                "field": "domain.type",
                "reason": "The method is domain-independent; per schema this may be empty."
            },
            {
                "field": "validation.goldStandard",
                "reason": "They use manually annotated samples but no named gold standard; the description summarises this."
            },
            {
                "field": "doi",
                "reason": "The DOI is not stated in the provided text; left empty to avoid invention."
            },
            {
                "field": "citations[6].ref",
                "reason": "First author appears as \"Huanhuan, J. H.\" in the reference text, which may reflect formatting/ordering issues."
            }
        ]
    },
    {
        "id": "2011_mulwad_automatically",
        "added": "",
        "year": 2011,
        "firstAuthor": "Mulwad",
        "authors": [
            "Varish Mulwad",
            "Tim Finin",
            "Anupam Joshi"
        ],
        "title": "Automatically Generating Government Linked Data from Tables",
        "venue": {
            "type": "conference",
            "acronym": "AAAI"
        },
        "nameOfApproach": "",
        "techniqueTags": [
            "SVM",
            "ontology-driven"
        ],
        "coreTasks": {
            "cta": true,
            "cpa": true,
            "cea": true,
            "cnea": true
        },
        "supportTasks": {
            "dataPreparation": {
                "description": "Discusses using captions/surrounding text and handling literals as additional evidence; details are limited.",
                "spellChecker": "",
                "unitsOfMeasurements": "Mentions extracting/using units information from captions or surrounding text."
            },
            "columnClassification": "",
            "subjectDetection": "",
            "datatypeAnnotation": "Maps literal columns (e.g., FIPS codes) to properties associated with related entities.",
            "typeAnnotation": "Maps column headers to ontology classes (e.g., DBpedia/Freebase/WordNet/YAGO).",
            "predicateAnnotation": "Discovers relations between columns via majority voting over relations observed in DBpedia.",
            "nilAnnotation": "Identifies cells that refer to entities not in the KB (NIL/new entities).",
            "entityLinking": {
                "description": "Two-stage linking: candidate retrieval from Wikitology, then SVM-based ranking and decision to link or mark as new.",
                "candidateGeneration": "Wikitology queries return top-N candidate entities per cell.",
                "entityDisambiguation": "SVM-Rank with features (KB score, page length, PageRank, Levenshtein, Dice), followed by an SVM classifier to accept/reject the top candidate."
            }
        },
        "mainMethod": {
            "type": "supervised",
            "technique": "SVM",
            "supervision": {
                "type": "supervised"
            }
        },
        "revision": {
            "type": "fully automated",
            "description": "Automatic pipeline; a human-in-the-loop is proposed as a potential enhancement but not required."
        },
        "domain": {
            "domain": "dependent",
            "type": "open government data"
        },
        "validation": {
            "goldStandard": "15 tables from Google Squared, Wikipedia and the Web; examples from data.gov dataset 1425",
            "metrics": [
                "MAP",
                "Recall",
                "Accuracy"
            ]
        },
        "code": "",
        "license": "Not Specified",
        "inputs": {
            "typeOfTable": "Web tables",
            "tableSources": [
                "gov-open-data",
                "web",
                "wiki"
            ]
        },
        "kg": {
            "tripleStore": "DBpedia",
            "index": "Wikitology"
        },
        "output": "RDF",
        "applicationPurpose": "Generate high-quality Linked Data from tabular open government datasets.",
        "userInterfaceTool": "",
        "checkedByAuthor": false,
        "checkedByAi": true,
        "doi": "",
        "citations": [
            {
                "ref": "2009_bizer_dbpedia",
                "title": "Dbpedia - a crystallization point for the web of data"
            },
            {
                "ref": "2009_bizer_the",
                "title": "The emerging web of linked data"
            },
            {
                "ref": "2004_brickley_rdf",
                "title": "RDF Vocabulary Description Language 1.0: RDF Schema"
            },
            {
                "ref": "2008_cafarella_webtables",
                "title": "WebTables: exploring the power of tables on the web"
            },
            {
                "ref": "",
                "title": "Dataset 1425 - Census of Agriculture Race, Ethnicity and Gender Profile Data"
            },
            {
                "ref": "2010_ding_twc",
                "title": "TWC Data-Gov Corpus: incrementally generating linked government data from data.gov"
            },
            {
                "ref": "2008_han_rdf123",
                "title": "RDF123: from Spreadsheets to RDF"
            },
            {
                "ref": "2009_koller_probabilistic",
                "title": "Probabilistic Graphical Models: Principles and Techniques"
            },
            {
                "ref": "2009_langegger_xlwrap",
                "title": "XLWrap - querying and integrating arbitrary spreadsheets with SPARQL"
            },
            {
                "ref": "2010_limaye_annotating",
                "title": "Annotating and searching web tables using entities, types and relationships"
            },
            {
                "ref": "2010_mulwad_t2ld",
                "title": "T2LD: Interpreting and Representing Tables as Linked Data"
            },
            {
                "ref": "2010_mulwad_using",
                "title": "Using linked data to interpret tables"
            },
            {
                "ref": "1996_sackett_evidence",
                "title": "Evidence based medicine: what it is and what it isn't"
            },
            {
                "ref": "2009_sahoo_a",
                "title": "A survey of current approaches for mapping of relational databases to RDF"
            },
            {
                "ref": "2011_syed_creating",
                "title": "Creating and Exploiting a Hybrid Knowledge Base for Linked Data"
            },
            {
                "ref": "2010_syed_exploiting",
                "title": "Exploiting a Web of Semantic Data for Interpreting Tables"
            },
            {
                "ref": "2011_venetis_recovering",
                "title": "Recovering semantics of tables on the web"
            },
            {
                "ref": "2011_wang_understanding",
                "title": "Understanding tables on the web"
            },
            {
                "ref": "2011_wu_towards",
                "title": "Towards a probabilistic taxonomy of many concepts"
            }
        ],
        "uncertainFields": [
            {
                "field": "venue.acronym",
                "reason": "PDF credits AAAI but does not state a specific venue edition; 'AAAI' acronym assumed."
            },
            {
                "field": "domain.domain",
                "reason": "Work is motivated by open government data but also evaluated on generic Web/Wikipedia tables; could be independent."
            },
            {
                "field": "supportTasks.datatypeAnnotation",
                "reason": "Paper maps literal columns to properties; explicit datatype typing (e.g., XSD) is not fully specified."
            },
            {
                "field": "inputs.tableSources",
                "reason": "Sources selected from examples in the text; exact evaluation mix may vary."
            },
            {
                "field": "nameOfApproach",
                "reason": "Related work references T2LD, but this paper does not clearly name the presented system."
            },
            {
                "field": "kg.index",
                "reason": "Wikitology is used for candidate generation; treated here as the indexing layer."
            },
            {
                "field": "validation.goldStandard",
                "reason": "Evaluation uses a small custom set of tables rather than a named gold standard."
            },
            {
                "field": "doi",
                "reason": "No DOI is provided in the paper/PDF."
            }
        ]
    },
    {
        "id": "2011_venetis_recovering",
        "added": "",
        "year": 2011,
        "firstAuthor": "Venetis",
        "authors": [
            "Petros Venetis",
            "Alon Halevy",
            "Jayant Madhavan",
            "Marius Paşca",
            "Warren Shen",
            "Fei Wu",
            "Gengxin Miao",
            "Chung Wu"
        ],
        "title": "Recovering Semantics of Tables on the Web",
        "venue": {
            "type": "journal",
            "acronym": "PVLDB"
        },
        "nameOfApproach": "",
        "techniqueTags": [
            "rule-based",
            "SVM",
            "CRF"
        ],
        "coreTasks": {
            "cta": true,
            "cpa": true,
            "cea": false,
            "cnea": false
        },
        "supportTasks": {
            "dataPreparation": {
                "description": "Extract and filter HTML tables from the Web; identify subject columns before annotation.",
                "spellChecker": "",
                "unitsOfMeasurements": ""
            },
            "columnClassification": "",
            "subjectDetection": "Subject column identified via a left-to-right heuristic and an SVM classifier.",
            "datatypeAnnotation": "",
            "typeAnnotation": "Assign class labels to columns using a Web-extracted isA database and a likelihood model.",
            "predicateAnnotation": "Assign relation labels between column pairs using Open Information Extraction over Web text.",
            "nilAnnotation": "",
            "entityLinking": {
                "description": "",
                "candidateGeneration": "",
                "entityDisambiguation": ""
            }
        },
        "mainMethod": {
            "type": "hybrid",
            "technique": "rule-based + CRF + SVM"
        },
        "revision": {
            "type": "fully automated",
            "description": "Automatic labelling based on probabilistic evidence thresholds; no human-in-the-loop correction."
        },
        "domain": {
            "domain": "independent",
            "type": "general"
        },
        "validation": {
            "goldStandard": "Manual gold standard of 168 tables; large-scale corpus of ~12.3M HTML tables and a user study on 100 class–property queries.",
            "metrics": [
                "Precision",
                "Recall"
            ]
        },
        "code": "",
        "license": "Not Specified",
        "inputs": {
            "typeOfTable": "HTML tables",
            "tableSources": [
                "web"
            ]
        },
        "output": "",
        "applicationPurpose": "Improve table search and find related tables by recovering column types and inter-column relations.",
        "userInterfaceTool": "",
        "checkedByAuthor": false,
        "checkedByAi": true,
        "doi": "https://doi.org/10.14778/2002938.2002939",
        "citations": [
            {
                "ref": "2007_banko_open",
                "title": "Open Information Extraction from the Web"
            },
            {
                "ref": "2008_banko_the",
                "title": "The Tradeoffs Between Open and Traditional Relation Extraction"
            },
            {
                "ref": "2008_cafarella_webtables",
                "title": "WebTables: Exploring the Power of Tables on the Web"
            },
            {
                "ref": "2008_cafarella_uncovering",
                "title": "Uncovering the Relational Web"
            },
            {
                "ref": "2005_downey_a",
                "title": "A Probabilistic Model of Redundancy in Information Extraction"
            },
            {
                "ref": "2009_elmeleegy_harvesting",
                "title": "Harvesting Relational Tables from Lists on the Web"
            },
            {
                "ref": "2009_gupta_answering",
                "title": "Answering Table Augmentation Queries from Unstructured Lists on the Web"
            },
            {
                "ref": "2010_limaye_annotating",
                "title": "Annotating and Searching Web Tables Using Entities, Types and Relationships"
            },
            {
                "ref": "2008_pasca_weakly",
                "title": "Weakly-Supervised Acquisition of Open-Domain Classes and Class Attributes from Web Documents and Query Logs"
            },
            {
                "ref": "2007_suchanek_yago",
                "title": "YAGO: a Core of Semantic Knowledge Unifying WordNet and Wikipedia"
            }
        ],
        "uncertainFields": [
            {
                "field": "doi",
                "reason": "DOI not stated in the provided text; PVLDB papers often use 10.14778/... identifiers but none is specified."
            },
            {
                "field": "nameOfApproach",
                "reason": "No formal system name given; 'TABLE' is mentioned only as an internal name for the experimental search engine."
            },
            {
                "field": "output",
                "reason": "No explicit serialisation format (e.g., RDF/JSON-LD) is described."
            },
            {
                "field": "userInterfaceTool",
                "reason": "The paper does not specify a UI or tool modality."
            },
            {
                "field": "supportTasks.columnClassification",
                "reason": "Numeric/date features are used in heuristics, but no explicit NE vs LIT classifier is reported."
            },
            {
                "field": "supportTasks.datatypeAnnotation",
                "reason": "No KG datatype annotation is described."
            },
            {
                "field": "citations",
                "reason": "List may be incomplete; only key references were extracted."
            }
        ]
    },
    {
        "id": "2012_goel_exploiting",
        "added": "",
        "year": 2012,
        "firstAuthor": "Goel",
        "authors": [
            "Aman Goel",
            "Craig A. Knoblock",
            "Kristina Lerman"
        ],
        "title": "Exploiting Structure within Data for Accurate Labeling using Conditional Random Fields",
        "venue": {
            "type": "conference",
            "acronym": "ICAI"
        },
        "nameOfApproach": "",
        "techniqueTags": [
            "CRF"
        ],
        "coreTasks": {
            "cta": false,
            "cpa": false,
            "cea": false,
            "cnea": false
        },
        "supportTasks": {
            "dataPreparation": {
                "description": "Custom lexical analysis to tokenise fields and extract generic alphabetic, numeric and symbol features.",
                "spellChecker": "",
                "unitsOfMeasurements": ""
            },
            "columnClassification": "",
            "subjectDetection": "",
            "datatypeAnnotation": "",
            "typeAnnotation": "",
            "predicateAnnotation": "",
            "nilAnnotation": "",
            "entityLinking": {
                "description": "",
                "candidateGeneration": "",
                "entityDisambiguation": ""
            }
        },
        "mainMethod": {
            "type": "supervised",
            "technique": "CRF",
            "supervision": {
                "type": "supervised"
            }
        },
        "revision": {
            "type": "fully automated",
            "description": "After training, labels are produced automatically by CRF inference with no manual post-editing described."
        },
        "domain": {
            "domain": "independent",
            "type": "generic"
        },
        "validation": {
            "goldStandard": "400 tuples per domain from four web sources (weather, flight status, geocoding) with manual labels for fields and tokens.",
            "metrics": [
                "Accuracy"
            ]
        },
        "code": "",
        "license": "Not Specified",
        "inputs": {
            "typeOfTable": "Structured fields/tuples from web pages and databases",
            "tableSources": [
                "web",
                "relational"
            ]
        },
        "output": "",
        "applicationPurpose": "Semantic labelling of structured data fields to support data integration.",
        "userInterfaceTool": "",
        "checkedByAuthor": false,
        "checkedByAi": true,
        "doi": "",
        "citations": [
            {
                "ref": "2001_borkar_automatic",
                "title": "Automatic segmentation of text into structured records"
            },
            {
                "ref": "2000_doan_learning",
                "title": "Learning source descriptions for data integration"
            },
            {
                "ref": "2001_kschischang_factor",
                "title": "Factor graphs and the sum-product algorithm"
            },
            {
                "ref": "2001_lafferty_conditional",
                "title": "Conditional random fields: Probabilistic models for segmenting and labeling sequence data"
            },
            {
                "ref": "1988_lauritzen_local",
                "title": "Local computations with probabilities on graphical structures and their application to expert systems"
            },
            {
                "ref": "2004_lerman_using",
                "title": "Using the structure of web sites for automatic segmentation of tables"
            },
            {
                "ref": "2006_lerman_semantic",
                "title": "Semantic labeling of online information sources"
            },
            {
                "ref": "1989_liu_on",
                "title": "On the limited memory method for large scale optimization"
            },
            {
                "ref": "2007_nadeau_a",
                "title": "A survey of named entity recognition and classification"
            },
            {
                "ref": "1988_pearl_probabilistic",
                "title": "Probabilistic Reasoning in Intelligent Systems"
            },
            {
                "ref": "2003_pinto_table",
                "title": "Table extraction using conditional random fields"
            },
            {
                "ref": "1989_rabiner_a",
                "title": "A tutorial on hidden markov models and selected applications in speech recognition"
            },
            {
                "ref": "2003_sha_shallow",
                "title": "Shallow parsing with conditional random fields"
            },
            {
                "ref": "2007_sutton_dynamic",
                "title": "Dynamic conditional random fields: Factorized probabilistic models for labeling and segmenting sequence data"
            },
            {
                "ref": "2006_tang_tree",
                "title": "Tree-structured conditional random fields for semantic annotation"
            },
            {
                "ref": "1967_viterbi_error",
                "title": "Error bounds for convolutional codes and an asymptotically optimum decoding algorithm"
            },
            {
                "ref": "2005_zhu_2d",
                "title": "2d conditional random fields for web information extraction"
            }
        ],
        "uncertainFields": [
            {
                "field": "venue.acronym",
                "reason": "Derived from the file name; the PDF text shown does not explicitly state the venue."
            },
            {
                "field": "doi",
                "reason": "No DOI is indicated in the available copy; the venue may not assign one."
            },
            {
                "field": "inputs.typeOfTable",
                "reason": "The method labels structured tuples rather than explicit tables; exact input format may vary."
            },
            {
                "field": "output",
                "reason": "No serialisation format (e.g., RDF/JSON-LD) is specified; outputs are label assignments."
            },
            {
                "field": "domain.type",
                "reason": "We marked it as generic, but the evaluation spans specific domains (weather, flights, geocoding)."
            },
            {
                "field": "code",
                "reason": "No code repository or download link is provided in the text."
            },
            {
                "field": "validation.goldStandard",
                "reason": "Datasets are scraped and manually labelled; not a named public GS."
            }
        ]
    },
    {
        "id": "2012_knoblock_semi-automatically",
        "added": "",
        "year": 2012,
        "firstAuthor": "Knoblock",
        "authors": [
            "Craig A. Knoblock",
            "Pedro A. Szekely",
            "José Luis Ambite",
            "Aman Goel",
            "Shubham Gupta",
            "Kristina Lerman",
            "Maria Muslea",
            "Mohsen Taheriyan",
            "Parag Mallick"
        ],
        "title": "Semi-automatically Mapping Structured Sources into the Semantic Web",
        "venue": {
            "type": "conference",
            "acronym": "ESWC"
        },
        "nameOfApproach": "Karma",
        "techniqueTags": [
            "CRF",
            "ontology-driven"
        ],
        "coreTasks": {
            "cta": true,
            "cpa": true,
            "cea": false,
            "cnea": false
        },
        "supportTasks": {
            "dataPreparation": {
                "description": "Cleaning and transformation operations may be needed during mapping; planned UI support is mentioned.",
                "spellChecker": "",
                "unitsOfMeasurements": ""
            },
            "columnClassification": "",
            "subjectDetection": "",
            "datatypeAnnotation": "Literal columns can be mapped to datatype properties in the ontology.",
            "typeAnnotation": "Semantic types for columns are inferred with a CRF and refined by the user.",
            "predicateAnnotation": "Relationships between columns are computed via ontology paths/Steiner tree and can be adjusted by the user.",
            "nilAnnotation": "",
            "entityLinking": {
                "description": "",
                "candidateGeneration": "",
                "entityDisambiguation": ""
            }
        },
        "mainMethod": {
            "type": "hybrid",
            "technique": "CRF-based semantic typing combined with ontology-driven graph construction (Steiner tree) and interactive constraints"
        },
        "revision": {
            "type": "semi automated",
            "description": "A GUI lets users correct semantic types, force relationships, and split class instances after the automatic proposal."
        },
        "domain": {
            "domain": "independent",
            "type": ""
        },
        "validation": {
            "goldStandard": "Equivalence to published SMW-LDE R2R mappings (41 rules) and modelling of an ACE OWL events database",
            "metrics": []
        },
        "code": "https://github.com/InformationIntegrationGroup/Web-Karma-Public",
        "license": "Apache License 2.0",
        "inputs": {
            "typeOfTable": "Structured sources (databases, spreadsheets, CSV, XML)",
            "tableSources": [
                "relational",
                "spreadsheet"
            ]
        },
        "kg": {
            "tripleStore": "",
            "index": ""
        },
        "output": "RDF",
        "applicationPurpose": "Build source models to generate RDF against a given ontology and expose SPARQL over sources.",
        "userInterfaceTool": "Web UI (Karma)",
        "checkedByAuthor": false,
        "checkedByAi": true,
        "doi": "https://doi.org/10.14778/2336664.2336665",
        "citations": [
            {
                "ref": "2010_bizer_the",
                "title": "The R2R Framework: Publishing and Discovering Mappings on the Web"
            },
            {
                "ref": "2006_bizer_d2r",
                "title": "D2R Server – Publishing Relational Databases on the Semantic Web"
            },
            {
                "ref": "2011_das_r2rml",
                "title": "R2RML: RDB to RDF Mapping Language"
            },
            {
                "ref": "2001_lafferty_conditional",
                "title": "Conditional Random Fields: Probabilistic Models for Segmenting and Labeling Sequence Data"
            },
            {
                "ref": "1981_kou_a",
                "title": "A fast algorithm for Steiner trees"
            },
            {
                "ref": "2010_becker_extending",
                "title": "Extending SMW+ with a Linked Data Integration Framework"
            }
        ],
        "uncertainFields": [
            {
                "field": "coreTasks.cea",
                "reason": "The system generates URIs and RDF from identifiers but does not explicitly describe entity linking/disambiguation at cell level."
            },
            {
                "field": "inputs.tableSources[0]",
                "reason": "Relational databases are clearly supported; inclusion of other sources is broad, but only relational and spreadsheet are selected to stay conservative."
            },
            {
                "field": "kg.tripleStore",
                "reason": "No specific triple store is stated; the paper focuses on producing RDF and GLAV mappings rather than querying a particular KG backend."
            },
            {
                "field": "validation.goldStandard",
                "reason": "Described as reproducing SMW-LDE R2R mappings and an ACE OWL database mapping rather than a formal GS with standard metrics. "
            },
            {
                "field": "code",
                "reason": "The URL appears as a footnote in the paper; repository status or licence is not detailed in the text. "
            },
            {
                "field": "supportTasks.datatypeAnnotation",
                "reason": "Datatype property mapping is implied by examples of data properties but not exhaustively specified."
            }
        ]
    },
    {
        "id": "2012_pimplikar_answering",
        "added": "",
        "year": 2012,
        "firstAuthor": "Pimplikar",
        "authors": [
            "Rakesh Pimplikar",
            "Sunita Sarawagi"
        ],
        "title": "Answering Table Queries on the Web using Column Keywords",
        "venue": {
            "type": "journal",
            "acronym": "PVLDB"
        },
        "nameOfApproach": "WWT",
        "techniqueTags": [],
        "coreTasks": {
            "cta": false,
            "cpa": false,
            "cea": false,
            "cnea": false
        },
        "supportTasks": {
            "dataPreparation": {
                "description": "Heuristic extraction of headers and context from HTML tables; Lucene indexing; filtering of non-data tables.",
                "spellChecker": "",
                "unitsOfMeasurements": ""
            },
            "columnClassification": "",
            "subjectDetection": "",
            "datatypeAnnotation": "",
            "typeAnnotation": "",
            "predicateAnnotation": "",
            "nilAnnotation": "",
            "entityLinking": {
                "description": "",
                "candidateGeneration": "",
                "entityDisambiguation": ""
            }
        },
        "mainMethod": {
            "type": "supervised",
            "technique": "Graphical model with bipartite matching and constrained graph cuts",
            "supervision": {
                "type": "supervised"
            }
        },
        "revision": {
            "type": "fully automated",
            "description": "Automated column mapping and consolidation; no manual post-editing described."
        },
        "domain": {
            "domain": "independent",
            "type": ""
        },
        "validation": {
            "goldStandard": "Manual ground truth labels for 1,906 tables over 59 queries",
            "metrics": [
                "F1"
            ]
        },
        "code": "",
        "license": "Not Specified",
        "inputs": {
            "typeOfTable": "HTML tables",
            "tableSources": [
                "web"
            ]
        },
        "output": "HTML table",
        "applicationPurpose": "Structured web table search and consolidation",
        "userInterfaceTool": "",
        "checkedByAuthor": false,
        "checkedByAi": true,
        "doi": "https://doi.org/10.1007/978-3-642-34002-4_11",
        "citations": [
            {
                "ref": "2009_cafarella_data",
                "title": "Data integration for the relational web"
            },
            {
                "ref": "2008_cafarella_webtables",
                "title": "Webtables: exploring the power of tables on the web"
            },
            {
                "ref": "2009_gupta_answering",
                "title": "Answering table augmentation queries from unstructured lists on the web"
            },
            {
                "ref": "2001_boykov_fast",
                "title": "Fast approximate energy minimization via graph cuts"
            },
            {
                "ref": "2006_kolmogorov_convergent",
                "title": "Convergent tree-reweighted message passing for energy minimization"
            },
            {
                "ref": "2009_koller_probabilistic",
                "title": "Probabilistic graphical models: principles and techniques"
            },
            {
                "ref": "2003_pinto_table",
                "title": "Table extraction using conditional random fields"
            },
            {
                "ref": "2011_crestan_web-scale",
                "title": "Web-scale table census and classification"
            }
        ],
        "uncertainFields": [
            {
                "field": "venue.type",
                "reason": "PVLDB is a journal tightly linked to the VLDB conference; some sources cite it as a conference proceeding."
            },
            {
                "field": "output",
                "reason": "The system returns a consolidated table but no explicit export format is specified."
            },
            {
                "field": "userInterfaceTool",
                "reason": "A structured search engine is presented, but a specific UI is not described."
            },
            {
                "field": "applicationPurpose",
                "reason": "Summarised from the abstract rather than given as an explicit section."
            },
            {
                "field": "nameOfApproach",
                "reason": "The system is referred to as WWT; exact stylisation is not formalised."
            },
            {
                "field": "validation.goldStandard",
                "reason": "They report manually labelled mappings for 1,906 tables (59 queries) but do not name a specific dataset."
            },
            {
                "field": "mainMethod.supervision.type",
                "reason": "Weights are tuned on labelled data, treated as supervised although training details are brief."
            },
            {
                "field": "inputs.tableSources",
                "reason": "Tables are harvested from arbitrary HTML pages; other sources like Wikipedia may be implicitly included."
            },
            {
                "field": "techniqueTags",
                "reason": "No listed tag (SVM/CRF/clustering/transformer/etc.) directly applies; left empty."
            }
        ]
    },
    {
        "id": "2012_wang_understanding",
        "added": "",
        "year": 2012,
        "firstAuthor": "Wang",
        "authors": [
            "Jingjing Wang",
            "Haixun Wang",
            "Zhongyuan Wang",
            "Kenny Q. Zhu"
        ],
        "title": "Understanding Tables on the Web",
        "venue": {
            "type": "conference",
            "acronym": "ER"
        },
        "nameOfApproach": "",
        "techniqueTags": [
            "rule-based",
            "ontology-driven"
        ],
        "coreTasks": {
            "cta": true,
            "cpa": false,
            "cea": false,
            "cnea": false
        },
        "supportTasks": {
            "dataPreparation": {
                "description": "Rules filter raw HTML tables, detect or generate headers, and identify the entity column using Probase-based scores. ",
                "spellChecker": "",
                "unitsOfMeasurements": ""
            },
            "columnClassification": "Detects entity (NE) vs attribute (literal) columns via κE/κA evidence from Probase. ",
            "subjectDetection": "Selects the entity column by maximising agreement between entity and attribute concepts. ",
            "datatypeAnnotation": "",
            "typeAnnotation": "Associates the entity column with a Probase concept (conceptualisation). ",
            "predicateAnnotation": "",
            "nilAnnotation": "",
            "entityLinking": {
                "description": "",
                "candidateGeneration": "",
                "entityDisambiguation": ""
            }
        },
        "mainMethod": {
            "type": "unsupervised",
            "technique": "rule-based"
        },
        "revision": {
            "type": "fully automated",
            "description": "Outputs are produced automatically without user curation; results are used for semantic search and to expand Probase. "
        },
        "domain": {
            "domain": "independent",
            "type": ""
        },
        "validation": {
            "goldStandard": "Manual evaluation of 200 filtered web tables, 200 Wikipedia tables, and 30 high-frequency concepts (reporting header detection and entity-column precision). SpringerLink",
            "metrics": [
                "Precision",
                "Accuracy"
            ]
        },
        "code": "",
        "license": "Not Specified",
        "inputs": {
            "typeOfTable": "HTML tables",
            "tableSources": [
                "web",
                "wiki"
            ]
        },
        "kg": {
            "tripleStore": "Probase",
            "index": "Knowledge APIs κA and κE with plausibility/ambiguity scoring; seed-attribute ranking and DBpedia lookups for attributes. "
        },
        "output": "table statements",
        "applicationPurpose": "Semantic table understanding for web-scale tables; semantic search; Probase taxonomy expansion. ",
        "userInterfaceTool": "Web UI (semantic table search prototype)",
        "checkedByAuthor": false,
        "checkedByAi": true,
        "doi": "https://doi.org/10.1007/978-3-642-34002-4_11",
        "citations": [
            {
                "ref": "2012_wu_probase",
                "title": "Probase: A probabilistic taxonomy for text understanding"
            },
            {
                "ref": "2008_cafarella_webtables",
                "title": "WebTables: Exploring the power of tables on the web"
            },
            {
                "ref": "2011_venetis_recovering",
                "title": "Recovering semantics of tables on the web"
            },
            {
                "ref": "1992_hearst_automatic",
                "title": "Automatic acquisition of hyponyms from large text corpora"
            },
            {
                "ref": "2007_auer_dbpedia",
                "title": "DBpedia: A Nucleus for a Web of Open Data"
            }
        ],
        "uncertainFields": [
            {
                "field": "venue.acronym",
                "reason": "Conference is ER 2012 (LNCS 7532); acronym normalised to 'ER' without year."
            },
            {
                "field": "kg.tripleStore",
                "reason": "Method centres on Probase but also consults DBpedia for attributes; we list Probase as the primary KG. "
            },
            {
                "field": "output",
                "reason": "The system returns ranked table statements/tables for queries but does not define a formal export format."
            },
            {
                "field": "userInterfaceTool",
                "reason": "A prototype search engine is described but not formally named; 'Web UI' is inferred. "
            },
            {
                "field": "validation.metrics",
                "reason": "Paper reports correctness rates and average scores; mapped to 'Precision' and 'Accuracy' as closest allowed metrics. "
            },
            {
                "field": "inputs.tableSources[1]",
                "reason": "Wikipedia tables were used for parts of the evaluation; broader web tables were also used."
            }
        ]
    },
    {
        "id": "2013_adelfio_schema",
        "added": "",
        "year": 2013,
        "firstAuthor": "Adelfio",
        "authors": [
            "Marco D. Adelfio",
            "Hanan Samet"
        ],
        "title": "Schema Extraction for Tabular Data on the Web",
        "venue": {
            "type": "journal",
            "acronym": "PVLDB"
        },
        "nameOfApproach": "",
        "techniqueTags": [
            "CRF"
        ],
        "coreTasks": {
            "cta": false,
            "cpa": false,
            "cea": false,
            "cnea": false
        },
        "supportTasks": {
            "dataPreparation": {
                "description": "",
                "spellChecker": "",
                "unitsOfMeasurements": ""
            },
            "columnClassification": "",
            "subjectDetection": "",
            "datatypeAnnotation": "",
            "typeAnnotation": "",
            "predicateAnnotation": "",
            "nilAnnotation": "",
            "entityLinking": {
                "description": "",
                "candidateGeneration": "",
                "entityDisambiguation": ""
            }
        },
        "mainMethod": {
            "type": "supervised",
            "technique": "CRF",
            "supervision": {
                "type": "supervised"
            }
        },
        "revision": {
            "type": "fully automated",
            "description": "Outputs are produced automatically by a trained CRF-based classifier without user post-editing."
        },
        "domain": {
            "domain": "independent",
            "type": ""
        },
        "validation": {
            "goldStandard": "10-fold cross-validation on a collected corpus of relational HTML tables and spreadsheets; comparisons with WebTables features.",
            "metrics": [
                "Precision",
                "Recall",
                "Accuracy"
            ]
        },
        "code": "",
        "license": "Not Specified",
        "inputs": {
            "typeOfTable": "HTML tables and spreadsheets",
            "tableSources": [
                "web",
                "spreadsheet"
            ]
        },
        "output": "",
        "applicationPurpose": "Schema extraction of web and spreadsheet tables",
        "userInterfaceTool": "",
        "checkedByAuthor": false,
        "checkedByAi": true,
        "doi": "https://doi.org/10.14778/2536336.2536343",
        "citations": [
            {
                "ref": "2011_venetis_recovering",
                "title": "Recovering semantics of tables on the web"
            },
            {
                "ref": "2003_sha_shallow",
                "title": "Shallow parsing with conditional random fields"
            },
            {
                "ref": "2012_yakout_infogather",
                "title": "InfoGather: entity augmentation and attribute discovery by holistic matching with web tables"
            },
            {
                "ref": "2002_wang_a",
                "title": "A machine learning based approach for table detection on the web"
            },
            {
                "ref": "2004_zanibbi_a",
                "title": "A survey of table recognition: Models, observations, transformations, and inferences"
            }
        ],
        "uncertainFields": [
            {
                "field": "venue.type",
                "reason": "Published in PVLDB (journal) and also presented at VLDB 2013; categorisation could be seen as conference-related."
            },
            {
                "field": "output",
                "reason": "The paper does not specify an exported output format such as RDF/CSV."
            },
            {
                "field": "applicationPurpose",
                "reason": "Purpose summarised broadly from context; not explicitly framed as an application section."
            },
            {
                "field": "validation.goldStandard",
                "reason": "Uses an internal collected corpus rather than a named public gold standard."
            },
            {
                "field": "userInterfaceTool",
                "reason": "No UI or tool is described; assumed absent."
            },
            {
                "field": "code",
                "reason": "No code repository or release is mentioned."
            }
        ]
    },
    {
        "id": "2013_buche_fuzzy",
        "added": "",
        "year": 2013,
        "firstAuthor": "Buche",
        "authors": [
            "Patrice Buche",
            "Juliette Dibie-Barthelemy",
            "Liliana Ibanescu",
            "Lydie Soler"
        ],
        "title": "Fuzzy Web Data Tables Integration Guided by an Ontological and Terminological Resource",
        "venue": {
            "type": "journal",
            "acronym": "TKDE"
        },
        "nameOfApproach": "ONDINE",
        "techniqueTags": [
            "rule-based",
            "ontology-driven"
        ],
        "coreTasks": {
            "cta": true,
            "cpa": true,
            "cea": false,
            "cnea": false
        },
        "supportTasks": {
            "dataPreparation": {
                "description": "Tables are standardised and structured; symbolic vs numerical columns are identified with the aid of the OTR.",
                "spellChecker": "",
                "unitsOfMeasurements": "Units are modelled in the OTR using an SI-based unit hierarchy."
            },
            "columnClassification": "Distinguishes symbolic and numerical columns using OTR knowledge about terms and units.",
            "subjectDetection": "",
            "datatypeAnnotation": "Maps numerical columns to quantities and associated units defined in the OTR.",
            "typeAnnotation": "Annotates columns with symbolic concepts (classes) from the OTR.",
            "predicateAnnotation": "Identifies n-ary relations represented by the table by matching column concepts to OTR relation signatures.",
            "nilAnnotation": "",
            "entityLinking": {
                "description": "",
                "candidateGeneration": "",
                "entityDisambiguation": ""
            }
        },
        "mainMethod": {
            "type": "unsupervised",
            "technique": "rule-based"
        },
        "revision": {
            "type": "semi automated",
            "description": "Human experts review and validate fuzzy RDF annotations before loading into the XML/RDF warehouse."
        },
        "domain": {
            "domain": "dependent",
            "type": "food safety (microbial risk)"
        },
        "validation": {
            "goldStandard": "",
            "metrics": [
                "Precision",
                "Recall"
            ]
        },
        "code": "",
        "license": "Not Specified",
        "inputs": {
            "typeOfTable": "Web tables (extracted from Web documents; represented as XML)",
            "tableSources": [
                "web",
                "scientific"
            ]
        },
        "kg": {
            "tripleStore": "XML/RDF data warehouse (OTR-based)",
            "index": ""
        },
        "output": "RDF",
        "applicationPurpose": "Supplement local data sources with annotated Web tables and enable flexible, preference-aware querying.",
        "userInterfaceTool": "Web UI (MIEL++ GUI; @Web)",
        "checkedByAuthor": false,
        "checkedByAi": true,
        "doi": "https://doi.org/10.1109/TKDE.2011.245",
        "citations": [
            {
                "ref": "2007_liu_tableseer",
                "title": "TableSeer: Automatic Table Metadata Extraction and Searching in Digital Libraries"
            },
            {
                "ref": "2008_cafarella_webtables",
                "title": "WebTables: Exploring the Power of Tables on the Web"
            },
            {
                "ref": "2008_pan_scalable",
                "title": "Scalable Querying Services over Fuzzy Ontologies"
            },
            {
                "ref": "2006_baziz_a",
                "title": "A Fuzzy Logic Approach to Information Retrieval Using a Ontology-Based Representation of Documents"
            }
        ],
        "uncertainFields": [
            {
                "field": "coreTasks.cpa",
                "reason": "The system recognises and instantiates n-ary relations from the OTR; mapping to CPA (pairwise KG properties) is analogous but not explicit."
            },
            {
                "field": "inputs.tableSources",
                "reason": "Sources are described as Web and digital library scientific documents; specific file formats are not exhaustively listed."
            },
            {
                "field": "kg.tripleStore",
                "reason": "They query an XML/RDF data warehouse with SPARQL rather than a named public KG; phrasing may vary."
            },
            {
                "field": "userInterfaceTool",
                "reason": "The paper mentions a GUI for MIEL++ and the @Web software; exact tool names/packaging may differ from the implementation."
            },
            {
                "field": "techniqueTags[0]",
                "reason": "The approach is algorithmic and OTR-guided with thresholds; categorising it as rule-based is reasonable but not explicitly named as such."
            }
        ]
    },
    {
        "id": "2013_cruz_giva",
        "added": "",
        "year": 2013,
        "firstAuthor": "Cruz",
        "authors": [
            "Isabel F. Cruz",
            "Venkat R. Ganesh",
            "Claudio Caletti",
            "Pavan Reddy"
        ],
        "title": "GIVA: A Semantic Framework for Geospatial and Temporal Data Integration, Visualization, and Analytics",
        "venue": {
            "type": "conference",
            "acronym": "SIGSPATIAL"
        },
        "nameOfApproach": "GIVA",
        "techniqueTags": [
            "ontology-driven"
        ],
        "coreTasks": {
            "cta": false,
            "cpa": false,
            "cea": false,
            "cnea": false
        },
        "supportTasks": {
            "dataPreparation": {
                "description": "Extraction of feature-rich tables from web tables and semantic processing to identify spatial coordinates/time stamps; translation into a common spatial format.",
                "spellChecker": "",
                "unitsOfMeasurements": ""
            },
            "columnClassification": "",
            "subjectDetection": "",
            "datatypeAnnotation": "",
            "typeAnnotation": "",
            "predicateAnnotation": "",
            "nilAnnotation": "",
            "entityLinking": {
                "description": "",
                "candidateGeneration": "",
                "entityDisambiguation": ""
            }
        },
        "mainMethod": {
            "type": "hybrid",
            "technique": "ontology-driven"
        },
        "revision": {
            "type": "semi automated",
            "description": "Users can optionally review the extracted ontology; other components (matching, translation, storage) run automatically."
        },
        "domain": {
            "domain": "dependent",
            "type": "geospatial/environmental"
        },
        "validation": {
            "goldStandard": "",
            "metrics": []
        },
        "code": "",
        "license": "Not Specified",
        "inputs": {
            "typeOfTable": "HTML tables and GIS formats (CSV, GML, KML, SHP)",
            "tableSources": [
                "web",
                "spreadsheet"
            ]
        },
        "kg": {
            "tripleStore": "OWLIM",
            "index": ""
        },
        "output": "RDF",
        "applicationPurpose": "Geospatial/temporal data integration, visualisation and analytics for domain experts.",
        "userInterfaceTool": "Web UI",
        "checkedByAuthor": false,
        "checkedByAi": true,
        "doi": "https://doi.org/10.1145/2525314.2525324",
        "citations": [
            {
                "ref": "1999_abiteboul_tools",
                "title": "Tools for Data Translation and Integration"
            },
            {
                "ref": "2009_cruz_agreementmaker",
                "title": "AgreementMaker: Efficient Matching for Large Real-World Schemas and Ontologies"
            },
            {
                "ref": "2012_cruz_automatic",
                "title": "Automatic Configuration Selection Using Ontology Matching Task Profiling"
            },
            {
                "ref": "2008_cruz_structural",
                "title": "Structural Alignment Methods with Applications to Geospatial Ontologies"
            },
            {
                "ref": "2009_cruz_ontology",
                "title": "Ontology Driven Data Integration in Heterogeneous Networks"
            },
            {
                "ref": "2005_kiryakov_owlima",
                "title": "OWLIM–A Pragmatic Semantic Repository for OWL"
            },
            {
                "ref": "2009_hall_the",
                "title": "The WEKA Data Mining Software: An Update"
            },
            {
                "ref": "2011_rishe_geospatial",
                "title": "Geospatial Data Management with TerraFly"
            },
            {
                "ref": "2001_mccurley_geospatial",
                "title": "Geospatial Mapping and Navigation of the Web"
            },
            {
                "ref": "2007_middel_a",
                "title": "A Framework for Visualizing Multivariate Geodata"
            }
        ],
        "uncertainFields": [
            {
                "field": "venue.acronym",
                "reason": "Paper mentions \"Proceedings of ACMGIS\" and SIGSPATIAL’13; using SIGSPATIAL as the venue acronym may be ambiguous."
            },
            {
                "field": "techniqueTags[0]",
                "reason": "Framework combines ontology matching with ML (decision tree) for table extraction; only \"ontology-driven\" fits allowed tags."
            },
            {
                "field": "mainMethod.technique",
                "reason": "Technique is a mix of ontology matching and ML; summarised as ontology-driven."
            },
            {
                "field": "revision.type",
                "reason": "Authors note optional user review of extracted ontology; extent of human-in-the-loop across components is not fully specified."
            },
            {
                "field": "domain.type",
                "reason": "Targets geospatial data with environmental/public administration examples; domain label consolidated as geospatial/environmental."
            },
            {
                "field": "validation.goldStandard",
                "reason": "Demo paper does not report a named gold standard; only mentions training on 100 web tables."
            },
            {
                "field": "output",
                "reason": "RDF triples are generated, but the application also exposes a WFS; RDF chosen as primary output."
            },
            {
                "field": "kg.tripleStore",
                "reason": "OWLIM is the RDF store; the system also consults DBpedia for ontology construction, which could be interpreted as the KG."
            },
            {
                "field": "inputs.tableSources",
                "reason": "Sources include web tables and CSV; spreadsheet chosen to represent CSV though the exact origin of CSV files is not fully detailed."
            },
            {
                "field": "userInterfaceTool",
                "reason": "Only described generically as a web interface (AJAX/jQuery, D3.js); no specific tool name provided."
            },
            {
                "field": "code",
                "reason": "No repository or download link is referenced."
            },
            {
                "field": "license",
                "reason": "No licensing information is provided in the paper."
            },
            {
                "field": "applicationPurpose",
                "reason": "Summarised from the abstract; phrasing may vary."
            },
            {
                "field": "coreTasks.cta",
                "reason": "Paper is not focused on STI tasks (CTA/CPA/CEA/CNEA); set to false conservatively."
            },
            {
                "field": "supportTasks.dataPreparation.description",
                "reason": "Description generalised from multiple sections; exact scope may differ."
            }
        ]
    },
    {
        "id": "2013_deng_scalable",
        "added": "",
        "year": 2013,
        "firstAuthor": "Deng",
        "authors": [
            "Dong Deng",
            "Yu Jiang",
            "Guoliang Li",
            "Jian Li",
            "Cong Yu"
        ],
        "title": "Scalable Column Concept Determination for Web Tables Using Large Knowledge Bases",
        "venue": {
            "type": "journal",
            "acronym": "PVLDB"
        },
        "nameOfApproach": "",
        "techniqueTags": [
            "rule-based",
            "ontology-driven"
        ],
        "coreTasks": {
            "cta": true,
            "cpa": false,
            "cea": false,
            "cnea": false
        },
        "supportTasks": {
            "dataPreparation": {
                "description": "Generates string signatures (e.g., q-grams) to enable fuzzy matching and uses MapReduce-based similarity joins for scalability.",
                "spellChecker": "",
                "unitsOfMeasurements": ""
            },
            "columnClassification": "",
            "subjectDetection": "",
            "datatypeAnnotation": "",
            "typeAnnotation": "Selects top-k KG types per column by aggregating fuzzy matches between cell values and KG entities and ranking via set-similarity functions.",
            "predicateAnnotation": "",
            "nilAnnotation": "",
            "entityLinking": {
                "description": "",
                "candidateGeneration": "",
                "entityDisambiguation": ""
            }
        },
        "mainMethod": {
            "type": "unsupervised",
            "technique": "rule-based"
        },
        "revision": {
            "type": "fully automated",
            "description": "Batch, MapReduce-based pipeline; no human-in-the-loop post-editing is described."
        },
        "domain": {
            "domain": "independent",
            "type": ""
        },
        "validation": {
            "goldStandard": "WWT (Wikipedia Web Tables) and WEX (Wikipedia Extraction) datasets with manual ground truth for evaluation; KG sources Freebase and YAGO.",
            "metrics": [
                "Precision",
                "Recall",
                "F1"
            ]
        },
        "code": "",
        "license": "Not Specified",
        "inputs": {
            "typeOfTable": "HTML tables",
            "tableSources": [
                "web",
                "wiki"
            ]
        },
        "kg": {
            "tripleStore": "Freebase; Yago",
            "index": "Signature-based indexing with bloom filter hierarchy for partition identification"
        },
        "output": "Top-k KG types per column",
        "applicationPurpose": "Web-scale table understanding to support search and integration.",
        "userInterfaceTool": "",
        "checkedByAuthor": false,
        "checkedByAi": true,
        "doi": "https://doi.org/10.14778/2536258.2536271",
        "citations": [
            {
                "ref": "2010_limaye_annotating",
                "title": "Annotating and searching web tables using entities, types and relationships"
            },
            {
                "ref": "2011_venetis_recovering",
                "title": "Recovering semantics of tables on the web"
            },
            {
                "ref": "2008_cafarella_webtables",
                "title": "WebTables: exploring the power of tables on the Web"
            },
            {
                "ref": "2007_auer_dbpedia",
                "title": "DBpedia: A nucleus for a web of open data"
            },
            {
                "ref": "2007_suchanek_yago",
                "title": "YAGO: a core of semantic knowledge"
            }
        ],
        "uncertainFields": [
            {
                "field": "inputs.typeOfTable",
                "reason": "The paper processes Web/Wikipedia tables rendered in HTML; the exact label expected by the schema could also be 'Web tables'."
            },
            {
                "field": "kg.index",
                "reason": "The description summarises mechanisms (signatures, bloom filter hierarchy) used in the pipeline rather than a conventional KG index component."
            },
            {
                "field": "output",
                "reason": "No explicit serialisation format is provided; the outcome is a ranked list of concepts per column."
            },
            {
                "field": "mainMethod.technique",
                "reason": "The method is algorithmic (similarity-join with heuristics) and not a classic 'rule-based' system; 'rule-based' is used as the closest allowed label."
            },
            {
                "field": "validation.goldStandard",
                "reason": "Named datasets WWT and WEX are used; the schema requests a GS name but the paper mixes manual ground truth and extracted tables."
            }
        ]
    },
    {
        "id": "2013_ermilov_user-driven",
        "added": "",
        "year": 2013,
        "firstAuthor": "Ermilov",
        "authors": [
            "Ivan Ermilov",
            "Sören Auer",
            "Claus Stadler"
        ],
        "title": "User-driven semantic mapping of tabular data",
        "venue": {
            "type": "conference",
            "acronym": "I-SEMANTICS"
        },
        "nameOfApproach": "CSV2RDF",
        "techniqueTags": [
            "rule-based"
        ],
        "coreTasks": {
            "cta": false,
            "cpa": false,
            "cea": false,
            "cnea": false
        },
        "supportTasks": {
            "dataPreparation": {
                "description": "Resources are crawled and cleaned; headers are extracted; default mappings are auto-generated for CSV files.",
                "spellChecker": "",
                "unitsOfMeasurements": ""
            },
            "columnClassification": "",
            "subjectDetection": "",
            "datatypeAnnotation": "",
            "typeAnnotation": "",
            "predicateAnnotation": "",
            "nilAnnotation": "",
            "entityLinking": {
                "description": "",
                "candidateGeneration": "",
                "entityDisambiguation": ""
            }
        },
        "mainMethod": {
            "type": "unsupervised",
            "technique": "rule-based"
        },
        "revision": {
            "type": "semi automated",
            "description": "Default mappings are created automatically and can be revised by users via a Semantic MediaWiki; data can be re-transformed after edits."
        },
        "domain": {
            "domain": "independent",
            "type": ""
        },
        "validation": {
            "goldStandard": "",
            "metrics": []
        },
        "code": "",
        "license": "Not Specified",
        "inputs": {
            "typeOfTable": "CSV",
            "tableSources": [
                "gov-open-data",
                "web"
            ]
        },
        "kg": {
            "tripleStore": "",
            "index": ""
        },
        "output": "RDF",
        "applicationPurpose": "Crowd-sourced mapping and mass conversion of tabular data from open data portals into RDF.",
        "userInterfaceTool": "Web UI (Semantic MediaWiki), CLI (Sparqlify-CSV)",
        "checkedByAuthor": false,
        "checkedByAi": true,
        "doi": "https://doi.org/10.1145/2506182.2506196",
        "citations": [
            {
                "ref": "2009_auer_triplify",
                "title": "Triplify: Light-weight linked data publication from relational databases"
            },
            {
                "ref": "berners-lee1998relational",
                "title": "Relational databases on the semantic web"
            },
            {
                "ref": "2009_ding_the",
                "title": "The data-gov wiki: A semantic web portal for linked government data"
            },
            {
                "ref": "2010_lebo_converting",
                "title": "Converting governmental datasets into linked data"
            },
            {
                "ref": "2007_pivk_transforming",
                "title": "Transforming arbitrary tables into logical form with TARTAR"
            }
        ],
        "uncertainFields": [
            {
                "field": "venue.acronym",
                "reason": "Proceedings refer to I-SEMANTICS '13; acronym formatting varies between sources."
            },
            {
                "field": "kg.tripleStore",
                "reason": "The approach focuses on CSV-to-RDF conversion without specifying a target KG or triple store."
            },
            {
                "field": "license",
                "reason": "No explicit licence for the system or code is stated in the paper."
            },
            {
                "field": "userInterfaceTool",
                "reason": "Described as a Semantic MediaWiki-based mapping wiki plus Sparqlify-CSV CLI; exact tool naming is not standardised."
            },
            {
                "field": "applicationPurpose",
                "reason": "Purpose summarised from the abstract rather than an explicit 'Application/Purpose' section."
            },
            {
                "field": "inputs.tableSources",
                "reason": "Derived from the use of PublicData.eu and web data portals; not listed as a controlled set by the authors."
            },
            {
                "field": "nameOfApproach",
                "reason": "Preprint emphasises 'CSV2RDF' while ACM record lists the generic paper title; using CSV2RDF as the system name."
            }
        ]
    },
    {
        "id": "2013_mulwad_semantic",
        "added": "",
        "year": 2013,
        "firstAuthor": "Mulwad",
        "authors": [
            "Varish Mulwad",
            "Tim Finin",
            "Anupam Joshi"
        ],
        "title": "Semantic Message Passing for Generating Linked Data from Tables",
        "venue": {
            "type": "conference",
            "acronym": "ISWC"
        },
        "nameOfApproach": "Semantic Message Passing",
        "techniqueTags": [
            "ontology-driven",
            "rule-based"
        ],
        "coreTasks": {
            "cta": true,
            "cpa": true,
            "cea": true,
            "cnea": true
        },
        "supportTasks": {
            "dataPreparation": {
                "description": "Preprocessing includes row sampling, acronym expansion and recognising stylised literals (e.g., phone numbers); literals are detected via regular expressions.",
                "spellChecker": "",
                "unitsOfMeasurements": ""
            },
            "columnClassification": "Detect columns with only literal values and map them to no-annotation.",
            "subjectDetection": "",
            "datatypeAnnotation": "",
            "typeAnnotation": "Assign DBpedia/Yago classes to column headers via majority voting over cell-entity classes and a granularity tie-break.",
            "predicateAnnotation": "Generate candidate relations between column pairs from DBpedia/Yago links and select via majority voting with thresholds.",
            "nilAnnotation": "Cells with absent/low-confidence candidates are assigned no-annotation (NIL).",
            "entityLinking": {
                "description": "Link cell strings to entities using candidates from Wikitology/LOD with contextual cues and an entity ranker.",
                "candidateGeneration": "Query Wikitology using the cell string plus header and row context; aggregate candidates' classes from DBpedia and Yago.",
                "entityDisambiguation": "Re-rank candidates using similarity/popularity features (Naive Bayes classifier) and joint inference constraints."
            }
        },
        "mainMethod": {
            "type": "hybrid",
            "technique": "Probabilistic graphical model with semantic message passing combined with knowledge-driven heuristics"
        },
        "revision": {
            "type": "fully automated",
            "description": "Joint inference runs automatically; future user-in-the-loop feedback is suggested but not part of the implementation."
        },
        "domain": {
            "domain": "independent",
            "type": ""
        },
        "validation": {
            "goldStandard": "Tables from Web/Wikipedia (Web Manual, Wiki Manual, Web Relation, Wiki Links), with additional manual GS for CTA/CPA.",
            "metrics": [
                "Precision",
                "Recall",
                "F1",
                "Accuracy"
            ]
        },
        "code": "",
        "license": "Not Specified",
        "inputs": {
            "typeOfTable": "HTML tables",
            "tableSources": [
                "web",
                "wiki"
            ]
        },
        "kg": {
            "tripleStore": "DBpedia; Yago; Wikitology",
            "index": "Wikitology and class/property alignments (e.g., PARIS)"
        },
        "output": "RDF",
        "applicationPurpose": "Convert tables into linked data to improve search, interoperability and integration.",
        "userInterfaceTool": "",
        "checkedByAuthor": false,
        "checkedByAi": true,
        "doi": "https://doi.org/10.1007/978-3-642-41335-3_23",
        "citations": [
            {
                "ref": "2009_bizer_dbpedia",
                "title": "DBpedia - A Crystallization Point for the Web of Data"
            },
            {
                "ref": "2008_cafarella_webtables",
                "title": "WebTables: Exploring the Power of Tables on the Web"
            },
            {
                "ref": "2010_limaye_annotating",
                "title": "Annotating and Searching Web Tables Using Entities, Types and Relationships"
            },
            {
                "ref": "2011_venetis_recovering",
                "title": "Recovering Semantics of Tables on the Web"
            },
            {
                "ref": "2011_suchanek_paris",
                "title": "PARIS: Probabilistic Alignment of Relations, Instances, and Schema"
            },
            {
                "ref": "2010_mulwad_using",
                "title": "Using Linked Data to Interpret Tables"
            },
            {
                "ref": "2008_han_rdf123",
                "title": "RDF123: From Spreadsheets to RDF"
            },
            {
                "ref": "2011_syed_creating",
                "title": "Creating and Exploiting a Hybrid Knowledge Base for Linked Data"
            }
        ],
        "uncertainFields": [
            {
                "field": "kg.tripleStore",
                "reason": "The system simultaneously uses multiple LOD sources; the field expects a single value."
            },
            {
                "field": "kg.index",
                "reason": "Wikitology functions as a hybrid KB/index; precise indexing infrastructure is not fully specified."
            },
            {
                "field": "inputs.typeOfTable",
                "reason": "Evaluation mentions Web and Wikipedia tables; \"HTML tables\" vs \"Web tables\" terminology varies."
            },
            {
                "field": "userInterfaceTool",
                "reason": "No UI/tool is described; future user feedback is only proposed."
            },
            {
                "field": "license",
                "reason": "The paper does not specify a software licence; assumed as not specified."
            },
            {
                "field": "supportTasks.subjectDetection",
                "reason": "Primary/subject column identification is discussed conceptually but not clearly implemented."
            },
            {
                "field": "supportTasks.datatypeAnnotation",
                "reason": "Literal columns are detected, but explicit mapping to KG datatypes is not described."
            }
        ]
    },
    {
        "id": "2013_munoz_triplifying",
        "added": "",
        "year": 2013,
        "firstAuthor": "Muñoz",
        "authors": [
            "Emir Muñoz",
            "Aidan Hogan",
            "Alessandra Mileo"
        ],
        "title": "Triplifying Wikipedia's Tables",
        "venue": {
            "type": "workshop",
            "acronym": "LD4IE"
        },
        "nameOfApproach": "",
        "techniqueTags": [
            "ontology-driven"
        ],
        "coreTasks": {
            "cta": false,
            "cpa": false,
            "cea": false,
            "cnea": false
        },
        "supportTasks": {
            "dataPreparation": {
                "description": "Normalises Wikitables into matrices by handling headers, captions, row/col spans, and repairs jagged tables after HTML parsing and cleaning. Extracts internal wiki-links and maps them to DBpedia entities.",
                "spellChecker": "",
                "unitsOfMeasurements": ""
            },
            "columnClassification": "",
            "subjectDetection": "",
            "datatypeAnnotation": "",
            "typeAnnotation": "",
            "predicateAnnotation": "",
            "nilAnnotation": "",
            "entityLinking": {
                "description": "",
                "candidateGeneration": "",
                "entityDisambiguation": ""
            }
        },
        "mainMethod": {
            "type": "unsupervised",
            "technique": "ontology-driven"
        },
        "revision": {
            "type": "fully automated",
            "description": "Extraction of candidate triples is automatic; authors discuss future ML-based post-filtering to improve precision."
        },
        "domain": {
            "domain": "independent",
            "type": ""
        },
        "validation": {
            "goldStandard": "250 randomly selected triples manually labelled by three judges (moderate agreement; ≈52% correct).",
            "metrics": [
                "Precision"
            ]
        },
        "code": "",
        "license": "Not Specified",
        "inputs": {
            "typeOfTable": "HTML tables",
            "tableSources": [
                "wiki"
            ]
        },
        "kg": {
            "tripleStore": "DBpedia",
            "index": "Local indexes/SPARQL lookups over DBpedia; two on-disk lookups per entity pair with LRU caching."
        },
        "output": "RDF",
        "applicationPurpose": "Extract RDF triples from Wikipedia tables to enrich knowledge bases and the Web of Data.",
        "userInterfaceTool": "",
        "checkedByAuthor": "",
        "checkedByAi": true,
        "doi": "",
        "citations": [
            {
                "ref": "2009_bizer_dbpedia",
                "title": "DBpedia – a crystallization point for the Web of Data"
            },
            {
                "ref": "2008_cafarella_webtables",
                "title": "WebTables: exploring the power of tables on the Web"
            },
            {
                "ref": "2013_hoffart_yago2",
                "title": "YAGO2: A spatially and temporally enhanced knowledge base from Wikipedia"
            },
            {
                "ref": "2010_limaye_annotating",
                "title": "Annotating and searching web tables using entities, types and relationships"
            },
            {
                "ref": "2012_das_r2rml",
                "title": "R2RML: RDB to RDF Mapping Language"
            },
            {
                "ref": "2011_mendes_dbpedia",
                "title": "DBpedia Spotlight: shedding light on the web of documents"
            },
            {
                "ref": "2011_venetis_recovering",
                "title": "Recovering semantics of tables on the Web"
            },
            {
                "ref": "2011_crestan_web-scale",
                "title": "Web-scale table census and classification"
            }
        ],
        "uncertainFields": [
            {
                "field": "venue.acronym",
                "reason": "Inferred as LD4IE from workshop context; acronym not explicitly printed in the provided excerpt."
            },
            {
                "field": "techniqueTags[0]",
                "reason": "Classified as ontology-driven since DBpedia guides extraction; alternative labels like rule-based could also apply."
            },
            {
                "field": "mainMethod.technique",
                "reason": "Described generally; no single named algorithm beyond KB lookups."
            },
            {
                "field": "validation.goldStandard",
                "reason": "Summary phrasing condensed; exact wording and scope of the gold standard may vary in the full text."
            },
            {
                "field": "coreTasks.cea",
                "reason": "Entities are mapped via wiki-links, but the paper does not explicitly frame this as the CEA task."
            },
            {
                "field": "coreTasks.cpa",
                "reason": "Relations are mined between table entities, but the paper does not explicitly define this as CPA."
            },
            {
                "field": "doi",
                "reason": "Workshop/CEUR papers often lack a DOI; none was stated in the provided material."
            }
        ]
    },
    {
        "id": "2013_quercini_entity",
        "added": "",
        "year": 2013,
        "firstAuthor": "Quercini",
        "authors": [
            "Gianluca Quercini",
            "Chantal Reynaud"
        ],
        "title": "Entity Discovery and Annotation in Tables",
        "venue": {
            "type": "conference",
            "acronym": "EDBT"
        },
        "nameOfApproach": "",
        "techniqueTags": [
            "SVM",
            "rule-based",
            "ontology-driven"
        ],
        "coreTasks": {
            "cta": false,
            "cpa": false,
            "cea": false,
            "cnea": false
        },
        "supportTasks": {
            "dataPreparation": {
                "description": "Filters cells via regex/patterns and column types; augments queries with spatial clues and geocoding to reduce ambiguity.",
                "spellChecker": "",
                "unitsOfMeasurements": ""
            },
            "columnClassification": "Applies a column-coherence scoring to identify the column most likely to contain entity names of the target type.",
            "subjectDetection": "",
            "datatypeAnnotation": "",
            "typeAnnotation": "",
            "predicateAnnotation": "",
            "nilAnnotation": "",
            "entityLinking": {
                "description": "",
                "candidateGeneration": "",
                "entityDisambiguation": ""
            }
        },
        "mainMethod": {
            "type": "supervised",
            "technique": "SVM",
            "supervision": {
                "type": "supervised"
            }
        },
        "revision": {
            "type": "fully automated",
            "description": "Post-processing removes spurious annotations using column-coherence scores; no human-in-the-loop validation is required."
        },
        "domain": {
            "domain": "independent",
            "type": ""
        },
        "validation": {
            "goldStandard": "Manually annotated 40 GFT tables; Wiki Manual dataset (36 tables).",
            "metrics": [
                "Precision",
                "Recall",
                "F1"
            ]
        },
        "code": "",
        "license": "Not Specified",
        "inputs": {
            "typeOfTable": "Web tables (Google Fusion Tables)",
            "tableSources": [
                "web"
            ]
        },
        "kg": {
            "tripleStore": "DBpedia",
            "index": ""
        },
        "output": "",
        "applicationPurpose": "Discover and annotate previously unseen entities in tables (e.g., POIs) to support data extraction and enrichment for faceted browsing.",
        "userInterfaceTool": "",
        "checkedByAuthor": false,
        "checkedByAi": true,
        "doi": "https://doi.org/10.1145/2452376.2452457",
        "citations": [
            {
                "ref": "2009_bizer_dbpedia",
                "title": "DBpedia - A Crystallization Point for the Web of Data."
            },
            {
                "ref": "2008_cafarella_webtables",
                "title": "WebTables: Exploring the Power of Tables on the Web."
            },
            {
                "ref": "2010_limaye_annotating",
                "title": "Annotating and Searching Web Tables Using Entities, Types and Relationships."
            },
            {
                "ref": "2011_venetis_recovering",
                "title": "Recovering Semantics of Tables on the Web."
            },
            {
                "ref": "2007_suchanek_yago",
                "title": "Yago: a Core of Semantic Knowledge."
            },
            {
                "ref": "2012_wu_probase",
                "title": "Probase: a Probabilistic Taxonomy for Text Understanding."
            },
            {
                "ref": "2010_gonzalez_google",
                "title": "Google Fusion Tables: Web-centered Data Management and Collaboration."
            },
            {
                "ref": "2009_hignette_fuzzy",
                "title": "Fuzzy Annotation of Web Data Tables Driven by a Domain Ontology."
            },
            {
                "ref": "2008_han_rdf123",
                "title": "RDF123: From Spreadsheets to RDF."
            }
        ],
        "uncertainFields": [
            {
                "field": "venue.acronym",
                "reason": "The event is jointly branded EDBT/ICDT; the appropriate acronym could be either \"EDBT\" or \"EDBT/ICDT\"."
            },
            {
                "field": "coreTasks.cea",
                "reason": "The work detects cells that are entity names and types but does not explicitly link them to KG identifiers as required by CEA."
            },
            {
                "field": "kg.tripleStore",
                "reason": "DBpedia is used to build training data rather than as a target KG for output annotations."
            },
            {
                "field": "applicationPurpose",
                "reason": "The algorithm was implemented within a faceted browser project for digital cities, but its primary stated purpose is general entity discovery in tables."
            }
        ]
    },
    {
        "id": "2013_zhang_infogather",
        "added": "",
        "year": 2013,
        "firstAuthor": "Zhang",
        "authors": [
            "Meihui Zhang",
            "Kaushik Chakrabarti"
        ],
        "title": "InfoGather+: Semantic Matching and Annotation of Numeric and Time-Varying Attributes in Web Tables",
        "venue": {
            "type": "conference",
            "acronym": "SIGMOD"
        },
        "nameOfApproach": "InfoGather+",
        "techniqueTags": [
            "rule-based"
        ],
        "coreTasks": {
            "cta": false,
            "cpa": false,
            "cea": false,
            "cnea": false
        },
        "supportTasks": {
            "dataPreparation": {
                "description": "Extract relational HTML tables from web crawl, split to entity–attribute binaries, and build indexes for entities, labels, and graph edges. Hard-coded unit/scale conversion rules and year tokens support matching and conversions. ",
                "spellChecker": "",
                "unitsOfMeasurements": "Pre-defined conversion rules (e.g., USD↔Euro; bil↔mil) and synonyms for units/scales. "
            },
            "columnClassification": "",
            "subjectDetection": "",
            "datatypeAnnotation": "",
            "typeAnnotation": "",
            "predicateAnnotation": "",
            "nilAnnotation": "",
            "entityLinking": {
                "description": "",
                "candidateGeneration": "",
                "entityDisambiguation": ""
            }
        },
        "mainMethod": {
            "type": "unsupervised",
            "technique": "Probabilistic graphical model (Markov random field) with label propagation and rule-based conversions"
        },
        "revision": {
            "type": "fully automated",
            "description": "Joint inference over labels and edges produces results automatically; no user-in-the-loop editing is described. "
        },
        "domain": {
            "domain": "independent",
            "type": ""
        },
        "validation": {
            "goldStandard": "Forbes Global 2000 (2011), Wikipedia list of countries by area, Tax Foundation corporate tax rates, City Mayors 2011 cities. ",
            "metrics": [
                "Precision",
                "Recall",
                "Accuracy"
            ]
        },
        "code": "",
        "license": "Not Specified",
        "inputs": {
            "typeOfTable": "HTML tables",
            "tableSources": [
                "web"
            ]
        },
        "output": "",
        "applicationPurpose": "Entity augmentation for numeric and time-varying attributes using a semantic graph.",
        "userInterfaceTool": "",
        "checkedByAuthor": false,
        "checkedByAi": true,
        "doi": "https://doi.org/10.1145/2463676.2465276",
        "citations": [
            {
                "ref": "2012_yakout_infogather",
                "title": "InfoGather: entity augmentation and attribute discovery by holistic matching with web tables"
            },
            {
                "ref": "2010_limaye_annotating",
                "title": "Annotating and searching web tables using entities, types and relationships"
            },
            {
                "ref": "2012_pimplikar_answering",
                "title": "Answering table queries on the web using column keywords"
            },
            {
                "ref": "2008_cafarella_webtables",
                "title": "WebTables: exploring the power of tables on the web"
            },
            {
                "ref": "2009_cafarella_data",
                "title": "Data integration for the relational web"
            },
            {
                "ref": "2011_venetis_recovering",
                "title": "Recovering semantics of tables on the web"
            }
        ],
        "uncertainFields": [
            {
                "field": "output",
                "reason": "The paper reports augmented table results but does not specify an export format (e.g., CSV/RDF). "
            },
            {
                "field": "userInterfaceTool",
                "reason": "An API is described conceptually, but no concrete UI/tool name is provided. "
            },
            {
                "field": "code",
                "reason": "No repository or downloadable implementation is referenced."
            },
            {
                "field": "mainMethod.type",
                "reason": "Treated as unsupervised since no labelled training data are used; if heuristics are considered supervision, one might argue 'hybrid'. "
            },
            {
                "field": "inputs.typeOfTable",
                "reason": "They refer to 'web/HTML tables'; we selected 'HTML tables' to match the schema wording. "
            },
            {
                "field": "validation.metrics",
                "reason": "Paper explicitly discusses precision/recall and accuracy for components; other metrics like F1 are not clearly reported. "
            },
            {
                "field": "doi",
                "reason": "DOI confirmed via ACM Digital Library."
            }
        ]
    },
    {
        "id": "2014_sekhavat_knowledge",
        "added": "",
        "year": 2014,
        "firstAuthor": "Sekhavat",
        "authors": [
            "Yoones A. Sekhavat",
            "Francesco di Paolo",
            "Denilson Barbosa",
            "Paolo Merialdo"
        ],
        "title": "Knowledge Base Augmentation using Tabular Data",
        "venue": {
            "type": "workshop",
            "acronym": "LDOW"
        },
        "nameOfApproach": "",
        "techniqueTags": [
            "rule-based",
            "ontology-driven"
        ],
        "coreTasks": {
            "cta": false,
            "cpa": true,
            "cea": false,
            "cnea": false
        },
        "supportTasks": {
            "dataPreparation": {
                "description": "Link table entities to a text corpus via exact string matching, then extract and match inter-entity text spans to known relational patterns; patterns are indexed for efficiency.",
                "spellChecker": "",
                "unitsOfMeasurements": ""
            },
            "columnClassification": "",
            "subjectDetection": "",
            "datatypeAnnotation": "",
            "typeAnnotation": "",
            "predicateAnnotation": "Assign a KB relation to the pair of columns using a probabilistic model over textual patterns (rank aggregation vs global ranking) and apply a confidence threshold.",
            "nilAnnotation": "",
            "entityLinking": {
                "description": "",
                "candidateGeneration": "",
                "entityDisambiguation": ""
            }
        },
        "mainMethod": {
            "type": "unsupervised",
            "technique": "rule-based"
        },
        "revision": {
            "type": "fully automated",
            "description": "Pipeline computes posterior probabilities for relations from observed patterns and selects the most probable relation without manual review."
        },
        "domain": {
            "domain": "independent",
            "type": ""
        },
        "validation": {
            "goldStandard": "Ground truth built from YAGO facts matched in the NELL corpus; 25 entity pairs per relation over 23–24 relations; evaluation reports the rank position of the correct relation.",
            "metrics": []
        },
        "code": "",
        "license": "Not Specified",
        "inputs": {
            "typeOfTable": "HTML tables and spreadsheets",
            "tableSources": [
                "web",
                "spreadsheet",
                "wiki"
            ]
        },
        "kg": {
            "tripleStore": "YAGO",
            "index": "Patterns indexed with an in-memory suffix tree; uses the intersection of PATTY patterns and NELL triples (4,357 patterns; 108,699,400 triples)."
        },
        "output": "triples",
        "applicationPurpose": "Augment an existing knowledge base with new facts inferred from tabular data.",
        "userInterfaceTool": "",
        "checkedByAuthor": "",
        "checkedByAi": true,
        "doi": "",
        "citations": [
            {
                "ref": "2008_cafarella_webtables",
                "title": "WebTables: Exploring the power of tables on the web"
            },
            {
                "ref": "2010_limaye_annotating",
                "title": "Annotating and searching web tables using entities, types and relationships"
            },
            {
                "ref": "2011_venetis_recovering",
                "title": "Recovering semantics of tables on the web"
            },
            {
                "ref": "2012_nakashole_patty",
                "title": "Patty: A taxonomy of relational patterns with semantic types"
            },
            {
                "ref": "2007_suchanek_yago",
                "title": "YAGO: A core of semantic knowledge"
            },
            {
                "ref": "2009_mintz_distant",
                "title": "Distant supervision for relation extraction without labeled data"
            },
            {
                "ref": "2013_mulwad_semantic",
                "title": "Semantic Message Passing for Generating Linked Data from Tables"
            },
            {
                "ref": "2013_munoz_triplifying",
                "title": "Triplifying Wikipedia's tables"
            },
            {
                "ref": "2011_yosef_aida",
                "title": "AIDA: An online tool for accurate disambiguation of named entities in text and tables"
            }
        ],
        "uncertainFields": [
            {
                "field": "output",
                "reason": "The paper extracts relational triples but does not specify an output serialisation such as RDF."
            },
            {
                "field": "doi",
                "reason": "A DOI is not provided in the paper; LDOW workshop papers often lack DOIs."
            },
            {
                "field": "code",
                "reason": "A link to data is provided, but no code repository is mentioned."
            },
            {
                "field": "techniqueTags[1]",
                "reason": "Tagged as ontology-driven because relations come from YAGO; this could be debated as the core method is pattern-based."
            }
        ]
    },
    {
        "id": "2014_taheriyan_a",
        "added": "",
        "year": 2014,
        "firstAuthor": "Taheriyan",
        "authors": [
            "Mohsen Taheriyan",
            "Craig A. Knoblock",
            "Pedro Szekely",
            "Jose Luis Ambite"
        ],
        "title": "A Scalable Approach to Learn Semantic Models of Structured Sources",
        "venue": {
            "type": "conference",
            "acronym": "ICSC"
        },
        "nameOfApproach": "",
        "techniqueTags": [
            "CRF",
            "ontology-driven"
        ],
        "coreTasks": {
            "cta": true,
            "cpa": true,
            "cea": false,
            "cnea": false
        },
        "supportTasks": {
            "dataPreparation": {
                "description": "",
                "spellChecker": "",
                "unitsOfMeasurements": ""
            },
            "columnClassification": "",
            "subjectDetection": "",
            "datatypeAnnotation": "Literal attributes are mapped to ontology data properties during semantic typing.",
            "typeAnnotation": "Semantic types for attributes are learned with a CRF over attribute names and sample values.",
            "predicateAnnotation": "Relationships are inferred by building a weighted graph from known models and ontologies and extracting a minimal Steiner tree.",
            "nilAnnotation": "",
            "entityLinking": {
                "description": "",
                "candidateGeneration": "",
                "entityDisambiguation": ""
            }
        },
        "mainMethod": {
            "type": "hybrid",
            "technique": "CRF for semantic typing + Steiner-tree-based graph search using domain ontologies and known models"
        },
        "revision": {
            "type": "semi automated",
            "description": "Produces ranked candidate semantic models automatically; minimal user input may select or correct the final model."
        },
        "domain": {
            "domain": "dependent",
            "type": "cultural heritage / museums"
        },
        "validation": {
            "goldStandard": "Manually created semantic models for 29 museum sources",
            "metrics": [
                "Precision",
                "Recall"
            ]
        },
        "code": "",
        "license": "Not Specified",
        "inputs": {
            "typeOfTable": "Relational databases, spreadsheets, XML/JSON sources and Web APIs",
            "tableSources": [
                "relational",
                "spreadsheet",
                "web"
            ]
        },
        "kg": {
            "tripleStore": "EDM, AAC, SKOS, Dublin Core, FOAF, ORE, ElementsGr2 (domain ontologies)",
            "index": ""
        },
        "output": "RDF",
        "applicationPurpose": "Learn semantic source models for data integration and RDF publishing.",
        "userInterfaceTool": "",
        "checkedByAuthor": "",
        "checkedByAi": true,
        "doi": "https://doi.org/10.1109/ICSC.2014.13",
        "citations": [
            {
                "ref": "2012_doan_principles",
                "title": "Principles of Data Integration"
            },
            {
                "ref": "2011_venetis_recovering",
                "title": "Recovering Semantics of Tables on the Web"
            },
            {
                "ref": "2010_limaye_annotating",
                "title": "Annotating and Searching Web Tables Using Entities, Types and Relationships"
            },
            {
                "ref": "2013_szekely_connecting",
                "title": "Connecting the Smithsonian American Art Museum to the Linked Data Cloud"
            },
            {
                "ref": "2001_lafferty_conditional",
                "title": "Conditional Random Fields: Probabilistic Models for Segmenting and Labeling Sequence Data"
            },
            {
                "ref": "1981_kou_a",
                "title": "A Fast Algorithm for Steiner Trees"
            },
            {
                "ref": "1987_winter_steiner",
                "title": "Steiner Problem in Networks - A survey"
            },
            {
                "ref": "2013_taheriyan_a",
                "title": "A Graph-based Approach to Learn Semantic Descriptions of Data Sources"
            },
            {
                "ref": "2012_knoblock_semi-automatically",
                "title": "Semi-Automatically Mapping Structured Sources into the Semantic Web"
            },
            {
                "ref": "2007_carman_learning",
                "title": "Learning Semantic Definitions of Online Information Sources"
            },
            {
                "ref": "2004_dhamankar_imap",
                "title": "iMAP: Discovering Complex Semantic Matches between Database Schemas"
            }
        ],
        "uncertainFields": [
            {
                "field": "nameOfApproach",
                "reason": "The paper presents an approach but does not introduce a specific system name."
            },
            {
                "field": "userInterfaceTool",
                "reason": "No concrete UI/tool is presented for this method; Karma is cited only in related work."
            },
            {
                "field": "kg.tripleStore",
                "reason": "They use several domain ontologies rather than a single public KG or triplestore."
            },
            {
                "field": "inputs.typeOfTable",
                "reason": "Covers heterogeneous structured sources beyond classic tabular formats; phrasing may be broader than typical table labels."
            },
            {
                "field": "code",
                "reason": "No repository link is provided in the paper; related software may exist elsewhere."
            },
            {
                "field": "validation.goldStandard",
                "reason": "Described as manual models by experts; no specific GS name is given."
            },
            {
                "field": "revision.type",
                "reason": "The text mentions minimal user input but does not formalise an interaction protocol."
            }
        ]
    },
    {
        "id": "2015_bhagavatula_tabel",
        "added": "",
        "year": 2015,
        "firstAuthor": "Bhagavatula",
        "authors": [
            "Chandra Sekhar Bhagavatula",
            "Thanapon Noraset",
            "Doug Downey"
        ],
        "title": "TabEL: Entity Linking in Web Tables",
        "venue": {
            "type": "conference",
            "acronym": "ISWC"
        },
        "nameOfApproach": "TabEL",
        "techniqueTags": [],
        "coreTasks": {
            "cta": false,
            "cpa": false,
            "cea": true,
            "cnea": false
        },
        "supportTasks": {
            "dataPreparation": {
                "description": "Wikipedia and Web tables are normalised to r×c matrices; mentions are identified and priors P(e|s) are estimated from hyperlinks to build features.",
                "spellChecker": "",
                "unitsOfMeasurements": ""
            },
            "columnClassification": "",
            "subjectDetection": "",
            "datatypeAnnotation": "",
            "typeAnnotation": "",
            "predicateAnnotation": "",
            "nilAnnotation": "",
            "entityLinking": {
                "description": "Entity linking over table cells using collective coherence across rows and columns.",
                "candidateGeneration": "For each surface s, candidates are all KB entities with non-zero P(e|s) estimated from Web and Wikipedia hyperlinks.",
                "entityDisambiguation": "Graphical model over row/column cliques with Iterative Classification Algorithm (ICA); a trained logistic-regression ranker selects entities using prior, semantic relatedness and context features."
            }
        },
        "mainMethod": {
            "type": "supervised",
            "technique": "Logistic regression ranking with collective inference (ICA)",
            "supervision": {
                "type": "supervised"
            }
        },
        "revision": {
            "type": "fully automated",
            "description": "Disambiguation is performed automatically without human validation in the loop."
        },
        "domain": {
            "domain": "independent",
            "type": "generic"
        },
        "validation": {
            "goldStandard": "WEB MANUAL, WEB MANUAL-FIXED, WIKI LINKS, WIKI LINKS-RANDOM, TABEL 35K",
            "metrics": [
                "Accuracy",
                "Macro-Precision",
                "Macro-Recall",
                "Macro-F1"
            ]
        },
        "code": "",
        "license": "Not Specified",
        "inputs": {
            "typeOfTable": "Web tables",
            "tableSources": [
                "web",
                "wiki"
            ]
        },
        "kg": {
            "tripleStore": "YAGO",
            "index": ""
        },
        "output": "",
        "applicationPurpose": "Entity linking in Web tables to support semantic table interpretation and downstream KG augmentation.",
        "userInterfaceTool": "",
        "checkedByAuthor": "",
        "checkedByAi": true,
        "doi": "",
        "citations": [
            {
                "ref": "2008_cafarella_webtables",
                "title": "WebTables: Exploring the Power of Tables on the Web"
            },
            {
                "ref": "2010_limaye_annotating",
                "title": "Annotating and Searching Web Tables Using Entities, Types and Relationships"
            },
            {
                "ref": "2013_mulwad_semantic",
                "title": "Semantic Message Passing for Generating Linked Data from Tables"
            },
            {
                "ref": "2007_suchanek_yago",
                "title": "YAGO: A Core of Semantic Knowledge"
            },
            {
                "ref": "2012_hecht_explanatory",
                "title": "Explanatory semantic relatedness and explicit spatialization for exploratory search"
            },
            {
                "ref": "2008_witten_an",
                "title": "An effective, low-cost measure of semantic relatedness obtained from Wikipedia links"
            }
        ],
        "uncertainFields": [
            {
                "field": "doi",
                "reason": "The DOI is not stated in the text available."
            },
            {
                "field": "code",
                "reason": "Authors mention releasing resources, but no code URL is provided."
            },
            {
                "field": "output",
                "reason": "The paper reports entity annotations but no explicit output serialisation format."
            },
            {
                "field": "kg.index",
                "reason": "No specific indexing structure for the KB is described."
            },
            {
                "field": "userInterfaceTool",
                "reason": "No UI or tool front-end is mentioned."
            },
            {
                "field": "inputs.typeOfTable",
                "reason": "They target both Wikipedia and general Web (HTML) tables; 'Web tables' is used generically."
            },
            {
                "field": "techniqueTags",
                "reason": "The approach uses logistic regression and collective inference, which do not map to the allowed tags."
            }
        ]
    },
    {
        "id": "2015_ramnandan_assigning",
        "added": "",
        "year": 2015,
        "firstAuthor": "Ramnandan",
        "authors": [
            "S.K. Ramnandan",
            "Amol Mittal",
            "Craig A. Knoblock",
            "Pedro Szekely"
        ],
        "title": "Assigning Semantic Labels to Data Sources",
        "venue": {
            "type": "conference",
            "acronym": "ESWC"
        },
        "nameOfApproach": "SemanticTyper",
        "techniqueTags": [],
        "coreTasks": {
            "cta": true,
            "cpa": false,
            "cea": false,
            "cnea": false
        },
        "supportTasks": {
            "dataPreparation": {
                "description": "Tokenisation and normalisation of values; stemming and stop-word removal for text; handling of numeric/text mixtures.",
                "spellChecker": "",
                "unitsOfMeasurements": ""
            },
            "columnClassification": "Heuristic detection of numeric vs textual columns based on fraction of numeric values.",
            "subjectDetection": "",
            "datatypeAnnotation": "",
            "typeAnnotation": "Assigns class/property labels using TF-IDF cosine similarity for text and KS test for numeric columns.",
            "predicateAnnotation": "",
            "nilAnnotation": "",
            "entityLinking": {
                "description": "",
                "candidateGeneration": "",
                "entityDisambiguation": ""
            }
        },
        "mainMethod": {
            "type": "supervised",
            "technique": "TF-IDF cosine similarity for textual columns combined with Kolmogorov–Smirnov two-sample test for numeric columns",
            "supervision": {
                "type": "supervised"
            }
        },
        "revision": {
            "type": "fully automated",
            "description": "Produces top-k candidate labels with confidence scores; no user validation stage described."
        },
        "domain": {
            "domain": "independent",
            "type": "generic"
        },
        "validation": {
            "goldStandard": "Europeana Data Model (museum), DBpedia City properties, and weather/phone/flight datasets",
            "metrics": [
                "MRR"
            ]
        },
        "code": "https://github.com/usc-isi-i2/eswc-2015-semantic-typing",
        "license": "Apache License 2.0",
        "inputs": {
            "typeOfTable": "Web tables and heterogeneous sources (tables, XML, JSON)",
            "tableSources": [
                "web",
                "wiki"
            ]
        },
        "kg": {
            "tripleStore": "DBpedia; Europeana Data Model",
            "index": "Apache Lucene used to index textual label documents"
        },
        "output": "",
        "applicationPurpose": "Automated semantic labelling of data source attributes to support data integration.",
        "userInterfaceTool": "",
        "checkedByAuthor": "",
        "checkedByAi": true,
        "doi": "https://doi.org/10.1007/978-3-319-18818-8_25",
        "citations": [
            {
                "ref": "2012_goel_exploiting",
                "title": "Exploiting structure within data for accurate labeling using conditional random fields"
            },
            {
                "ref": "2010_limaye_annotating",
                "title": "Annotating and searching web tables using entities, types and relationships"
            },
            {
                "ref": "2011_venetis_recovering",
                "title": "Recovering semantics of tables on the web"
            },
            {
                "ref": "2013_stonebraker_data",
                "title": "Data curation at scale: the Data Tamer system"
            },
            {
                "ref": "2009_ambite_automatically",
                "title": "Automatically Constructing Semantic Web Services from Online Sources"
            }
        ],
        "uncertainFields": [
            {
                "field": "techniqueTags",
                "reason": "The paper does not use any of the allowed tag categories (e.g., SVM/CRF/transformer/rule-based) as core techniques."
            },
            {
                "field": "output",
                "reason": "No serialisation format (e.g., RDF/JSON-LD) is specified; the system outputs label predictions only."
            },
            {
                "field": "kg.tripleStore",
                "reason": "DBpedia is used; Europeana Data Model is an ontology rather than a triple store, but both are cited as resources."
            },
            {
                "field": "kg.index",
                "reason": "Lucene indexes training ‘documents’ of label values, not a KG index; mapping this to the KG 'index' field may be approximate."
            },
            {
                "field": "inputs.typeOfTable",
                "reason": "They consider generic data sources (tables, XML, JSON); phrasing may not match a single specific table type."
            },
            {
                "field": "license",
                "reason": "The paper shares a GitHub repo but the licence is not specified in the paper text."
            },
            {
                "field": "applicationPurpose",
                "reason": "Purpose is inferred from motivation; no explicit application label is given."
            }
        ]
    },
    {
        "id": "2015_ritze_matching",
        "added": "",
        "year": 2015,
        "firstAuthor": "Ritze",
        "authors": [
            "Dominique Ritze",
            "Oliver Lehmberg",
            "Christian Bizer"
        ],
        "title": "Matching HTML Tables to DBpedia",
        "venue": {
            "type": "conference",
            "acronym": "WIMS"
        },
        "nameOfApproach": "T2K Match",
        "techniqueTags": [
            "ontology-driven",
            "rule-based"
        ],
        "coreTasks": {
            "cta": true,
            "cpa": true,
            "cea": true,
            "cnea": false
        },
        "supportTasks": {
            "dataPreparation": {
                "description": "Clean HTML, split value lists, lower-case and normalise values; detect headers, entity-label column, and data types.",
                "spellChecker": "",
                "unitsOfMeasurements": "Normalisation of units via ~200 handcrafted conversion rules (e.g., 8mi2 → 20.72 million m2)."
            },
            "columnClassification": "",
            "subjectDetection": "Heuristic to detect the entity-label attribute: string column with most unique values (tie → left-most).",
            "datatypeAnnotation": "Detect column data types (string, numeric, timestamp, coordinate) using ~100 regexes to select similarity measures.",
            "typeAnnotation": "Aggregate property scores to select table-to-class correspondences.",
            "predicateAnnotation": "Duplicate-based schema matching aggregates value similarities to map attributes to DBpedia properties.",
            "nilAnnotation": "",
            "entityLinking": {
                "description": "Iterative instance–schema matching to select a DBpedia resource per row with thresholding.",
                "candidateGeneration": "Search DBpedia labels (Lucene), keep top-k, refine with class constraints; handle surface forms and redirects.",
                "entityDisambiguation": "Iteratively weight value similarities with property/class scores and pick the top candidate."
            }
        },
        "mainMethod": {
            "type": "unsupervised",
            "technique": "rule-based iterative schema/instance matching"
        },
        "revision": {
            "type": "fully automated",
            "description": "Outputs are produced automatically without user interaction; evaluation is performed against a gold standard."
        },
        "domain": {
            "domain": "independent",
            "type": "cross-domain web tables"
        },
        "validation": {
            "goldStandard": "T2D Gold Standard (1,748 tables schema-level; 233 tables entity-level; 26,124 row-to-entity; 7,983 column-to-property).",
            "metrics": [
                "Precision",
                "Recall",
                "F1"
            ]
        },
        "code": "http://dws.informatik.uni-mannheim.de/en/research/T2K",
        "license": "Not Specified",
        "inputs": {
            "typeOfTable": "HTML tables",
            "tableSources": [
                "web"
            ]
        },
        "kg": {
            "tripleStore": "DBpedia",
            "index": "Lucene"
        },
        "output": "",
        "applicationPurpose": "Knowledge base extension (slot filling).",
        "userInterfaceTool": "",
        "checkedByAuthor": "",
        "checkedByAi": true,
        "doi": "https://doi.org/10.1145/2797115.2797118",
        "citations": [
            {
                "ref": "2008_cafarella_webtables",
                "title": "WebTables: Exploring the Power of Tables on the Web"
            },
            {
                "ref": "2010_limaye_annotating",
                "title": "Annotating and Searching Web Tables Using Entities, Types and Relationships"
            },
            {
                "ref": "2011_venetis_recovering",
                "title": "Recovering Semantics of Tables on the Web"
            },
            {
                "ref": "2014_dong_knowledge",
                "title": "Knowledge Vault: A Web-scale Approach to Probabilistic Knowledge Fusion"
            },
            {
                "ref": "2011_suchanek_paris",
                "title": "Paris: Probabilistic alignment of Relations, Instances, and Schema"
            },
            {
                "ref": "2012_wang_understanding",
                "title": "Understanding Tables on the Web"
            },
            {
                "ref": "2014_zhang_towards",
                "title": "Towards efficient and effective semantic table interpretation"
            },
            {
                "ref": "2014_gupta_biperpedia",
                "title": "Biperpedia: An Ontology for Search Applications"
            },
            {
                "ref": "2012_yakout_infogather",
                "title": "InfoGather: Entity Augmentation and Attribute Discovery by Holistic Matching with Web Tables"
            }
        ],
        "uncertainFields": [
            {
                "field": "code",
                "reason": "The paper references a project page with downloads; explicit source code availability is not clearly stated."
            },
            {
                "field": "output",
                "reason": "The output format of correspondences is not specified (e.g., RDF/CSV), only that correspondences are produced."
            },
            {
                "field": "userInterfaceTool",
                "reason": "No UI or tool front-end is described; likely a research prototype without a public UI."
            },
            {
                "field": "coreTasks.cnea",
                "reason": "The gold standard marks some rows as not matchable, but the approach does not explicitly perform NIL prediction."
            },
            {
                "field": "techniqueTags",
                "reason": "Classed as ontology-driven and rule-based based on KB-driven, heuristic matching; no explicit ML model is reported."
            }
        ]
    },
    {
        "id": "2016_ermilov_taipan",
        "added": "",
        "year": 2016,
        "firstAuthor": "Ermilov",
        "authors": [
            "Ivan Ermilov",
            "Axel-Cyrille Ngonga Ngomo"
        ],
        "title": "TAIPAN: Automatic Property Mapping for Tabular Data",
        "venue": {
            "type": "conference",
            "acronym": "EKAW"
        },
        "nameOfApproach": "Taipan",
        "techniqueTags": [
            "rule-based",
            "SVM",
            "ontology-driven"
        ],
        "coreTasks": {
            "cta": false,
            "cpa": true,
            "cea": false,
            "cnea": false
        },
        "supportTasks": {
            "dataPreparation": {
                "description": "",
                "spellChecker": "",
                "unitsOfMeasurements": ""
            },
            "columnClassification": "",
            "subjectDetection": "Identifies the subject column using support (entity disambiguation via AGDISTIS) and connectivity features, then classifies columns with learned models. ",
            "datatypeAnnotation": "",
            "typeAnnotation": "",
            "predicateAnnotation": "Maps binary relations from the subject column to DBpedia predicates using triple-pattern queries and LOV-derived seed properties with probabilistic ranking. ",
            "nilAnnotation": "",
            "entityLinking": {
                "description": "",
                "candidateGeneration": "",
                "entityDisambiguation": ""
            }
        },
        "mainMethod": {
            "type": "hybrid",
            "technique": "SVM + rule-based"
        },
        "revision": {
            "type": "fully automated",
            "description": "Automatic scoring and selection of subject columns and properties; no interactive correction is required. "
        },
        "domain": {
            "domain": "independent",
            "type": "cross-domain"
        },
        "validation": {
            "goldStandard": "T2D* (manually curated from T2D) and DBD (DBpedia Table Dataset). ",
            "metrics": [
                "Precision",
                "Recall",
                "F1"
            ]
        },
        "code": "https://github.com/aksw/taipan",
        "license": "GNU Affero General Public License v3.0",
        "inputs": {
            "typeOfTable": "Web tables",
            "tableSources": [
                "web",
                "wiki"
            ]
        },
        "kg": {
            "tripleStore": "DBpedia",
            "index": "LOV reverse index over rdfs:label and rdfs:comment with score threshold. "
        },
        "output": "RDF",
        "applicationPurpose": "Table expansion and knowledge base augmentation. ",
        "userInterfaceTool": "",
        "checkedByAuthor": "",
        "checkedByAi": true,
        "doi": "https://doi.org/10.1007/978-3-319-49004-5_11",
        "citations": [
            {
                "ref": "2015_ritze_matching",
                "title": "Matching HTML tables to DBpedia"
            },
            {
                "ref": "2011_venetis_recovering",
                "title": "Recovering semantics of tables on the web"
            },
            {
                "ref": "2014_usbeck_agdistis",
                "title": "AGDISTIS - graph-based disambiguation of named entities using linked data"
            },
            {
                "ref": "2010_limaye_annotating",
                "title": "Annotating and searching web tables using entities, types and relationships"
            }
        ],
        "uncertainFields": [
            {
                "field": "mainMethod.technique",
                "reason": "The paper evaluates several classifiers (e.g., SVM, decision tree) for subject detection and uses rule-based scoring for property mapping; summarised here as 'SVM + rule-based'. "
            },
            {
                "field": "inputs.tableSources",
                "reason": "Includes 'wiki' because one evaluation dataset is generated from DBpedia; the main corpus is web tables. "
            },
            {
                "field": "kg.index",
                "reason": "Described as LOV reverse index with a score threshold; exact indexing details are brief. "
            },
            {
                "field": "license",
                "reason": "License is not stated in the paper; repository license not verified in the text. "
            },
            {
                "field": "userInterfaceTool",
                "reason": "No UI for Taipan is mentioned; only annotation interfaces for gold-standard curation are referenced. "
            },
            {
                "field": "output",
                "reason": "Approach outputs RDF triples conceptually, but no explicit serialisation format is specified. "
            }
        ]
    },
    {
        "id": "2016_neumaier_multi-level",
        "added": "",
        "year": 2016,
        "firstAuthor": "Neumaier",
        "authors": [
            "Sebastian Neumaier",
            "Jürgen Umbrich",
            "Josiane Xavier Parreira",
            "Axel Polleres"
        ],
        "title": "Multi-level semantic labelling of numerical values",
        "venue": {
            "type": "conference",
            "acronym": "ISWC"
        },
        "nameOfApproach": "",
        "techniqueTags": [
            "clustering",
            "ontology-driven"
        ],
        "coreTasks": {
            "cta": false,
            "cpa": false,
            "cea": false,
            "cnea": false
        },
        "supportTasks": {
            "dataPreparation": {
                "description": "Constructs a background knowledge graph from DBpedia, grouping numerical properties by subjects and contexts, and computes descriptive statistics/KS distances.",
                "spellChecker": "",
                "unitsOfMeasurements": ""
            },
            "columnClassification": "",
            "subjectDetection": "",
            "datatypeAnnotation": "",
            "typeAnnotation": "",
            "predicateAnnotation": "",
            "nilAnnotation": "",
            "entityLinking": {
                "description": "",
                "candidateGeneration": "",
                "entityDisambiguation": ""
            }
        },
        "mainMethod": {
            "type": "unsupervised",
            "technique": "k-nearest neighbours over a hierarchically clustered background graph using Kolmogorov–Smirnov distance and descriptive statistics"
        },
        "revision": {
            "type": "fully automated",
            "description": "Predictions are produced automatically by nearest neighbour ranking without user intervention."
        },
        "domain": {
            "domain": "independent",
            "type": ""
        },
        "validation": {
            "goldStandard": "DBpedia 3.9 dump with 50 frequent numerical properties; large-scale test nodes derived from held-out subjects",
            "metrics": [
                "Accuracy",
                "Top-1 Accuracy",
                "Top-k Accuracy"
            ]
        },
        "code": "",
        "license": "Not Specified",
        "inputs": {
            "typeOfTable": "CSV tables",
            "tableSources": [
                "wiki",
                "gov-open-data"
            ]
        },
        "kg": {
            "tripleStore": "DBpedia",
            "index": ""
        },
        "output": "",
        "applicationPurpose": "Semantic labelling of numerical columns and their contexts in tabular data",
        "userInterfaceTool": "",
        "checkedByAuthor": "",
        "checkedByAi": true,
        "doi": "",
        "citations": [
            {
                "ref": "2013_adelfio_schema",
                "title": "Schema extraction for tabular data on the web"
            },
            {
                "ref": "2015_ramnandan_assigning",
                "title": "Assigning semantic labels to data sources"
            },
            {
                "ref": "2015_tandy_generating",
                "title": "Generating RDF from tabular data on the web"
            },
            {
                "ref": "2014_fleischhacker_detecting",
                "title": "Detecting errors in numerical linked data using cross-checked outlier detection"
            },
            {
                "ref": "2014_wienand_detecting",
                "title": "Detecting incorrect numerical data in DBpedia"
            },
            {
                "ref": "2014_zhang_towards",
                "title": "Towards efficient and effective semantic table interpretation"
            }
        ],
        "uncertainFields": [
            {
                "field": "doi",
                "reason": "The DOI is not stated in the available text."
            },
            {
                "field": "output",
                "reason": "No explicit output serialisation or format is described."
            },
            {
                "field": "coreTasks.cta",
                "reason": "The paper labels numeric columns with properties and contexts but does not explicitly frame this as CTA."
            },
            {
                "field": "coreTasks.cpa",
                "reason": "Although properties are predicted, the paper does not present this as CPA in the STI sense."
            },
            {
                "field": "inputs.typeOfTable",
                "reason": "The approach is demonstrated on CSV-like Open Data and DBpedia-derived values; exact table type wording is inferred."
            },
            {
                "field": "userInterfaceTool",
                "reason": "A prototype is mentioned but no UI/tool is specified."
            },
            {
                "field": "kg.index",
                "reason": "Indexing details are not provided."
            },
            {
                "field": "license",
                "reason": "No license information is specified."
            },
            {
                "field": "validation.goldStandard",
                "reason": "Summarised from the description; no formal GS name is given."
            },
            {
                "field": "mainMethod.technique",
                "reason": "Technique phrasing paraphrases the described method."
            }
        ]
    },
    {
        "id": "2016_pham_semantic",
        "added": "",
        "year": 2016,
        "firstAuthor": "Pham",
        "authors": [
            "Minh Pham",
            "Suresh Alse",
            "Craig A. Knoblock",
            "Pedro Szekely"
        ],
        "title": "Semantic labeling: A domain-independent approach",
        "venue": {
            "type": "conference",
            "acronym": "ISWC"
        },
        "nameOfApproach": "DSL (Domain-independent Semantic Labeler) ",
        "techniqueTags": [],
        "coreTasks": {
            "cta": true,
            "cpa": true,
            "cea": false,
            "cnea": false
        },
        "supportTasks": {
            "dataPreparation": {
                "description": "Computes similarity features over attribute names and values (e.g., Jaccard, TF-IDF cosine, numeric Jaccard, KS test, Mann–Whitney histogram) with adjustments for text/number mixes. ",
                "spellChecker": "",
                "unitsOfMeasurements": ""
            },
            "columnClassification": "",
            "subjectDetection": "",
            "datatypeAnnotation": "",
            "typeAnnotation": "Assigns each column a KG class as part of a <class, property> semantic type. ",
            "predicateAnnotation": "Matches columns to KG properties (property matching) using learned similarity-based ranking. ",
            "nilAnnotation": "",
            "entityLinking": {
                "description": "",
                "candidateGeneration": "",
                "entityDisambiguation": ""
            }
        },
        "mainMethod": {
            "type": "supervised",
            "technique": "Logistic Regression over similarity metrics",
            "supervision": {
                "type": "supervised"
            }
        },
        "revision": {
            "type": "fully automated",
            "description": "Fully automatic ranking of top-k semantic types using classifier probabilities; no user-in-the-loop editing. "
        },
        "domain": {
            "domain": "independent",
            "type": "generic"
        },
        "validation": {
            "goldStandard": "Evaluated on city, museum, soccer, and weather datasets; additionally on the T2D Gold Standard for property matching. ",
            "metrics": [
                "MRR",
                "F1"
            ]
        },
        "code": "https://github.com/minhptx/iswc-2016-semantic-labeling.git",
        "license": "Apache License 2.0",
        "inputs": {
            "typeOfTable": "Web tables, spreadsheets, and relational tables",
            "tableSources": [
                "web",
                "spreadsheet",
                "relational"
            ]
        },
        "kg": {
            "tripleStore": "DBpedia",
            "index": ""
        },
        "output": "",
        "applicationPurpose": "Automatic semantic labelling of table attributes for heterogeneous data integration. ",
        "userInterfaceTool": "",
        "checkedByAuthor": "",
        "checkedByAi": true,
        "doi": "https://doi.org/10.1007/978-3-319-46523-4_27",
        "citations": [
            {
                "ref": "2015_ramnandan_assigning",
                "title": "Assigning Semantic Labels to Data Sources"
            },
            {
                "ref": "2015_ritze_matching",
                "title": "Matching HTML Tables to DBpedia"
            },
            {
                "ref": "2010_limaye_annotating",
                "title": "Annotating and Searching Web Tables Using Entities, Types and Relationships"
            },
            {
                "ref": "2013_mulwad_semantic",
                "title": "Semantic message passing for generating linked data from tables"
            },
            {
                "ref": "2009_craswell_mean",
                "title": "Mean reciprocal rank"
            },
            {
                "ref": "2001_breiman_random",
                "title": "Random Forests"
            }
        ],
        "uncertainFields": [
            {
                "field": "coreTasks.cpa",
                "reason": "The paper performs property matching for columns but does not explicitly model inter-column relations as in some CPA definitions; marked true due to property matching focus. "
            },
            {
                "field": "output",
                "reason": "No explicit serialisation format (e.g., RDF/CSV) is specified for outputs; system reports ranked labels. "
            },
            {
                "field": "license",
                "reason": "The paper does not state a licence; the repository’s licence was not confirmed here. "
            },
            {
                "field": "inputs.typeOfTable",
                "reason": "Examples include relational databases, web tables and spreadsheets; exact supported formats may extend beyond those explicitly described. "
            },
            {
                "field": "kg.index",
                "reason": "Indexing mechanism is not specified; only the use of DBpedia is clearly mentioned. "
            }
        ]
    },
    {
        "id": "2016_taheriyan_leveraging",
        "added": "",
        "year": 2016,
        "firstAuthor": "Taheriyan",
        "authors": [
            "Mohsen Taheriyan",
            "Craig A. Knoblock",
            "Pedro Szekely",
            "José Luis Ambite"
        ],
        "title": "Leveraging Linked Data to Discover Semantic Relations Within Data Sources",
        "venue": {
            "type": "conference",
            "acronym": "ISWC"
        },
        "nameOfApproach": "Karma",
        "techniqueTags": [
            "ontology-driven"
        ],
        "coreTasks": {
            "cta": false,
            "cpa": true,
            "cea": false,
            "cnea": false
        },
        "supportTasks": {
            "dataPreparation": {
                "description": "Assumes columns are already assigned semantic labels; no specific preprocessing described.",
                "spellChecker": "",
                "unitsOfMeasurements": ""
            },
            "columnClassification": "",
            "subjectDetection": "",
            "datatypeAnnotation": "",
            "typeAnnotation": "",
            "predicateAnnotation": "Infers relations between columns using LOD graph-pattern mining combined with ontology paths.",
            "nilAnnotation": "",
            "entityLinking": {
                "description": "",
                "candidateGeneration": "",
                "entityDisambiguation": ""
            }
        },
        "mainMethod": {
            "type": "unsupervised",
            "technique": "Ontology-driven graph pattern mining over Linked Open Data"
        },
        "revision": {
            "type": "fully automated",
            "description": "Automatically generates and ranks candidate semantic models; can be refined by users in Karma if desired."
        },
        "domain": {
            "domain": "dependent",
            "type": "Cultural heritage (CIDOC-CRM/EDM) and schema.org extension (weapons ads)"
        },
        "validation": {
            "goldStandard": "Gold-standard semantic models for 29 museum sources (CIDOC-CRM/EDM) and 15 weapons-ad tables; leave-one-out evaluation; datasets on GitHub.",
            "metrics": [
                "Precision",
                "Recall"
            ]
        },
        "code": "https://github.com/usc-isi-i2/Web-Karma",
        "license": "Apache License 2.0",
        "inputs": {
            "typeOfTable": "CSV, XML, JSON",
            "tableSources": [
                "web"
            ]
        },
        "kg": {
            "tripleStore": "CIDOC-CRM; EDM; schema.org",
            "index": "Patterns mined from Linked Open Data stored in Virtuoso; ontology paths used for graph expansion."
        },
        "output": "RDF",
        "applicationPurpose": "Automatically infer relations between columns to build complete semantic models.",
        "userInterfaceTool": "Karma (Web UI)",
        "checkedByAuthor": "",
        "checkedByAi": true,
        "doi": "https://doi.org/10.1007/978-3-319-46523-4_33",
        "citations": [
            {
                "ref": "2016_schaible_termpicker",
                "title": "TermPicker: Enabling the Reuse of Vocabulary Terms by Exploiting Data from the Linked Open Data Cloud"
            },
            {
                "ref": "2013_mulwad_semantic",
                "title": "Semantic Message Passing for Generating Linked Data from Tables"
            },
            {
                "ref": "2010_limaye_annotating",
                "title": "Annotating and Searching Web Tables Using Entities, Types and Relationships"
            },
            {
                "ref": "2011_venetis_recovering",
                "title": "Recovering Semantics of Tables on the Web"
            },
            {
                "ref": "2016_pham_semantic",
                "title": "Semantic Labeling: A Domain-independent Approach"
            },
            {
                "ref": "2012_knoblock_semi-automatically",
                "title": "Semi-Automatically Mapping Structured Sources into the Semantic Web"
            },
            {
                "ref": "2015_taheriyan_leveraging",
                "title": "Leveraging Linked Data to Infer Semantic Relations within Structured Sources"
            },
            {
                "ref": "2016_taheriyan_learning",
                "title": "Learning the Semantics of Structured Data Sources"
            }
        ],
        "uncertainFields": [
            {
                "field": "nameOfApproach",
                "reason": "The paper presents a method integrated into the Karma system but does not brand the method with a unique name; using the tool name may be debatable."
            },
            {
                "field": "inputs.tableSources",
                "reason": "Sources are described as CSV/XML/JSON from museums; assumed to be web-hosted, but exact provenance is not exhaustively specified."
            },
            {
                "field": "kg.tripleStore",
                "reason": "They rely on domain ontologies (CIDOC-CRM/EDM) and a schema.org extension plus Smithsonian LOD; representing these as a single 'tripleStore' is approximate."
            },
            {
                "field": "output",
                "reason": "The method outputs semantic models; RDF is typical via Karma but not stated as a direct serialized output of the algorithm."
            },
            {
                "field": "userInterfaceTool",
                "reason": "The algorithm is implemented within Karma; whether a specific UI was used for this paper's experiments is implied rather than explicitly detailed."
            }
        ]
    },
    {
        "id": "2016_taheriyan_learning",
        "added": "",
        "year": 2016,
        "firstAuthor": "Taheriyan",
        "authors": [
            "Mohsen Taheriyan",
            "Craig A. Knoblock",
            "Pedro Szekely",
            "José Luis Ambite"
        ],
        "title": "Learning the semantics of structured data sources",
        "venue": {
            "type": "journal",
            "acronym": "Web Semantics"
        },
        "nameOfApproach": "Karma",
        "techniqueTags": [
            "ontology-driven"
        ],
        "coreTasks": {
            "cta": true,
            "cpa": true,
            "cea": false,
            "cnea": false
        },
        "supportTasks": {
            "dataPreparation": {
                "description": "Uses sample data from the new source and merges known semantic models and ontology paths; no specific normalisation steps are detailed.",
                "spellChecker": "",
                "unitsOfMeasurements": ""
            },
            "columnClassification": "",
            "subjectDetection": "",
            "datatypeAnnotation": "Attributes with literal values are typed using pairs ⟨class, data property⟩ inferred during semantic labelling.",
            "typeAnnotation": "Semantic labelling assigns candidate semantic types (classes or class/property pairs) to source attributes.",
            "predicateAnnotation": "Relationships between attributes are inferred via a weighted graph built from known models and ontology paths, selecting minimum-cost (Steiner) trees.",
            "nilAnnotation": "",
            "entityLinking": {
                "description": "",
                "candidateGeneration": "",
                "entityDisambiguation": ""
            }
        },
        "mainMethod": {
            "type": "hybrid",
            "technique": "Semantic labelling (supervised) + ontology-driven graph search with top-k Steiner trees"
        },
        "revision": {
            "type": "semi automated",
            "description": "System suggests ranked semantic models; users can refine/correct them in the Karma UI to improve future predictions."
        },
        "domain": {
            "domain": "dependent",
            "type": "cultural heritage / museum"
        },
        "validation": {
            "goldStandard": "29 museum sources with expert-crafted gold-standard models using EDM and CIDOC-CRM",
            "metrics": [
                "Precision",
                "Recall",
                "MRR"
            ]
        },
        "code": "https://github.com/usc-isi-i2/Web-Karma",
        "license": "Apache License 2.0",
        "inputs": {
            "typeOfTable": "CSV, XML, JSON, relational tables",
            "tableSources": [
                "web",
                "spreadsheet",
                "relational"
            ]
        },
        "kg": {
            "tripleStore": "EDM; CIDOC-CRM; FOAF; DBpedia; SKOS; DCMI Terms; FRBR; ORE; ElementsGr2",
            "index": ""
        },
        "output": "RDF",
        "applicationPurpose": "Automatic publication of structured sources as RDF into knowledge graphs; supports source discovery, information integration, and service composition.",
        "userInterfaceTool": "Karma (Web UI)",
        "checkedByAuthor": "",
        "checkedByAi": true,
        "doi": "https://doi.org/10.1016/j.websem.2015.12.003",
        "citations": [
            {
                "ref": "2015_krishnamurthy_assigning",
                "title": "Assigning semantic labels to data sources"
            },
            {
                "ref": "2012_das_r2rml",
                "title": "R2RML: RDB to RDF Mapping Language"
            },
            {
                "ref": "2013_szekely_connecting",
                "title": "Connecting the Smithsonian American art museum to the linked data cloud"
            }
        ],
        "uncertainFields": [
            {
                "field": "venue.acronym",
                "reason": "The journal’s full name is given as “Web Semantics: Science, Services and Agents on the World Wide Web”; the common short form/acronym isn’t explicitly stated, so “Web Semantics” is used. "
            },
            {
                "field": "coreTasks.cta",
                "reason": "The paper does not use the CTA label; we mapped their ‘semantic labelling’ of attributes to CTA by analogy. "
            },
            {
                "field": "coreTasks.cpa",
                "reason": "They infer relationships between attributes via ontology paths and Steiner trees, which aligns with CPA though the term isn’t used. "
            },
            {
                "field": "kg.tripleStore",
                "reason": "They model against multiple domain ontologies (EDM, CIDOC-CRM, SKOS, DCMI Terms, FOAF, FRBR, ORE, ElementsGr2) and show an example with DBpedia/FOAF; no single KG/triple store is prescribed. "
            },
            {
                "field": "inputs.tableSources",
                "reason": "Sources include relational databases, spreadsheets, XML/JSON and Web APIs; we mapped these to the closest allowed categories (web, spreadsheet, relational). "
            },
            {
                "field": "nameOfApproach",
                "reason": "The approach is implemented within the Karma framework; no separate unique method name is introduced, so we used “Karma”. "
            },
            {
                "field": "license",
                "reason": "No explicit software licence name is stated in the paper; thus set to “Not Specified”. "
            },
            {
                "field": "code",
                "reason": "The paper states the approach is integrated into the open-source Karma project; the linked repository is assumed to host the relevant code. "
            }
        ]
    },
    {
        "id": "2017_efthymiou_matching",
        "added": "",
        "year": 2017,
        "firstAuthor": "Efthymiou",
        "authors": [
            "Vasilis Efthymiou",
            "Oktie Hassanzadeh",
            "Mariano Rodriguez-Muro",
            "Vassilis Christophides"
        ],
        "title": "Matching Web Tables with Knowledge Base Entities: From Entity Lookups to Entity Embeddings",
        "venue": {
            "type": "conference",
            "acronym": "ISWC"
        },
        "nameOfApproach": "FactBase lookup",
        "techniqueTags": [
            "rule-based",
            "embeddings",
            "ontology-driven"
        ],
        "coreTasks": {
            "cta": false,
            "cpa": false,
            "cea": true,
            "cnea": false
        },
        "supportTasks": {
            "dataPreparation": {
                "description": "Heuristic label/column detection and refined/loose lookups with edit-distance tolerance and frequent description tokens.",
                "spellChecker": "",
                "unitsOfMeasurements": ""
            },
            "columnClassification": "Detect label and reference columns heuristically; mark potential reference (entity) columns via sampling lookups.",
            "subjectDetection": "Identify the label column as the leftmost column with maximum distinct non-numeric values.",
            "datatypeAnnotation": "",
            "typeAnnotation": "",
            "predicateAnnotation": "",
            "nilAnnotation": "",
            "entityLinking": {
                "description": "Unsupervised entity linking via lookup refinement, relation-aware constraints, and global disambiguation with entity embeddings.",
                "candidateGeneration": "DBpedia Lookup and a generic KB index (FactBase) over Wikidata labels/descriptions.",
                "entityDisambiguation": "Weighted PageRank over embedding-similarity graphs; relation-constrained refined lookups when applicable."
            }
        },
        "mainMethod": {
            "type": "hybrid",
            "technique": "rule-based + embeddings"
        },
        "revision": {
            "type": "fully automated",
            "description": "No human-in-the-loop; methods run end-to-end (MapReduce-based experiments and automatic evaluation). "
        },
        "domain": {
            "domain": "independent",
            "type": "general web tables"
        },
        "validation": {
            "goldStandard": "Evaluated on T2D, Limaye, and a new large Wikipedia tables gold standard; metrics reported as micro-averaged. ",
            "metrics": [
                "Precision",
                "Recall",
                "F1"
            ]
        },
        "code": "http://ibm.biz/webtables",
        "license": "Not Specified",
        "inputs": {
            "typeOfTable": "Web tables (HTML tables)",
            "tableSources": [
                "web",
                "wiki"
            ]
        },
        "kg": {
            "tripleStore": "DBpedia; Wikidata",
            "index": "FactBase generic index; DBpedia Lookup"
        },
        "output": "",
        "applicationPurpose": "Unsupervised annotation of web tables and empirical benchmarking of methods for KB augmentation/search. ",
        "userInterfaceTool": "",
        "checkedByAuthor": "",
        "checkedByAi": true,
        "doi": "https://doi.org/10.1007/978-3-319-68288-4_16",
        "citations": [
            {
                "ref": "2015_ritze_matching",
                "title": "Matching HTML tables to DBpedia"
            },
            {
                "ref": "2010_limaye_annotating",
                "title": "Annotating and searching web tables using entities, types and relationships"
            },
            {
                "ref": "2015_bhagavatula_tabel",
                "title": "TabEL: entity linking in web tables"
            },
            {
                "ref": "2016_zwicklbauer_doser",
                "title": "DoSeR - a knowledge-base-agnostic framework for entity disambiguation using semantic embeddings"
            },
            {
                "ref": "jimenez-ruiz2011logmap",
                "title": "LogMap: logic-based and scalable ontology matching"
            },
            {
                "ref": "2011_suchanek_paris",
                "title": "PARIS: probabilistic alignment of relations, instances, and schema"
            }
        ],
        "uncertainFields": [
            {
                "field": "nameOfApproach",
                "reason": "Paper evaluates multiple methods (lookup, embeddings, ontology matching) and two hybrids; selecting only “FactBase lookup” may not represent the whole contribution."
            },
            {
                "field": "kg.tripleStore",
                "reason": "Both DBpedia and Wikidata are used; the exact primary KB per experiment varies."
            },
            {
                "field": "code",
                "reason": "The provided URL hosts datasets/implementation details; it may not be a traditional source-code repository."
            },
            {
                "field": "output",
                "reason": "No explicit serialisation format (e.g., RDF/JSON-LD) is stated; the work reports annotations and metrics rather than an exported file format."
            },
            {
                "field": "license",
                "reason": "No explicit software licence is stated for the implementations."
            },
            {
                "field": "supportTasks.columnClassification",
                "reason": "Their heuristics target label/reference column detection rather than a full NE vs LIT column classifier."
            }
        ]
    },
    {
        "id": "2017_ell_towards",
        "added": "",
        "year": 2017,
        "firstAuthor": "Ell",
        "authors": [
            "Basil Ell",
            "Sherzod Hakimov",
            "Philipp Braukmann",
            "Lorenzo Cazzoli",
            "Fabian Kaupmann",
            "Amerigo Mancino",
            "Junaid Altaf Memon",
            "Kai Rother",
            "Abhishek Saini",
            "Philipp Cimiano"
        ],
        "title": "Towards a Large Corpus of Richly Annotated Web Tables for Knowledge Base Population",
        "venue": {
            "type": "conference",
            "acronym": "ISWC"
        },
        "nameOfApproach": "",
        "techniqueTags": [
            "rule-based",
            "ontology-driven"
        ],
        "coreTasks": {
            "cta": false,
            "cpa": false,
            "cea": true,
            "cnea": false
        },
        "supportTasks": {
            "dataPreparation": {
                "description": "Language detection and table normalisation (dates, numbers, and units) producing JSON hypotheses for cells. Plain hypotheses are always created to preserve original strings.",
                "spellChecker": "",
                "unitsOfMeasurements": "Values converted to base units (e.g., kg, km)."
            },
            "columnClassification": "",
            "subjectDetection": "",
            "datatypeAnnotation": "",
            "typeAnnotation": "",
            "predicateAnnotation": "",
            "nilAnnotation": "",
            "entityLinking": {
                "description": "Links plain cell strings to DBpedia resources and records top candidates with confidences.",
                "candidateGeneration": "Per-language indices of DBpedia entity, class, and property labels; retrieve top-N by frequency.",
                "entityDisambiguation": "Rank candidates by normalised frequency; no supervised disambiguation."
            }
        },
        "mainMethod": {
            "type": "unsupervised",
            "technique": "rule-based"
        },
        "revision": {
            "type": "fully automated",
            "description": "A scheduled pipeline applies tasks sequentially; no manual review during processing."
        },
        "domain": {
            "domain": "independent",
            "type": ""
        },
        "validation": {
            "goldStandard": "1,000,000 tables from the WDC Web Table Corpus 2015 (WTC).",
            "metrics": []
        },
        "code": "https://github.com/isywtu/code",
        "license": "Apache License 2.0",
        "inputs": {
            "typeOfTable": "HTML tables",
            "tableSources": [
                "web"
            ]
        },
        "kg": {
            "tripleStore": "DBpedia",
            "index": "Per-language string indices over DBpedia labels for entities, classes, and properties with frequency counts."
        },
        "output": "JSON",
        "applicationPurpose": "Enable knowledge base population and support higher-level table understanding on web tables.",
        "userInterfaceTool": "",
        "checkedByAuthor": "",
        "checkedByAi": true,
        "doi": "",
        "citations": [
            {
                "ref": "2012_wang_understanding",
                "title": "Understanding Tables on the Web"
            },
            {
                "ref": "2015_bhagavatula_tabel",
                "title": "TabEL: Entity Linking in Web Tables"
            },
            {
                "ref": "2015_ritze_matching",
                "title": "Matching HTML Tables to DBpedia"
            },
            {
                "ref": "2007_pivk_transforming",
                "title": "Transforming Arbitrary Tables into F-Logic Frames with TARTAR"
            }
        ],
        "uncertainFields": [
            {
                "field": "venue.acronym",
                "reason": "Assumed from the filename; not explicitly stated in the paper header."
            },
            {
                "field": "doi",
                "reason": "A DOI for the paper was not found in the provided text; only a dataset DOI was mentioned."
            },
            {
                "field": "techniqueTags[1]",
                "reason": "Classified as ontology-driven because the approach relies on DBpedia; the paper does not use this exact label."
            },
            {
                "field": "kg.index",
                "reason": "High-level description inferred; precise indexing implementation details are not fully specified."
            }
        ]
    },
    {
        "id": "2017_lehmberg_stitching",
        "added": "",
        "year": 2017,
        "firstAuthor": "Lehmberg",
        "authors": [
            "Oliver Lehmberg",
            "Christian Bizer"
        ],
        "title": "Stitching Web Tables for Improving Matching Quality",
        "venue": {
            "type": "journal",
            "acronym": "PVLDB"
        },
        "nameOfApproach": "",
        "techniqueTags": [],
        "coreTasks": {
            "cta": false,
            "cpa": true,
            "cea": false,
            "cnea": false
        },
        "supportTasks": {
            "dataPreparation": {
                "description": "De-duplicate tables, recognise entities via DBpedia label matching, and create per-host union and stitched tables with holistic correspondence refinement.",
                "spellChecker": "",
                "unitsOfMeasurements": ""
            },
            "columnClassification": "Heuristic identification of the entity label column to guide schema matching.",
            "subjectDetection": "Detects a key/subject column (entity label column) within tables from the same host.",
            "datatypeAnnotation": "",
            "typeAnnotation": "",
            "predicateAnnotation": "Schema matching from web-table columns to DBpedia properties using T2K Match/COMA with holistic refinement.",
            "nilAnnotation": "",
            "entityLinking": {
                "description": "",
                "candidateGeneration": "",
                "entityDisambiguation": ""
            }
        },
        "mainMethod": {
            "type": "hybrid",
            "technique": "Hybrid schema matching combining label-, value-, and duplicate-based matchers with holistic correspondence refinement"
        },
        "revision": {
            "type": "fully automated",
            "description": "Fully automated stitching (union and holistic stitching) followed by automated schema matching without user intervention."
        },
        "domain": {
            "domain": "independent",
            "type": ""
        },
        "validation": {
            "goldStandard": "Random sample of 1,000 WDC 2015 web tables with 427 manually created column-to-DBpedia-property correspondences; per-host evaluations.",
            "metrics": [
                "Precision",
                "Recall",
                "F1"
            ]
        },
        "code": "https://github.com/olehmberg/WebTableStitching",
        "license": "Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International",
        "inputs": {
            "typeOfTable": "HTML tables",
            "tableSources": [
                "web"
            ]
        },
        "kg": {
            "tripleStore": "DBpedia",
            "index": ""
        },
        "output": "",
        "applicationPurpose": "Knowledge base augmentation and improved schema matching on small web tables",
        "userInterfaceTool": "",
        "checkedByAuthor": "",
        "checkedByAi": true,
        "doi": "https://doi.org/10.14778/3137628.3137657",
        "citations": [
            {
                "ref": "2017_ritze_matching",
                "title": "Matching Web Tables To DBpedia - A Feature Utility Study"
            },
            {
                "ref": "2010_limaye_annotating",
                "title": "Annotating and Searching Web Tables Using Entities, Types and Relationships"
            },
            {
                "ref": "2013_ling_synthesizing",
                "title": "Synthesizing union tables from the web"
            },
            {
                "ref": "2005_aumueller_schema",
                "title": "Schema and ontology matching with COMA++"
            },
            {
                "ref": "2015_lehmann_dbpedia",
                "title": "DBpedia - A Large-scale, Multilingual Knowledge Base Extracted from Wikipedia"
            }
        ],
        "uncertainFields": [
            {
                "field": "nameOfApproach",
                "reason": "The paper does not introduce a branded system name; it presents a stitching procedure and evaluation."
            },
            {
                "field": "techniqueTags",
                "reason": "None of the allowed technique tags precisely fit classical schema matching and stitching; left empty to avoid misclassification."
            },
            {
                "field": "supportTasks.columnClassification",
                "reason": "Entity label/key column detection is implied in the procedure but not formalised as a distinct module."
            },
            {
                "field": "supportTasks.subjectDetection",
                "reason": "Subject/key column identification is heuristic and not explicitly labelled as 'subject detection' in the paper."
            },
            {
                "field": "kg.index",
                "reason": "Specific KG indexing structures are not described beyond label lookups; details are unclear."
            },
            {
                "field": "output",
                "reason": "The exported result format is not specified; results are reported as correspondences and metrics."
            },
            {
                "field": "userInterfaceTool",
                "reason": "No UI is described; usage may rely on libraries/tools (e.g., WInte.r) but a specific UI is not stated."
            },
            {
                "field": "validation.goldStandard",
                "reason": "The description summarises the sampling and manual mapping; no official GS name is given for this new sample."
            },
            {
                "field": "mainMethod.type",
                "reason": "Classified as 'hybrid' due to combining several matchers and holistic refinement; some readers might label it 'unsupervised'."
            }
        ]
    },
    {
        "id": "2017_zhang_effective",
        "added": "",
        "year": 2017,
        "firstAuthor": "Zhang",
        "authors": [
            "Ziqi Zhang"
        ],
        "title": "Effective and Efficient Semantic Table Interpretation using TableMiner+",
        "venue": {
            "type": "journal",
            "acronym": "SWJ"
        },
        "nameOfApproach": "TableMiner+",
        "techniqueTags": [
            "ontology-driven"
        ],
        "coreTasks": {
            "cta": true,
            "cpa": true,
            "cea": true,
            "cnea": false
        },
        "supportTasks": {
            "dataPreparation": {
                "description": "Normalises content and collects in-table/out-of-table context (titles, captions, Microdata) and caches KB lookups to reduce latency. ",
                "spellChecker": "",
                "unitsOfMeasurements": ""
            },
            "columnClassification": "Identifies NE vs literal columns and classifies columns using KB-derived evidence. ",
            "subjectDetection": "Detects a subject (reference) column used to anchor relations to other columns. ",
            "datatypeAnnotation": "",
            "typeAnnotation": "Assigns KG concepts to NE-columns via bootstrapped inference and message passing with KB features. ",
            "predicateAnnotation": "Enumerates relations between the subject column and other columns (binary CPA). ",
            "nilAnnotation": "",
            "entityLinking": {
                "description": "Links cell mentions to KB entities using Freebase candidates and contextual features from table and page. ",
                "candidateGeneration": "Retrieves candidates via Freebase Search/MQL APIs, with local caching. ",
                "entityDisambiguation": "Scores candidates with in-table and out-of-table context; refines via iterative message passing. "
            }
        },
        "mainMethod": {
            "type": "unsupervised",
            "technique": "Incremental bootstrapping with semantic message passing over KB features"
        },
        "revision": {
            "type": "fully automated",
            "description": "System performs iterative inference without human-in-the-loop; annotations are refined via message passing. "
        },
        "domain": {
            "domain": "independent",
            "type": "generic"
        },
        "validation": {
            "goldStandard": "Limaye200 (200 tables), LimayeAll (6,310 tables; 227,046 NE cells), IMDB (7,416 tables), MusicBrainz (1,406 tables). ",
            "metrics": [
                "Precision",
                "Recall",
                "F1"
            ]
        },
        "code": "https://github.com/ziqizhang/sti",
        "license": "Not Specified",
        "inputs": {
            "typeOfTable": "Web tables (HTML)",
            "tableSources": [
                "web",
                "wiki"
            ]
        },
        "kg": {
            "tripleStore": "Freebase",
            "index": "Freebase Search/MQL APIs; local cache; later DBpedia interface noted. "
        },
        "output": "RDF",
        "applicationPurpose": "Semantic indexing/search of tables and creation of Linked Open Data/KB population. ",
        "userInterfaceTool": "",
        "checkedByAuthor": "",
        "checkedByAi": true,
        "doi": "https://doi.org/10.3233/SW-160242",
        "citations": [
            {
                "ref": "2010_limaye_annotating",
                "title": "Annotating and searching web tables using entities, types and relationships"
            },
            {
                "ref": "2011_venetis_recovering",
                "title": "Recovering semantics of tables on the Web"
            },
            {
                "ref": "2013_mulwad_semantic",
                "title": "Semantic message passing for generating linked data from tables"
            },
            {
                "ref": "2014_munoz_using",
                "title": "Using linked data to mine RDF from Wikipedia’s tables"
            },
            {
                "ref": "2012_wang_understanding",
                "title": "Understanding tables on the Web"
            }
        ],
        "uncertainFields": [
            {
                "field": "venue.acronym",
                "reason": "Used the common 'SWJ' acronym for Semantic Web Journal; some datasets use 'Semantic Web'."
            },
            {
                "field": "kg.tripleStore",
                "reason": "Primary experiments use Freebase, but the paper notes an interface/migration to DBpedia/Google KG; Freebase chosen to reflect evaluation. "
            },
            {
                "field": "output",
                "reason": "The paper states enabling LOD creation but does not explicitly specify an export format; 'RDF' inferred. "
            },
            {
                "field": "supportTasks.datatypeAnnotation",
                "reason": "Approach handles literal columns for CPA, but explicit mapping to datatype vocabularies is not clearly described."
            },
            {
                "field": "techniqueTags[0]",
                "reason": "Tagged as ontology-driven due to heavy KB use; other tags (e.g., rule-based/clustering) do not neatly apply."
            },
            {
                "field": "citations[2].ref",
                "reason": "Slug for the ISWC 2013 'Semantic message passing' paper may vary in exact first word; format approximated."
            }
        ]
    },
    {
        "id": "2018_kacprzak_making",
        "added": "",
        "year": 2018,
        "firstAuthor": "Kacprzak",
        "authors": [
            "Emilia Kacprzak",
            "José M. Giménez-García",
            "Alessandro Piscopo",
            "Laura Koesten",
            "Luis-Daniel Ibáñez",
            "Jeni Tennison",
            "Elena Simperl"
        ],
        "title": "Making Sense of Numerical Data - Semantic Labelling of Web Tables",
        "venue": {
            "type": "conference",
            "acronym": "EKAW"
        },
        "nameOfApproach": "NUMER",
        "techniqueTags": [
            "rule-based",
            "ontology-driven"
        ],
        "coreTasks": {
            "cta": false,
            "cpa": true,
            "cea": false,
            "cnea": false
        },
        "supportTasks": {
            "dataPreparation": {
                "description": "Partition columns into numerical vs textual, identify a subject column, disambiguate its cells to KB entities, and strip units/non-numeric characters from numeric cells.",
                "spellChecker": "",
                "unitsOfMeasurements": "Units (e.g., Km, %) are removed during preprocessing to keep only numeric values."
            },
            "columnClassification": "Classify columns as numerical or textual to focus annotation.",
            "subjectDetection": "Identify the subject column (textual NE-column) using support/connectivity heuristics from prior work.",
            "datatypeAnnotation": "Consider owl:DatatypeProperty candidates linked to subject-entity types for numeric columns.",
            "typeAnnotation": "",
            "predicateAnnotation": "Rank KB datatype properties (e.g., dbo:populationTotal) for each numeric column via KS-test distribution matching and row-wise relative difference.",
            "nilAnnotation": "",
            "entityLinking": {
                "description": "",
                "candidateGeneration": "",
                "entityDisambiguation": ""
            }
        },
        "mainMethod": {
            "type": "unsupervised",
            "technique": "rule-based"
        },
        "revision": {
            "type": "fully automated",
            "description": "Produces a ranked list of KB properties per numeric column without manual post-editing."
        },
        "domain": {
            "domain": "independent",
            "type": ""
        },
        "validation": {
            "goldStandard": "NumDB (synthetic tables from DBpedia; multiple sizes and error deviations)",
            "metrics": [
                "Top-1 Accuracy",
                "Top-k Accuracy"
            ]
        },
        "code": "https://github.com/chabrowa/semantification",
        "license": "MIT License",
        "inputs": {
            "typeOfTable": "Web tables",
            "tableSources": [
                "wiki"
            ]
        },
        "kg": {
            "tripleStore": "DBpedia",
            "index": ""
        },
        "output": "",
        "applicationPurpose": "Assign semantic labels to numerical columns to aid data discovery and KB integration.",
        "userInterfaceTool": "",
        "usesLLM": null,
        "checkedByAuthor": "",
        "checkedByAi": true,
        "doi": "",
        "citations": [
            {
                "ref": "2016_neumaier_multi-level",
                "title": "Multi-level semantic labelling of numerical values"
            },
            {
                "ref": "2011_venetis_recovering",
                "title": "Recovering semantics of tables on the web"
            },
            {
                "ref": "2015_ramnandan_assigning",
                "title": "Assigning semantic labels to data sources"
            },
            {
                "ref": "2016_ermilov_taipan",
                "title": "TAIPAN: Automatic Property Mapping for Tabular Data"
            },
            {
                "ref": "2018_piscopo_numdb",
                "title": "NumDB"
            }
        ],
        "uncertainFields": [
            {
                "field": "doi",
                "reason": "The DOI of the paper is not stated in the provided text excerpt."
            },
            {
                "field": "output",
                "reason": "The paper reports ranked predictions but does not specify an export serialisation (e.g., RDF/CSV)."
            },
            {
                "field": "userInterfaceTool",
                "reason": "No UI or tool front-end is described; unclear if a CLI/Web UI exists."
            },
            {
                "field": "techniqueTags",
                "reason": "Mapped to 'rule-based' and 'ontology-driven' based on KB-driven matching and heuristics; no explicit ML/embeddings mentioned."
            },
            {
                "field": "inputs.tableSources",
                "reason": "Benchmark tables are derived from DBpedia (wiki); applicability to other sources is discussed but not validated."
            }
        ]
    },
    {
        "id": "2018_luo_cross-lingual",
        "added": "",
        "year": 2018,
        "firstAuthor": "Luo",
        "authors": [
            "Xusheng Luo",
            "Kangqi Luo",
            "Xianyang Chen",
            "Kenny Q. Zhu"
        ],
        "title": "Cross-Lingual Entity Linking for Web Tables",
        "venue": {
            "type": "conference",
            "acronym": "AAAI"
        },
        "nameOfApproach": "",
        "techniqueTags": [
            "embeddings"
        ],
        "coreTasks": {
            "cta": false,
            "cpa": false,
            "cea": true,
            "cnea": false
        },
        "supportTasks": {
            "dataPreparation": {
                "description": "Stop-word removal on translations/anchors and simple text normalisation used during candidate generation.",
                "spellChecker": "",
                "unitsOfMeasurements": ""
            },
            "columnClassification": "",
            "subjectDetection": "",
            "datatypeAnnotation": "",
            "typeAnnotation": "",
            "predicateAnnotation": "",
            "nilAnnotation": "",
            "entityLinking": {
                "description": "Joint neural model links all table mentions simultaneously with mention, context, and column-coherence features.",
                "candidateGeneration": "Translate mentions via multiple MT services; generate candidates by exact/anchor/fuzzy matches with heuristics (e.g., Jaccard/edit distance).",
                "entityDisambiguation": "Pairwise ranking (RankNet) with bilingual embedding transformation and local-search descent to select globally coherent entities."
            }
        },
        "mainMethod": {
            "type": "supervised",
            "technique": "neural network ranking (joint model with RankNet)",
            "supervision": {
                "type": "supervised"
            }
        },
        "revision": {
            "type": "fully automated",
            "description": "System automatically scores and selects entities using a learned model and local search; no human-in-the-loop post-editing."
        },
        "domain": {
            "domain": "independent",
            "type": "generic web tables"
        },
        "validation": {
            "goldStandard": "Cross-lingual table linking dataset (150 tables, 2883 linkable cells; Chinese→English Wikipedia).",
            "metrics": [
                "Accuracy"
            ]
        },
        "code": "",
        "license": "Not Specified",
        "inputs": {
            "typeOfTable": "Web tables",
            "tableSources": [
                "web",
                "wiki"
            ]
        },
        "kg": {
            "tripleStore": "Wikipedia",
            "index": ""
        },
        "output": "",
        "applicationPurpose": "KB enrichment and fact discovery from non-English web tables.",
        "userInterfaceTool": "",
        "checkedByAuthor": "",
        "checkedByAi": true,
        "doi": "https://doi.org/10.1609/aaai.v32i1.11252",
        "citations": [
            {
                "ref": "2015_bhagavatula_tabel",
                "title": "Tabel: Entity Linking in Web Tables"
            },
            {
                "ref": "2016_wu_entity",
                "title": "Entity Linking in Web Tables with Multiple Linked Knowledge Bases"
            },
            {
                "ref": "2010_limaye_annotating",
                "title": "Annotating and Searching Web Tables Using Entities, Types and Relationships"
            },
            {
                "ref": "2011_mcnamee_cross",
                "title": "Cross-Language Entity Linking"
            },
            {
                "ref": "2016_tsai_cross",
                "title": "Cross-lingual Wikification Using Multilingual Embeddings"
            },
            {
                "ref": "2013_zhang_cross",
                "title": "Cross Lingual Entity Linking with Bilingual Topic Model"
            },
            {
                "ref": "2013_socher_reasoning",
                "title": "Reasoning with Neural Tensor Networks for Knowledge Base Completion"
            }
        ],
        "uncertainFields": [
            {
                "field": "nameOfApproach",
                "reason": "No specific system name or acronym is stated; described as a joint neural model."
            },
            {
                "field": "kg.tripleStore",
                "reason": "They use Wikipedia articles as the KB rather than a conventional triple store like DBpedia or Wikidata."
            },
            {
                "field": "validation.goldStandard",
                "reason": "Dataset is described but not given a formal GS name."
            },
            {
                "field": "output",
                "reason": "The paper does not specify an exported output format for annotations."
            },
            {
                "field": "userInterfaceTool",
                "reason": "No UI or tool front-end is mentioned."
            },
            {
                "field": "code",
                "reason": "No repository or code link is provided in the paper."
            }
        ]
    },
    {
        "id": "2018_zhang_ad",
        "added": "",
        "year": 2018,
        "firstAuthor": "Zhang",
        "authors": [
            "Shuo Zhang",
            "Krisztian Balog"
        ],
        "title": "Ad Hoc Table Retrieval using Semantic Similarity",
        "venue": {
            "type": "conference",
            "acronym": "WWW"
        },
        "nameOfApproach": "Semantic Table Retrieval (STR)",
        "techniqueTags": [
            "embeddings"
        ],
        "coreTasks": {
            "cta": false,
            "cpa": false,
            "cea": false,
            "cnea": false
        },
        "supportTasks": {
            "dataPreparation": {
                "description": "WikiTables corpus with links in table bodies replaced by DBpedia entity identifiers (version 2015-10).",
                "spellChecker": "",
                "unitsOfMeasurements": ""
            },
            "columnClassification": "",
            "subjectDetection": "",
            "datatypeAnnotation": "",
            "typeAnnotation": "",
            "predicateAnnotation": "",
            "nilAnnotation": "",
            "entityLinking": {
                "description": "",
                "candidateGeneration": "",
                "entityDisambiguation": ""
            }
        },
        "mainMethod": {
            "type": "supervised",
            "technique": "Learning-to-rank (Random Forest) with semantic similarity features",
            "supervision": {
                "type": "supervised"
            }
        },
        "revision": {
            "type": "fully automated",
            "description": "Produces a ranked list of tables automatically; no user editing phase is described."
        },
        "domain": {
            "domain": "independent",
            "type": "general (web tables)"
        },
        "validation": {
            "goldStandard": "Purpose-built test collection of 1.6M Wikipedia tables with 60 queries and graded relevance (3120 query–table pairs). ",
            "metrics": [
                "NDCG@5",
                "NDCG@10",
                "NDCG@15",
                "NDCG@20"
            ]
        },
        "code": "https://github.com/iai-group/www2018-table",
        "license": "Not Specified",
        "inputs": {
            "typeOfTable": "Web tables",
            "tableSources": [
                "wiki"
            ]
        },
        "kg": {
            "tripleStore": "DBpedia",
            "index": ""
        },
        "output": "",
        "applicationPurpose": "Ad hoc table retrieval / table search. ",
        "userInterfaceTool": "",
        "checkedByAuthor": "",
        "checkedByAi": true,
        "doi": "https://doi.org/10.1145/3178876.3186067",
        "citations": [
            {
                "ref": "2008_cafarella_webtables",
                "title": "WebTables: Exploring the Power of Tables on the Web"
            },
            {
                "ref": "2012_pimplikar_answering",
                "title": "Answering Table Queries on the Web Using Column Keywords"
            },
            {
                "ref": "2013_bhagavatula_methods",
                "title": "Methods for Exploring and Mining Tables on Wikipedia"
            },
            {
                "ref": "2017_hasibi_dbpedia",
                "title": "DBpedia-Entity V2: A Test Collection for Entity Search"
            },
            {
                "ref": "2013_mikolov_distributed",
                "title": "Distributed Representations of Words and Phrases and Their Compositionality"
            },
            {
                "ref": "2016_ristoski_rdf2vec",
                "title": "RDF2vec: RDF Graph Embeddings for Data Mining"
            },
            {
                "ref": "2003_ogilvie_combining",
                "title": "Combining Document Representations for Known-item Search"
            },
            {
                "ref": "2015_balakrishnan_applying",
                "title": "Applying WebTables in Practice"
            },
            {
                "ref": "2011_venetis_recovering",
                "title": "Recovering Semantics of Tables on the Web"
            }
        ],
        "uncertainFields": [
            {
                "field": "nameOfApproach",
                "reason": "The paper labels the method as 'STR' in results tables, but it is not clearly presented as a formal system name. "
            },
            {
                "field": "license",
                "reason": "The article states a CC BY 4.0 publication licence; the software licence for the repository is not specified in the paper text. "
            },
            {
                "field": "output",
                "reason": "No serialisation/format of outputs is described; the result is a ranked list rather than an export format."
            },
            {
                "field": "kg.index",
                "reason": "An explicit KB indexing component is not described; only that entity retrieval uses a fielded representation and external resources."
            },
            {
                "field": "inputs.typeOfTable",
                "reason": "Tables are from Wikipedia (HTML on the Web); either 'Web tables' or 'HTML tables' could be appropriate. "
            },
            {
                "field": "techniqueTags",
                "reason": "Besides 'embeddings', one could argue 'ontology-driven' since entities/categories from DBpedia are leveraged; the paper does not frame it that way."
            },
            {
                "field": "venue.acronym",
                "reason": "Venue is 'The Web Conference (WWW)'; we normalised to 'WWW'. "
            },
            {
                "field": "validation.goldStandard",
                "reason": "The test collection is described but not given a formal name in the paper. "
            }
        ]
    },
    {
        "id": "2019_chabot_dagobah",
        "added": "",
        "year": 2019,
        "firstAuthor": "Chabot",
        "authors": [
            "Yoan Chabot",
            "Thomas Labbé",
            "Jixiong Liu",
            "Raphaël Troncy"
        ],
        "title": "DAGOBAH: An End-to-End Context-Free Tabular Data Semantic Annotation System",
        "venue": {
            "type": "challenge",
            "acronym": "SemTab"
        },
        "nameOfApproach": "DAGOBAH",
        "techniqueTags": [
            "rule-based",
            "clustering",
            "embeddings",
            "ontology-driven"
        ],
        "coreTasks": {
            "cta": true,
            "cpa": true,
            "cea": true,
            "cnea": false
        },
        "supportTasks": {
            "dataPreparation": {
                "description": "Pre-processing chain: orientation detection, header extraction, key column detection, and string cleaning.",
                "spellChecker": "",
                "unitsOfMeasurements": ""
            },
            "columnClassification": "Identify Object/Number/Date/Unit columns and the key column.",
            "subjectDetection": "Key column detection used to infer the subject column for triple generation.",
            "datatypeAnnotation": "",
            "typeAnnotation": "Column typing via lookup counts with relative/specificity scores; alternative embedding-based clustering with DBpedia hierarchy scoring.",
            "predicateAnnotation": "CPA by searching relations between CEA-linked entity pairs and majority voting; early version used header lookup.",
            "nilAnnotation": "",
            "entityLinking": {
                "description": "Cell candidates from multiple lookup services (Wikidata/DBpedia/Wikipedia APIs and an internal ES index) with occurrence-based voting and type-aware disambiguation; embedding variant clusters candidates and scores them.",
                "candidateGeneration": "Query labels/aliases using regex and Levenshtein ≥0.75 across services and an Elasticsearch index.",
                "entityDisambiguation": "Select entities consistent with the predicted column type or its parents using scoring."
            }
        },
        "mainMethod": {
            "type": "hybrid",
            "technique": "rule-based and clustering"
        },
        "revision": {
            "type": "fully automated",
            "description": "Automatic pipeline for CEA/CTA/CPA with no interactive user validation described."
        },
        "domain": {
            "domain": "independent",
            "type": "generic"
        },
        "validation": {
            "goldStandard": "SemTab 2019 challenge test datasets (AICrowd evaluator)",
            "metrics": [
                "Precision",
                "F1"
            ]
        },
        "code": "",
        "license": "Not Specified",
        "inputs": {
            "typeOfTable": "Web tables",
            "tableSources": []
        },
        "kg": {
            "tripleStore": "Wikidata and DBpedia",
            "index": "Elasticsearch index over Wikidata labels, aliases and types"
        },
        "output": "RDF",
        "applicationPurpose": "Annotate tables to enrich/extend knowledge graphs and support dataset search.",
        "userInterfaceTool": "",
        "checkedByAuthor": "",
        "checkedByAi": true,
        "doi": "",
        "citations": [
            {
                "ref": "2019_hassanzadeh_semtab2019",
                "title": "SemTab2019: Semantic Web Challenge on Tabular Data to Knowledge Graph Matching - Data Sets"
            },
            {
                "ref": "2018_chen_colnet",
                "title": "ColNet: Embedding the Semantics of Web Tables for Column Type Prediction"
            },
            {
                "ref": "2018_han_openke",
                "title": "OpenKE: An open toolkit for knowledge embedding"
            },
            {
                "ref": "2015_farber_a",
                "title": "A Comparative Survey of DBpedia, Freebase, OpenCyc, Wikidata, and YAGO"
            },
            {
                "ref": "2019_chapman_dataset",
                "title": "Dataset search: a survey"
            },
            {
                "ref": "2016_sarkar_junitmz",
                "title": "JUNITMZ at SemEval-2016 Task 1: Identifying semantic similarity using Levenshtein ratio"
            }
        ],
        "uncertainFields": [
            {
                "field": "venue.acronym",
                "reason": "The paper appears in SemTab 2019 materials, but the exact proceedings/workshop acronym is not explicitly stated in the text."
            },
            {
                "field": "doi",
                "reason": "A DOI for the system paper is not visible; CEUR-WS style papers often lack a DOI."
            },
            {
                "field": "code",
                "reason": "No repository URL is provided; unclear whether code is publicly available."
            },
            {
                "field": "license",
                "reason": "Paper text notes CC BY 4.0 for the manuscript, but the software licence for the approach is not specified."
            },
            {
                "field": "inputs.typeOfTable",
                "reason": "The system targets generic tabular data; 'Web tables' is inferred from SemTab but not explicitly fixed."
            },
            {
                "field": "kg.tripleStore",
                "reason": "Both Wikidata and DBpedia are used; representing both in a single string may not reflect a single backing store."
            },
            {
                "field": "output",
                "reason": "They mention transforming table knowledge into triples; 'RDF' is inferred rather than explicitly formatted output."
            },
            {
                "field": "validation.metrics",
                "reason": "CTA evaluation uses primary/secondary scores not listed among the allowed metrics; 'Precision' and 'F1' are reported for other tasks."
            },
            {
                "field": "userInterfaceTool",
                "reason": "The paper describes a pipeline but does not mention a UI or tool interface."
            }
        ]
    },
    {
        "id": "2019_chen_learning",
        "added": "",
        "year": 2019,
        "firstAuthor": "Chen",
        "authors": [
            "Jiaoyan Chen",
            "Ernesto Jiménez-Ruiz",
            "Ian Horrocks",
            "Charles Sutton"
        ],
        "title": "Learning Semantic Annotations for Tabular Data",
        "venue": {
            "type": "conference",
            "acronym": "IJCAI"
        },
        "nameOfApproach": "HNN + P2Vec",
        "techniqueTags": [
            "embeddings",
            "ontology-driven"
        ],
        "coreTasks": {
            "cta": true,
            "cpa": false,
            "cea": false,
            "cnea": false
        },
        "supportTasks": {
            "dataPreparation": {
                "description": "Samples are extracted as fixed-size micro tables; cell text is tokenised and embedded (word2vec/Att-BiRNN), with cropping/padding and parsing of dates/numbers.",
                "spellChecker": "",
                "unitsOfMeasurements": ""
            },
            "columnClassification": "",
            "subjectDetection": "",
            "datatypeAnnotation": "",
            "typeAnnotation": "Predicts the DBpedia class (type) for a target NE-column using HNN features and KB-derived property features.",
            "predicateAnnotation": "",
            "nilAnnotation": "",
            "entityLinking": {
                "description": "",
                "candidateGeneration": "",
                "entityDisambiguation": ""
            }
        },
        "mainMethod": {
            "type": "hybrid",
            "technique": "Hybrid Neural Network (Att-BiRNN + CNN) combined with KB lookup and query answering (P2Vec)"
        },
        "revision": {
            "type": "fully automated",
            "description": "System produces predictions automatically; no manual post-editing is required."
        },
        "domain": {
            "domain": "independent",
            "type": "general web"
        },
        "validation": {
            "goldStandard": "T2Dv2, Limaye, Efthymiou (DBpedia)",
            "metrics": [
                "Accuracy"
            ]
        },
        "code": "https://github.com/alan-turing-institute/SemAIDA",
        "license": "Apache License 2.0",
        "inputs": {
            "typeOfTable": "Web tables",
            "tableSources": [
                "web",
                "wiki"
            ]
        },
        "kg": {
            "tripleStore": "DBpedia",
            "index": "DBpedia Lookup service and SPARQL endpoint"
        },
        "output": "",
        "applicationPurpose": "Column type prediction for web tables using DBpedia.",
        "userInterfaceTool": "",
        "checkedByAuthor": "",
        "checkedByAi": true,
        "doi": "https://doi.org/10.24963/ijcai.2019/289",
        "citations": [
            {
                "ref": "2010_limaye_annotating",
                "title": "Annotating and searching web tables using entities, types and relationships"
            },
            {
                "ref": "2015_ritze_matching",
                "title": "Matching HTML tables to DBpedia"
            },
            {
                "ref": "2017_efthymiou_matching",
                "title": "Matching web tables with knowledge base entities: from entity lookups to entity embeddings"
            },
            {
                "ref": "2011_mendes_dbpedia",
                "title": "DBpedia Spotlight: shedding light on the web of documents"
            },
            {
                "ref": "2019_chen_colnet",
                "title": "ColNet: Embedding the Semantics of Web Tables for Column Type Prediction"
            },
            {
                "ref": "2018_luo_cross-lingual",
                "title": "Cross-lingual entity linking for web tables"
            },
            {
                "ref": "2017_zhang_effective",
                "title": "Effective and efficient semantic table interpretation using TableMiner+"
            }
        ],
        "uncertainFields": [
            {
                "field": "nameOfApproach",
                "reason": "The paper does not brand the system with a formal name; 'HNN + P2Vec' is descriptive."
            },
            {
                "field": "mainMethod.type",
                "reason": "Method is supervised but also integrates KB lookup features; classified as 'hybrid'."
            },
            {
                "field": "license",
                "reason": "The repository/license for the referenced code is not specified in the paper."
            },
            {
                "field": "inputs.tableSources",
                "reason": "Sources include T2Dv2 (general web) and Wikipedia tables; 'wiki' is inferred from datasets."
            },
            {
                "field": "kg.index",
                "reason": "Described generically as DBpedia Lookup and SPARQL; specific indexing details are not given."
            },
            {
                "field": "output",
                "reason": "Output serialisation format is not specified; the system outputs predicted classes."
            },
            {
                "field": "userInterfaceTool",
                "reason": "No UI or tool interface is described."
            },
            {
                "field": "code",
                "reason": "The SemAIDA link is given in the paper but may refer to a project umbrella rather than this specific implementation."
            }
        ]
    },
    {
        "id": "2019_chen_colnet",
        "added": "",
        "year": 2019,
        "firstAuthor": "Chen",
        "authors": [
            "Jiaoyan Chen",
            "Ernesto Jiménez-Ruiz",
            "Ian Horrocks",
            "Charles Sutton"
        ],
        "title": "ColNet: Embedding the Semantics of Web Tables for Column Type Prediction",
        "venue": {
            "type": "conference",
            "acronym": "AAAI"
        },
        "nameOfApproach": "ColNet",
        "techniqueTags": [
            "embeddings",
            "ontology-driven"
        ],
        "coreTasks": {
            "cta": true,
            "cpa": false,
            "cea": false,
            "cnea": false
        },
        "supportTasks": {
            "dataPreparation": {
                "description": "",
                "spellChecker": "",
                "unitsOfMeasurements": ""
            },
            "columnClassification": "",
            "subjectDetection": "",
            "datatypeAnnotation": "",
            "typeAnnotation": "Column-to-class mapping using CNN-based prediction combined with KB lookup/ensemble.",
            "predicateAnnotation": "",
            "nilAnnotation": "",
            "entityLinking": {
                "description": "",
                "candidateGeneration": "",
                "entityDisambiguation": ""
            }
        },
        "mainMethod": {
            "type": "hybrid",
            "technique": "CNN-based supervised learning with KB lookup/ensemble"
        },
        "revision": {
            "type": "fully automated",
            "description": "Automatic pipeline of lookup, prediction and ensemble; no manual validation stage reported."
        },
        "domain": {
            "domain": "independent",
            "type": "generic web tables"
        },
        "validation": {
            "goldStandard": "T2Dv2; Limaye",
            "metrics": [
                "Precision",
                "Recall",
                "F1"
            ]
        },
        "code": "https://github.com/alan-turing-institute/SemAIDA",
        "license": "Apache License 2.0",
        "inputs": {
            "typeOfTable": "Web tables",
            "tableSources": [
                "web",
                "wiki"
            ]
        },
        "kg": {
            "tripleStore": "DBpedia",
            "index": "Lexical index over KB entity labels/anchors; DBpedia Lookup/SPARQL."
        },
        "output": "column-to-class annotations",
        "applicationPurpose": "Accurate column type prediction for web tables; supports KB population and table understanding.",
        "userInterfaceTool": "",
        "checkedByAuthor": "",
        "checkedByAi": true,
        "doi": "https://doi.org/10.1609/aaai.v33i01.330129",
        "citations": [
            {
                "ref": "2007_auer_dbpedia",
                "title": "DBpedia: A Nucleus for a Web of Open Data"
            },
            {
                "ref": "2008_cafarella_webtables",
                "title": "Webtables: exploring the power of tables on the web"
            },
            {
                "ref": "2016_lehmberg_a",
                "title": "A large public corpus of web tables containing time and context metadata"
            },
            {
                "ref": "2010_limaye_annotating",
                "title": "Annotating and searching web tables using entities, types and relationships"
            },
            {
                "ref": "2014_kim_convolutional",
                "title": "Convolutional Neural Networks for Sentence Classification"
            },
            {
                "ref": "2017_efthymiou_matching",
                "title": "Matching web tables with knowledge base entities: from entity lookups to entity embeddings"
            },
            {
                "ref": "2015_bhagavatula_tabel",
                "title": "Tabel: entity linking in web tables"
            }
        ],
        "uncertainFields": [
            {
                "field": "license",
                "reason": "The paper references a GitHub repository but does not state the code licence."
            },
            {
                "field": "inputs.tableSources",
                "reason": "Evaluations use general Web and Wikipedia tables; exact source mix beyond these is not explicitly enumerated."
            },
            {
                "field": "kg.index",
                "reason": "A lexical index and DBpedia lookup are mentioned, but implementation details are brief."
            },
            {
                "field": "output",
                "reason": "No explicit serialisation format is specified; the output is conceptually column-to-class annotations."
            },
            {
                "field": "mainMethod.type",
                "reason": "Could be interpreted as supervised (auto-labelled training) or hybrid due to ensemble with KB lookup."
            }
        ]
    },
    {
        "id": "2019_cremaschi_mantistable",
        "added": "",
        "year": 2019,
        "firstAuthor": "Cremaschi",
        "authors": [
            "Marco Cremaschi",
            "Roberto Avogadro",
            "David Chieregato"
        ],
        "title": "MantisTable: an Automatic Approach for the Semantic Table Interpretation",
        "venue": {
            "type": "challenge",
            "acronym": "SemTab"
        },
        "nameOfApproach": "MantisTable",
        "techniqueTags": [
            "rule-based",
            "ontology-driven"
        ],
        "coreTasks": {
            "cta": true,
            "cpa": true,
            "cea": true,
            "cnea": false
        },
        "supportTasks": {
            "dataPreparation": {
                "description": "Cleans and normalises table text (lowercasing, removing HTML/brackets), resolves acronyms/abbreviations, and standardises units via regular expressions.",
                "spellChecker": "",
                "unitsOfMeasurements": "Normalises many units (e.g., area, currency, density, energy, length, mass, speed, temperature, time, voltage) using extended regex rules."
            },
            "columnClassification": "Regex-based detection of L-columns vs NE-columns using frequency thresholds over predefined Regextypes.",
            "subjectDetection": "Scores NE-columns using features (unique content, average words, empty cells, distance from first NE-column) and selects the highest-scoring S-column.",
            "datatypeAnnotation": "Maps literal columns to KG datatypes leveraging information from linked entities and headers.",
            "typeAnnotation": "Builds per-column concept distributions from rdf:type of linked entities and selects a best path in the concept hierarchy maximising a component score.",
            "predicateAnnotation": "Chooses the property between the subject and other columns with maximum frequency among candidates discovered during entity linking.",
            "nilAnnotation": "",
            "entityLinking": {
                "description": "Row-wise candidate graph built from entities whose labels contain the cell text/tokens; literals (dates, numbers, strings) are matched and paths scored.",
                "candidateGeneration": "SPARQL label-contains queries over tokens and redirects to collect eligible entities for each cell.",
                "entityDisambiguation": "Selects the path with maximum score combining path length and Levenshtein edit distance between cell text and entity labels."
            }
        },
        "mainMethod": {
            "type": "unsupervised",
            "technique": "rule-based"
        },
        "revision": {
            "type": "fully automated",
            "description": "All STI steps execute without user intervention; a Web UI offers guidance but outputs are computed automatically."
        },
        "domain": {
            "domain": "independent",
            "type": ""
        },
        "validation": {
            "goldStandard": "SemTab 2019 (Rounds 1–4)",
            "metrics": [
                "F1",
                "Precision"
            ]
        },
        "code": "https://bitbucket.org/disco_unimib/mantistable-tool.py",
        "license": "CC BY 4.0",
        "inputs": {
            "typeOfTable": "CSV",
            "tableSources": []
        },
        "kg": {
            "tripleStore": "DBpedia",
            "index": ""
        },
        "output": "JSON",
        "applicationPurpose": "End-to-end STI to make table semantics accessible for search, querying and KG enrichment.",
        "userInterfaceTool": "Web UI",
        "checkedByAuthor": "",
        "checkedByAi": true,
        "doi": "",
        "citations": [
            {
                "ref": "2013_deng_scalable",
                "title": "Scalable column concept determination for web tables using large knowledge bases"
            },
            {
                "ref": "2012_knoblock_semi-automatically",
                "title": "Semi-automatically Mapping Structured Sources into the Semantic Web"
            },
            {
                "ref": "2010_limaye_annotating",
                "title": "Annotating and searching web tables using entities, types and relationships"
            },
            {
                "ref": "2013_mulwad_semantic",
                "title": "Semantic message passing for generating linked data from tables"
            },
            {
                "ref": "2016_pham_semantic",
                "title": "Semantic Labeling: A Domain-Independent Approach"
            },
            {
                "ref": "2013_quercini_entity",
                "title": "Entity discovery and annotation in tables"
            },
            {
                "ref": "2015_ramnandan_assigning",
                "title": "Assigning Semantic Labels to Data Sources"
            },
            {
                "ref": "2015_ritze_matching",
                "title": "Matching html tables to dbpedia"
            },
            {
                "ref": "2010_syed_exploiting",
                "title": "Exploiting a web of semantic data for interpreting tables"
            },
            {
                "ref": "2016_taheriyan_learning",
                "title": "Learning the semantics of structured data sources"
            },
            {
                "ref": "2011_venetis_recovering",
                "title": "Recovering semantics of tables on the web"
            },
            {
                "ref": "2012_wang_understanding",
                "title": "Understanding tables on the web"
            },
            {
                "ref": "2017_zhang_effective",
                "title": "Effective and efficient semantic table interpretation using TableMiner+"
            }
        ],
        "uncertainFields": [
            {
                "field": "venue.acronym",
                "reason": "The document is a SemTab challenge system paper; exact official acronym formatting is not explicitly stated."
            },
            {
                "field": "kg.tripleStore",
                "reason": "Examples use DBpedia, and Wikidata is mentioned as a potential resource; primary KG may vary by run."
            },
            {
                "field": "inputs.tableSources",
                "reason": "Sources of the challenge tables are not specified in the paper; they may mix wiki/web origins."
            },
            {
                "field": "doi",
                "reason": "Workshop/system description appears to have no DOI (typical for CEUR-WS); left empty."
            },
            {
                "field": "output",
                "reason": "Tool originally exported JSON, but challenge submissions also involved CSV; JSON chosen here."
            },
            {
                "field": "validation.metrics",
                "reason": "Paper reports 'F1' and another score labelled 'F2' which in places corresponds to Precision; mapped conservatively to Precision."
            }
        ]
    },
    {
        "id": "2019_hulsebos_sherlock",
        "added": "",
        "year": 2019,
        "firstAuthor": "Hulsebos",
        "authors": [
            "Madelon Hulsebos",
            "Kevin Hu",
            "Michiel Bakker",
            "Emanuel Zgraggen",
            "Arvind Satyanarayan",
            "Tim Kraska",
            "Çağatay Demiralp",
            "César Hidalgo"
        ],
        "title": "Sherlock: A Deep Learning Approach to Semantic Data Type Detection",
        "venue": {
            "type": "conference",
            "acronym": "KDD"
        },
        "nameOfApproach": "Sherlock",
        "techniqueTags": [
            "embeddings"
        ],
        "coreTasks": {
            "cta": true,
            "cpa": false,
            "cea": false,
            "cnea": false
        },
        "supportTasks": {
            "dataPreparation": {
                "description": "Extracts statistics, character distributions, word embeddings, and paragraph vectors from column values; imputes missing feature values and filters types based on frequency/coverage criteria.",
                "spellChecker": "",
                "unitsOfMeasurements": ""
            },
            "columnClassification": "",
            "subjectDetection": "",
            "datatypeAnnotation": "",
            "typeAnnotation": "Predicts semantic types for columns via a multi-input deep neural network trained on labelled columns.",
            "predicateAnnotation": "",
            "nilAnnotation": "",
            "entityLinking": {
                "description": "",
                "candidateGeneration": "",
                "entityDisambiguation": ""
            }
        },
        "mainMethod": {
            "type": "supervised",
            "technique": "multi-input deep neural network",
            "supervision": {
                "type": "supervised"
            }
        },
        "revision": {
            "type": "fully automated",
            "description": "Predictions are produced automatically; authors discuss using confidence-based rejection to hand-review low-confidence cases."
        },
        "domain": {
            "domain": "independent",
            "type": ""
        },
        "validation": {
            "goldStandard": "VizNet corpus with T2Dv2-derived types (686,765 columns; 78 types)",
            "metrics": [
                "Precision",
                "Recall",
                "F1"
            ]
        },
        "code": "https://sherlock.media.mit.edu",
        "license": "Not Specified",
        "inputs": {
            "typeOfTable": "Web tables",
            "tableSources": [
                "web",
                "gov-open-data"
            ]
        },
        "kg": {
            "tripleStore": "DBpedia",
            "index": ""
        },
        "output": "",
        "applicationPurpose": "Semantic type detection to support data cleaning, schema matching, and data discovery.",
        "userInterfaceTool": "Python library",
        "checkedByAuthor": false,
        "checkedByAi": true,
        "doi": "https://doi.org/10.1145/3292500.3330993",
        "citations": [
            {
                "ref": "2008_cafarella_webtables",
                "title": "WebTables: Exploring the Power of Tables on the Web"
            },
            {
                "ref": "2007_auer_dbpedia",
                "title": "DBpedia: A nucleus for a web of open data"
            },
            {
                "ref": "2019_hu_viznet",
                "title": "VizNet: Towards a large-scale visualization learning and benchmarking repository"
            },
            {
                "ref": "2014_pennington_glove",
                "title": "GloVe: Global vectors for word representation"
            },
            {
                "ref": "2016_pham_semantic",
                "title": "Semantic labeling: a domain-independent approach"
            },
            {
                "ref": "2011_venetis_recovering",
                "title": "Recovering semantics of tables on the web"
            },
            {
                "ref": "2010_limaye_annotating",
                "title": "Annotating and searching web tables using entities, types and relationships"
            },
            {
                "ref": "2016_bartoli_inference",
                "title": "Inference of regular expressions for text extraction from examples"
            }
        ],
        "uncertainFields": [
            {
                "field": "kg.tripleStore",
                "reason": "DBpedia is used to define semantic types; the system does not appear to query a KG during inference."
            },
            {
                "field": "inputs.tableSources",
                "reason": "VizNet aggregates multiple sources; exact proportions and additional categories beyond 'web' and 'gov-open-data' are not specified."
            },
            {
                "field": "revision.type",
                "reason": "A human-in-the-loop is suggested via rejection thresholds but not part of the default pipeline."
            },
            {
                "field": "output",
                "reason": "The paper does not specify an export format for predictions."
            },
            {
                "field": "validation.goldStandard",
                "reason": "Evaluation is on a dataset split rather than a separate external gold standard; summary string combines dataset and type source."
            },
            {
                "field": "kg.index",
                "reason": "No indexing mechanism for the KG is described."
            }
        ]
    },
    {
        "id": "2019_kruit_extracting",
        "added": "",
        "year": 2019,
        "firstAuthor": "Kruit",
        "authors": [
            "Benno Kruit",
            "Peter Boncz",
            "Jacopo Urbani"
        ],
        "title": "Extracting Novel Facts from Tables for Knowledge Graph Completion",
        "venue": {
            "type": "conference",
            "acronym": "ISWC"
        },
        "nameOfApproach": "TAKCO",
        "techniqueTags": [
            "embeddings"
        ],
        "coreTasks": {
            "cta": false,
            "cpa": true,
            "cea": true,
            "cnea": false
        },
        "supportTasks": {
            "dataPreparation": {
                "description": "Heuristic key-column detection; build a label index including redirects and disambiguation pages; token-based string matching and TF-IDF ranking.",
                "spellChecker": "",
                "unitsOfMeasurements": ""
            },
            "columnClassification": "",
            "subjectDetection": "Key-column identification via most-unique non-numeric values (leftmost on ties).",
            "datatypeAnnotation": "",
            "typeAnnotation": "",
            "predicateAnnotation": "Map attribute columns to KG relations using column likelihoods aggregated over rows (ColScore) and disambiguation.",
            "nilAnnotation": "",
            "entityLinking": {
                "description": "Row–entity assignments scored from label/attribute matches and refined for table-wide coherence using a probabilistic graphical model.",
                "candidateGeneration": "Lookup over KG label index (incl. titles, redirects, disambiguation); length-normalised smoothed TF-IDF; keep top-1 or top-3 per heuristic.",
                "entityDisambiguation": "Loopy Belief Propagation over entity similarity graph to maximise coherence; final slot-filling re-ranked with TransE embeddings."
            }
        },
        "mainMethod": {
            "type": "unsupervised",
            "technique": "Probabilistic graphical model with Loopy Belief Propagation for table interpretation; KG embeddings (TransE) for slot-filling re-ranking"
        },
        "revision": {
            "type": "fully automated",
            "description": "End-to-end automated inference and extraction with thresholding to tune precision–recall; no user edits required after the core run."
        },
        "domain": {
            "domain": "independent",
            "type": "open-domain"
        },
        "validation": {
            "goldStandard": "Evaluated on T2D-v2 (web tables) and Webaroo (YAGO/DBpedia-mapped) plus a large Wikipedia tables run.",
            "metrics": [
                "Precision",
                "Recall",
                "F1",
                "P@1",
                "P@3"
            ]
        },
        "code": "https://github.com/karmaresearch/takco",
        "license": "MIT License",
        "inputs": {
            "typeOfTable": "HTML tables",
            "tableSources": [
                "web",
                "wiki"
            ]
        },
        "kg": {
            "tripleStore": "DBpedia; Wikidata",
            "index": "Label index over KG labels, redirects and disambiguation pages; TF-IDF retrieval"
        },
        "output": "RDF",
        "applicationPurpose": "Knowledge graph completion by extracting novel facts from web tables",
        "userInterfaceTool": "",
        "checkedByAuthor": false,
        "checkedByAi": true,
        "doi": "https://doi.org/10.1007/978-3-030-30793-6_21",
        "citations": [
            {
                "ref": "2015_ritze_matching",
                "title": "Matching HTML tables to DBpedia"
            },
            {
                "ref": "2017_zhang_effective",
                "title": "Effective and efficient semantic table interpretation using TableMiner+"
            },
            {
                "ref": "2010_limaye_annotating",
                "title": "Annotating and searching web tables using entities, types and relationships"
            },
            {
                "ref": "2015_bhagavatula_tabel",
                "title": "TabEL: entity linking in web tables"
            },
            {
                "ref": "2013_bordes_translating",
                "title": "Translating embeddings for modeling multi-relational data"
            },
            {
                "ref": "2019_kruit_extracting",
                "title": "Extracting novel facts from tables for knowledge graph completion (extended version)"
            }
        ],
        "uncertainFields": [
            {
                "field": "coreTasks.cta",
                "reason": "CTA is mentioned as optional and was not explicitly evaluated; the focus is on CEA and CPA."
            },
            {
                "field": "output",
                "reason": "The exported serialisation is not stated; triples/RDF are assumed from the KG context."
            },
            {
                "field": "userInterfaceTool",
                "reason": "No user interface or tool front-end is described; likely CLI only, but unspecified."
            },
            {
                "field": "license",
                "reason": "The paper references code but does not specify a licence."
            },
            {
                "field": "kg.tripleStore",
                "reason": "The system supports multiple KGs (DBpedia and Wikidata); a single-string field was used to list both."
            },
            {
                "field": "inputs.tableSources[1]",
                "reason": "Both generic web tables and Wikipedia tables are used; classification overlap may apply."
            },
            {
                "field": "supportTasks.columnClassification",
                "reason": "Explicit column type classification is not described; method relies mainly on key-column detection."
            }
        ]
    },
    {
        "id": "2019_morikawa_semantic",
        "added": "",
        "year": 2019,
        "firstAuthor": "Morikawa",
        "authors": [
            "Hiroaki Morikawa"
        ],
        "title": "Semantic Table Interpretation using LOD4ALL",
        "venue": {
            "type": "challenge",
            "acronym": "SemTab"
        },
        "nameOfApproach": "LOD4ALL",
        "techniqueTags": [
            "rule-based",
            "ontology-driven"
        ],
        "coreTasks": {
            "cta": true,
            "cpa": true,
            "cea": true,
            "cnea": false
        },
        "supportTasks": {
            "dataPreparation": {
                "description": "Builds a Score DB (BM25 over classes) and a Keyword Store from the target KG to support prediction. Enhances literal search with keyword variants and approximate matching.",
                "spellChecker": "",
                "unitsOfMeasurements": ""
            },
            "columnClassification": "",
            "subjectDetection": "",
            "datatypeAnnotation": "",
            "typeAnnotation": "Predicts column semantic types using coverage ratios of candidate entities and BM25 class scores.",
            "predicateAnnotation": "For each row, queries predicates between entity pairs and selects the most frequent relation as the column-pair property.",
            "nilAnnotation": "",
            "entityLinking": {
                "description": "Links cells to KG entities using enhanced literal/keyword search and type-constrained selection.",
                "candidateGeneration": "Direct URI match, keyword search over labels/names, and approximate string matching (SimString) via Elasticsearch/LOD4ALL.",
                "entityDisambiguation": "Ranks candidates by combined search-similarity score and selects one consistent with the predicted column type."
            }
        },
        "mainMethod": {
            "type": "unsupervised",
            "technique": "rule-based"
        },
        "revision": {
            "type": "fully automated",
            "description": "End-to-end pipeline produces CTA/CEA/CPA without manual intervention."
        },
        "domain": {
            "domain": "independent",
            "type": "generic"
        },
        "validation": {
            "goldStandard": "SemTab 2019 (Round1–4)",
            "metrics": [
                "F1",
                "Precision"
            ]
        },
        "code": "https://github.com/lod4all/semanticTableInterpretation",
        "license": "CC BY 4.0",
        "inputs": {
            "typeOfTable": "CSV",
            "tableSources": [
                "web",
                "wiki"
            ]
        },
        "kg": {
            "tripleStore": "DBpedia",
            "index": "LOD4ALL keyword store with Elasticsearch and SimString; BM25-based Score DB for classes"
        },
        "output": "",
        "applicationPurpose": "Knowledge Graph construction from web tables",
        "userInterfaceTool": "",
        "checkedByAuthor": false,
        "checkedByAi": true,
        "doi": "",
        "citations": [
            {
                "ref": "2016_lehmberg_a",
                "title": "A large public corpus of web tables containing time and context metadata."
            },
            {
                "ref": "2019_kruit_extracting",
                "title": "Extracting Novel Facts from Tables for Knowledge Graph Completion."
            },
            {
                "ref": "2014_naseer_lod",
                "title": "LOD for all: Unlocking infinite opportunities."
            },
            {
                "ref": "",
                "title": "Semantic Web Challenge on Tabular Data to Knowledge Graph Matching"
            },
            {
                "ref": "2017_efthymiou_matching",
                "title": "Matching web tables with knowledge base entities: from entity lookups to entity embeddings."
            },
            {
                "ref": "2013_zwicklbauer_towards",
                "title": "Towards Disambiguating Web Tables."
            },
            {
                "ref": "2009_robertson_the",
                "title": "The probabilistic relevance framework: BM25 and beyond."
            },
            {
                "ref": "2010_okazaki_simple",
                "title": "Simple and efficient algorithm for approximate dictionary matching."
            },
            {
                "ref": "2016_fang_dbpedia",
                "title": "DBpedia Entity Type Inference Using Categories."
            }
        ],
        "uncertainFields": [
            {
                "field": "venue.acronym",
                "reason": "Assumed workshop acronym is 'SemTab' for the SemTab 2019 challenge paper; some records list only CEUR-WS."
            },
            {
                "field": "inputs.typeOfTable",
                "reason": "Example shows a CSV file, but the approach targets generic web tables; the exact default input format is not explicitly fixed."
            },
            {
                "field": "inputs.tableSources",
                "reason": "The system targets web tables and examples are from Wikipedia; other sources might be supported but are not stated."
            },
            {
                "field": "output",
                "reason": "Submission/serialisation format is not specified in the text."
            },
            {
                "field": "validation.goldStandard",
                "reason": "Described as participation across SemTab rounds; the precise dataset names per round are not enumerated."
            }
        ]
    },
    {
        "id": "2019_nguyen_mtab",
        "added": "",
        "year": 2019,
        "firstAuthor": "Nguyen",
        "authors": [
            "Phuc Nguyen",
            "Natthawut Kertkeidkachorn",
            "Ryutaro Ichise",
            "Hideaki Takeda"
        ],
        "title": "MTab: Matching Tabular Data to Knowledge Graph using Probability Models",
        "venue": {
            "type": "challenge",
            "acronym": "SemTab"
        },
        "nameOfApproach": "MTab",
        "techniqueTags": [
            "embeddings"
        ],
        "coreTasks": {
            "cta": true,
            "cpa": true,
            "cea": true,
            "cnea": false
        },
        "supportTasks": {
            "dataPreparation": {
                "description": "Pre-processing includes text decoding, language prediction, data type and entity type prediction, and multi-source entity lookup.",
                "spellChecker": "ftfy",
                "unitsOfMeasurements": ""
            },
            "columnClassification": "Majority voting over data type/entity tags to separate entity vs numerical columns.",
            "subjectDetection": "",
            "datatypeAnnotation": "",
            "typeAnnotation": "Aggregates signals (from numerical columns, lookups, NER types, and headers) to estimate DBpedia classes.",
            "predicateAnnotation": "Estimates relations via SPARQL links between entity candidates and value-similarity for entity–literal pairs; aggregates scores.",
            "nilAnnotation": "",
            "entityLinking": {
                "description": "Generates entity candidates from multiple lookup services and re-estimates probabilities using column, cell, and row context.",
                "candidateGeneration": "DBpedia Lookup/SPARQL plus Wikipedia/Wikidata redirects with language-aware queries.",
                "entityDisambiguation": "Probability aggregation with learnable weights over lookup rank, type consistency, string match ratios, and row-wise relation evidence."
            }
        },
        "mainMethod": {
            "type": "hybrid",
            "technique": "Probabilistic aggregation with embedding-based numerical column labelling (EmbNum) and heuristic similarity measures"
        },
        "revision": {
            "type": "fully automated",
            "description": "Outputs are selected by automated re-estimation and majority voting without user intervention."
        },
        "domain": {
            "domain": "independent",
            "type": ""
        },
        "validation": {
            "goldStandard": "SemTab 2019 datasets (Rounds 1–4)",
            "metrics": [
                "F1"
            ]
        },
        "code": "https://github.com/phucty/MTab",
        "license": "MIT License",
        "inputs": {
            "typeOfTable": "Vertical relational tables",
            "tableSources": []
        },
        "kg": {
            "tripleStore": "DBpedia",
            "index": "DBpedia Lookup; DBpedia SPARQL endpoint; Wikipedia/Wikidata redirects"
        },
        "output": "",
        "applicationPurpose": "SemTab 2019 challenge system for matching tables to DBpedia",
        "userInterfaceTool": "",
        "checkedByAuthor": false,
        "checkedByAi": true,
        "doi": "",
        "citations": [
            {
                "ref": "2010_limaye_annotating",
                "title": "Annotating and searching web tables using entities, types and relationships"
            },
            {
                "ref": "2019_speer_ftfy",
                "title": "ftfy"
            },
            {
                "ref": "2017_joulin_bag",
                "title": "Bag of tricks for efficient text classification"
            },
            {
                "ref": "2017_honnibal_spacy",
                "title": "spaCy 2: Natural language understanding with Bloom embeddings, convolutional neural networks and incremental parsing"
            },
            {
                "ref": "2018_nguyen_embnum",
                "title": "Embnum: Semantic labeling for numerical values with deep metric learning"
            },
            {
                "ref": "2019_hassanzadeh_semtab2019",
                "title": "SemTab2019: Semantic Web Challenge on Tabular Data to Knowledge Graph Matching - 2019 Data Sets"
            },
            {
                "ref": "2017_zhang_effective",
                "title": "Effective and efficient semantic table interpretation using tableminer+"
            },
            {
                "ref": "2017_nishida_understanding",
                "title": "Understanding the semantic structures of tables with a hybrid deep neural network architecture"
            },
            {
                "ref": "2017_lehmberg_stitching",
                "title": "Stitching web tables for improving matching quality"
            },
            {
                "ref": "2017_ritze_web",
                "title": "Web-scale web table to knowledge base matching"
            }
        ],
        "uncertainFields": [
            {
                "field": "techniqueTags[0]",
                "reason": "EmbNum relies on deep metric learning embeddings; other components are heuristic/probabilistic rather than explicit rule-based or transformer."
            },
            {
                "field": "validation.metrics[0]",
                "reason": "CTA results are reported primarily with an average hierarchical score (AH); only Round 1 explicitly shows F1 for CTA, so listing F1 may not uniformly reflect all tasks."
            },
            {
                "field": "inputs.typeOfTable",
                "reason": "Paper assumes vertical relational tables but does not constrain specific file formats (e.g., HTML/CSV/PDF)."
            },
            {
                "field": "inputs.tableSources",
                "reason": "The provenance of evaluation tables is via SemTab datasets, but specific source categories (web/wiki/gov-open-data) are not detailed in the paper."
            },
            {
                "field": "output",
                "reason": "No explicit export format for annotations is described."
            },
            {
                "field": "license",
                "reason": "Paper states CC BY 4.0 for the publication; the software licence for MTab itself is not specified in the text."
            }
        ]
    },
    {
        "id": "2019_oliveira_adog",
        "added": "",
        "year": 2019,
        "firstAuthor": "Oliveira",
        "authors": [
            "Daniela Oliveira",
            "Mathieu d'Aquin"
        ],
        "title": "ADOG - Annotating Data with Ontologies and Graphs",
        "venue": {
            "type": "challenge",
            "acronym": "SemTab"
        },
        "nameOfApproach": "ADOG",
        "techniqueTags": [
            "rule-based",
            "ontology-driven"
        ],
        "coreTasks": {
            "cta": true,
            "cpa": true,
            "cea": true,
            "cnea": false
        },
        "supportTasks": {
            "dataPreparation": {
                "description": "String normalisation (punctuation removal, bracketed words ignored) and indexing of KG labels and categories; weights include tf-idf.",
                "spellChecker": "",
                "unitsOfMeasurements": ""
            },
            "columnClassification": "",
            "subjectDetection": "",
            "datatypeAnnotation": "",
            "typeAnnotation": "Assign DBpedia ontology classes to columns using ontology graph depth and shortest paths.",
            "predicateAnnotation": "Relations between matched entities extracted via KG object properties to assign column properties.",
            "nilAnnotation": "",
            "entityLinking": {
                "description": "Link cells to DBpedia entities via ElasticSearch search with scoring.",
                "candidateGeneration": "Label lookup over indexed KG entities.",
                "entityDisambiguation": "Levenshtein similarity, property frequency and weighted final score."
            }
        },
        "mainMethod": {
            "type": "unsupervised",
            "technique": "rule-based"
        },
        "revision": {
            "type": "fully automated",
            "description": "Annotations are computed automatically using graph-based scoring with no user post-editing described."
        },
        "domain": {
            "domain": "independent",
            "type": ""
        },
        "validation": {
            "goldStandard": "SemTab 2019 challenge ground truths (Rounds 1–4).",
            "metrics": [
                "Precision",
                "Recall",
                "F1"
            ]
        },
        "code": "https://github.com/danielapoliveira/iswc-annotation-challenge",
        "license": "Not Specified",
        "inputs": {
            "typeOfTable": "structured and semi-structured tables",
            "tableSources": []
        },
        "kg": {
            "tripleStore": "DBpedia",
            "index": "ElasticSearch index of labels; categories/types with tf-idf weighting."
        },
        "output": "",
        "applicationPurpose": "Semantic annotation of tables to a KG (CTA/CEA/CPA) and evaluation in the SemTab challenge.",
        "userInterfaceTool": "",
        "checkedByAuthor": false,
        "checkedByAi": true,
        "doi": "",
        "citations": [
            {
                "ref": "2019_oliveira_leveraging",
                "title": "Leveraging Ontologies for Knowledge Graph Schemas."
            }
        ],
        "uncertainFields": [
            {
                "field": "venue.acronym",
                "reason": "The acronym 'SemTab' is inferred from the file name and challenge name rather than explicitly stated in the text."
            },
            {
                "field": "validation.metrics",
                "reason": "CTA was also evaluated with AH-Score and AP-Score, which are not in the allowed list; only common metrics are recorded."
            },
            {
                "field": "inputs.typeOfTable",
                "reason": "The paper mentions structured and semi-structured data but not a specific table format (e.g., HTML, CSV)."
            },
            {
                "field": "inputs.tableSources",
                "reason": "Sources of tables (web, wiki, etc.) are not explicitly specified."
            },
            {
                "field": "output",
                "reason": "The output format of the annotations is not described."
            },
            {
                "field": "userInterfaceTool",
                "reason": "No UI or tool interface is mentioned."
            },
            {
                "field": "license",
                "reason": "The approach/repository licence is not stated in the paper."
            },
            {
                "field": "mainMethod.technique",
                "reason": "Approach relies on graph-based heuristics; labelled as rule-based, but the exact categorisation is not explicitly given."
            },
            {
                "field": "coreTasks.cpa",
                "reason": "CPA results were derived from CEA in later rounds; unclear whether CPA is a primary target of the core algorithm."
            },
            {
                "field": "kg.index",
                "reason": "Indexing details are summarised (labels, categories with tf-idf) without full configuration specifics."
            }
        ]
    },
    {
        "id": "2019_steenwinckel_csv2kg",
        "added": "",
        "year": 2019,
        "firstAuthor": "Steenwinckel",
        "authors": [
            "Bram Steenwinckel",
            "Gilles Vandewiele",
            "Filip De Turck",
            "Femke Ongenae"
        ],
        "title": "CSV2KG: Transforming Tabular Data into Semantic Knowledge",
        "venue": {
            "type": "challenge",
            "acronym": "SemTab"
        },
        "nameOfApproach": "CSV2KG",
        "techniqueTags": [
            "rule-based",
            "ontology-driven"
        ],
        "coreTasks": {
            "cta": true,
            "cpa": true,
            "cea": true,
            "cnea": false
        },
        "supportTasks": {
            "dataPreparation": {
                "description": "Cell value normalisation (e.g., trimming text before brackets, removing specific characters) to reduce noisy strings for matching.",
                "spellChecker": "",
                "unitsOfMeasurements": ""
            },
            "columnClassification": "",
            "subjectDetection": "Treats the first column as the head/subject column and uses inferred predicates to refine head/non-head annotations.",
            "datatypeAnnotation": "",
            "typeAnnotation": "Infers column types via majority voting over the DBpedia class hierarchy with an entropy-based stopping rule; adds ancestors and equivalent classes.",
            "predicateAnnotation": "Selects predicates linking column pairs by counting observed (s,p,o) across annotated cell pairs; breaks ties using domain/range depth.",
            "nilAnnotation": "",
            "entityLinking": {
                "description": "Generates candidate entities and disambiguates to DBpedia resources.",
                "candidateGeneration": "Tries direct resource IRIs from cleaned strings; uses DBpedia Lookup; falls back to DBpedia Spotlight.",
                "entityDisambiguation": "Chooses candidates with minimal Levenshtein distance; later iterations incorporate column-type and row-wise predicate constraints."
            }
        },
        "mainMethod": {
            "type": "unsupervised",
            "technique": "rule-based"
        },
        "revision": {
            "type": "fully automated",
            "description": "Six-phase pipeline executes automatically without manual intervention during inference."
        },
        "domain": {
            "domain": "independent",
            "type": ""
        },
        "validation": {
            "goldStandard": "SemTab2019 (ISWC) challenge datasets, rounds 1–4",
            "metrics": [
                "Precision",
                "Recall",
                "F1"
            ]
        },
        "code": "https://github.com/IBCNServices/CSV2KG",
        "license": "Other",
        "inputs": {
            "typeOfTable": "CSV",
            "tableSources": []
        },
        "kg": {
            "tripleStore": "DBpedia",
            "index": "DBpedia Lookup API; DBpedia Spotlight; SPARQL queries for domain/range"
        },
        "output": "",
        "applicationPurpose": "Semantic annotation of CSV tables and KG construction/linking for DBpedia; SemTab 2019 participation.",
        "userInterfaceTool": "",
        "checkedByAuthor": false,
        "checkedByAi": true,
        "doi": "",
        "citations": [
            {
                "ref": "2007_auer_dbpedia",
                "title": "Dbpedia: A nucleus for a web of open data"
            },
            {
                "ref": "2015_bhagavatula_tabel",
                "title": "Tabel: entity linking in web tables"
            },
            {
                "ref": "2019_chen_colnet",
                "title": "Colnet: Embedding the semantics of web tables for column type prediction"
            },
            {
                "ref": "2014_dimou_rml",
                "title": "RML: A generic language for integrated RDF mappings of heterogeneous data"
            },
            {
                "ref": "2017_efthymiou_matching",
                "title": "Matching web tables with knowledge base entities: from entity lookups to entity embeddings"
            },
            {
                "ref": "2019_chen_semtab2019",
                "title": "Semtab2019: Semantic web challenge on tabular data to knowledge graph matching - 2019 data sets"
            },
            {
                "ref": "2015_ritze_matching",
                "title": "Matching HTML tables to DBpedia"
            },
            {
                "ref": "2017_zhang_effective",
                "title": "Effective and efficient semantic table interpretation using TableMiner+"
            },
            {
                "ref": "2013_zwicklbauer_towards",
                "title": "Towards disambiguating web tables"
            }
        ],
        "uncertainFields": [
            {
                "field": "doi",
                "reason": "No DOI is indicated in the paper; CEUR-WS challenge papers sometimes lack DOIs."
            },
            {
                "field": "license",
                "reason": "The article text shows CC BY 4.0 for the paper, but the software licence of CSV2KG is not stated in the text."
            },
            {
                "field": "output",
                "reason": "The exact exported format (e.g., RDF, JSON-LD) is not explicitly specified."
            },
            {
                "field": "inputs.tableSources",
                "reason": "Tables are described as CSV from the SemTab datasets, but their upstream source category (web/wiki/gov-open-data, etc.) is not stated."
            },
            {
                "field": "userInterfaceTool",
                "reason": "No graphical UI or CLI details are described; only a Python implementation is mentioned."
            },
            {
                "field": "kg.index",
                "reason": "APIs (Lookup/Spotlight) and SPARQL are used, but it is unclear whether a dedicated index beyond these services is maintained."
            },
            {
                "field": "supportTasks.subjectDetection",
                "reason": "The method treats the first column as the head/subject; it is not clear if a general subject-detection algorithm is applied."
            },
            {
                "field": "venue.acronym",
                "reason": "The venue is the SemTab challenge at ISWC 2019; acronym could also appear as 'ISWC SemTab' in other sources."
            }
        ]
    },
    {
        "id": "2019_takeoka_meimei",
        "added": "",
        "year": 2019,
        "firstAuthor": "Takeoka",
        "authors": [
            "Kunihiro Takeoka",
            "Masafumi Oyamada",
            "Shinji Nakadai",
            "Takeshi Okadome"
        ],
        "title": "Meimei: An Efficient Probabilistic Approach for Semantically Annotating Tables",
        "venue": {
            "type": "conference",
            "acronym": "AAAI"
        },
        "nameOfApproach": "Meimei",
        "techniqueTags": [
            "embeddings"
        ],
        "coreTasks": {
            "cta": true,
            "cpa": false,
            "cea": false,
            "cnea": false
        },
        "supportTasks": {
            "dataPreparation": {
                "description": "Extracts features from columns (textual similarity to KG lemmas for NE-columns; numeric statistics and simple textual features for literal-columns). ",
                "spellChecker": "",
                "unitsOfMeasurements": "Robustness to differing units via unit-invariant features; no explicit unit normalisation step described. "
            },
            "columnClassification": "Handles NE-columns and literal-columns with distinct feature extractors and classifiers. ",
            "subjectDetection": "",
            "datatypeAnnotation": "",
            "typeAnnotation": "Assigns KG concepts to columns via a Markov random field with multi-label classifier potentials and title/column interactions. ",
            "predicateAnnotation": "",
            "nilAnnotation": "",
            "entityLinking": {
                "description": "",
                "candidateGeneration": "",
                "entityDisambiguation": ""
            }
        },
        "mainMethod": {
            "type": "supervised",
            "technique": "Multi-label classification with Markov random field potentials (column–content, column–column, title–column) and KG embeddings.",
            "supervision": {
                "type": "supervised"
            }
        },
        "revision": {
            "type": "fully automated",
            "description": "Fully automated inference (Gibbs sampling) to maximise potentials; no human-in-the-loop revision described. "
        },
        "domain": {
            "domain": "independent",
            "type": ""
        },
        "validation": {
            "goldStandard": "183 human-annotated tables from the UCI Machine Learning Repository. ",
            "metrics": [
                "MAP@5",
                "NDCG@5"
            ]
        },
        "code": "",
        "license": "Not Specified",
        "inputs": {
            "typeOfTable": "Tabular data (UCI tables)",
            "tableSources": [
                "scientific"
            ]
        },
        "kg": {
            "tripleStore": "WordNet",
            "index": ""
        },
        "output": "Column-level semantic labels",
        "applicationPurpose": "Improve search, joining, and semantic operations on tables by unifying ambiguous column semantics. ",
        "userInterfaceTool": "",
        "checkedByAuthor": "",
        "checkedByAi": true,
        "doi": "",
        "citations": [
            {
                "ref": "2010_limaye_annotating",
                "title": "Annotating and searching web tables using entities, types and relationships"
            },
            {
                "ref": "2016_pham_semantic",
                "title": "Semantic labeling: a domain-independent approach"
            },
            {
                "ref": "2016_neumaier_multi-level",
                "title": "Multi-level semantic labelling of numerical values"
            },
            {
                "ref": "2017_nickel_poincare",
                "title": "Poincaré embeddings for learning hierarchical representations"
            },
            {
                "ref": "2016_trouillon_complex",
                "title": "ComplEx embeddings for simple link prediction"
            },
            {
                "ref": "2013_bordes_translating",
                "title": "Translating embeddings for modeling multi-relational data"
            },
            {
                "ref": "2017_zhang_effective",
                "title": "Effective and efficient semantic table interpretation using TableMiner+"
            },
            {
                "ref": "2011_venetis_recovering",
                "title": "Recovering semantics of tables on the web"
            },
            {
                "ref": "2015_chu_katara",
                "title": "Katara: A data cleaning system powered by knowledge bases and crowdsourcing"
            },
            {
                "ref": "2013_zhang_infogather",
                "title": "InfoGather+: Semantic matching and annotation of numeric and time-varying attributes in web tables"
            }
        ],
        "uncertainFields": [
            {
                "field": "doi",
                "reason": "The DOI for the AAAI-19 paper was not present in the provided text; leaving it empty to avoid speculation. "
            },
            {
                "field": "code",
                "reason": "No code repository or URL was mentioned in the paper excerpt. "
            },
            {
                "field": "userInterfaceTool",
                "reason": "No UI or tool front-end is described; the work focuses on methodology and experiments. "
            },
            {
                "field": "kg.index",
                "reason": "The paper uses KG embeddings (Poincaré) but does not describe a specific index structure for lookup. "
            },
            {
                "field": "inputs.typeOfTable",
                "reason": "Tables are from UCI datasets, but exact file formats (e.g., CSV, spreadsheet) are not explicitly specified. "
            }
        ]
    },
    {
        "id": "2019_thawani_entity",
        "added": "",
        "year": 2019,
        "firstAuthor": "Thawani",
        "authors": [
            "Avijit Thawani",
            "Minda Hu",
            "Erdong Hu",
            "Husain Zafar",
            "Naren Teja Divvala",
            "Amandeep Singh",
            "Ehsan Qasemi",
            "Pedro Szekely",
            "Jay Pujara"
        ],
        "title": "Entity Linking to Knowledge Graphs to Infer Column Types and Properties",
        "venue": {
            "type": "challenge",
            "acronym": "SemTab"
        },
        "nameOfApproach": "",
        "techniqueTags": [
            "rule-based",
            "ontology-driven"
        ],
        "coreTasks": {
            "cta": true,
            "cpa": true,
            "cea": true,
            "cnea": false
        },
        "supportTasks": {
            "dataPreparation": {
                "description": "Input cleaning (headers, empty lines, encodings) and building auxiliary indices (e.g., name-abbreviation index).",
                "spellChecker": "",
                "unitsOfMeasurements": ""
            },
            "columnClassification": "",
            "subjectDetection": "",
            "datatypeAnnotation": "Transforms string, date, and numeric literals to align with KG values; no explicit datatype mapping reported.",
            "typeAnnotation": "Computes column class via hierarchical voting over DBpedia class tree using thresholded frequencies.",
            "predicateAnnotation": "Selects the most frequent DBpedia property between candidate pairs across rows (with synonym mapping).",
            "nilAnnotation": "",
            "entityLinking": {
                "description": "Two-stage pipeline: candidate generation (Wikidata API + Elasticsearch over Wikidata/DBpedia + abbreviation index) and candidate selection (heuristics and learned ranker).",
                "candidateGeneration": "Combines Wikidata API with Elasticsearch indexes for labels/aliases/descriptions and DBpedia-to-Wikidata mappings; includes special handling for abbreviated person names.",
                "entityDisambiguation": "Heuristic linear combination (TF-IDF-like semantic features + string similarities) and a 2-layer neural ranking model trained on T2Dv2."
            }
        },
        "mainMethod": {
            "type": "hybrid",
            "technique": "Heuristic scoring (TF-IDF + string similarity) combined with a neural network ranking model"
        },
        "revision": {
            "type": "fully automated",
            "description": "Automatic pipeline with no manual post-editing reported."
        },
        "domain": {
            "domain": "independent",
            "type": "generic"
        },
        "validation": {
            "goldStandard": "SemTab 2019 (Round 2); T2Dv2",
            "metrics": [
                "Precision",
                "F1"
            ]
        },
        "code": "",
        "license": "Not Specified",
        "inputs": {
            "typeOfTable": "Web tables",
            "tableSources": [
                "web"
            ]
        },
        "kg": {
            "tripleStore": "DBpedia; Wikidata",
            "index": "Elasticsearch indexes over Wikidata (labels/aliases/descriptions) and DBpedia labels mapped to Wikidata; Name Abbreviations Index"
        },
        "output": "",
        "applicationPurpose": "Linking tabular data to knowledge graphs (CEA/CTA/CPA) for the SemTab challenge.",
        "userInterfaceTool": "",
        "checkedByAuthor": "",
        "checkedByAi": true,
        "doi": "",
        "citations": [
            {
                "ref": "2006_hadsell_dimensionality",
                "title": "Dimensionality reduction by learning an invariant mapping"
            },
            {
                "ref": "2010_nair_rectified",
                "title": "Rectified linear units improve restricted boltzmann machines"
            },
            {
                "ref": "2015_ritze_t2dv2",
                "title": "T2dv2 gold standard for matching web tables to DBpedia"
            }
        ],
        "uncertainFields": [
            {
                "field": "venue.acronym",
                "reason": "Paper is part of the ISWC SemTab challenge; exact workshop acronym used in the proceedings may vary."
            },
            {
                "field": "code",
                "reason": "No repository or download link is mentioned in the text provided."
            },
            {
                "field": "doi",
                "reason": "CEUR-WS challenge papers often lack DOIs; none is stated in the text."
            },
            {
                "field": "inputs.tableSources",
                "reason": "Datasets include SemTab and T2Dv2; exact original table sources are not explicitly detailed."
            },
            {
                "field": "output",
                "reason": "Submission/output format (e.g., CSV, RDF) is not specified in the text."
            },
            {
                "field": "kg.tripleStore",
                "reason": "Both DBpedia and Wikidata are used; field expects a single string so both are listed."
            },
            {
                "field": "nameOfApproach",
                "reason": "No specific system name is given; approach is described generically."
            },
            {
                "field": "techniqueTags",
                "reason": "A neural model is used but tags do not include 'neural network'; selected tags reflect heuristics and ontology features."
            }
        ]
    },
    {
        "id": "2020_zhang_sato",
        "added": "",
        "year": 2020,
        "firstAuthor": "Zhang",
        "authors": [
            "Dan Zhang",
            "Yoshihiko Suhara",
            "Jinfeng Li",
            "Madelon Hulsebos",
            "Çağatay Demiralp",
            "Wang-Chiew Tan"
        ],
        "title": "Sato: Contextual Semantic Type Detection in Tables",
        "venue": {
            "type": "conference",
            "acronym": "VLDB"
        },
        "nameOfApproach": "Sato",
        "techniqueTags": [
            "embeddings",
            "CRF",
            "transformer"
        ],
        "coreTasks": {
            "cta": true,
            "cpa": false,
            "cea": false,
            "cnea": false
        },
        "supportTasks": {
            "dataPreparation": {
                "description": "Feature extraction from column values and creation of a table-level topic vector from all table values via LDA; no explicit normalisation steps are detailed.",
                "spellChecker": "",
                "unitsOfMeasurements": ""
            },
            "columnClassification": "",
            "subjectDetection": "",
            "datatypeAnnotation": "",
            "typeAnnotation": "Predicts column semantic types using a deep neural network augmented with table-topic features and a linear-chain CRF for structured prediction.",
            "predicateAnnotation": "",
            "nilAnnotation": "",
            "entityLinking": {
                "description": "",
                "candidateGeneration": "",
                "entityDisambiguation": ""
            }
        },
        "mainMethod": {
            "type": "hybrid",
            "technique": "Neural network with LDA topic features and linear-chain CRF"
        },
        "revision": {
            "type": "fully automated",
            "description": "Predictions are produced automatically by the model without human intervention."
        },
        "domain": {
            "domain": "independent",
            "type": "generic"
        },
        "validation": {
            "goldStandard": "VizNet WebTables subset with 78 semantic types (derived from T2Dv2); ~80K tables with canonicalised headers.",
            "metrics": [
                "Macro-F1",
                "Weighted-F1"
            ]
        },
        "code": "https://github.com/megagonlabs/sato",
        "license": "Apache License 2.0",
        "inputs": {
            "typeOfTable": "Web tables",
            "tableSources": [
                "web"
            ]
        },
        "kg": {
            "tripleStore": "",
            "index": ""
        },
        "output": "",
        "applicationPurpose": "Semantic typing of table columns to support data cleaning, schema matching, and data discovery.",
        "userInterfaceTool": "Web UI (demo)",
        "usesLLM": null,
        "checkedByAuthor": "",
        "checkedByAi": true,
        "doi": "https://doi.org/10.48550/arXiv.1911.06311",
        "citations": [
            {
                "ref": "2019_hulsebos_sherlock",
                "title": "Sherlock: A deep learning approach to semantic data type detection"
            },
            {
                "ref": "2019_hu_viznet",
                "title": "VizNet: Towards a large-scale visualization learning and benchmarking repository"
            },
            {
                "ref": "2003_blei_latent",
                "title": "Latent Dirichlet Allocation"
            },
            {
                "ref": "2001_lafferty_conditional",
                "title": "Conditional Random Fields: Probabilistic Models for Segmenting and Labeling Sequence Data"
            },
            {
                "ref": "2008_cafarella_webtables",
                "title": "WebTables: Exploring the Power of Tables on the Web"
            },
            {
                "ref": "2011_venetis_recovering",
                "title": "Recovering Semantics of Tables on the Web"
            },
            {
                "ref": "2019_devlin_bert",
                "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"
            }
        ],
        "uncertainFields": [
            {
                "field": "venue.type",
                "reason": "The PDF appears to be an arXiv preprint; the final publication venue may be PVLDB (journal) rather than a conference."
            },
            {
                "field": "venue.acronym",
                "reason": "Set to 'VLDB' based on the file name; the official acronym could be 'PVLDB'."
            },
            {
                "field": "doi",
                "reason": "Using the arXiv DataCite DOI inferred from the arXiv identifier; a different publisher DOI may exist."
            },
            {
                "field": "kg.tripleStore",
                "reason": "The approach does not rely on a knowledge graph; no triple store is specified."
            },
            {
                "field": "output",
                "reason": "Output serialisation format is not stated; the system returns predicted types, not a specific file format."
            },
            {
                "field": "userInterfaceTool",
                "reason": "An online demo is mentioned but not formally described."
            },
            {
                "field": "techniqueTags[2]",
                "reason": "‘Transformer’ is included because BERT is discussed as an alternative single-column model, not the main one."
            },
            {
                "field": "citations",
                "reason": "Only key references are listed; the paper contains many more citations."
            }
        ]
    },
    {
        "id": "2020_abdelmageed_jentab",
        "added": "",
        "year": 2020,
        "firstAuthor": "Abdelmageed",
        "authors": [
            "Nora Abdelmageed",
            "Sirko Schindler"
        ],
        "title": "JenTab: Matching Tabular Data to Knowledge Graphs",
        "venue": {
            "type": "challenge",
            "acronym": "SemTab"
        },
        "nameOfApproach": "JenTab",
        "techniqueTags": [
            "rule-based",
            "ontology-driven"
        ],
        "coreTasks": {
            "cta": true,
            "cpa": true,
            "cea": true,
            "cnea": false
        },
        "supportTasks": {
            "dataPreparation": {
                "description": "Preprocessing fixes encodings, tokenises/sanitises text, and applies an off-the-shelf spell checker; columns are typed as OBJECT/DATE/STRING/NUMBER.",
                "spellChecker": "autocorrect used after ftfy and regex-based cleaning",
                "unitsOfMeasurements": ""
            },
            "columnClassification": "Columns are typed into OBJECT, DATE, STRING, NUMBER during preprocessing to steer later steps.",
            "subjectDetection": "Assumes a single subject column and uses it to drive property discovery across rows.",
            "datatypeAnnotation": "Literal columns (DATE/STRING/NUMBER) are recognised to enable datatype-aware matching for CPA (date parsing, string overlap, numeric tolerance).",
            "typeAnnotation": "Types are derived from CEA candidates via P31, P279, and P31/P279 and filtered/selected with support and LCS strategies.",
            "predicateAnnotation": "Properties between column pairs are generated from subject candidates and matched to target cells (majority vote at column level).",
            "nilAnnotation": "",
            "entityLinking": {
                "description": "Generates CEA candidates via label lookup and string similarity, then filters by context (properties/columns) and selects by similarity/popularity.",
                "candidateGeneration": "Wikidata Lookup API with strategies (full/cleaned/autocorrected values, token permutations) plus Jaro-Winkler/Levenshtein-based retrieval.",
                "entityDisambiguation": "Filters by unmatched/property support and string distance; final selection by Levenshtein similarity with popularity as tie-breaker."
            }
        },
        "mainMethod": {
            "type": "unsupervised",
            "technique": "rule-based"
        },
        "revision": {
            "type": "fully automated",
            "description": "Create–Filter–Select pipeline executes automatically; no explicit user validation stage."
        },
        "domain": {
            "domain": "independent",
            "type": "generic"
        },
        "validation": {
            "goldStandard": "SemTab 2020 rounds (R1–R4) and Tough Tables (2T) subsets",
            "metrics": [
                "F1",
                "Precision"
            ]
        },
        "code": "",
        "license": "Not Specified",
        "inputs": {
            "typeOfTable": "CSV",
            "tableSources": []
        },
        "kg": {
            "tripleStore": "Wikidata",
            "index": "Wikidata Lookup API and SPARQL endpoint"
        },
        "output": "",
        "applicationPurpose": "Semantic table annotation to link tabular data to Wikidata",
        "userInterfaceTool": "",
        "checkedByAuthor": "",
        "checkedByAi": true,
        "doi": "",
        "citations": [
            {
                "ref": "2020_cutrona_tough",
                "title": "Tough Tables: Carefully Evaluating Entity Linking for Tabular Data"
            },
            {
                "ref": "2020_hassanzadeh_semtab",
                "title": "SemTab 2020: Semantic Web Challenge on Tabular Data to Knowledge Graph Matching Data Sets"
            },
            {
                "ref": "2019_keil_efficient",
                "title": "Efficient bounded Jaro-Winkler Similarity based search"
            },
            {
                "ref": "1965_levenshtein_binary",
                "title": "Binary codes capable of correcting deletions, insertions and reversals"
            },
            {
                "ref": "2014_vrandecic_wikidata",
                "title": "Wikidata: a free collaborative knowledgebase"
            },
            {
                "ref": "1990_winkler_string",
                "title": "String comparator metrics and enhanced decision rules in the fellegi-sunter model of record linkage"
            }
        ],
        "uncertainFields": [
            {
                "field": "venue.acronym",
                "reason": "Paper appears in the SemTab 2020 challenge/workshop proceedings; exact official acronym of the venue is not explicitly stated."
            },
            {
                "field": "validation.goldStandard",
                "reason": "Text reports evaluations on SemTab 2020 rounds and 2T, but the precise GS names/versions are not formalised in the paper."
            },
            {
                "field": "inputs.tableSources",
                "reason": "Sources of the input tables (web/wiki/spreadsheet, etc.) are not explicitly specified for this paper."
            },
            {
                "field": "output",
                "reason": "Export/serialisation format of the annotations (e.g., RDF/CSV) is not described."
            },
            {
                "field": "code",
                "reason": "No repository or download link for the implementation is provided."
            },
            {
                "field": "license",
                "reason": "Paper license (CC BY 4.0) is stated, but code/approach licence is not specified."
            },
            {
                "field": "userInterfaceTool",
                "reason": "The presence of a CLI or Web UI is not discussed."
            },
            {
                "field": "kg.index",
                "reason": "System relies on Wikidata Lookup/SPARQL; no separate indexing layer is detailed."
            },
            {
                "field": "doi",
                "reason": "Workshop paper likely has no DOI; none is provided in the document."
            },
            {
                "field": "mainMethod.type",
                "reason": "Classified as unsupervised because no training data is used; authors do not explicitly frame it under this taxonomy."
            }
        ]
    },
    {
        "id": "2020_azzi_amalgam",
        "added": "",
        "year": 2020,
        "firstAuthor": "Azzi",
        "authors": [
            "Rabia Azzi",
            "Gayo Diallo"
        ],
        "title": "AMALGAM: making tabular dataset explicit with knowledge graph",
        "venue": {
            "type": "challenge",
            "acronym": "SemTab"
        },
        "nameOfApproach": "AMALGAM",
        "techniqueTags": [
            "rule-based",
            "ontology-driven"
        ],
        "coreTasks": {
            "cta": true,
            "cpa": false,
            "cea": true,
            "cnea": false
        },
        "supportTasks": {
            "dataPreparation": {
                "description": "Pre-processing tables (encoding/delimiters) with Pandas; integrate spell checking to correct noisy items.",
                "spellChecker": "Gurunudi and Wikipedia API with fuzzy string matching (threshold 90%).",
                "unitsOfMeasurements": ""
            },
            "columnClassification": "",
            "subjectDetection": "",
            "datatypeAnnotation": "",
            "typeAnnotation": "Assigns column types by Wikidata lookup of P31/P279/P361 statements and selects the most frequent candidate.",
            "predicateAnnotation": "",
            "nilAnnotation": "",
            "entityLinking": {
                "description": "Generates candidates via Wikidata lookups and uses column concept plus row context to select target entities.",
                "candidateGeneration": "Wikidata wbsearchentities/parse API and claims of the first-row entity; fall back after spell correction.",
                "entityDisambiguation": "Use CTA-derived column concept and context matching; validate with fuzzy matching and choose the most consistent candidate."
            }
        },
        "mainMethod": {
            "type": "unsupervised",
            "technique": "rule-based"
        },
        "revision": {
            "type": "fully automated",
            "description": "Automatic pipeline combining lookups, filtering and spell checking; no manual review during evaluation."
        },
        "domain": {
            "domain": "independent",
            "type": "generic"
        },
        "validation": {
            "goldStandard": "SemTab 2020 (Rounds 1–4) and Tough Tables (2T)",
            "metrics": [
                "F1",
                "Precision"
            ]
        },
        "code": "",
        "license": "Not Specified",
        "inputs": {
            "typeOfTable": "CSV",
            "tableSources": [
                "web",
                "wiki"
            ]
        },
        "kg": {
            "tripleStore": "Wikidata",
            "index": ""
        },
        "output": "",
        "applicationPurpose": "Fast annotation of tabular data with KG entities and types (CTA/CEA) for table-to-KG matching.",
        "userInterfaceTool": "",
        "checkedByAuthor": "",
        "checkedByAi": true,
        "doi": "",
        "citations": [
            {
                "ref": "2016_wilkinson_the",
                "title": "The FAIR Guiding Principles for scientific data management and stewardship."
            },
            {
                "ref": "2011_diallo_efficient",
                "title": "Efficient Building of Local Repository of Distributed Ontologies."
            },
            {
                "ref": "2020_ji_a",
                "title": "A survey on knowledge graphs: Representation, acquisition and applications."
            },
            {
                "ref": "2018_subramanian_semantic",
                "title": "Semantic Interpretation and Integration of Open Data Tables."
            },
            {
                "ref": "2016_taheriyan_learning",
                "title": "Learning the semantics of structured data sources."
            },
            {
                "ref": "2019_zhang_a",
                "title": "A semi-structured information semantic annotation method for Web pages."
            },
            {
                "ref": "2017_efthymiou_matching",
                "title": "Matching Web Tables with Knowledge Base Entities: From Entity Lookups to Entity Embeddings."
            },
            {
                "ref": "2020_eslahi_annotating",
                "title": "Annotating Web Tables through Knowledge Bases: A Context-Based Approach."
            },
            {
                "ref": "2019_hassanzadeh_semtab2019",
                "title": "SemTab2019: Semantic Web Challenge on Tabular Data to Knowledge Graph Matching - 2019 Data Sets (Version 2019)."
            },
            {
                "ref": "2020_hassanzadeh_semtab2020",
                "title": "SemTab2020: Semantic Web Challenge on Tabular Data to Knowledge Graph Matching - 2020 Data Sets."
            },
            {
                "ref": "2019_shashank_systematic",
                "title": "Systematic review of spell-checkers for highly inflectional languages."
            },
            {
                "ref": "2020_cutrona_tough",
                "title": "Tough Tables: Carefully Evaluating Entity Linking for Tabular Data."
            }
        ],
        "uncertainFields": [
            {
                "field": "venue.acronym",
                "reason": "Paper is in the SemTab 2020 challenge context; exact workshop label/acronym vs. hosting venue not explicitly stated."
            },
            {
                "field": "code",
                "reason": "No repository or download link mentioned."
            },
            {
                "field": "license",
                "reason": "Publication license (CC BY 4.0) appears, but software licence of the approach is not specified."
            },
            {
                "field": "inputs.tableSources",
                "reason": "SemTab tables derive from web/wiki sources, but the paper does not explicitly enumerate table origins."
            },
            {
                "field": "output",
                "reason": "Submission/output format (e.g., CSV/RDF) not explicitly described."
            },
            {
                "field": "kg.index",
                "reason": "Uses Wikidata API; an explicit indexing component is not described."
            },
            {
                "field": "userInterfaceTool",
                "reason": "No UI or tool name is described."
            },
            {
                "field": "doi",
                "reason": "No DOI is provided for the paper."
            },
            {
                "field": "supportTasks.subjectDetection",
                "reason": "Row context is discussed, but a dedicated subject column detection procedure is not clearly defined."
            },
            {
                "field": "supportTasks.columnClassification",
                "reason": "The paper does not describe a specific column literal/NE classification step."
            }
        ]
    },
    {
        "id": "2020_baazouzi_kepler-asi",
        "added": "",
        "year": 2020,
        "firstAuthor": "Baazouzi",
        "authors": [
            "Wiem Baazouzi",
            "Marouen Kachroudi",
            "Sami Faiz"
        ],
        "title": "Kepler-aSI : Kepler as A Semantic Interpreter",
        "venue": {
            "type": "challenge",
            "acronym": "SemTab"
        },
        "nameOfApproach": "Kepler-aSI",
        "techniqueTags": [
            "rule-based",
            "ontology-driven"
        ],
        "coreTasks": {
            "cta": true,
            "cpa": false,
            "cea": false,
            "cnea": false
        },
        "supportTasks": {
            "dataPreparation": {
                "description": "Lowercasing, removal of bracketed text/special characters, acronym resolution, and regex-based normalisation of units.",
                "spellChecker": "Spell checking used during preprocessing; cited as the most effective technique tried.",
                "unitsOfMeasurements": "Regex normalisation for many units (e.g., area, currency, length, mass, temperature)."
            },
            "columnClassification": "16 regex-based detectors (e.g., numbers, URLs, addresses) with a 0.7 threshold to mark L-columns vs NE-columns.",
            "subjectDetection": "Select S-column among NE-columns via combined score using average words, empty-cell fraction, uniqueness, and distance to first NE-column.",
            "datatypeAnnotation": "",
            "typeAnnotation": "CTA via SPARQL on Wikidata using cell contents (ItemDescription) to infer column class (P31).",
            "predicateAnnotation": "",
            "nilAnnotation": "",
            "entityLinking": {
                "description": "",
                "candidateGeneration": "",
                "entityDisambiguation": ""
            }
        },
        "mainMethod": {
            "type": "unsupervised",
            "technique": "rule-based"
        },
        "revision": {
            "type": "fully automated",
            "description": "End-to-end automatic pipeline; no interactive user validation described."
        },
        "domain": {
            "domain": "independent",
            "type": ""
        },
        "validation": {
            "goldStandard": "SemTab 2020 challenge (Rounds 1–4), CTA task",
            "metrics": [
                "F1",
                "Precision"
            ]
        },
        "code": "",
        "license": "Not Specified",
        "inputs": {
            "typeOfTable": "CSV",
            "tableSources": []
        },
        "kg": {
            "tripleStore": "Wikidata",
            "index": ""
        },
        "output": "",
        "applicationPurpose": "Participation in SemTab 2020 CTA task.",
        "userInterfaceTool": "",
        "checkedByAuthor": "",
        "checkedByAi": true,
        "doi": "",
        "citations": [
            {
                "ref": "2016_pham_semantic",
                "title": "Semantic labeling: a domain-independent approach"
            },
            {
                "ref": "2016_taheriyan_learning",
                "title": "Learning the semantics of structured data sources"
            },
            {
                "ref": "2015_ramnandan_assigning",
                "title": "Assigning semantic labels to data sources"
            },
            {
                "ref": "2012_knoblock_semi-automatically",
                "title": "Semi-automatically mapping structured sources into the semantic web"
            },
            {
                "ref": "2020_cremaschi_a",
                "title": "A fully automated approach to a complete semantic table interpretation"
            },
            {
                "ref": "2017_zhang_effective",
                "title": "Effective and efficient semantic table interpretation using tableminer+"
            },
            {
                "ref": "2017_kachroudi_oaei",
                "title": "OAEI 2017 results of KEPLER"
            },
            {
                "ref": "2018_kachroudi_dealing",
                "title": "Dealing with direct and indirect ontology alignment"
            },
            {
                "ref": "2018_kachroudi_kepler",
                "title": "KEPLER at OAEI 2018"
            },
            {
                "ref": "2016_ehrlinger_towards",
                "title": "Towards a definition of knowledge graphs"
            },
            {
                "ref": "2018_farber_linked",
                "title": "Linked data quality of dbpedia, freebase, opencyc, wikidata, and yago"
            },
            {
                "ref": "2019_cremaschi_mantistable",
                "title": "Mantistable: an automatic approach for the semantic table interpretation"
            },
            {
                "ref": "2015_ritze_matching",
                "title": "Matching html tables to dbpedia"
            }
        ],
        "uncertainFields": [
            {
                "field": "venue.acronym",
                "reason": "Classified as the SemTab challenge; proceedings may also be associated with a workshop venue."
            },
            {
                "field": "code",
                "reason": "No repository or download link is mentioned."
            },
            {
                "field": "license",
                "reason": "Paper is under CC BY 4.0, but no software licence is provided for the approach."
            },
            {
                "field": "inputs.tableSources",
                "reason": "Only the CSV format is stated; the original source (web/wiki/gov-open-data, etc.) is not specified."
            },
            {
                "field": "output",
                "reason": "No export/serialisation format is described."
            },
            {
                "field": "applicationPurpose",
                "reason": "Described as a SemTab 2020 submission; exact downstream application beyond the challenge is not detailed."
            },
            {
                "field": "validation.goldStandard",
                "reason": "Named generically as SemTab 2020 CTA; specific dataset subset identifiers are not given."
            },
            {
                "field": "supportTasks.dataPreparation.spellChecker",
                "reason": "Spell checking is mentioned as tried and effective, but details are limited."
            },
            {
                "field": "citations[4].ref",
                "reason": "Slug formation assumes exact title wording; minor variations could change the first word."
            }
        ]
    },
    {
        "id": "2020_chen_linkingpark",
        "added": "",
        "year": 2020,
        "firstAuthor": "Chen",
        "authors": [
            "Shuang Chen",
            "Alperen Karaoglu",
            "Carina Negreanu",
            "Tingting Ma",
            "Jin-Ge Yao",
            "Jack Williams",
            "Andy Gordon",
            "Chin-Yew Lin"
        ],
        "title": "LinkingPark: An Integrated Approach for Semantic Table Interpretation",
        "venue": {
            "type": "challenge",
            "acronym": "SemTab"
        },
        "nameOfApproach": "LinkingPark",
        "techniqueTags": [
            "rule-based",
            "ontology-driven",
            "embeddings"
        ],
        "coreTasks": {
            "cta": true,
            "cpa": true,
            "cea": true,
            "cnea": false
        },
        "supportTasks": {
            "dataPreparation": {
                "description": "Normalises mentions, corrects spelling, queries MediaWiki, and builds a fine-grained ElasticSearch index for candidate retrieval.",
                "spellChecker": "Tailored mention spelling corrector using Levenshtein 1-edit distance over Wikidata titles.",
                "unitsOfMeasurements": "Unit conversion is handled for numerical properties during property linking."
            },
            "columnClassification": "",
            "subjectDetection": "Main column detection is assumed/used to compute row support in disambiguation and for property linking.",
            "datatypeAnnotation": "For numerical/date columns, matches value ranges and units to properties via pre-computed statistics over types.",
            "typeAnnotation": "Heuristic multi-pass sieve over linked entities using SupportCount, AverageLevel, and Population/InstanceRank on Wikidata types.",
            "predicateAnnotation": "Two-phase property linker with lexical/direct matches, row voting, and refinement using nearest neighbours (BigGraph) and statistics for numerical columns.",
            "nilAnnotation": "",
            "entityLinking": {
                "description": "Cascaded candidate generation followed by an iterative coarse-to-fine disambiguation enforcing column type consistency and row property relatedness.",
                "candidateGeneration": "MediaWiki API (top-k), spelling correction for mentions, and fine-grained ElasticSearch (BM25 word+trigram) fuzzy matching.",
                "entityDisambiguation": "Iterative Classification Algorithm with TF–IDF-weighted property/type features for column support, lexical/property co-occurrence for row support, pruning, and fine-grained value comparison."
            },
            "entityLinkingNote": ""
        },
        "mainMethod": {
            "type": "unsupervised",
            "technique": "rule-based"
        },
        "revision": {
            "type": "fully automated",
            "description": "Automatic end-to-end pipeline; no human-in-the-loop during SemTab runs."
        },
        "domain": {
            "domain": "independent",
            "type": "generic"
        },
        "validation": {
            "goldStandard": "SemTab 2020 (Rounds 1–4)",
            "metrics": [
                "F1",
                "Precision"
            ]
        },
        "code": "",
        "license": "Not Specified",
        "inputs": {
            "typeOfTable": "CSV",
            "tableSources": [
                "wiki"
            ]
        },
        "kg": {
            "tripleStore": "Wikidata",
            "index": "ElasticSearch (BM25 word and trigram) for entity titles; PyTorch-BigGraph for nearest-neighbour similarity"
        },
        "output": "CSV",
        "applicationPurpose": "Challenge system for semantic table interpretation on SemTab 2020.",
        "userInterfaceTool": "",
        "checkedByAuthor": "",
        "checkedByAi": true,
        "doi": "",
        "citations": [
            {
                "ref": "2015_bhagavatula_tabel",
                "title": "Tabel: entity linking in web tables"
            },
            {
                "ref": "2017_efthymiou_matching",
                "title": "Matching web tables with knowledge base entities: from entity lookups to entity embeddings"
            },
            {
                "ref": "2020_karaoglu_wiki2row",
                "title": "Wiki2row - the in’s and out’s or row suggestion with a large scale knowledge base"
            },
            {
                "ref": "2019_lerer_pytorch-biggraph",
                "title": "PyTorch-BigGraph: A Large-scale Graph Embedding System"
            },
            {
                "ref": "2010_limaye_annotating",
                "title": "Annotating and searching web tables using entities, types and relationships"
            },
            {
                "ref": "2015_ritze_matching",
                "title": "Matching HTML tables to DBpedia"
            },
            {
                "ref": "2019_thawani_entity",
                "title": "Entity linking to knowledge graphs to infer column types and properties"
            }
        ],
        "uncertainFields": [
            {
                "field": "doi",
                "reason": "CEUR-WS challenge papers typically lack DOIs; no DOI is stated in the paper."
            },
            {
                "field": "inputs.typeOfTable",
                "reason": "SemTab submissions are commonly CSV, but the exact file format is not explicitly stated."
            },
            {
                "field": "inputs.tableSources[0]",
                "reason": "Tables are synthetically generated from Wikidata for SemTab; mapping this to 'wiki' may be approximate."
            },
            {
                "field": "output",
                "reason": "Submission format is not explicitly specified; CSV is inferred from common SemTab practice."
            },
            {
                "field": "userInterfaceTool",
                "reason": "No UI/tool is described."
            },
            {
                "field": "code",
                "reason": "No repository link is provided in the paper."
            }
        ]
    },
    {
        "id": "2020_cremaschi_a",
        "added": "",
        "year": 2020,
        "firstAuthor": "Cremaschi",
        "authors": [
            "Marco Cremaschi",
            "Flavio De Paoli",
            "Anisa Rula",
            "Blerina Spahiu"
        ],
        "title": "A fully automated approach to a complete Semantic Table Interpretation",
        "venue": {
            "type": "journal",
            "acronym": "FGCS"
        },
        "nameOfApproach": "MantisTable",
        "techniqueTags": [
            "rule-based",
            "ontology-driven"
        ],
        "coreTasks": {
            "cta": true,
            "cpa": true,
            "cea": true,
            "cnea": false
        },
        "supportTasks": {
            "dataPreparation": {
                "description": "Normalises table content (HTML removal, case folding, bracket text removal), expands acronyms and abbreviations, and standardises units of measurement via regular expressions and conversion rules.",
                "spellChecker": "Oxford English Dictionary used for acronym/abbreviation expansion; no explicit spell-checker.",
                "unitsOfMeasurements": "Comprehensive regex-based detection and conversion (e.g., area, length, mass, speed, temperature)."
            },
            "columnClassification": "Regex-driven detection of datatypes; classifies columns as Literal (L) vs Named-Entity (NE).",
            "subjectDetection": "Heuristic scoring using fraction of empty cells, uniqueness, distance from first NE-column, and average words per cell.",
            "datatypeAnnotation": "Maps detected Regextypes to XSD datatypes; disambiguates where one-to-many mappings occur.",
            "typeAnnotation": "Selects column concepts via entity linking on sampled cells, rdf:type aggregation, and ontology hierarchy resolution.",
            "predicateAnnotation": "Finds predicates between S-column concept and other columns using exploratory SPARQL and ABSTAT summary profiles; ranks by context overlap and frequency.",
            "nilAnnotation": "",
            "entityLinking": {
                "description": "Links cells to KG entities and assigns best candidate per cell.",
                "candidateGeneration": "SPARQL queries over DBpedia using cell text, header synonyms, and limited top-k results.",
                "entityDisambiguation": "Combines context overlap (row/header), edit distance on labels, and a weighted confidence score."
            }
        },
        "mainMethod": {
            "type": "unsupervised",
            "technique": "rule-based"
        },
        "revision": {
            "type": "semi automated",
            "description": "Pipeline runs fully automatically; the Web UI allows users to inspect and optionally edit annotations post-hoc."
        },
        "domain": {
            "domain": "independent",
            "type": "general"
        },
        "validation": {
            "goldStandard": "T2Dv2, Limaye200, SemTab2019",
            "metrics": [
                "Precision",
                "Recall",
                "F1"
            ]
        },
        "code": "https://bitbucket.org/disco_unimib/mantistable-tool.py/",
        "license": "Not Specified",
        "inputs": {
            "typeOfTable": "Web tables",
            "tableSources": [
                "web",
                "wiki"
            ]
        },
        "kg": {
            "tripleStore": "DBpedia",
            "index": "ABSTAT summaries and SPARQL endpoint"
        },
        "output": "RDF, JSON-LD",
        "applicationPurpose": "End-to-end semantic table interpretation and KG matching for CTA/CEA/CPA tasks.",
        "userInterfaceTool": "Web UI (Django-based application)",
        "checkedByAuthor": "",
        "checkedByAi": true,
        "doi": "https://doi.org/10.1016/j.future.2020.05.019",
        "citations": [
            {
                "ref": "2010_limaye_annotating",
                "title": "Annotating and searching web tables using entities, types and relationships"
            },
            {
                "ref": "2015_ritze_matching",
                "title": "Matching HTML tables to DBpedia"
            },
            {
                "ref": "2017_zhang_effective",
                "title": "Effective and efficient semantic table interpretation using TableMiner+"
            },
            {
                "ref": "2016_neumaier_multi-level",
                "title": "Multi-level semantic labelling of numerical values"
            },
            {
                "ref": "2017_efthymiou_matching",
                "title": "Matching web tables with knowledge base entities: From entity lookups to entity embeddings"
            },
            {
                "ref": "2013_deng_scalable",
                "title": "Scalable column concept determination for web tables using large knowledge bases"
            },
            {
                "ref": "2011_venetis_recovering",
                "title": "Recovering semantics of tables on the web"
            },
            {
                "ref": "2012_wang_understanding",
                "title": "Understanding tables on the web"
            },
            {
                "ref": "2013_mulwad_semantic",
                "title": "Semantic message passing for generating linked data from tables"
            },
            {
                "ref": "2015_mazumdar_a",
                "title": "A tool for creating and visualizing semantic annotations on relational tables"
            }
        ],
        "uncertainFields": [
            {
                "field": "license",
                "reason": "Paper states code is open and freely available but does not name a licence."
            },
            {
                "field": "kg.index",
                "reason": "ABSTAT is used as a summary index; exact indexing/storage details beyond summaries and SPARQL are not fully specified."
            },
            {
                "field": "inputs.typeOfTable",
                "reason": "They process generic tables and evaluate on Web/Wikipedia datasets; broader formats may also be supported by the tool."
            },
            {
                "field": "output",
                "reason": "Multiple serialisations are supported (RDF/XML, N3, N-Triples, N-Quads, Turtle, JSON-LD); field condensed to a string."
            },
            {
                "field": "revision.type",
                "reason": "Approach is fully automated but the UI supports optional user edits; marked as semi automated to reflect this."
            },
            {
                "field": "userInterfaceTool",
                "reason": "Described as a user-friendly Web app built with Django; exact UI label is not formalised in the paper."
            }
        ]
    },
    {
        "id": "2020_eslahi_annotating",
        "added": "",
        "year": 2020,
        "firstAuthor": "Eslahi",
        "authors": [
            "Yasamin Eslahi",
            "Akansha Bhardwaj",
            "Paolo Rosso",
            "Kurt Stockinger",
            "Philippe Cudré-Mauroux"
        ],
        "title": "Annotating Web Tables through Knowledge Bases: A Context-Based Approach",
        "venue": {
            "type": "conference",
            "acronym": "SDS"
        },
        "nameOfApproach": "Context-Lookup; Looping",
        "techniqueTags": [
            "embeddings",
            "ontology-driven"
        ],
        "coreTasks": {
            "cta": false,
            "cpa": false,
            "cea": true,
            "cnea": false
        },
        "supportTasks": {
            "dataPreparation": {
                "description": "",
                "spellChecker": "",
                "unitsOfMeasurements": ""
            },
            "columnClassification": "",
            "subjectDetection": "",
            "datatypeAnnotation": "",
            "typeAnnotation": "",
            "predicateAnnotation": "",
            "nilAnnotation": "",
            "entityLinking": {
                "description": "Entity candidates are gathered and disambiguated using table context and embedding-based graphs.",
                "candidateGeneration": "Surface-form lookup to retrieve Wikidata identifiers for label-column entries.",
                "entityDisambiguation": "Context-Lookup (majority entity types and relations) and Looping (embedding graph with PageRank)."
            }
        },
        "mainMethod": {
            "type": "unsupervised",
            "technique": "embeddings"
        },
        "revision": {
            "type": "fully automated",
            "description": "Annotations are produced automatically without user validation."
        },
        "domain": {
            "domain": "independent",
            "type": "web tables"
        },
        "validation": {
            "goldStandard": "T2D; Limaye (corrected to Wikidata)",
            "metrics": [
                "Precision",
                "Recall",
                "F1"
            ]
        },
        "code": "https://github.com/eXascaleInfolab/sds2020_web_table_annotation",
        "license": "Not Specified",
        "inputs": {
            "typeOfTable": "HTML tables",
            "tableSources": [
                "web"
            ]
        },
        "kg": {
            "tripleStore": "Wikidata",
            "index": "Surface-form index mapping labels to Wikidata IDs"
        },
        "output": "",
        "applicationPurpose": "Enable web table annotation to support knowledge base augmentation, search, and downstream applications.",
        "userInterfaceTool": "",
        "checkedByAuthor": "",
        "checkedByAi": true,
        "doi": "",
        "citations": [
            {
                "ref": "2010_limaye_annotating",
                "title": "Annotating and Searching Web Tables Using Entities, Types and Relationships"
            },
            {
                "ref": "2017_efthymiou_matching",
                "title": "Matching web tables with knowledge base entities: From entity lookups to entity embeddings"
            },
            {
                "ref": "2016_zwicklbauer_doser",
                "title": "DoSeR: A knowledge-base agnostic framework for entity disambiguation using semantic embeddings"
            },
            {
                "ref": "2008_cafarella_webtables",
                "title": "WebTables: Exploring the Power of Tables on the Web"
            },
            {
                "ref": "2011_venetis_recovering",
                "title": "Recovering semantics of tables on the web"
            }
        ],
        "uncertainFields": [
            {
                "field": "venue.acronym",
                "reason": "The acronym is inferred from the repository name and not explicitly stated in the text."
            },
            {
                "field": "doi",
                "reason": "A DOI is not visible in the provided text; it may be absent or on a missing page."
            },
            {
                "field": "code",
                "reason": "The PDF shows a GitHub link with line breaks; the URL here is a normalised guess."
            },
            {
                "field": "kg.tripleStore",
                "reason": "While the corrected annotations use Wikidata, parts of the discussion reference DBpedia; Wikidata is assumed for the system’s target KG."
            },
            {
                "field": "inputs.tableSources",
                "reason": "Datasets comprise web tables and may include Wikipedia sources; only 'web' is reported."
            },
            {
                "field": "techniqueTags[1]",
                "reason": "‘Ontology-driven’ is included because KB types/relations are exploited, but the paper does not label the approach as such."
            },
            {
                "field": "output",
                "reason": "No explicit output serialisation format is specified."
            }
        ]
    },
    {
        "id": "2020_guo_web",
        "added": "",
        "year": 2020,
        "firstAuthor": "Guo",
        "authors": [
            "Tong Guo",
            "Derong Shen",
            "Tiezheng Nie",
            "Yue Kou"
        ],
        "title": "Web Table Column Type Detection Using Deep Learning and Probability Graph Model",
        "venue": {
            "type": "conference",
            "acronym": "WISA"
        },
        "nameOfApproach": "",
        "techniqueTags": [
            "CRF",
            "embeddings"
        ],
        "coreTasks": {
            "cta": true,
            "cpa": false,
            "cea": false,
            "cnea": false
        },
        "supportTasks": {
            "dataPreparation": {
                "description": "Combines word- and character-level representations to handle noisy strings and short sequences; numeric columns use statistical features.",
                "spellChecker": "",
                "unitsOfMeasurements": ""
            },
            "columnClassification": "Columns are split into character vs numeric before modelling.",
            "subjectDetection": "",
            "datatypeAnnotation": "",
            "typeAnnotation": "Predicts KG class/type for each column via BiGRU+Attention pre-classifier followed by CRF over columns.",
            "predicateAnnotation": "",
            "nilAnnotation": "",
            "entityLinking": {
                "description": "",
                "candidateGeneration": "",
                "entityDisambiguation": ""
            }
        },
        "mainMethod": {
            "type": "supervised",
            "technique": "CRF with BiGRU-Attention",
            "supervision": {
                "type": "supervised"
            }
        },
        "revision": {
            "type": "fully automated",
            "description": "End-to-end automatic pipeline; no manual post-editing described. "
        },
        "domain": {
            "domain": "independent",
            "type": "generic web tables"
        },
        "validation": {
            "goldStandard": "T2Dv2; Limaye. ",
            "metrics": [
                "Precision",
                "Recall",
                "F1",
                "Micro-F1",
                "Macro-F1",
                "Weighted-F1"
            ]
        },
        "code": "",
        "license": "Not Specified",
        "inputs": {
            "typeOfTable": "Web tables",
            "tableSources": [
                "web"
            ]
        },
        "kg": {
            "tripleStore": "DBpedia",
            "index": ""
        },
        "output": "",
        "applicationPurpose": "Improve column type detection for table interpretation by modelling single-column semantics and inter-column dependencies. ",
        "userInterfaceTool": "",
        "checkedByAuthor": "",
        "checkedByAi": true,
        "doi": "https://doi.org/10.1007/978-3-030-60029-7_37",
        "citations": [
            {
                "ref": "",
                "title": "Web table extraction, retrieval, and augmentation: a survey"
            },
            {
                "ref": "",
                "title": "Ten Years of Web Tables"
            },
            {
                "ref": "",
                "title": "Table cell search for question answering"
            },
            {
                "ref": "",
                "title": "Profiling the potential of web tables for augmenting cross-domain knowledge bases"
            },
            {
                "ref": "",
                "title": "Knowledge base augmentation using tabular data"
            },
            {
                "ref": "",
                "title": "Towards disambiguating web tables"
            },
            {
                "ref": "",
                "title": "Effective and efficient semantic table interpretation using tableminer+"
            },
            {
                "ref": "",
                "title": "Matching web tables with knowledge base entities: from entity lookups to entity embeddings"
            },
            {
                "ref": "",
                "title": "Annotating and searching web tables using entities, types and relationships"
            },
            {
                "ref": "",
                "title": "Using linked data to interpret tables"
            },
            {
                "ref": "",
                "title": "Tabel: entity linking in web tables"
            },
            {
                "ref": "",
                "title": "Recovering semantics of tables on the web"
            },
            {
                "ref": "",
                "title": "Assigning semantic labels to data sources"
            },
            {
                "ref": "",
                "title": "Semantic labeling: a domain-independent approach"
            },
            {
                "ref": "",
                "title": "ColNet: embedding the semantics of web tables for column type prediction"
            },
            {
                "ref": "",
                "title": "Sherlock: a deep learning approach to semantic data type detection"
            },
            {
                "ref": "",
                "title": "Distributed representations of sentences and documents"
            },
            {
                "ref": "",
                "title": "Matching HTML tables to DBpedia"
            },
            {
                "ref": "",
                "title": "BiRNN-DKT: transfer bi-directional LSTM RNN for knowledge tracing"
            }
        ],
        "uncertainFields": [
            {
                "field": "venue.type",
                "reason": "WISA is presented as LNCS 12432; assumed as a conference venue but could be interpreted as a workshop. "
            },
            {
                "field": "inputs.tableSources",
                "reason": "Limaye tables are often sourced from Wikipedia; we conservatively marked sources as \"web\" only."
            },
            {
                "field": "output",
                "reason": "No export/serialisation format for annotations is specified in the paper."
            },
            {
                "field": "mainMethod.type",
                "reason": "The approach combines a supervised neural classifier with a CRF over column sequences; could be seen as hybrid, but we classified it as supervised."
            },
            {
                "field": "kg.index",
                "reason": "No specific indexing infrastructure is described beyond use of DBpedia and co-occurrence/relationship matrices."
            },
            {
                "field": "citations[0].ref",
                "reason": "First-author surname not explicitly given in the reference snippet; slug cannot be safely constructed."
            }
        ]
    },
    {
        "id": "2020_huynh_dagobah",
        "added": "",
        "year": 2020,
        "firstAuthor": "Huynh",
        "authors": [
            "Viet-Phi Huynh",
            "Jixiong Liu",
            "Yoan Chabot",
            "Thomas Labbé",
            "Pierre Monnin",
            "Raphaël Troncy"
        ],
        "title": "DAGOBAH: Enhanced Scoring Algorithms for Scalable Annotations of Tabular Data",
        "venue": {
            "type": "challenge",
            "acronym": "SemTab"
        },
        "nameOfApproach": "DAGOBAH",
        "techniqueTags": [
            "rule-based",
            "clustering",
            "embeddings",
            "ontology-driven"
        ],
        "coreTasks": {
            "cta": true,
            "cpa": true,
            "cea": true,
            "cnea": false
        },
        "supportTasks": {
            "dataPreparation": {
                "description": "Candidate lookup via regex token matching and thresholded Levenshtein; custom Wikidata-based index for scalable retrieval.",
                "spellChecker": "",
                "unitsOfMeasurements": ""
            },
            "columnClassification": "",
            "subjectDetection": "",
            "datatypeAnnotation": "",
            "typeAnnotation": "Uses P31/P279 hierarchy and ranks; majority voting picks the most specific fine-grained type.",
            "predicateAnnotation": "Selects relation by occurrence and accumulated confidence; supports entity, numeric, string and date tails with tailored matching.",
            "nilAnnotation": "",
            "entityLinking": {
                "description": "Generates candidates with label/alias matches and disambiguates using context-aware scoring influenced by CPA.",
                "candidateGeneration": "Regex inclusion of all tokens and Levenshtein ratio (top-k) over labels/aliases.",
                "entityDisambiguation": "Score combines literal similarity and graph-context matches; CPA-consistent candidates are boosted."
            }
        },
        "mainMethod": {
            "type": "unsupervised",
            "technique": "rule-based scoring and clustering"
        },
        "revision": {
            "type": "fully automated",
            "description": "End-to-end automatic pipeline; no manual post-editing described."
        },
        "domain": {
            "domain": "independent",
            "type": "generic"
        },
        "validation": {
            "goldStandard": "SemTab2020 (Rounds 1–4) datasets including Tough Tables",
            "metrics": [
                "Precision",
                "F1"
            ]
        },
        "code": "",
        "license": "Not Specified",
        "inputs": {
            "typeOfTable": "Relational tables (CSV/HTML)",
            "tableSources": [
                "wiki",
                "web",
                "spreadsheet"
            ]
        },
        "kg": {
            "tripleStore": "Wikidata",
            "index": "Spark-based lookup using Wikidata Toolkit on HDFS"
        },
        "output": "",
        "applicationPurpose": "Automatic semantic table interpretation for entity, type and relation annotation aligned to Wikidata; competitive SemTab system.",
        "userInterfaceTool": "",
        "checkedByAuthor": "",
        "checkedByAi": true,
        "doi": "",
        "citations": [
            {
                "ref": "2015_bhagavatula_tabel",
                "title": "TabEL: Entity linking in web tables"
            },
            {
                "ref": "2019_chabot_dagobah",
                "title": "DAGOBAH: An End-to-End Context-Free Tabular Data Semantic Annotation System"
            },
            {
                "ref": "2019_cremaschi_mantistable",
                "title": "MantisTable: an automatic approach for the Semantic Table Interpretation"
            },
            {
                "ref": "2020_cutrona_tough",
                "title": "Tough tables: Carefully evaluating entity linking for tabular data"
            },
            {
                "ref": "2019_hassanzadeh_semtab2019",
                "title": "SemTab2019: Semantic Web Challenge on Tabular Data to Knowledge Graph Matching - Data Sets"
            },
            {
                "ref": "2020_jimnez-ruiz_semtab",
                "title": "SemTab 2019: Resources to Benchmark Tabular Data to Knowledge Graph Matching Systems"
            },
            {
                "ref": "2010_limaye_annotating",
                "title": "Annotating and searching web tables using entities, types and relationships"
            },
            {
                "ref": "2019_nguyen_mtab",
                "title": "MTab: Matching Tabular Data to Knowledge Graph using Probability Models"
            },
            {
                "ref": "2019_thawani_entity",
                "title": "Entity Linking to Knowledge Graphs to Infer Column Types and Properties"
            },
            {
                "ref": "2014_zhang_towards",
                "title": "Towards efficient and effective semantic table interpretation"
            }
        ],
        "uncertainFields": [
            {
                "field": "venue.acronym",
                "reason": "The paper is part of the SemTab 2020 challenge; acronym recorded as 'SemTab' but could be styled with ISWC context."
            },
            {
                "field": "code",
                "reason": "No repository link is mentioned in the paper; code availability is unclear."
            },
            {
                "field": "doi",
                "reason": "CEUR-WS challenge papers often lack DOIs; none is stated in the paper."
            },
            {
                "field": "output",
                "reason": "The export/serialisation format of annotations is not described."
            },
            {
                "field": "inputs.tableSources",
                "reason": "SemTab tables are CSV derived from web/wiki sources; exact source breakdown is not explicitly stated."
            },
            {
                "field": "kg.index",
                "reason": "Index description summarises the implementation but precise component names/configurations are not fully specified."
            },
            {
                "field": "userInterfaceTool",
                "reason": "Authors mention future GUIs; no current UI/tool is specified."
            },
            {
                "field": "techniqueTags",
                "reason": "Tags include 'ontology-driven' and 'rule-based' based on hierarchy use and heuristics; the paper does not explicitly label them as such."
            },
            {
                "field": "validation.goldStandard",
                "reason": "Summarised as SemTab2020 rounds including Tough Tables; exact dataset names per round are not exhaustively listed."
            }
        ]
    },
    {
        "id": "2020_kim_generating",
        "added": "",
        "year": 2020,
        "firstAuthor": "Kim",
        "authors": [
            "Donguk Kim",
            "Heesung Park",
            "Jae Kyu Lee",
            "Wooju Kim"
        ],
        "title": "Generating Conceptual Subgraph from Tabular Data for Knowledge Graph Matching",
        "venue": {
            "type": "challenge",
            "acronym": "SemTab"
        },
        "nameOfApproach": "",
        "techniqueTags": [
            "rule-based",
            "ontology-driven"
        ],
        "coreTasks": {
            "cta": true,
            "cpa": true,
            "cea": true,
            "cnea": false
        },
        "supportTasks": {
            "dataPreparation": {
                "description": "Selects SPARQL queries by datatype (text/number/date), applies ±1.5% tolerance for numeric values, uses UTF-8 conversion, and addresses typos via web crawling and search auto-correction.",
                "spellChecker": "Google search auto-correction heuristics during crawling",
                "unitsOfMeasurements": ""
            },
            "columnClassification": "",
            "subjectDetection": "Assumes the first column is the subject and selects the subject entity with highest candidate probability/frequency.",
            "datatypeAnnotation": "",
            "typeAnnotation": "CTA restricted to Wikidata 'instance of' (P31).",
            "predicateAnnotation": "Infers CPA by choosing the most probable property between columns from SPARQL-derived candidate lists (e.g., P131).",
            "nilAnnotation": "",
            "entityLinking": {
                "description": "Links cells to Wikidata items using advanced SPARQL queries; resolves typos via crawling and graph-based inference with candidate scoring.",
                "candidateGeneration": "Datatype-aware SPARQL queries over Wikidata.",
                "entityDisambiguation": "Selects candidates by probability/frequency and consistency within the evolving subgraph."
            }
        },
        "mainMethod": {
            "type": "unsupervised",
            "technique": "rule-based"
        },
        "revision": {
            "type": "fully automated",
            "description": "Pipeline executes SPARQL-based extraction, candidate selection, crawling, and inference without human-in-the-loop validation."
        },
        "domain": {
            "domain": "independent",
            "type": "generic"
        },
        "validation": {
            "goldStandard": "SemTab Challenge (Rounds 1–4)",
            "metrics": [
                "F1",
                "Precision"
            ]
        },
        "code": "",
        "license": "CC BY 4.0",
        "inputs": {
            "typeOfTable": "Tabular data",
            "tableSources": []
        },
        "kg": {
            "tripleStore": "Wikidata",
            "index": ""
        },
        "output": "",
        "applicationPurpose": "Knowledge graph matching for semantic table annotation",
        "userInterfaceTool": "",
        "checkedByAuthor": "",
        "checkedByAi": true,
        "doi": "",
        "citations": [
            {
                "ref": "2018_bielefeldt_practical",
                "title": "Practical Linked Data Access via SPARQL: The Case of Wikidata"
            },
            {
                "ref": "2020_jimenez-ruiz_semtab",
                "title": "SemTab 2019: Tabular Data to Knowledge Graph Matching Challenge"
            },
            {
                "ref": "2016_hernandez_querying",
                "title": "Querying Wikidata: Comparing SPARQL, relational and graph databases"
            }
        ],
        "uncertainFields": [
            {
                "field": "venue.acronym",
                "reason": "The paper reports SemTab challenge tasks and results, but the exact proceedings or event acronym is not explicitly stated."
            },
            {
                "field": "code",
                "reason": "No repository or download link is mentioned."
            },
            {
                "field": "output",
                "reason": "The output format of annotations is not specified; SemTab typically uses CSV submissions, but this is not stated."
            },
            {
                "field": "inputs.tableSources",
                "reason": "The precise origin of tables (web, wiki, spreadsheet, etc.) is not described; only generic 'tabular data' and challenge data are mentioned."
            },
            {
                "field": "supportTasks.columnClassification",
                "reason": "While datatypes are discussed for queries, an explicit literal vs named-entity column classification process is not described."
            },
            {
                "field": "supportTasks.datatypeAnnotation",
                "reason": "Numbers/dates are handled in querying, but mapping LIT-columns to specific KG datatypes is not stated."
            },
            {
                "field": "kg.index",
                "reason": "They query the Wikidata SPARQL endpoint, but no separate indexing component is described."
            },
            {
                "field": "applicationPurpose",
                "reason": "Purpose inferred from title and narrative; no dedicated 'application' section is provided."
            }
        ]
    },
    {
        "id": "2020_nguyen_mtab4wikidata",
        "added": "",
        "year": 2020,
        "firstAuthor": "Nguyen",
        "authors": [
            "Phuc Nguyen",
            "Ikuya Yamada",
            "Natthawut Kertkeidkachorn",
            "Ryutaro Ichise",
            "Hideaki Takeda"
        ],
        "title": "MTab4Wikidata at SemTab 2020: Tabular Data Annotation with Wikidata",
        "venue": {
            "type": "challenge",
            "acronym": "SemTab"
        },
        "nameOfApproach": "MTab4Wikidata",
        "techniqueTags": [
            "rule-based"
        ],
        "coreTasks": {
            "cta": true,
            "cpa": true,
            "cea": true,
            "cnea": false
        },
        "supportTasks": {
            "dataPreparation": {
                "description": "Prepares Wikidata dumps and history revisions and builds fuzzy search indexes; no explicit table normalisation steps described.",
                "spellChecker": "Misspellings handled via fuzzy entity search using edit distance; no separate spell-checker module stated.",
                "unitsOfMeasurements": ""
            },
            "columnClassification": "",
            "subjectDetection": "Assumes the first column is the core attribute (subject) of the table.",
            "datatypeAnnotation": "",
            "typeAnnotation": "Derives column types from CEA results and selects via majority voting of direct types.",
            "predicateAnnotation": "Aggregates candidate statement properties across rows and applies majority voting to choose CPA relations.",
            "nilAnnotation": "",
            "entityLinking": {
                "description": "Generates entity candidates via fuzzy entity search and fuzzy statement search; ranks and selects with value matching.",
                "candidateGeneration": "Fuzzy entity lookup over labels/aliases (Levenshtein up to six edits) plus two-cells fuzzy statement search.",
                "entityDisambiguation": "Context/value matching within rows and majority voting used to select final entities."
            }
        },
        "mainMethod": {
            "type": "unsupervised",
            "technique": "rule-based"
        },
        "revision": {
            "type": "fully automated",
            "description": "Post-processing performs value matching and majority voting without user intervention."
        },
        "domain": {
            "domain": "independent",
            "type": ""
        },
        "validation": {
            "goldStandard": "SemTab 2020 (Rounds 1–4) and Tough Tables (2T) datasets",
            "metrics": [
                "Precision",
                "Recall",
                "F1"
            ]
        },
        "code": "",
        "license": "CC BY 4.0",
        "inputs": {
            "typeOfTable": "tabular data",
            "tableSources": []
        },
        "kg": {
            "tripleStore": "Wikidata",
            "index": "Fuzzy entity and statement indexes built from a Wikidata dump and item history revisions."
        },
        "output": "",
        "applicationPurpose": "Automatic semantic annotation of table cells, columns and column relations against Wikidata for SemTab 2020.",
        "userInterfaceTool": "",
        "checkedByAuthor": "",
        "checkedByAi": true,
        "doi": "",
        "citations": [
            {
                "ref": "2020_jimenez-ruiz_semtab",
                "title": "Semtab 2019: Resources to benchmark tabular data to knowledge graph matching systems"
            },
            {
                "ref": "2020_cutrona_tough",
                "title": "Tough tables: Carefully evaluating entity linking for tabular data"
            },
            {
                "ref": "2019_nguyen_mtab",
                "title": "Mtab: Matching tabular data to knowledge graph using probability models"
            },
            {
                "ref": "2019_vandewiele_cvs2kg",
                "title": "Cvs2kg: Transforming tabular data into semantic knowledge"
            },
            {
                "ref": "2019_thawani_entity",
                "title": "Entity linking to knowledge graphs to infer column types and properties"
            },
            {
                "ref": "2019_oliveira_adog-annotating",
                "title": "Adog-annotating data with ontologies and graphs"
            },
            {
                "ref": "2019_morikawa_semantic",
                "title": "Semantic table interpretation using lod4all"
            },
            {
                "ref": "2019_chabot_dagobah",
                "title": "Dagobah: an end-to-end context-free tabular data semantic annotation system"
            },
            {
                "ref": "2019_cremaschi_mantistable",
                "title": "Mantistable: an automatic approach for the semantic table interpretation"
            },
            {
                "ref": "2020_nguyen_tabeano",
                "title": "Tabeano: Table to knowledge graph entity annotation"
            }
        ],
        "uncertainFields": [
            {
                "field": "venue.type",
                "reason": "SemTab papers are often published in a workshop proceedings; classifying it as a challenge paper may be ambiguous."
            },
            {
                "field": "venue.acronym",
                "reason": "Could also be written as \"SemTab@ISWC\"; the acronym without year is inferred."
            },
            {
                "field": "code",
                "reason": "No code repository is referenced in the paper."
            },
            {
                "field": "inputs.tableSources",
                "reason": "The specific origins of the input tables (e.g., wiki, web) are not explicitly stated."
            },
            {
                "field": "output",
                "reason": "The export/submission output format is not specified in the text."
            },
            {
                "field": "license",
                "reason": "CC BY 4.0 refers to the paper; the system/software licence is not specified."
            },
            {
                "field": "supportTasks.columnClassification",
                "reason": "No explicit column classification step is described; assumption about core column is provided instead."
            },
            {
                "field": "doi",
                "reason": "Challenge/workshop papers in CEUR-WS typically lack DOIs; none is provided."
            },
            {
                "field": "mainMethod.technique",
                "reason": "Described as fuzzy search, statement search and voting; labelled broadly as rule-based for taxonomy alignment."
            },
            {
                "field": "validation.goldStandard",
                "reason": "Named collectively; exact official dataset titles/versions are not fully enumerated in the text."
            }
        ]
    },
    {
        "id": "2020_shigapov_bbw",
        "added": "",
        "year": 2020,
        "firstAuthor": "Shigapov",
        "authors": [
            "Renat Shigapov",
            "Philipp Zumstein",
            "Jan Kamlah",
            "Lars Oberländer",
            "Jörg Mechnich",
            "Irene Schumm"
        ],
        "title": "bbw: Matching CSV to Wikidata via Meta-lookup",
        "venue": {
            "type": "challenge",
            "acronym": "SemTab"
        },
        "nameOfApproach": "bbw",
        "techniqueTags": [
            "rule-based",
            "ontology-driven"
        ],
        "coreTasks": {
            "cta": true,
            "cpa": true,
            "cea": true,
            "cnea": false
        },
        "supportTasks": {
            "dataPreparation": {
                "description": "Fixes encoding issues (ftfy) and predicts cell data types via regular expressions; identifies names.",
                "spellChecker": "",
                "unitsOfMeasurements": ""
            },
            "columnClassification": "Detects entity columns if at least one type annotation is inferred.",
            "subjectDetection": "Assumes the first cell in each row is the subject item label.",
            "datatypeAnnotation": "Predicts number, time, name and string via regex-based heuristics.",
            "typeAnnotation": "Infers types (P31) via contextual matching and resolves to a common superclass using a SPARQL SSSP query.",
            "predicateAnnotation": "Chooses the most frequent property per column after contextual matching of subjects and objects.",
            "nilAnnotation": "",
            "entityLinking": {
                "description": "Links cell strings to Wikidata QIDs.",
                "candidateGeneration": "Meta-lookup via SearX across multiple engines and SPARQL queries to gather candidates; uses suggestions/corrections and edit distance.",
                "entityDisambiguation": "Contextual matching over labels, types and properties with exact/case-insensitive/edit-distance; tolerates numbers (±2%) and dates (±6 months)."
            }
        },
        "mainMethod": {
            "type": "unsupervised",
            "technique": "rule-based"
        },
        "revision": {
            "type": "fully automated",
            "description": "Selects most frequent annotations and for CTA resolves to the first common superclass; filters to annotations present in target files."
        },
        "domain": {
            "domain": "independent",
            "type": "generic tabular data to Wikidata"
        },
        "validation": {
            "goldStandard": "SemTab2020 (AG and 2T datasets).",
            "metrics": [
                "F1",
                "Precision",
                "Recall",
                "AP"
            ]
        },
        "code": "http://github.com/UB-Mannheim/bbw",
        "license": "MIT License",
        "inputs": {
            "typeOfTable": "CSV",
            "tableSources": []
        },
        "kg": {
            "tripleStore": "Wikidata",
            "index": "Wikidata SPARQL endpoint; no local dump index"
        },
        "output": "CSV",
        "applicationPurpose": "Semantic annotation of CSV tables against Wikidata (CPA, CTA, CEA) using meta-lookup and contextual matching.",
        "userInterfaceTool": "CLI; Streamlit GUI",
        "checkedByAuthor": "",
        "checkedByAi": true,
        "doi": "",
        "citations": [
            {
                "ref": "2019_chabot_dagobah",
                "title": "DAGOBAH: An end-to-end context-free tabular data semantic annotation system"
            },
            {
                "ref": "2019_cremaschi_mantistable",
                "title": "MantisTable: An automatic approach for the semantic table interpretation"
            },
            {
                "ref": "2020_cutrona_tough",
                "title": "Tough Tables: Carefully evaluating entity linking for tabular data"
            },
            {
                "ref": "2020_jimenez-ruiz_semtab",
                "title": "SemTab 2019: Resources to benchmark tabular data to knowledge graph matching systems"
            },
            {
                "ref": "2019_morikawa_semantic",
                "title": "Semantic table interpretation using LOD4ALL"
            },
            {
                "ref": "2019_nguyen_mtab",
                "title": "MTab: Matching tabular data to knowledge graph with probability models"
            },
            {
                "ref": "2019_oliveira_adog",
                "title": "ADOG - Annotating data with ontologies and graphs"
            },
            {
                "ref": "2017_ritze_matching",
                "title": "Matching Web tables to DBpedia - A feature utility study"
            },
            {
                "ref": "2019_speer_ftfy",
                "title": "ftfy"
            },
            {
                "ref": "2019_steenwinckel_cvs2kg",
                "title": "CVS2KG: Transforming tabular data into semantic knowledge"
            },
            {
                "ref": "2020_tange_gnu",
                "title": "GNU parallel 20200722 ('Privacy Shield')"
            },
            {
                "ref": "2019_thawani_entity",
                "title": "Entity linking to knowledge graphs to infer column types and properties"
            }
        ],
        "uncertainFields": [
            {
                "field": "venue.acronym",
                "reason": "The paper reports participation in the SemTab 2020 challenge but does not explicitly give a proceedings acronym; using 'SemTab' conservatively."
            },
            {
                "field": "output",
                "reason": "Submissions follow challenge target files; explicit output format not formally named, assumed CSV from context."
            },
            {
                "field": "doi",
                "reason": "A DOI for this specific paper is not stated in the document; CEUR-WS challenge papers often lack DOIs."
            },
            {
                "field": "inputs.tableSources",
                "reason": "The sources of the tables (web/wiki/etc.) are not specified beyond being CSV inputs from the challenge."
            },
            {
                "field": "techniqueTags",
                "reason": "Classified as rule-based and ontology-driven based on heuristics and Wikidata use; no ML models are mentioned."
            }
        ]
    },
    {
        "id": "2020_yumusak_knowledge",
        "added": "",
        "year": 2020,
        "firstAuthor": "Yumusak",
        "authors": [
            "Semih Yumusak"
        ],
        "title": "Knowledge graph matching with inter-service information transfer",
        "venue": {
            "type": "challenge",
            "acronym": "SemTab"
        },
        "nameOfApproach": "TeamTR",
        "techniqueTags": [
            "rule-based"
        ],
        "coreTasks": {
            "cta": false,
            "cpa": true,
            "cea": false,
            "cnea": false
        },
        "supportTasks": {
            "dataPreparation": {
                "description": "Normalisation with spell correction via external search engines and separated numeric/date handling using thresholds. ",
                "spellChecker": "Context-aware spell checking via Google/Yandex suggestions to correct misspellings. ",
                "unitsOfMeasurements": ""
            },
            "columnClassification": "",
            "subjectDetection": "",
            "datatypeAnnotation": "Typed numeric and date values and applied numeric proximity thresholds during matching. ",
            "typeAnnotation": "",
            "predicateAnnotation": "Assigned KG properties between column pairs by querying entity neighbours with SPARQL and filtering literals (exact/approximate). ",
            "nilAnnotation": "",
            "entityLinking": {
                "description": "",
                "candidateGeneration": "",
                "entityDisambiguation": ""
            }
        },
        "mainMethod": {
            "type": "unsupervised",
            "technique": "rule-based"
        },
        "revision": {
            "type": "fully automated",
            "description": "Outputs were produced automatically with no manual corrections or adaptations. "
        },
        "domain": {
            "domain": "independent",
            "type": "generic"
        },
        "validation": {
            "goldStandard": "SemTab 2020 CPA (Rounds 1–3). ",
            "metrics": [
                "F1"
            ]
        },
        "code": "",
        "license": "Not Specified",
        "inputs": {
            "typeOfTable": "CSV",
            "tableSources": [
                "wiki"
            ]
        },
        "kg": {
            "tripleStore": "Wikidata",
            "index": ""
        },
        "output": "",
        "applicationPurpose": "CPA in the SemTab challenge using deterministic SPARQL-based matching. ",
        "userInterfaceTool": "",
        "checkedByAuthor": "",
        "checkedByAi": true,
        "doi": "",
        "citations": [
            {
                "ref": "2001_berners-lee_the",
                "title": "The semantic web"
            },
            {
                "ref": "",
                "title": "The Linked Open Data Cloud"
            },
            {
                "ref": "2020_jimenez-ruiz_semtab",
                "title": "SemTab 2019: Resources to Benchmark Tabular Data to Knowledge Graph Matching Systems"
            },
            {
                "ref": "2014_vrandecic_wikidata",
                "title": "Wikidata: a free collaborative knowledge-base"
            },
            {
                "ref": "",
                "title": "SemTab 2020: Semantic Web Challenge on Tabular Data to Knowledge Graph Matching"
            }
        ],
        "uncertainFields": [
            {
                "field": "venue.type",
                "reason": "Treated as a challenge paper; it may alternatively be considered a workshop system description."
            },
            {
                "field": "venue.acronym",
                "reason": "Set to SemTab; the broader event is ISWC, but the submission is specific to the SemTab challenge."
            },
            {
                "field": "nameOfApproach",
                "reason": "Paper mentions submission as TeamTR; unclear if this is the formal system name."
            },
            {
                "field": "inputs.typeOfTable",
                "reason": "CSV inferred from text mentioning comma-delimited tables; explicit output format not stated."
            },
            {
                "field": "kg.index",
                "reason": "No explicit indexing mechanism described beyond SPARQL and search services."
            },
            {
                "field": "output",
                "reason": "Challenge submission format not specified in the paper."
            },
            {
                "field": "doi",
                "reason": "No DOI provided; CEUR-WS challenge papers often lack DOIs."
            },
            {
                "field": "code",
                "reason": "No repository or code link mentioned."
            },
            {
                "field": "license",
                "reason": "License information is not specified in the paper."
            },
            {
                "field": "supportTasks.datatypeAnnotation",
                "reason": "Numeric/date handling is described, but it is unclear if it is framed as a formal datatype annotation sub-task."
            }
        ]
    },
    {
        "id": "2020_tyagi_lexma",
        "added": "",
        "year": 2020,
        "firstAuthor": "Tyagi",
        "authors": [
            "Shalini Tyagi",
            "Ernesto Jimenez-Ruiz"
        ],
        "title": "LexMa: Tabular Data to Knowledge Graph Matching using Lexical Techniques",
        "venue": {
            "type": "challenge",
            "acronym": "SemTab"
        },
        "nameOfApproach": "LexMa",
        "techniqueTags": [
            "rule-based"
        ],
        "coreTasks": {
            "cta": true,
            "cpa": false,
            "cea": true,
            "cnea": false
        },
        "supportTasks": {
            "dataPreparation": {
                "description": "Pre-processing includes trimming, case normalisation, tokenisation, stop-word and duplicate/special-character removal to improve lookup efficiency.",
                "spellChecker": "",
                "unitsOfMeasurements": ""
            },
            "columnClassification": "",
            "subjectDetection": "",
            "datatypeAnnotation": "",
            "typeAnnotation": "Entity types are retrieved via the Wikidata SPARQL endpoint and the most frequent type per column is selected.",
            "predicateAnnotation": "",
            "nilAnnotation": "",
            "entityLinking": {
                "description": "Cells are linked to KG entities using lexical matching with cosine similarity and fallbacks across KGs.",
                "candidateGeneration": "Top-5 candidates from Wikidata Lookup; if none found, query DBpedia Lookup and map to Wikidata via sameAs.",
                "entityDisambiguation": "Cosine similarity over one-hot token vectors of labels vs cell values guides final selection."
            }
        },
        "mainMethod": {
            "type": "unsupervised",
            "technique": "rule-based"
        },
        "revision": {
            "type": "fully automated",
            "description": "Pipeline executes automatically without manual post-editing; results are produced and submitted as-is."
        },
        "domain": {
            "domain": "independent",
            "type": "generic"
        },
        "validation": {
            "goldStandard": "SemTab 2020 datasets and Round 4 2T (Tough Tables) dataset",
            "metrics": [
                "Precision",
                "Recall",
                "F1",
                "Accuracy"
            ]
        },
        "code": "https://github.com/shaliniktyagi/TabularData_to_Knowledge_graph",
        "license": "CC BY 4.0",
        "inputs": {
            "typeOfTable": "Web tables",
            "tableSources": [
                "web"
            ]
        },
        "kg": {
            "tripleStore": "Wikidata; DBpedia",
            "index": "Wikidata and DBpedia lookup services; SPARQL endpoints"
        },
        "output": "CSV",
        "applicationPurpose": "Automatic annotation of tables with KG entities and classes for SemTab 2020 participation.",
        "userInterfaceTool": "Google Colab notebooks; CLI scripts",
        "checkedByAuthor": "",
        "checkedByAi": true,
        "doi": "",
        "citations": [
            {
                "ref": "2018_malyshev_getting",
                "title": "Getting the Most out of Wikidata: Semantic Technology Usage in Wikipedia’s Knowledge Graph."
            },
            {
                "ref": "2007_suchanek_yago",
                "title": "YAGO: A core of semantic knowledge unifying WordNet and Wikipedia."
            },
            {
                "ref": "2008_cafarella_webtables",
                "title": "WebTables: Exploring the Power of Tables on the Web."
            },
            {
                "ref": "2019_chen_colnet",
                "title": "ColNet: Embedding the Semantics of Web Tables for Column Type Prediction."
            },
            {
                "ref": "2019_pahi_a",
                "title": "A Comparison of Semantic Similarity Methods for Maximum Human Interpretability."
            },
            {
                "ref": "2020_cutrona_tough",
                "title": "Tough Tables: Carefully Evaluating Entity Linking for Tabular Data."
            },
            {
                "ref": "",
                "title": "Parallelism In Python."
            },
            {
                "ref": "2020_jimenez-ruiz_semtab",
                "title": "SemTab 2019: Resources to Benchmark Tabular Data to Knowledge Graph Matching Systems."
            },
            {
                "ref": "2020_hassanzadeh_semtab",
                "title": "SemTab 2020: Semantic Web Challenge on Tabular Data to Knowledge Graph Matching Data Sets (Version 2020)."
            },
            {
                "ref": "2020_cutrona_tough",
                "title": "Tough Tables: Carefully Benchmarking Semantic Table Annotators."
            },
            {
                "ref": "",
                "title": "Tabular Data Semantics for Python."
            }
        ],
        "uncertainFields": [
            {
                "field": "venue.acronym",
                "reason": "The paper reports participation in SemTab 2020; treating this as the venue acronym, but proceedings details are not explicitly stated."
            },
            {
                "field": "license",
                "reason": "Paper explicitly states CC BY 4.0; code repository licence is not specified in the paper."
            },
            {
                "field": "inputs.tableSources",
                "reason": "The text mentions Web tables but does not enumerate specific sources; 'web' is inferred."
            },
            {
                "field": "output",
                "reason": "SemTab submissions are typically CSV files, but the paper does not explicitly state the output format."
            },
            {
                "field": "kg.index",
                "reason": "Described functionally (lookup services and SPARQL); no specific indexing framework or engine is named."
            },
            {
                "field": "doi",
                "reason": "No DOI for the paper is provided."
            }
        ]
    },
    {
        "id": "2020_zhang_novel",
        "added": "",
        "year": 2020,
        "firstAuthor": "Zhang",
        "authors": [
            "Shuo Zhang",
            "Edgar Meij",
            "Krisztian Balog",
            "Ridho Reinanda"
        ],
        "title": "Novel Entity Discovery from Web Tables",
        "venue": {
            "type": "conference",
            "acronym": "WWW"
        },
        "nameOfApproach": "",
        "techniqueTags": [
            "embeddings"
        ],
        "coreTasks": {
            "cta": false,
            "cpa": true,
            "cea": true,
            "cnea": true
        },
        "supportTasks": {
            "dataPreparation": {
                "description": "Normalisation and filtering of mentions (e.g., removing obvious non-entities) and feature extraction for candidate scoring. Candidate retrieval uses Wikipedia search and table-type inference.",
                "spellChecker": "",
                "unitsOfMeasurements": ""
            },
            "columnClassification": "",
            "subjectDetection": "",
            "datatypeAnnotation": "",
            "typeAnnotation": "",
            "predicateAnnotation": "Entity-assisted column heading–to–property matching using label and value similarities guided by entities linked in the table.",
            "nilAnnotation": "Classifies unlinked core-column mentions as out-of-KB (NIL), in-KB, or not-entity; then resolves novel entities by type and surface-form clustering.",
            "entityLinking": {
                "description": "Feature-based entity linking on core-column mentions using lexical and semantic similarities plus popularity signals.",
                "candidateGeneration": "Top-k candidates from the Wikipedia search API for each mention.",
                "entityDisambiguation": "Disambiguation via a classifier and a table-type majority-vote filter to keep at most one candidate per mention."
            }
        },
        "mainMethod": {
            "type": "supervised",
            "technique": "Feature-based classification (Random Forest) with lexical and embedding similarities",
            "supervision": {
                "type": "supervised"
            }
        },
        "revision": {
            "type": "fully automated",
            "description": "Pipeline runs automatically without user-in-the-loop post-editing."
        },
        "domain": {
            "domain": "independent",
            "type": ""
        },
        "validation": {
            "goldStandard": "T2Dv2 (row–entity and heading–property), W2D; three custom crowdsourced test collections (20K mentions; type and surface-form resolution)",
            "metrics": [
                "Precision",
                "Recall",
                "F1",
                "Accuracy"
            ]
        },
        "code": "",
        "license": "CC-BY 4.0",
        "inputs": {
            "typeOfTable": "HTML tables",
            "tableSources": [
                "web",
                "wiki"
            ]
        },
        "kg": {
            "tripleStore": "DBpedia",
            "index": "Wikipedia search API and DBpedia lookup/surface forms"
        },
        "output": "",
        "applicationPurpose": "Knowledge base population and extension",
        "userInterfaceTool": "",
        "checkedByAuthor": "",
        "checkedByAi": true,
        "doi": "https://doi.org/10.1145/3366423.3380205",
        "citations": [
            {
                "ref": "2015_bhagavatula_tabel",
                "title": "TabEL: Entity Linking in Web Tables"
            },
            {
                "ref": "2007_bhattacharya_collective",
                "title": "Collective Entity Resolution in Relational Data"
            },
            {
                "ref": "2018_cannaviccio_leveraging",
                "title": "Leveraging Wikipedia Table Schemas for Knowledge Graph Augmentation"
            },
            {
                "ref": "2016_chirigati_knowledge",
                "title": "Knowledge Exploration Using Tables on the Web"
            },
            {
                "ref": "2014_dong_knowledge",
                "title": "Knowledge Vault: A Web-scale Approach to Probabilistic Knowledge Fusion"
            },
            {
                "ref": "2017_efthymiou_matching",
                "title": "Matching Web Tables with Knowledge Base Entities: From Entity Lookups to Entity Embeddings"
            },
            {
                "ref": "2014_fan_hybrid",
                "title": "A Hybrid Machine-Crowdsourcing System for Matching Web Tables"
            },
            {
                "ref": "2013_gabrilovich_facc1",
                "title": "FACC1: Freebase annotation of ClueWeb corpora, Version 1 (Release date 2013-06-26, Format version 1, Correction level 0)"
            },
            {
                "ref": "2017_ganea_deep",
                "title": "Deep Joint Entity Disambiguation with Local Neural Attention"
            },
            {
                "ref": "2018_graus_the",
                "title": "The Birth of Collective Memories: Analyzing Emerging Entities in Text streams"
            },
            {
                "ref": "2016_guo_a",
                "title": "A Deep Relevance Matching Model for Ad-hoc Retrieval"
            },
            {
                "ref": "2019_guo_matchzoo",
                "title": "MatchZoo: A Learning, Practicing, and Developing System for Neural Text Matching"
            },
            {
                "ref": "2016_ibrahim_making",
                "title": "Making Sense of Entities and Quantities in Web Tables"
            },
            {
                "ref": "2018_kolitsas_end-to-end",
                "title": "End-to-End Neural Entity Linking"
            },
            {
                "ref": "2018_le_improving",
                "title": "Improving Entity Linking by Modeling Latent Relations between Mentions"
            },
            {
                "ref": "2016_lehmberg_web",
                "title": "Web Table Column Categorisation and Profiling"
            },
            {
                "ref": "2016_lehmberg_a",
                "title": "A Large Public Corpus of Web Tables Containing Time and Context Metadata"
            },
            {
                "ref": "2015_lehmberg_the",
                "title": "The Mannheim Search Join Engine"
            },
            {
                "ref": "2012_lin_no",
                "title": "No Noun Phrase Left Behind: Detecting and Typing Unlinkable Entities"
            },
            {
                "ref": "2007_marie_on",
                "title": "On the Stable Marriage of Maximum Weight Royal Couples"
            },
            {
                "ref": "2013_mulwad_semantic",
                "title": "Semantic Message Passing for Generating Linked Data from Tables"
            },
            {
                "ref": "2010_mulwad_using",
                "title": "Using Linked Data to Interpret Tables"
            },
            {
                "ref": "2013_quercini_entity",
                "title": "Entity Discovery and Annotation in Tables"
            },
            {
                "ref": "2017_ritze_matching",
                "title": "Matching Web Tables To DBpedia - A Feature Utility Study"
            },
            {
                "ref": "2015_ritze_matching",
                "title": "Matching HTML Tables to DBpedia"
            },
            {
                "ref": "2016_ritze_profiling",
                "title": "Profiling the Potential of Web Tables for Augmenting Cross-domain Knowledge Bases"
            },
            {
                "ref": "2014_sekhavat_knowledge",
                "title": "Knowledge Base Augmentation using Tabular Data"
            },
            {
                "ref": "2011_venetis_recovering",
                "title": "Recovering Semantics of Tables on the Web"
            },
            {
                "ref": "2016_wu_exploring",
                "title": "Exploring Multiple Feature Spaces for Novel Entity Discovery"
            },
            {
                "ref": "2013_zhang_infogather",
                "title": "InfoGather+: Semantic Matching and Annotation of Numeric and Time-varying Attributes in Web Tables"
            },
            {
                "ref": "2018_zhang_ad",
                "title": "Ad Hoc Table Retrieval using Semantic Similarity"
            },
            {
                "ref": "2018_zhang_on-the-fly",
                "title": "On-the-fly Table Generation"
            },
            {
                "ref": "2019_zhang_auto-completion",
                "title": "Auto-completion for Data Cells in Relational Tables"
            },
            {
                "ref": "2013_zhang_mapping",
                "title": "Mapping Entity-Attribute Web Tables to Web-Scale Knowledge Bases"
            },
            {
                "ref": "2013_zwicklbauer_towards",
                "title": "Towards Disambiguating Web Tables"
            }
        ],
        "uncertainFields": [
            {
                "field": "venue.acronym",
                "reason": "Acronym may also be styled as 'The Web Conference'; using 'WWW' here."
            },
            {
                "field": "nameOfApproach",
                "reason": "No single system name provided; paper presents multiple components (e.g., entity-assisted matching, OSS)."
            },
            {
                "field": "output",
                "reason": "Paper reports correspondences and discovered entities but no explicit serialisation format."
            },
            {
                "field": "code",
                "reason": "A dataset is released, but no code repository is stated."
            },
            {
                "field": "inputs.tableSources",
                "reason": "Main corpus is generic web tables (WDC), but evaluation also uses Wikipedia tables (W2D)."
            },
            {
                "field": "supportTasks.typeAnnotation",
                "reason": "They infer table type for disambiguation, not full CTA for column types."
            },
            {
                "field": "kg.index",
                "reason": "Described via Wikipedia search/lookup rather than a bespoke index; interpretation as 'index' is approximate."
            },
            {
                "field": "userInterfaceTool",
                "reason": "No UI is mentioned; assuming none."
            }
        ]
    },
    {
        "id": "2021_abdelmageed_jentab-1",
        "added": "",
        "year": 2021,
        "firstAuthor": "Abdelmageed",
        "authors": [
            "Nora Abdelmageed",
            "Sirko Schindler"
        ],
        "title": "JenTab Meets SemTab 2021’s New Challenges",
        "venue": {
            "type": "challenge",
            "acronym": "SemTab"
        },
        "nameOfApproach": "JenTab",
        "techniqueTags": [
            "rule-based",
            "ontology-driven"
        ],
        "coreTasks": {
            "cta": true,
            "cpa": true,
            "cea": true,
            "cnea": false
        },
        "supportTasks": {
            "dataPreparation": {
                "description": "Preprocessing and cleaning of cell values; centralised caching and a precomputed Jaro–Winkler lookup to handle noise and abbreviations.",
                "spellChecker": "",
                "unitsOfMeasurements": ""
            },
            "columnClassification": "",
            "subjectDetection": "Subject columns/candidates inferred via row/column contexts and CPA-driven filters.",
            "datatypeAnnotation": "",
            "typeAnnotation": "Assigns KG classes to columns (CTA).",
            "predicateAnnotation": "Identifies KG properties between column pairs using filters and row context (CPA).",
            "nilAnnotation": "",
            "entityLinking": {
                "description": "Links cells to KG entities (CEA) using Wikidata/DBpedia lookups plus a generic fuzzy lookup and contextual filtering.",
                "candidateGeneration": "Lookup APIs and a precomputed Jaro–Winkler candidate map over unique cell values.",
                "entityDisambiguation": "Iterative filtering with cell, row, column, and row–column contexts; selection by compatibility and similarity."
            }
        },
        "mainMethod": {
            "type": "unsupervised",
            "technique": "rule-based"
        },
        "revision": {
            "type": "fully automated",
            "description": "Automatic multi-phase pipeline; no human-in-the-loop editing reported."
        },
        "domain": {
            "domain": "independent",
            "type": ""
        },
        "validation": {
            "goldStandard": "SemTab 2021 datasets (Rounds 1–3: 2T, HardTables, BioTables, BiodivTab, GitTables)",
            "metrics": [
                "F1",
                "Precision"
            ]
        },
        "code": "https://github.com/fusion-jena/JenTab",
        "license": "Apache License 2.0",
        "inputs": {
            "typeOfTable": "Web tables",
            "tableSources": [
                "web",
                "relational",
                "scientific"
            ]
        },
        "kg": {
            "tripleStore": "Wikidata and DBpedia",
            "index": "Generic precomputed lookup (Jaro–Winkler) and caching over KG labels/aliases"
        },
        "output": "",
        "applicationPurpose": "Semantic table annotation for SemTab 2021 (CEA/CTA/CPA).",
        "userInterfaceTool": "",
        "usesLLM": {},
        "checkedByAuthor": "",
        "checkedByAi": true,
        "doi": "",
        "citations": [
            {
                "ref": "2020_abdelmageed_jentab",
                "title": "Jentab: Matching tabular data to knowledge graphs"
            },
            {
                "ref": "",
                "title": "fusion-jena/jentab (2021)"
            },
            {
                "ref": "2021_abdelmageed_jentab-2",
                "title": "Jentab: A toolkit for semantic table annotations"
            },
            {
                "ref": "",
                "title": "JenTab Solution Files for SemTab 2021"
            },
            {
                "ref": "",
                "title": "JenTab precomputed lookup 2021"
            },
            {
                "ref": "",
                "title": "fusion-jena/BiodivTab"
            },
            {
                "ref": "2007_auer_dbpedia",
                "title": "DBpedia: A nucleus for a web of open data"
            },
            {
                "ref": "2020_cutrona_tough",
                "title": "Tough Tables: Carefully Evaluating Entity Linking for Tabular Data"
            },
            {
                "ref": "2013_daiber_improving",
                "title": "Improving efficiency and accuracy in multilingual entity extraction"
            },
            {
                "ref": "2021_hulsebos_gittables",
                "title": "Gittables: A large-scale corpus of relational tables"
            },
            {
                "ref": "2019_keil_efficient",
                "title": "Efficient bounded Jaro-Winkler Similarity based search"
            },
            {
                "ref": "2019_steenwinckel_csv2kg",
                "title": "Csv2kg: Transforming tabular data into semantic knowledge"
            },
            {
                "ref": "2014_vrandecic_wikidata",
                "title": "Wikidata: a free collaborative knowledgebase"
            },
            {
                "ref": "1990_winkler_string",
                "title": "String comparator metrics and enhanced decision rules in the fellegi-sunter model of record linkage"
            }
        ],
        "uncertainFields": [
            {
                "field": "venue.type",
                "reason": "The paper reports participation in SemTab; this could be classed as a challenge or a workshop paper depending on proceedings."
            },
            {
                "field": "venue.acronym",
                "reason": "Acronym assumed as 'SemTab'; proceedings may also appear as 'ISWC SemTab'."
            },
            {
                "field": "kg.tripleStore",
                "reason": "The system targets both Wikidata and DBpedia; the field expects a single value."
            },
            {
                "field": "inputs.typeOfTable",
                "reason": "Exact table format(s) for submissions are not explicitly specified; 'Web tables' chosen as the safest generic label."
            },
            {
                "field": "output",
                "reason": "Submission/output format is not stated explicitly (e.g., CSV vs RDF)."
            },
            {
                "field": "license",
                "reason": "The paper’s text license (CC BY 4.0) differs from software licensing, which is not explicitly stated."
            },
            {
                "field": "validation.goldStandard",
                "reason": "Summarised across SemTab 2021 datasets; the exact GS names per track are not fully enumerated in the text."
            },
            {
                "field": "supportTasks.subjectDetection",
                "reason": "Subject detection is implied by pipeline modules but not described as a standalone sub-task."
            },
            {
                "field": "doi",
                "reason": "A DOI for the paper was not identified in the text; CEUR-WS challenge papers sometimes lack DOIs."
            }
        ]
    },
    {
        "id": "2021_baazouzi_kepler-asi",
        "added": "",
        "year": 2021,
        "firstAuthor": "Baazouzi",
        "authors": [
            "Wiem Baazouzi",
            "Marouen Kachroudi",
            "Sami Faiz"
        ],
        "title": "Kepler-aSI at SemTab 2021",
        "venue": {
            "type": "challenge",
            "acronym": "SemTab"
        },
        "nameOfApproach": "Kepler-aSI",
        "techniqueTags": [
            "rule-based",
            "ontology-driven"
        ],
        "coreTasks": {
            "cta": true,
            "cpa": true,
            "cea": true,
            "cnea": false
        },
        "supportTasks": {
            "dataPreparation": {
                "description": "Normalisation and cleaning of table text (punctuation/stopword removal, lowercasing, language detection) and regex-based detection of datatypes/units.",
                "spellChecker": "TextBlob; Pyspellchecker",
                "unitsOfMeasurements": "Area, currency, density, electric current, energy, flow rate, force, frequency, efficiency, information units, length, mass, numbers, population density, power, pressure, speed, temperature, time, torque, voltage, volume."
            },
            "columnClassification": "",
            "subjectDetection": "",
            "datatypeAnnotation": "",
            "typeAnnotation": "SPARQL over Wikidata/DBpedia using P31 (instance of), P279 (subclass of) and P361 (part of) to assign column semantic types.",
            "predicateAnnotation": "SPARQL queries to select KG properties connecting pairs of columns after CEA/CTA.",
            "nilAnnotation": "",
            "entityLinking": {
                "description": "Match cells to KG entities using SPARQL, guided by CTA context and text preprocessing.",
                "candidateGeneration": "Label/description lookups via Wikidata/DBpedia APIs/SPARQL with multilingual labels.",
                "entityDisambiguation": "Use column context (types from CTA) and external resource UniProt for biomedical ambiguities."
            }
        },
        "mainMethod": {
            "type": "unsupervised",
            "technique": "rule-based"
        },
        "revision": {
            "type": "fully automated",
            "description": "Automatic pipeline for SemTab submissions; later re-runs adjusted filters but no interactive user validation."
        },
        "domain": {
            "domain": "independent",
            "type": ""
        },
        "validation": {
            "goldStandard": "SemTab 2021 datasets (Rounds 1–3: Wikidata/DBpedia; BioTable, HardTable, BioDiv, GitTables).",
            "metrics": [
                "Precision",
                "F1"
            ]
        },
        "code": "",
        "license": "Not Specified",
        "inputs": {
            "typeOfTable": "CSV",
            "tableSources": []
        },
        "kg": {
            "tripleStore": "Wikidata; DBpedia",
            "index": ""
        },
        "output": "",
        "applicationPurpose": "Table-to-KG matching for the SemTab 2021 challenge (annotation of tabular data against Wikidata/DBpedia).",
        "userInterfaceTool": "",
        "checkedByAuthor": "",
        "checkedByAi": true,
        "doi": "",
        "citations": [
            {
                "ref": "2019_chen_colnet",
                "title": "ColNet: Embedding the semantics of web tables for column type prediction"
            },
            {
                "ref": "2018_malyshev_getting",
                "title": "Getting the most out of Wikidata: Semantic technology usage in Wikipedia’s knowledge graph"
            },
            {
                "ref": "2016_pham_semantic",
                "title": "Semantic labeling: a domain-independent approach"
            },
            {
                "ref": "2016_taheriyan_learning",
                "title": "Learning the semantics of structured data sources"
            },
            {
                "ref": "2015_ramnandan_assigning",
                "title": "Assigning semantic labels to data sources"
            },
            {
                "ref": "2012_knoblock_semi-automatically",
                "title": "Semi-automatically mapping structured sources into the semantic web"
            },
            {
                "ref": "2020_cremaschi_a",
                "title": "A fully automated approach to a complete semantic table interpretation"
            },
            {
                "ref": "2017_zhang_effective",
                "title": "Effective and efficient semantic table interpretation using TableMiner+"
            },
            {
                "ref": "2009_zghal_oacas",
                "title": "OACAS: Ontologies alignment using composition and aggregation of similarities"
            },
            {
                "ref": "2011_kachroudi_ldoa",
                "title": "LDOA results for OAEI 2011"
            },
            {
                "ref": "2017_kachroudi_oaei",
                "title": "OAEI 2017 results of KEPLER"
            },
            {
                "ref": "2018_kachroudi_dealing",
                "title": "Dealing with direct and indirect ontology alignment"
            },
            {
                "ref": "2018_kachroudi_kepler",
                "title": "KEPLER at OAEI 2018"
            },
            {
                "ref": "2014_kachroudi_bridging",
                "title": "Bridging the multilingualism gap in ontology alignment"
            },
            {
                "ref": "2013_kachroudi_using",
                "title": "Using linguistic resource for cross-lingual ontology alignment"
            },
            {
                "ref": "2019_chen_learning",
                "title": "Learning semantic annotations for tabular data"
            },
            {
                "ref": "2017_efthymiou_matching",
                "title": "Matching web tables with knowledge base entities: from entity lookups to entity embeddings"
            },
            {
                "ref": "2016_ehrlinger_towards",
                "title": "Towards a definition of knowledge graphs"
            },
            {
                "ref": "2018_farber_linked",
                "title": "Linked data quality of DBpedia, Freebase, OpenCyc, Wikidata, and YAGO"
            },
            {
                "ref": "2011_kachroudi_damo",
                "title": "Damo - direct alignment for multilingual ontologies"
            },
            {
                "ref": "2013_kachroudi_when",
                "title": "When external linguistic resource supports cross-lingual ontology alignment"
            },
            {
                "ref": "2021_ruch_uniprot",
                "title": "UniProt"
            },
            {
                "ref": "2020_drysdale_the",
                "title": "The ELIXIR Core Data Resources: fundamental infrastructure for the life sciences"
            },
            {
                "ref": "2019_garcia_fair",
                "title": "FAIR adoption, assessment and challenges at UniProt"
            },
            {
                "ref": "2016_kachroudi_initiating",
                "title": "Initiating cross-lingual ontology alignment with information retrieval techniques"
            },
            {
                "ref": "2016_zghal_alignement",
                "title": "Alignement d’ontologies base d’instances indexées"
            }
        ],
        "uncertainFields": [
            {
                "field": "doi",
                "reason": "No DOI is indicated in the paper; CEUR-WS challenge papers often lack DOIs."
            },
            {
                "field": "code",
                "reason": "No repository or download link is specified."
            },
            {
                "field": "inputs.tableSources",
                "reason": "SemTab inputs are CSVs compiled from various datasets, but the specific source categories are not stated."
            },
            {
                "field": "kg.index",
                "reason": "Indexing is mentioned as future work; the implemented system appears to rely on SPARQL endpoints only."
            },
            {
                "field": "output",
                "reason": "The submission/export format is not described."
            },
            {
                "field": "userInterfaceTool",
                "reason": "No UI or tool front-end is mentioned."
            },
            {
                "field": "applicationPurpose",
                "reason": "Stated mainly as participation in SemTab; broader application scope is not detailed."
            },
            {
                "field": "validation.goldStandard",
                "reason": "Named from task families; exact dataset identifiers are not fully specified in the text."
            },
            {
                "field": "techniqueTags",
                "reason": "Classified as rule-based/ontology-driven from SPARQL and KG lookups; no ML models are explicitly described."
            },
            {
                "field": "mainMethod.type",
                "reason": "Marked as unsupervised since no training data are cited; hybrid elements are limited to external resource lookups."
            },
            {
                "field": "kg.tripleStore",
                "reason": "Both Wikidata and DBpedia are used; field expects a single string."
            },
            {
                "field": "supportTasks.columnClassification",
                "reason": "Not explicitly reported as an implemented sub-task."
            },
            {
                "field": "supportTasks.subjectDetection",
                "reason": "Subject/object notions are described, but an implemented subject detection step is not clearly stated."
            },
            {
                "field": "supportTasks.datatypeAnnotation",
                "reason": "Datatype annotation is not discussed for this system."
            },
            {
                "field": "supportTasks.nilAnnotation",
                "reason": "CNEA is not covered in the reported SemTab runs."
            }
        ]
    },
    {
        "id": "2021_deng_turl",
        "added": "",
        "year": 2021,
        "firstAuthor": "Deng",
        "authors": [
            "Xiang Deng",
            "Huan Sun",
            "Alyssa Lees",
            "You Wu",
            "Cong Yu"
        ],
        "title": "TURL: Table Understanding through Representation Learning",
        "venue": {
            "type": "journal",
            "acronym": "PVLDB"
        },
        "nameOfApproach": "TURL",
        "techniqueTags": [
            "embeddings",
            "transformer"
        ],
        "coreTasks": {
            "cta": true,
            "cpa": true,
            "cea": true,
            "cnea": false
        },
        "supportTasks": {
            "dataPreparation": {
                "description": "Concatenates page title, section title, and caption; normalises headers; uses Wikipedia hyperlinks as mentions; detects subject columns heuristically.",
                "spellChecker": "",
                "unitsOfMeasurements": ""
            },
            "columnClassification": "Identifies entity columns versus literals to select relational tables.",
            "subjectDetection": "Heuristic: subject column is in the first two columns and contains unique entities.",
            "datatypeAnnotation": "",
            "typeAnnotation": "Column type annotation using Freebase types, fine-tuned on table metadata and entity/context representations.",
            "predicateAnnotation": "Relation extraction between subject–object column pairs using Freebase relations.",
            "nilAnnotation": "",
            "entityLinking": {
                "description": "Generates candidates with Wikidata Lookup and ranks them with a fine-tuned TURL encoder using table context, mention, description and type info.",
                "candidateGeneration": "Wikidata Lookup service (top-k candidates).",
                "entityDisambiguation": "Contextual TURL representations score and rank candidates."
            }
        },
        "mainMethod": {
            "type": "hybrid",
            "technique": "transformer"
        },
        "revision": {
            "type": "fully automated",
            "description": "Pre-training and fine-tuning run automatically without human-in-the-loop validation."
        },
        "domain": {
            "domain": "independent",
            "type": "web tables (Wikipedia and general web)"
        },
        "validation": {
            "goldStandard": "WikiGS (DBpedia), T2D/T2Dv2, Efthymiou subset, Freebase-derived benchmarks and held-out Wikipedia tables",
            "metrics": [
                "F1",
                "Precision",
                "Recall",
                "MAP",
                "P@k",
                "Accuracy"
            ]
        },
        "code": "https://github.com/sunlab-osu/TURL",
        "license": "Apache License 2.0",
        "inputs": {
            "typeOfTable": "Web tables",
            "tableSources": [
                "web",
                "wiki"
            ]
        },
        "kg": {
            "tripleStore": "DBpedia; Freebase; Wikidata",
            "index": "Wikidata Lookup"
        },
        "output": "",
        "applicationPurpose": "Universal pre-trained model for table understanding and augmentation with minimal task-specific engineering.",
        "userInterfaceTool": "",
        "checkedByAuthor": "",
        "checkedByAi": true,
        "doi": "https://doi.org/10.14778/3430915.3430921",
        "citations": [
            {
                "ref": "2015_bhagavatula_tabel",
                "title": "TabEL: Entity Linking in Web Tables"
            },
            {
                "ref": "2008_cafarella_webtables",
                "title": "Webtables: exploring the power of tables on the web"
            },
            {
                "ref": "2019_devlin_bert",
                "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"
            },
            {
                "ref": "2020_herzig_tapas",
                "title": "TAPAS: Weakly Supervised Table Parsing via Pre-training"
            },
            {
                "ref": "2020_yin_tabert",
                "title": "TaBERT: Pretraining for Joint Understanding of Textual and Tabular Data"
            },
            {
                "ref": "2019_hulsebos_sherlock",
                "title": "Sherlock: A Deep Learning Approach to Semantic Data Type Detection"
            },
            {
                "ref": "2017_zhang_entitables",
                "title": "Entitables: Smart assistance for entity-focused tables"
            },
            {
                "ref": "2019_zhang_autocompletion",
                "title": "Auto-completion for data cells in relational tables"
            },
            {
                "ref": "2020_jimenez-ruiz_semtab",
                "title": "SemTab 2019: Resources to Benchmark Tabular Data to Knowledge Graph Matching Systems"
            },
            {
                "ref": "2019_chen_learning",
                "title": "Learning Semantic Annotations for Tabular Data"
            },
            {
                "ref": "2016_lehmberg_large",
                "title": "A Large Public Corpus of Web Tables containing Time and Context Metadata"
            },
            {
                "ref": "2010_limaye_annotating",
                "title": "Annotating and searching web tables using entities, types and relationships"
            },
            {
                "ref": "2015_ritze_matching",
                "title": "Matching HTML Tables to DBpedia"
            },
            {
                "ref": "2012_yakout_infogather",
                "title": "Infogather: entity augmentation and attribute discovery by holistic matching with web tables"
            },
            {
                "ref": "2012_das-sarma_finding",
                "title": "Finding Related Tables"
            },
            {
                "ref": "2019_deng_table2vec",
                "title": "Table2Vec: Neural Word and Entity Embeddings for Table Population and Retrieval"
            },
            {
                "ref": "2017_vaswani_attention",
                "title": "Attention is all you need"
            },
            {
                "ref": "2019_jiao_tinybert",
                "title": "TinyBERT: Distilling BERT for Natural Language Understanding"
            }
        ],
        "uncertainFields": [
            {
                "field": "license",
                "reason": "The paper states an article license, but the code’s software licence is not specified."
            },
            {
                "field": "kg.tripleStore",
                "reason": "Multiple KGs are used across tasks (DBpedia, Freebase, Wikidata); represented jointly in one string."
            },
            {
                "field": "kg.index",
                "reason": "Only the use of Wikidata Lookup is explicit; no additional KG indexing details are given."
            },
            {
                "field": "output",
                "reason": "This is a research framework rather than a tool with an export format; no explicit output format is defined."
            },
            {
                "field": "userInterfaceTool",
                "reason": "No UI or tool front-end is described."
            },
            {
                "field": "inputs.typeOfTable",
                "reason": "Targets relational web tables (chiefly Wikipedia); ‘Web tables’ chosen over ‘HTML tables’ for generality."
            },
            {
                "field": "supportTasks.datatypeAnnotation",
                "reason": "Datatype annotation is not a focus of the paper."
            },
            {
                "field": "validation.goldStandard",
                "reason": "Summarises several datasets/GS used across different tasks rather than a single GS."
            },
            {
                "field": "applicationPurpose",
                "reason": "Purpose summarised from contributions and experiments rather than a single explicit sentence."
            },
            {
                "field": "techniqueTags",
                "reason": "Tagged as transformer and embeddings; other techniques (e.g., rule-based) are not used."
            }
        ]
    },
    {
        "id": "2021_heist_information",
        "added": "",
        "year": 2021,
        "firstAuthor": "Heist",
        "authors": [
            "Nicolas Heist",
            "Heiko Paulheim"
        ],
        "title": "Information Extraction From Co-Occurring Similar Entities",
        "venue": {
            "type": "conference",
            "acronym": "WWW"
        },
        "nameOfApproach": "",
        "techniqueTags": [
            "rule-based"
        ],
        "coreTasks": {
            "cta": false,
            "cpa": false,
            "cea": false,
            "cnea": false
        },
        "supportTasks": {
            "dataPreparation": {
                "description": "Wikipedia blue/red links are expanded; a specialised NER is trained for listings and listing context is extracted; tag-based filtering is applied.",
                "spellChecker": "",
                "unitsOfMeasurements": ""
            },
            "columnClassification": "",
            "subjectDetection": "",
            "datatypeAnnotation": "",
            "typeAnnotation": "",
            "predicateAnnotation": "",
            "nilAnnotation": "",
            "entityLinking": {
                "description": "",
                "candidateGeneration": "",
                "entityDisambiguation": ""
            }
        },
        "mainMethod": {
            "type": "unsupervised",
            "technique": "rule-based"
        },
        "revision": {
            "type": "fully automated",
            "description": "Descriptive rules are mined and applied automatically; assertions are filtered automatically via tag-based thresholds."
        },
        "domain": {
            "domain": "independent",
            "type": ""
        },
        "validation": {
            "goldStandard": "",
            "metrics": [
                "Accuracy"
            ]
        },
        "code": "https://github.com/nheist/CaLiGraph",
        "license": "GNU General Public License v3.0",
        "inputs": {
            "typeOfTable": "Wikipedia listings (tables and lists)",
            "tableSources": [
                "wiki",
                "web"
            ]
        },
        "kg": {
            "tripleStore": "DBpedia; CaLiGraph",
            "index": ""
        },
        "output": "RDF",
        "applicationPurpose": "Knowledge graph extension with novel entities and assertions",
        "userInterfaceTool": "",
        "checkedByAuthor": "",
        "checkedByAi": true,
        "doi": "https://doi.org/10.1145/3442381.3449836",
        "citations": [
            {
                "ref": "1993_agrawal_mining",
                "title": "Mining association rules between sets of items in large databases"
            },
            {
                "ref": "2018_cannaviccio_leveraging",
                "title": "Leveraging Wikipedia table schemas for knowledge graph augmentation"
            },
            {
                "ref": "2019_chu_tifi",
                "title": "TiFi: Taxonomy Induction for Fictional Domains"
            },
            {
                "ref": "2013_delcorro_clausie",
                "title": "Clausie: clause-based open information extraction"
            },
            {
                "ref": "2015_dong_knowledge-based",
                "title": "Knowledge-Based Trust: Estimating the Trustworthiness of Web Sources"
            },
            {
                "ref": "2016_farber_on",
                "title": "On emerging entity detection"
            },
            {
                "ref": "2019_fetahu_tablenet",
                "title": "TableNet: An approach for determining fine-grained relations for Wikipedia tables"
            },
            {
                "ref": "2015_galarraga_fast",
                "title": "Fast rule mining in ontological knowledge bases with AMIE+"
            },
            {
                "ref": "2020_heist_knowledge",
                "title": "Knowledge Graphs on the Web–an Overview"
            },
            {
                "ref": "2019_heist_uncovering",
                "title": "Uncovering the Semantics of Wikipedia Categories"
            },
            {
                "ref": "2020_heist_entity",
                "title": "Entity Extraction from Wikipedia List Pages"
            },
            {
                "ref": "2020_hertling_dbkwik",
                "title": "DBkWik: extracting and integrating knowledge from thousands of wikis"
            },
            {
                "ref": "2009_lehmann_dl-learner",
                "title": "DL-Learner: learning concepts in description logics"
            },
            {
                "ref": "2015_lehmann_dbpedia",
                "title": "DBpedia–a large-scale, multilingual knowledge base extracted from Wikipedia"
            },
            {
                "ref": "2017_lehmberg_stitching",
                "title": "Stitching web tables for improving matching quality"
            },
            {
                "ref": "2020_liu_extracting",
                "title": "Extracting Knowledge from Web Text with Monte Carlo Tree Search"
            },
            {
                "ref": "2020_macdonald_neural",
                "title": "Neural Relation Extraction on Wikipedia Tables for Augmenting Knowledge Graphs"
            },
            {
                "ref": "2019_meilicke_anytime",
                "title": "Anytime Bottom-Up Rule Learning for Knowledge Graph Completion."
            },
            {
                "ref": "2011_mendes_dbpedia",
                "title": "DBpedia spotlight: shedding light on the web of documents"
            },
            {
                "ref": "2014_meusel_the",
                "title": "The webdatacommons microdata, rdfa and microformat dataset series"
            },
            {
                "ref": "2019_oulabi_using",
                "title": "Using weak supervision to identify long-tail entities for knowledge base completion"
            },
            {
                "ref": "2017_paulheim_knowledge",
                "title": "Knowledge graph refinement: A survey of approaches and evaluation methods"
            },
            {
                "ref": "2012_paulheim_unsupervised",
                "title": "Unsupervised generation of data mining features from linked open data"
            },
            {
                "ref": "2013_paulheim_extending",
                "title": "Extending DBpedia with Wikipedia List Pages"
            },
            {
                "ref": "2016_ritze_profiling",
                "title": "Profiling the potential of web tables for augmenting cross-domain knowledge bases"
            },
            {
                "ref": "2020_sakor_falcon",
                "title": "Falcon 2.0: An entity and relation linking tool over Wikidata"
            },
            {
                "ref": "2018_stanovsky_supervised",
                "title": "Supervised open information extraction"
            },
            {
                "ref": "2007_suchanek_yago",
                "title": "Yago: a core of semantic knowledge"
            },
            {
                "ref": "2016_vanerp_evaluating",
                "title": "Evaluating entity linking: An analysis of current benchmark datasets and a roadmap for doing a better job"
            },
            {
                "ref": "2011_volker_statistical",
                "title": "Statistical schema induction"
            },
            {
                "ref": "2014_vrandecic_wikidata",
                "title": "Wikidata: a free collaborative knowledgebase"
            },
            {
                "ref": "2017_wang_knowledge",
                "title": "Knowledge graph embedding: A survey of approaches and applications"
            },
            {
                "ref": "2016_xu_learning",
                "title": "Learning defining features for categories"
            },
            {
                "ref": "2012_yakout_infogather",
                "title": "InfoGather: entity augmentation and attribute discovery by holistic matching with web tables"
            },
            {
                "ref": "2020_zhang_novel",
                "title": "Novel Entity Discovery from Web Tables"
            },
            {
                "ref": "2020_zhang_web",
                "title": "Web Table Extraction, Retrieval, and Augmentation: A Survey"
            },
            {
                "ref": "2020_zhang_generating",
                "title": "Generating Categories for Sets of Entities"
            },
            {
                "ref": "2014_zhang_towards",
                "title": "Towards efficient and effective semantic table interpretation"
            },
            {
                "ref": "2018_zhu_exploiting",
                "title": "Exploiting semantic similarity for named entity disambiguation in knowledge graphs"
            }
        ],
        "uncertainFields": [
            {
                "field": "license",
                "reason": "Only the paper’s publication licence (CC-BY 4.0) is stated; no explicit software licence for the approach is specified."
            },
            {
                "field": "output",
                "reason": "The format is not explicitly named; inferred as RDF because assertions extend DBpedia/CaLiGraph."
            },
            {
                "field": "validation.goldStandard",
                "reason": "Evaluation uses manual assessment of sampled assertions rather than a named gold standard."
            },
            {
                "field": "techniqueTags",
                "reason": "The method is descriptive rule mining with distant supervision; other allowed tags (e.g., embeddings/transformer) are not explicitly mentioned."
            },
            {
                "field": "inputs.typeOfTable",
                "reason": "Approach targets Wikipedia listings broadly (tables and lists), not only traditional tables."
            },
            {
                "field": "coreTasks",
                "reason": "Paper focuses on KG extension from listings rather than STI tasks (CTA/CPA/CEA/CNEA)."
            }
        ]
    },
    {
        "id": "2021_huynh_dagobah",
        "added": "",
        "year": 2021,
        "firstAuthor": "Huynh",
        "authors": [
            "Viet-Phi Huynh",
            "Jixiong Liu",
            "Yoan Chabot",
            "Frédéric Deuzé",
            "Thomas Labbé",
            "Pierre Monnin",
            "Raphaël Troncy"
        ],
        "title": "DAGOBAH: Table and Graph Contexts for Efficient Semantic Annotation of Tabular Data",
        "venue": {
            "type": "challenge",
            "acronym": "SemTab"
        },
        "nameOfApproach": "DAGOBAH SL 2021",
        "techniqueTags": [
            "rule-based",
            "ontology-driven"
        ],
        "coreTasks": {
            "cta": true,
            "cpa": true,
            "cea": true,
            "cnea": false
        },
        "supportTasks": {
            "dataPreparation": {
                "description": "Pre-processing includes orientation and header detection, key column detection, and primitive typing of columns/cells to aid later annotations.",
                "spellChecker": "",
                "unitsOfMeasurements": "Unit detection/typing for literals with units (e.g., Distance, Speed, Temperature)."
            },
            "columnClassification": "Primitive typing separates object (named-entity) columns from literal columns (e.g., numbers, dates, emails, URLs, IPs).",
            "subjectDetection": "Key column (subject) detection with current support for a single key column.",
            "datatypeAnnotation": "Primitive typing for literals; for GitTables, primitives are mapped to Schema.org/DBpedia ontology classes.",
            "typeAnnotation": "Collect candidate entity types per column and apply majority voting to select the most specific class.",
            "predicateAnnotation": "Majority voting over one-hop and two-hop predicate paths between column pairs to choose properties.",
            "nilAnnotation": "",
            "entityLinking": {
                "description": "Entity lookup retrieves candidates and pre-scores them with text similarity and soft graph-context scoring; final disambiguation combines pre-score with CTA/CPA signals.",
                "candidateGeneration": "Elasticsearch-based lookup over enriched indexes for Wikidata and DBpedia (labels+aliases, including properties like P2561, P1705, P742 and DBpedia alias/redirect labels).",
                "entityDisambiguation": "Levenshtein-based similarity amplified and weighted by two-hop KG contexts with soft scoring; final score integrates CTA/CPA consistency."
            }
        },
        "mainMethod": {
            "type": "unsupervised",
            "technique": "rule-based scoring over KG contexts"
        },
        "revision": {
            "type": "fully automated",
            "description": "Pipeline runs automatically; results can be inspected via a REST API and a web UI but no user-in-the-loop correction is described."
        },
        "domain": {
            "domain": "independent",
            "type": ""
        },
        "validation": {
            "goldStandard": "SemTab 2021 (WDTable, DBPTable, BioTable, HardTable, BioDivTable, GitTables)",
            "metrics": [
                "Precision",
                "F1"
            ]
        },
        "code": "",
        "license": "Not Specified",
        "inputs": {
            "typeOfTable": "Relational tables",
            "tableSources": []
        },
        "kg": {
            "tripleStore": "Wikidata; DBpedia",
            "index": "Elasticsearch-based index with enriched labels and aliases"
        },
        "output": "",
        "applicationPurpose": "Automatic STI for dataset indexing/recommendation and KG refinement; industrial deployment via TableAnnotation API and DAGOBAH UI.",
        "userInterfaceTool": "TableAnnotation REST API; DAGOBAH UI",
        "checkedByAuthor": "",
        "checkedByAi": true,
        "doi": "",
        "citations": [
            {
                "ref": "2021_abdelmageed_biodivtab",
                "title": "BiodivTab: A Tabular Benchmark based on Biodiversity Research Data."
            },
            {
                "ref": "2021_chabot_a",
                "title": "A Framework for Automatically Interpreting Tabular Data at Orange."
            },
            {
                "ref": "2020_chen_linkingpark",
                "title": "LinkingPark: An Integrated Approach for Semantic Table Interpretation."
            },
            {
                "ref": "2015_ciampaglia_computational",
                "title": "Computational fact checking from knowledge networks."
            },
            {
                "ref": "2020_cremaschi_mantistable",
                "title": "MantisTable SE: an Efficient Approach for the Semantic Table Interpretation."
            },
            {
                "ref": "2021_hulsebos_gittables",
                "title": "Gittables: A large-scale corpus of relational tables."
            },
            {
                "ref": "2020_huynh_dagobah",
                "title": "DAGOBAH: enhanced scoring algorithms for scalable annotations of tabular data."
            },
            {
                "ref": "2020_nguyen_mtab4wikidata",
                "title": "Mtab4wikidata at semtab 2020: Tabular data annotation with wikidata."
            },
            {
                "ref": "2020_shigapov_bbw",
                "title": "bbw: Matching CSV to Wikidata via Meta-lookup."
            }
        ],
        "uncertainFields": [
            {
                "field": "title",
                "reason": "PDF shows both 'Efficient Semantic Annotation of Tabular Data' and 'Efficient Annotation of Tables'; exact canonical title may vary. "
            },
            {
                "field": "venue.type",
                "reason": "Work appears in the International Semantic Web Challenge (SemTab) proceedings hosted as a workshop at ISWC; could be classified as 'workshop' or 'challenge'. "
            },
            {
                "field": "code",
                "reason": "Paper mentions a deployed API/UI but does not cite a public code repository URL. "
            },
            {
                "field": "output",
                "reason": "No explicit export/serialisation format (e.g., RDF/CSV/JSON-LD) is stated in the text. "
            },
            {
                "field": "inputs.tableSources",
                "reason": "The exact provenance of input tables is not fixed (SemTab datasets + internal data) and no single source category is declared. "
            },
            {
                "field": "kg.index",
                "reason": "Indexing uses Elasticsearch with enriched labels/aliases; further implementation specifics are not detailed. "
            },
            {
                "field": "license",
                "reason": "Paper is CC BY 4.0, but the software’s licence is not specified; field refers to approach/code, not publication. "
            },
            {
                "field": "doi",
                "reason": "CEUR-WS challenge papers typically lack DOIs and none is shown in the PDF. "
            },
            {
                "field": "supportTasks.datatypeAnnotation",
                "reason": "Datatype mapping is described mainly for GitTables; general availability across inputs is unclear. "
            }
        ]
    },
    {
        "id": "2021_li_deep",
        "added": "",
        "year": 2021,
        "firstAuthor": "Li",
        "authors": [
            "Yuliang Li",
            "Jinfeng Li",
            "Yoshihiko Suhara",
            "AnHai Doan",
            "Wang-Chiew Tan"
        ],
        "title": "Deep Entity Matching with Pre-Trained Language Models",
        "venue": {
            "type": "journal",
            "acronym": "PVLDB"
        },
        "nameOfApproach": "Ditto",
        "techniqueTags": [
            "embeddings",
            "transformer"
        ],
        "coreTasks": {
            "cta": false,
            "cpa": false,
            "cea": false,
            "cnea": false
        },
        "supportTasks": {
            "dataPreparation": {
                "description": "Serialises record pairs with special tokens and applies TF-IDF-based summarisation; allows span typing/normalisation to inject domain knowledge.",
                "spellChecker": "",
                "unitsOfMeasurements": ""
            },
            "columnClassification": "",
            "subjectDetection": "",
            "datatypeAnnotation": "",
            "typeAnnotation": "",
            "predicateAnnotation": "",
            "nilAnnotation": "",
            "entityLinking": {
                "description": "",
                "candidateGeneration": "",
                "entityDisambiguation": ""
            }
        },
        "mainMethod": {
            "type": "supervised",
            "technique": "Fine-tuned pre-trained Transformer encoder (BERT/RoBERTa/DistilBERT)",
            "supervision": {
                "type": "supervised"
            }
        },
        "revision": {
            "type": "fully automated",
            "description": "Automatic binary classification; no post-hoc user validation stage described."
        },
        "domain": {
            "domain": "independent",
            "type": ""
        },
        "validation": {
            "goldStandard": "ER-Magellan datasets; WDC product data corpus (4,400 labelled test pairs)",
            "metrics": [
                "F1"
            ]
        },
        "code": "https://github.com/megagonlabs/ditto",
        "license": "Apache License 2.0",
        "inputs": {
            "typeOfTable": "Relational tables and web product offers",
            "tableSources": [
                "web",
                "relational",
                "scientific"
            ]
        },
        "kg": {
            "tripleStore": "",
            "index": ""
        },
        "output": "CSV (match/no-match labels)",
        "applicationPurpose": "Entity resolution / duplicate detection across heterogeneous tables",
        "userInterfaceTool": "",
        "checkedByAuthor": "",
        "checkedByAi": true,
        "doi": "https://doi.org/10.14778/3421424.3421431",
        "citations": [
            {
                "ref": "2018_mudgal_deep",
                "title": "Deep learning for entity matching: A design space exploration"
            },
            {
                "ref": "2018_ebraheem_distributed",
                "title": "Distributed representations of tuples for entity resolution"
            },
            {
                "ref": "2019_devlin_bert",
                "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"
            },
            {
                "ref": "2019_liu_roberta",
                "title": "RoBERTa: A robustly optimized bert pretraining approach"
            },
            {
                "ref": "2019_sanh_distilbert",
                "title": "DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter"
            },
            {
                "ref": "2019_reimers_sentence",
                "title": "Sentence-BERT: Sentence embeddings using Siamese BERT-networks"
            },
            {
                "ref": "2016_konda_magellan",
                "title": "Magellan: Toward Building Entity Matching Management Systems"
            },
            {
                "ref": "2019_primpeli_the",
                "title": "The WDC training dataset and gold standard for large-scale product matching"
            },
            {
                "ref": "2019_zhao_auto",
                "title": "Auto-EM: End-to-end Fuzzy Entity-Matching using Pre-trained Deep Models and Transfer Learning"
            },
            {
                "ref": "2020_brunner_entity",
                "title": "Entity matching with transformer architectures-a step forward in data integration"
            }
        ],
        "uncertainFields": [
            {
                "field": "license",
                "reason": "The paper specifies a publication licence, but the software repository licence is not stated in the text examined."
            },
            {
                "field": "inputs.typeOfTable",
                "reason": "The datasets include both relational records and web product offers; exact normalisation in the paper is not strictly labelled as 'tables'."
            },
            {
                "field": "inputs.tableSources",
                "reason": "Sources inferred from dataset descriptions; not explicitly enumerated using these categories."
            },
            {
                "field": "kg.tripleStore",
                "reason": "No KG is used; left empty to indicate non-applicability."
            },
            {
                "field": "kg.index",
                "reason": "No KG/index is used; left empty to indicate non-applicability."
            },
            {
                "field": "output",
                "reason": "Output format is not explicitly declared; assumed as standard prediction labels (CSV)."
            },
            {
                "field": "userInterfaceTool",
                "reason": "No UI/tool is described beyond code; field left empty."
            },
            {
                "field": "validation.goldStandard",
                "reason": "Gold standards summarised by family names; the paper lists many datasets in detail, which are not all enumerated here."
            },
            {
                "field": "citations",
                "reason": "Not exhaustive; only key references included due to space constraints."
            }
        ]
    },
    {
        "id": "2021_nguyen_semtab",
        "added": "",
        "year": 2021,
        "firstAuthor": "Nguyen",
        "authors": [
            "Phuc Nguyen",
            "Ikuya Yamada",
            "Natthawut Kertkeidkachorn",
            "Ryutaro Ichise",
            "Hideaki Takeda"
        ],
        "title": "SemTab 2021: Tabular Data Annotation with MTab Tool",
        "venue": {
            "type": "challenge",
            "acronym": "SemTab"
        },
        "nameOfApproach": "MTab",
        "techniqueTags": [
            "rule-based",
            "ontology-driven"
        ],
        "coreTasks": {
            "cta": true,
            "cpa": true,
            "cea": true,
            "cnea": false
        },
        "supportTasks": {
            "dataPreparation": {
                "description": "Loads CSV/TSV/Excel/markdown or pasted tables, removes HTML/noise tokens, and fixes encoding issues (e.g., via ftfy).",
                "spellChecker": "",
                "unitsOfMeasurements": ""
            },
            "columnClassification": "Predicts column data types (named-entity vs literal) from cell-level types using majority voting.",
            "subjectDetection": "Heuristic subject-column prediction (e.g., uniqueness score, NE-type, adapted Ritze et al. rules).",
            "datatypeAnnotation": "",
            "typeAnnotation": "Assigns KG classes to NE-columns based on context similarities and majority voting.",
            "predicateAnnotation": "Infers properties between subject and other columns via value-based context matching and majority voting.",
            "nilAnnotation": "",
            "entityLinking": {
                "description": "Generates cell-entity candidates and disambiguates using table context to produce CEA annotations.",
                "candidateGeneration": "BM25 keyword search, fuzzy search with Damerau–Levenshtein and Symmetric Delete hashing, combined via aggregation.",
                "entityDisambiguation": "Row-level value-based context similarity and majority voting to select final entities."
            }
        },
        "mainMethod": {
            "type": "unsupervised",
            "technique": "rule-based"
        },
        "revision": {
            "type": "fully automated",
            "description": "Produces annotations automatically; interfaces/API expose results without a manual correction step."
        },
        "domain": {
            "domain": "independent",
            "type": ""
        },
        "validation": {
            "goldStandard": "SemTab 2021 datasets: HardTable, BioTable, BioDivTab, HardTablesR3",
            "metrics": [
                "F1"
            ]
        },
        "code": "https://github.com/phucty/mtab_tool",
        "license": "MIT License",
        "inputs": {
            "typeOfTable": "CSV, TSV, Excel, markdown tables, pasted text",
            "tableSources": []
        },
        "kg": {
            "tripleStore": "Wikidata, DBpedia, Wikipedia (integrated WikiGraph)",
            "index": "BM25 index; Symmetric Delete precomputed deletes for fuzzy matching"
        },
        "output": "",
        "applicationPurpose": "General-purpose tabular data annotation with knowledge graphs, emphasising usability and performance.",
        "userInterfaceTool": "Web UI and public APIs",
        "checkedByAuthor": "",
        "checkedByAi": true,
        "doi": "",
        "citations": [
            {
                "ref": "2020_abdelmageed_jentab",
                "title": "Jentab: Matching tabular data to knowledge graphs"
            },
            {
                "ref": "2021_azzi_amalgam",
                "title": "Amalgam: A matching approach to fairfy tabular data with knowledge graph model"
            },
            {
                "ref": "2019_chabot_dagobah",
                "title": "Dagobah: an end-to-end context-free tabular data semantic annotation system"
            },
            {
                "ref": "2020_chen_linkingpark",
                "title": "Linkingpark: An integrated approach for semantic table interpretation"
            },
            {
                "ref": "2020_cremaschi_mantistable",
                "title": "Mantistable se: an efficient approach for the semantic table interpretation"
            },
            {
                "ref": "2019_cremaschi_mantistable",
                "title": "Mantistable: an automatic approach for the semantic table interpretation"
            },
            {
                "ref": "2020_cremaschi_a",
                "title": "A fully automated approach to a complete semantic table interpretation"
            },
            {
                "ref": "2020_cutrona_tough",
                "title": "Tough tables: Carefully evaluating entity linking for tabular data"
            },
            {
                "ref": "2012_garbe_symspell",
                "title": "Symspell: Symmetric delete algorithm"
            },
            {
                "ref": "2017_honnibal_spacy",
                "title": "spaCy 2: Natural language understanding with Bloom embeddings, convolutional neural networks and incremental parsing"
            },
            {
                "ref": "2020_huynh_dagobah",
                "title": "Dagobah: Enhanced scoring algorithms for scalable annotations of tabular data"
            },
            {
                "ref": "2020_jimenezruiz_semtab",
                "title": "Semtab 2019: Resources to benchmark tabular data to knowledge graph matching systems"
            },
            {
                "ref": "2020_jimenezruiz_results",
                "title": "Results of semtab 2020"
            },
            {
                "ref": "2020_kim_generating",
                "title": "Generating conceptual subgraph from tabular data for knowledge graph matching"
            },
            {
                "ref": "2019_morikawa_semantic",
                "title": "Semantic table interpretation using lod4all"
            },
            {
                "ref": "2019_nguyen_mtab",
                "title": "Mtab: Matching tabular data to knowledge graph using probability models"
            },
            {
                "ref": "2020_nguyen_tabeano",
                "title": "Tabeano: Table to knowledge graph entity annotation"
            },
            {
                "ref": "2020_nguyen_mtab4wikidata",
                "title": "Mtab4wikidata at semtab 2020: Tabular data annotation with wikidata"
            },
            {
                "ref": "2019_oliveira_adog-annotating",
                "title": "Adog-annotating data with ontologies and graphs"
            },
            {
                "ref": "2015_ritze_matching",
                "title": "Matching html tables to dbpedia"
            },
            {
                "ref": "2020_shigapov_bbw",
                "title": "bbw: Matching csv to wikidata via meta-lookup"
            },
            {
                "ref": "2019_speer_ftfy",
                "title": "ftfy"
            },
            {
                "ref": "2019_thawani_entity",
                "title": "Entity linking to knowledge graphs to infer column types and properties"
            },
            {
                "ref": "2019_vandewiele_csv2kg",
                "title": "Cvs2kg: Transforming tabular data into semantic knowledge"
            },
            {
                "ref": "2021_wang_tcn",
                "title": "TCN: table convolutional network for web table interpretation"
            }
        ],
        "uncertainFields": [
            {
                "field": "venue.type",
                "reason": "Presented in the SemTab 2021 context; treated as a challenge paper but could also be considered a workshop system paper."
            },
            {
                "field": "venue.acronym",
                "reason": "Could be recorded as “SemTab@ISWC”; acronym here shortened to “SemTab”."
            },
            {
                "field": "license",
                "reason": "Paper license is CC BY 4.0; the code repository’s licence may differ and is not stated in the text."
            },
            {
                "field": "doi",
                "reason": "No DOI is indicated in the paper; CEUR-WS style often lacks a DOI."
            },
            {
                "field": "output",
                "reason": "Output serialisation format is not explicitly specified."
            },
            {
                "field": "inputs.tableSources",
                "reason": "Sources of the input tables (e.g., web/wiki) are not explicitly stated beyond SemTab datasets."
            },
            {
                "field": "mainMethod.type",
                "reason": "Primarily heuristic and search-based (unsupervised), but uses pre-trained NER for data-type prediction, which could be seen as hybrid."
            },
            {
                "field": "kg.tripleStore",
                "reason": "Described as an integrated WikiGraph built from Wikidata, DBpedia, and Wikipedia; exact back-end store not specified."
            },
            {
                "field": "validation.metrics",
                "reason": "Paper reports F1 and AF1; only F1 is captured due to the allowed metrics list."
            },
            {
                "field": "supportTasks.datatypeAnnotation",
                "reason": "Paper includes data type prediction (NE vs literal) but not explicit KG datatype annotation."
            }
        ]
    },
    {
        "id": "2021_sarthou-camy_dagobah",
        "added": "",
        "year": 2021,
        "firstAuthor": "Sarthou-Camy",
        "authors": [
            "Christophe Sarthou-Camy",
            "Guillaume Jourdain",
            "Yoan Chabot",
            "Pierre Monnin",
            "Frédéric Deuzé",
            "Viet-Phi Huynh",
            "Jixiong Liu",
            "Thomas Labbé",
            "Raphael Troncy"
        ],
        "title": "DAGOBAH UI: A New Hope For Semantic Table Interpretation",
        "venue": {
            "type": "conference",
            "acronym": ""
        },
        "nameOfApproach": "DAGOBAH UI",
        "techniqueTags": [
            "rule-based",
            "ontology-driven"
        ],
        "coreTasks": {
            "cta": true,
            "cpa": true,
            "cea": true,
            "cnea": false
        },
        "supportTasks": {
            "dataPreparation": {
                "description": "Preprocessing toolbox to clean tables (encoding, alignment) and extract topology (orientation, headers).",
                "spellChecker": "",
                "unitsOfMeasurements": ""
            },
            "columnClassification": "",
            "subjectDetection": "",
            "datatypeAnnotation": "",
            "typeAnnotation": "Maps columns to KG classes (e.g., Wikidata/DBpedia).",
            "predicateAnnotation": "Identifies KG properties connecting pairs of columns.",
            "nilAnnotation": "",
            "entityLinking": {
                "description": "Links cell mentions to KG entities using lookup and disambiguation.",
                "candidateGeneration": "Elasticsearch-based lookup service to retrieve entity candidates.",
                "entityDisambiguation": "Syntactic distances and table/KG context comparison."
            }
        },
        "mainMethod": {
            "type": "unsupervised",
            "technique": "rule-based"
        },
        "revision": {
            "type": "semi automated",
            "description": "Users visualise and validate annotations via a Web UI; the underlying STI process runs automatically."
        },
        "domain": {
            "domain": "independent",
            "type": ""
        },
        "validation": {
            "goldStandard": "SemTab challenge datasets (2019–2021)",
            "metrics": [
                "Accuracy"
            ]
        },
        "code": "",
        "license": "Not Specified",
        "inputs": {
            "typeOfTable": "CSV, spreadsheets, HTML tables",
            "tableSources": [
                "web",
                "spreadsheet",
                "wiki"
            ]
        },
        "kg": {
            "tripleStore": "Wikidata; DBpedia",
            "index": "Elasticsearch"
        },
        "output": "",
        "applicationPurpose": "Table enrichment and knowledge graph enrichment through annotation-driven completion and expansion.",
        "userInterfaceTool": "Web UI",
        "checkedByAuthor": "",
        "checkedByAi": true,
        "doi": "",
        "citations": [
            {
                "ref": "2021_chabot_a",
                "title": "A Framework for Automatically Interpreting Tabular Data at Orange"
            },
            {
                "ref": "2020_chapman_dataset",
                "title": "Dataset search: a survey"
            },
            {
                "ref": "2019_cremaschi_mantistable",
                "title": "Mantistable: A tool for creating semantic annotations on tabular data"
            },
            {
                "ref": "2019_hassanzadeh_semtab",
                "title": "SemTab 2019: Semantic Web Challenge on Tabular Data to Knowledge Graph Matching Data Sets"
            },
            {
                "ref": "2021_huynh_dagobah",
                "title": "DAGOBAH: Table and Graph Contexts for Efficient Semantic Annotation of Tabular Data"
            },
            {
                "ref": "2020_jimenez-ruiz_results",
                "title": "Results of SemTab 2020"
            },
            {
                "ref": "2016_lehmberg_a",
                "title": "A Large Public Corpus of Web Tables containing Time and Context Metadata"
            },
            {
                "ref": "2021_nguyen_semtab",
                "title": "SemTab 2021: Tabular Data Annotation with MTab Tool"
            },
            {
                "ref": "2014_vrandecic_wikidata",
                "title": "Wikidata: a free collaborative knowledgebase"
            }
        ],
        "uncertainFields": [
            {
                "field": "venue.type",
                "reason": "The paper describes a demonstration at a conference but the specific venue is not explicitly stated."
            },
            {
                "field": "venue.acronym",
                "reason": "Acronym of the hosting venue is not given in the text."
            },
            {
                "field": "validation.metrics[0]",
                "reason": "Only that the system won the 'Accuracy' track is stated; exact metric definitions used in evaluation are not detailed."
            },
            {
                "field": "kg.tripleStore",
                "reason": "Both Wikidata and DBpedia are mentioned as supported; primary store for the specific experiments is not singled out."
            },
            {
                "field": "inputs.tableSources",
                "reason": "Web and spreadsheet inputs are stated; inclusion of 'wiki' is inferred from examples but not formalised as a source type."
            },
            {
                "field": "output",
                "reason": "Export is mentioned, and RDF export is future work; specific current output format is not specified."
            },
            {
                "field": "doi",
                "reason": "No DOI is provided in the paper."
            },
            {
                "field": "code",
                "reason": "An API endpoint is referenced, but no code repository or package link is provided."
            }
        ]
    },
    {
        "id": "2021_steenwinckel_magic",
        "added": "",
        "year": 2021,
        "firstAuthor": "Steenwinckel",
        "authors": [
            "Bram Steenwinckel",
            "Filip De Turck",
            "Femke Ongenae"
        ],
        "title": "MAGIC: Mining an Augmented Graph using INK, starting from a CSV",
        "venue": {
            "type": "challenge",
            "acronym": "SemTab"
        },
        "nameOfApproach": "MAGIC",
        "techniqueTags": [
            "embeddings"
        ],
        "coreTasks": {
            "cta": true,
            "cpa": true,
            "cea": true,
            "cnea": false
        },
        "supportTasks": {
            "dataPreparation": {
                "description": "External candidate lookup and optional candidate prefiltering; selection of a major column for processing.",
                "spellChecker": "",
                "unitsOfMeasurements": ""
            },
            "columnClassification": "",
            "subjectDetection": "Identifies a major column (from CPA targets when available) or iterates per column.",
            "datatypeAnnotation": "",
            "typeAnnotation": "Determines column types using counts of rdf:type (DBpedia) and P31 (Wikidata) from INK embeddings.",
            "predicateAnnotation": "Infers relations between columns by selecting properties with maximal support in the embeddings.",
            "nilAnnotation": "",
            "entityLinking": {
                "description": "Links cells to KG entities and disambiguates using interpretable INK embeddings and row context.",
                "candidateGeneration": "DBpedia Spotlight; Wikidata wbsearchentities API",
                "entityDisambiguation": "Selects the candidate whose embedding best matches other cells in the row (highest match count)."
            }
        },
        "mainMethod": {
            "type": "unsupervised",
            "technique": "embedding-based"
        },
        "revision": {
            "type": "fully automated",
            "description": "Pipeline automatically generates candidates, builds INK embeddings, and outputs CTA/CPA/CEA; a GUI exists for augmentation but no manual validation is required."
        },
        "domain": {
            "domain": "independent",
            "type": ""
        },
        "validation": {
            "goldStandard": "SemTab 2021 challenge datasets (Rounds 1–3, incl. DBpedia tables, BioTable, HardTable, BioDivTab, HardTableR3).",
            "metrics": [
                "Precision",
                "Recall",
                "F1"
            ]
        },
        "code": "https://github.com/IBCNServices/MAGIC",
        "license": "Other",
        "inputs": {
            "typeOfTable": "CSV",
            "tableSources": []
        },
        "kg": {
            "tripleStore": "DBpedia; Wikidata",
            "index": "HDT via RDFLib"
        },
        "output": "",
        "applicationPurpose": "Data enrichment and augmentation of tables via KGs.",
        "userInterfaceTool": "GUI",
        "checkedByAuthor": "",
        "checkedByAi": true,
        "doi": "",
        "citations": [
            {
                "ref": "2020_abdelmageed_jentab",
                "title": "JENTAB: Matching Tabular Data to Knowledge Graphs"
            },
            {
                "ref": "2007_auer_dbpedia",
                "title": "DBpedia: A Nucleus for a Web of Open Data"
            },
            {
                "ref": "2020_azzi_amalgam",
                "title": "AMALGAM: Making Tabular Dataset Explicit with Knowledge Graph"
            },
            {
                "ref": "2020_cremaschi_mantistable",
                "title": "MantisTable SE: An Efficient Approach for the Semantic Table Interpretation"
            },
            {
                "ref": "2013_fernandez_binary",
                "title": "Binary RDF Representation for Publication and Exchange (HDT)"
            },
            {
                "ref": "2019_galhotra_automated",
                "title": "Automated Feature Enhancement for Predictive Modeling Using External Knowledge"
            },
            {
                "ref": "2020_huynh_dagobah",
                "title": "DAGOBAH: Enhanced Scoring Algorithms for Scalable Annotations of Tabular Data"
            },
            {
                "ref": "2020_jimenez-ruiz_semtab",
                "title": "SemTab 2019: Resources to Benchmark Tabular Data to Knowledge Graph Matching Systems"
            },
            {
                "ref": "2020_jimenez-ruiz_results",
                "title": "Results of SemTab 2020"
            },
            {
                "ref": "2006_krech_rdflib",
                "title": "RDFLib: A Python Library for Working with RDF"
            },
            {
                "ref": "2011_mendes_dbpedia",
                "title": "DBpedia Spotlight: Shedding Light on the Web of Documents"
            },
            {
                "ref": "2020_nguyen_mtab4wikidata",
                "title": "MTab4Wikidata at SemTab 2020: Tabular Data Annotation with Wikidata"
            },
            {
                "ref": "2016_ristoski_rdf2vec",
                "title": "RDF2Vec: RDF Graph Embeddings for Data Mining"
            },
            {
                "ref": "2021_steenwinckel_walk",
                "title": "Walk Extraction Strategies for Node Embeddings with RDF2Vec in Knowledge Graphs"
            },
            {
                "ref": "2019_steenwinckel_csv2kg",
                "title": "CSV2KG: Transforming Tabular Data into Semantic Knowledge"
            },
            {
                "ref": "2021_steenwinckel_ink",
                "title": "INK: Knowledge Graph Embeddings for Node Classification"
            },
            {
                "ref": "2014_vrandecic_wikidata",
                "title": "Wikidata: A Free Collaborative Knowledgebase"
            }
        ],
        "uncertainFields": [
            {
                "field": "venue.acronym",
                "reason": "The paper appears in the SemTab challenge track under ISWC, but the exact acronym used by the venue may vary across editions."
            },
            {
                "field": "output",
                "reason": "The paper reports task outputs (CEA/CPA/CTA) but does not specify a serialisation format."
            },
            {
                "field": "inputs.tableSources",
                "reason": "Tables are described as CSV from the challenge; their original source category (web/wiki/government etc.) is not stated."
            },
            {
                "field": "license",
                "reason": "Code licence of the MAGIC repository is not stated in the paper; the PDF uses CC BY 4.0 for the article."
            },
            {
                "field": "kg.tripleStore",
                "reason": "Both DBpedia and Wikidata are used; represented here as a combined string."
            },
            {
                "field": "userInterfaceTool",
                "reason": "A GUI is mentioned, but the exact tool type (desktop vs web) is not specified."
            },
            {
                "field": "doi",
                "reason": "CEUR-WS challenge papers often lack DOIs; none is provided in the text."
            },
            {
                "field": "citations[7].ref",
                "reason": "Normalisation of the hyphenated surname in the slug may differ (Jimenez-Ruiz vs Jimenez Ruiz)."
            }
        ]
    },
    {
        "id": "2021_wang_tcn",
        "added": "",
        "year": 2021,
        "firstAuthor": "Wang",
        "authors": [
            "Daheng Wang",
            "Prashant Shiralkar",
            "Colin Lockard",
            "Binxuan Huang",
            "Xin Luna Dong",
            "Meng Jiang"
        ],
        "title": "TCN: Table Convolutional Network for Web Table Interpretation",
        "venue": {
            "type": "conference",
            "acronym": "WWW"
        },
        "nameOfApproach": "TCN (Table Convolutional Network)",
        "techniqueTags": [
            "embeddings"
        ],
        "coreTasks": {
            "cta": true,
            "cpa": true,
            "cea": false,
            "cnea": false
        },
        "supportTasks": {
            "dataPreparation": {
                "description": "Normalisation of cell text (lowercasing and trimming spaces) to canonicalise values across tables.",
                "spellChecker": "",
                "unitsOfMeasurements": ""
            },
            "columnClassification": "",
            "subjectDetection": "Assumes the first column is the subject column for relation prediction.",
            "datatypeAnnotation": "",
            "typeAnnotation": "Predicts semantic types for columns from a fixed ontology.",
            "predicateAnnotation": "Predicts relations between the subject column and each object column.",
            "nilAnnotation": "",
            "entityLinking": {
                "description": "",
                "candidateGeneration": "",
                "entityDisambiguation": ""
            }
        },
        "mainMethod": {
            "type": "hybrid",
            "technique": "graph neural network with attention and multi-task learning"
        },
        "revision": {
            "type": "fully automated",
            "description": "Model produces annotations automatically without human post-editing."
        },
        "domain": {
            "domain": "independent",
            "type": "general web tables"
        },
        "validation": {
            "goldStandard": "Two datasets: Dm (music domain, ~128K tables, manually annotated schemas) and Dw (Wikipedia subset, ~5.5K tables with existing annotations).",
            "metrics": [
                "Accuracy",
                "Weighted-F1"
            ]
        },
        "code": "",
        "license": "Not Specified",
        "inputs": {
            "typeOfTable": "Web tables",
            "tableSources": [
                "web",
                "wiki"
            ]
        },
        "kg": {
            "tripleStore": "",
            "index": ""
        },
        "output": "",
        "applicationPurpose": "Web table interpretation (column typing and relation prediction) for knowledge base augmentation.",
        "userInterfaceTool": "",
        "checkedByAuthor": "",
        "checkedByAi": true,
        "doi": "https://doi.org/10.1145/3442381.3450090",
        "citations": [
            {
                "ref": "2020_deng_turl",
                "title": "TURL: Table Understanding through Representation Learning"
            },
            {
                "ref": "2020_yin_tabert",
                "title": "TaBERT: Pretraining for Joint Understanding of Textual and Tabular Data"
            },
            {
                "ref": "2019_hulsebos_sherlock",
                "title": "Sherlock: A deep learning approach to semantic data type detection"
            },
            {
                "ref": "2019_zhang_table2vec",
                "title": "Table2Vec: neural word and entity embeddings for table population and retrieval"
            },
            {
                "ref": "2010_limaye_annotating",
                "title": "Annotating and searching web tables using entities, types and relationships"
            },
            {
                "ref": "2015_lehmann_dbpedia",
                "title": "DBpedia–a large-scale, multilingual knowledge base extracted from Wikipedia"
            },
            {
                "ref": "2014_vrandecic_wikidata",
                "title": "Wikidata: a free collaborative knowledgebase"
            },
            {
                "ref": "2019_devlin_bert",
                "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"
            },
            {
                "ref": "2020_herzig_tapas",
                "title": "TAPAS: Weakly Supervised Table Parsing via Pre-training"
            },
            {
                "ref": "2019_steenwinckel_csv2kg",
                "title": "Csv2kg: Transforming tabular data into semantic knowledge"
            }
        ],
        "uncertainFields": [
            {
                "field": "kg.tripleStore",
                "reason": "The specific KG used for labels is not clearly named (music dataset mentions a proprietary ontology; open-domain subset is from Wikipedia)."
            },
            {
                "field": "output",
                "reason": "The paper reports predicted types/relations but does not specify an export serialisation (e.g., RDF/CSV)."
            },
            {
                "field": "code",
                "reason": "No repository or download link is referenced; availability unclear."
            },
            {
                "field": "license",
                "reason": "Software licence for any implementation is not stated; only the paper licence is explicit."
            },
            {
                "field": "inputs.tableSources",
                "reason": "Assumed 'web' and 'wiki' from datasets; other sources are not explicitly supported."
            },
            {
                "field": "supportTasks.columnClassification",
                "reason": "No explicit NE vs LIT column classification step is described."
            },
            {
                "field": "supportTasks.datatypeAnnotation",
                "reason": "Datatype-specific annotation is not discussed."
            },
            {
                "field": "userInterfaceTool",
                "reason": "No UI or tool front-end is mentioned."
            },
            {
                "field": "mainMethod.technique",
                "reason": "Described broadly as a GNN with attention; the exact architectural label may vary."
            }
        ]
    },
    {
        "id": "2021_yang_gbmtab",
        "added": "",
        "year": 2021,
        "firstAuthor": "Yang",
        "authors": [
            "Lianzheng Yang",
            "Shuyang Shen",
            "Jingyi Ding",
            "Jiahui Jin"
        ],
        "title": "GBMTab: A Graph-Based Method for Interpreting Noisy Semantic Table to Knowledge Graph",
        "venue": {
            "type": "challenge",
            "acronym": "SemTab"
        },
        "nameOfApproach": "GBMTab",
        "techniqueTags": [
            "embeddings",
            "ontology-driven"
        ],
        "coreTasks": {
            "cta": true,
            "cpa": false,
            "cea": true,
            "cnea": false
        },
        "supportTasks": {
            "dataPreparation": {
                "description": "Noise-mention repair via search engine autocorrection; multilingual handling; candidate indexing.",
                "spellChecker": "Google Search autocorrect",
                "unitsOfMeasurements": ""
            },
            "columnClassification": "",
            "subjectDetection": "Primary key column identification to guide CTA.",
            "datatypeAnnotation": "",
            "typeAnnotation": "Types ranked via SPARQL type search, property intersection, voting and embedding similarity.",
            "predicateAnnotation": "",
            "nilAnnotation": "",
            "entityLinking": {
                "description": "Two-stage EL with candidate generation and probabilistic disambiguation using table context.",
                "candidateGeneration": "DBpedia: string-similarity index with threshold and multilingual support plus noise repair; Wikidata: MediaWiki API fuzzy search (top-k) with noise repair.",
                "entityDisambiguation": "Probabilistic graphical model with iterative probability propagation using priori, context, and abstract features."
            }
        },
        "mainMethod": {
            "type": "unsupervised",
            "technique": "Probabilistic graphical model with iterative probability propagation and embedding-based scoring"
        },
        "revision": {
            "type": "fully automated",
            "description": "Automatic pipeline evaluated in the SemTab 2021 challenge with no manual post-editing."
        },
        "domain": {
            "domain": "independent",
            "type": ""
        },
        "validation": {
            "goldStandard": "SemTab 2021 (Round 1: DBpedia 2016-10; Round 2: BioTable/Wikidata)",
            "metrics": [
                "F1",
                "Precision"
            ]
        },
        "code": "",
        "license": "Not Specified",
        "inputs": {
            "typeOfTable": "Web tables",
            "tableSources": [
                "web"
            ]
        },
        "kg": {
            "tripleStore": "DBpedia; Wikidata",
            "index": "Custom hash-table index for DBpedia; Wikidata MediaWiki API"
        },
        "output": "",
        "applicationPurpose": "Participation in SemTab 2021 to interpret tables and match them to KG entities and types.",
        "userInterfaceTool": "",
        "checkedByAuthor": "",
        "checkedByAi": true,
        "doi": "",
        "citations": [
            {
                "ref": "2021_wang_tcn",
                "title": "TCN: Table Convolutional Network for Web Table Interpretation"
            },
            {
                "ref": "2016_ritze_profiling",
                "title": "Profiling the Potential of Web Tables for Augmenting Cross-domain Knowledge Bases"
            },
            {
                "ref": "2010_limaye_annotating",
                "title": "Annotating and searching web tables using entities, types and relationships"
            },
            {
                "ref": "2013_mulwad_semantic",
                "title": "Semantic message passing for generating linked data from tables"
            },
            {
                "ref": "2020_nguyen_mtab4wikidata",
                "title": "MTab4Wikidata at SemTab 2020: Tabular Data Annotation with Wikidata"
            },
            {
                "ref": "2015_bhagavatula_tabel",
                "title": "TabEL: Entity Linking in Web Tables"
            },
            {
                "ref": "2016_ibrahim_making",
                "title": "Making Sense of Entities and Quantities in Web Tables"
            },
            {
                "ref": "2018_chen_colnet",
                "title": "ColNet: Embedding the Semantics of Web Tables for Column Type Prediction"
            },
            {
                "ref": "2018_devlin_bert",
                "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"
            },
            {
                "ref": "2020_tyagi_lexma",
                "title": "LexMa: Tabular Data to Knowledge Graph Matching using Lexical Techniques"
            }
        ],
        "uncertainFields": [
            {
                "field": "venue.acronym",
                "reason": "Paper appears in the SemTab 2021 challenge proceedings; using 'SemTab' as the acronym may omit the ISWC workshop context."
            },
            {
                "field": "doi",
                "reason": "CEUR-WS challenge papers often lack a DOI; none was stated."
            },
            {
                "field": "kg.tripleStore",
                "reason": "Both DBpedia and Wikidata were used across rounds; represented jointly as a single string."
            },
            {
                "field": "kg.index",
                "reason": "Indexing details are described qualitatively; exact implementation specifics are not fully detailed."
            },
            {
                "field": "output",
                "reason": "Output format (e.g., RDF/CSV) for the system is not specified; submissions are likely challenge-specific files."
            },
            {
                "field": "inputs.tableSources",
                "reason": "The paper discusses web tables broadly; specific sources for SemTab datasets are not enumerated."
            },
            {
                "field": "license",
                "reason": "Paper license (CC BY 4.0) is stated, but software license for the approach/code is not specified."
            },
            {
                "field": "domain",
                "reason": "Method is generic, but Round 2 uses BioTable (biomedical); treated as domain-independent overall."
            }
        ]
    },
    {
        "id": "2021_zhou_tabular",
        "added": "",
        "year": 2021,
        "firstAuthor": "Zhou",
        "authors": [
            "Yiwei Zhou",
            "Siffi Singh",
            "Christos Christodoulopoulos"
        ],
        "title": "Tabular Data Concept Type Detection Using Star-Transformers",
        "venue": {
            "type": "conference",
            "acronym": "CIKM"
        },
        "nameOfApproach": "",
        "techniqueTags": [
            "embeddings",
            "transformer"
        ],
        "coreTasks": {
            "cta": true,
            "cpa": false,
            "cea": false,
            "cnea": false
        },
        "supportTasks": {
            "dataPreparation": {
                "description": "Order-invariant features (global statistics, character distributions, word embeddings) extracted per column; headers not used; during training columns lacking labels are ignored.",
                "spellChecker": "",
                "unitsOfMeasurements": ""
            },
            "columnClassification": "",
            "subjectDetection": "",
            "datatypeAnnotation": "",
            "typeAnnotation": "Predicts DBpedia class (level-2/3) for each column using Star-Transformer over column representations.",
            "predicateAnnotation": "",
            "nilAnnotation": "",
            "entityLinking": {
                "description": "",
                "candidateGeneration": "",
                "entityDisambiguation": ""
            }
        },
        "mainMethod": {
            "type": "supervised",
            "technique": "transformer",
            "supervision": {
                "type": "distant"
            }
        },
        "revision": {
            "type": "fully automated",
            "description": "Predictions are produced automatically by the trained model without user intervention."
        },
        "domain": {
            "domain": "independent",
            "type": "open-domain"
        },
        "validation": {
            "goldStandard": "Wikipedia tables with columns labelled by DBpedia classes (43 concept types) via distant supervision",
            "metrics": [
                "Accuracy",
                "Macro-Precision",
                "Macro-Recall",
                "Macro-F1",
                "Weighted-F1"
            ]
        },
        "code": "",
        "license": "Not Specified",
        "inputs": {
            "typeOfTable": "HTML tables",
            "tableSources": [
                "web",
                "wiki"
            ]
        },
        "kg": {
            "tripleStore": "DBpedia",
            "index": ""
        },
        "output": "",
        "applicationPurpose": "Improve column concept type detection (CTA) in tabular data to support search, information extraction and question answering.",
        "userInterfaceTool": "",
        "checkedByAuthor": "",
        "checkedByAi": true,
        "doi": "https://doi.org/10.1145/3459637.3482197",
        "citations": [
            {
                "ref": "2015_bhagavatula_tabel",
                "title": "Tabel: Entity linking in web tables"
            },
            {
                "ref": "2018_cannaviccio_leveraging",
                "title": "Leveraging wikipedia table schemas for knowledge graph augmentation"
            },
            {
                "ref": "2019_chen_learning",
                "title": "Learning semantic annotations for tabular data"
            },
            {
                "ref": "2018_chen_generating",
                "title": "Generating schema labels through dataset content analysis"
            },
            {
                "ref": "2015_dai_document",
                "title": "Document embedding with paragraph vectors"
            },
            {
                "ref": "2021_deng_turl",
                "title": "Turl: Table understanding through representation learning"
            },
            {
                "ref": "2019_guo_star-transformer",
                "title": "Star-transformer"
            },
            {
                "ref": "2019_hulsebos_sherlock",
                "title": "Sherlock: A deep learning approach to semantic data type detection"
            },
            {
                "ref": "2010_limaye_annotating",
                "title": "Annotating and searching web tables using entities, types and relationships"
            },
            {
                "ref": "2019_loshchilov_decoupled",
                "title": "Decoupled weight decay regularization"
            },
            {
                "ref": "2013_mulwad_semantic",
                "title": "Semantic message passing for generating linked data from tables"
            },
            {
                "ref": "2014_pennington_glove",
                "title": "Glove: Global vectors for word representation"
            },
            {
                "ref": "2016_pham_semantic",
                "title": "Semantic labeling: a domain-independent approach"
            },
            {
                "ref": "2017_ritze_matching",
                "title": "Matching web tables to dbpedia-a feature utility study"
            },
            {
                "ref": "2018_rummele_evaluating",
                "title": "Evaluating approaches for supervised semantic labeling"
            },
            {
                "ref": "2016_szegedy_rethinking",
                "title": "Rethinking the inception architecture for computer vision"
            },
            {
                "ref": "2017_vaswani_attention",
                "title": "Attention is all you need"
            },
            {
                "ref": "2011_venetis_recovering",
                "title": "Recovering semantics of tables on the web"
            },
            {
                "ref": "2020_yin_tabert",
                "title": "Tabert: Pretraining for joint understanding of textual and tabular data"
            },
            {
                "ref": "2020_zhang_sato",
                "title": "Sato: Contextual semantic type detection in tables"
            },
            {
                "ref": "2017_zhang_effective",
                "title": "Effective and efficient semantic table interpretation using tableminer+"
            }
        ],
        "uncertainFields": [
            {
                "field": "nameOfApproach",
                "reason": "The paper does not assign a specific system name beyond describing the model."
            },
            {
                "field": "inputs.tableSources",
                "reason": "Dataset is from Wikipedia (web); whether both \"web\" and \"wiki\" should be listed separately may be arguable."
            },
            {
                "field": "kg.index",
                "reason": "No indexing strategy is described."
            },
            {
                "field": "output",
                "reason": "Output serialisation/format is not specified; only classification labels are reported."
            },
            {
                "field": "userInterfaceTool",
                "reason": "No UI or tool is mentioned."
            },
            {
                "field": "validation.goldStandard",
                "reason": "The dataset is constructed via distant supervision and is not given a formal GS name."
            },
            {
                "field": "code",
                "reason": "No implementation repository or download link is provided."
            }
        ]
    },
    {
        "id": "2022_abdelmageed_jentab",
        "added": "",
        "year": 2022,
        "firstAuthor": "Abdelmageed",
        "authors": [
            "Nora Abdelmageed",
            "Sirko Schindler"
        ],
        "title": "JenTab: Do CTA Solutions Affect the Entire Scores?",
        "venue": {
            "type": "workshop",
            "acronym": "SemTab"
        },
        "nameOfApproach": "JenTab",
        "techniqueTags": [
            "rule-based",
            "embeddings",
            "ontology-driven"
        ],
        "coreTasks": {
            "cta": true,
            "cpa": true,
            "cea": true,
            "cnea": false
        },
        "supportTasks": {
            "dataPreparation": {
                "description": "Generic lookup against KG labels/aliases (Jaro–Winkler ≥0.9) and a 2T-specific cleanup using fastText embeddings with cosine similarity ≥0.7 to reduce misspellings.",
                "spellChecker": "Misspelling correction via embedding similarity and string matching; no dedicated dictionary-based spell checker.",
                "unitsOfMeasurements": ""
            },
            "columnClassification": "",
            "subjectDetection": "",
            "datatypeAnnotation": "",
            "typeAnnotation": "CTA candidates created via P31 and 2Hops (P279) strategies; selected by Majority Vote or Least Common Subsumer (LCS).",
            "predicateAnnotation": "CPA inferred within a Create–Filter–Select pipeline using KG relations for column pairs; selection heuristics not detailed.",
            "nilAnnotation": "",
            "entityLinking": {
                "description": "Cell values linked to KG entities using label/alias lookup and CFS filtering with row/column context.",
                "candidateGeneration": "Lookup over KG dumps/APIs for labels and aliases to form candidates.",
                "entityDisambiguation": "Context-based filtering and voting (e.g., Majority Vote) within the CFS pipeline."
            }
        },
        "mainMethod": {
            "type": "unsupervised",
            "technique": "rule-based"
        },
        "revision": {
            "type": "fully automated",
            "description": "Automatic CFS pipeline; no human-in-the-loop post-editing."
        },
        "domain": {
            "domain": "independent",
            "type": ""
        },
        "validation": {
            "goldStandard": "SemTab 2022 (HardTables, 2T, BiodivTab)",
            "metrics": [
                "Precision",
                "Recall",
                "F1"
            ]
        },
        "code": "https://github.com/fusion-jena/JenTab",
        "license": "Apache License 2.0",
        "inputs": {
            "typeOfTable": "CSV",
            "tableSources": [
                "web",
                "wiki",
                "scientific"
            ]
        },
        "kg": {
            "tripleStore": "Wikidata; DBpedia",
            "index": "Generic lookup over labels/aliases using proxies and Jaro–Winkler-based index"
        },
        "output": "CSV",
        "applicationPurpose": "Analyse how CTA strategies and preprocessing affect overall STA performance in SemTab 2022.",
        "userInterfaceTool": "CLI",
        "checkedByAuthor": "",
        "checkedByAi": true,
        "doi": "",
        "citations": [
            {
                "ref": "2021_nguyen_semtab",
                "title": "Semtab 2021: Tabular data annotation with mtab tool"
            },
            {
                "ref": "2021_huynh_dagobah",
                "title": "DAGOBAH: table and graph contexts for efficient semantic annotation of tabular data"
            },
            {
                "ref": "2020_shigapov_bbw",
                "title": "bbw: Matching CSV to wikidata via meta-lookup"
            },
            {
                "ref": "2020_abdelmageed_jentab",
                "title": "Jentab: Matching tabular data to knowledge graphs"
            },
            {
                "ref": "2014_vrandecic_wikidata",
                "title": "Wikidata: a free collaborative knowledgebase"
            },
            {
                "ref": "2007_auer_dbpedia",
                "title": "DBpedia: A nucleus for a web of open data"
            },
            {
                "ref": "2021_abdelmageed_jentab-2",
                "title": "Jentab: A toolkit for semantic table annotations"
            },
            {
                "ref": "2020_cutrona_tough",
                "title": "Tough Tables: Carefully Evaluating Entity Linking for Tabular Data"
            },
            {
                "ref": "2021_abdelmageed_jentab-1",
                "title": "Jentab meets semtab 2021's new challenges"
            },
            {
                "ref": "2022_hassanzadeh_wikidata",
                "title": "Wikidata Truthy Dump from May 21, 2022"
            },
            {
                "ref": "2017_bojanowski_enriching",
                "title": "Enriching word vectors with subword information"
            },
            {
                "ref": "2021_abdelmageed_biodivtab",
                "title": "Biodivtab: A table annotation benchmark based on biodiversity research data"
            },
            {
                "ref": "2019_keil_efficient",
                "title": "Efficient bounded Jaro-Winkler Similarity based search"
            },
            {
                "ref": "",
                "title": "fusion-jena/jentab: Jentab code for SemTab 2022"
            },
            {
                "ref": "",
                "title": "fusion-jena/jentab_precomputed_lookup: Semtab2022"
            },
            {
                "ref": "",
                "title": "fusion-jena/jentab_solution_files: Semtab2022"
            }
        ],
        "uncertainFields": [
            {
                "field": "doi",
                "reason": "The CEUR-WS workshop paper appears not to have a DOI; none stated in the text."
            },
            {
                "field": "venue.acronym",
                "reason": "Could be reported as SemTab or CEUR-WS; the paper is in the SemTab workshop at ISWC."
            },
            {
                "field": "license",
                "reason": "The paper licence (CC BY 4.0) is stated, but the software licence is not specified in the text."
            },
            {
                "field": "inputs.typeOfTable",
                "reason": "CSV is mentioned as a common format, but the exact submission input format for each dataset is not explicitly stated."
            },
            {
                "field": "inputs.tableSources",
                "reason": "Sources inferred from dataset descriptions (web/wiki/scientific) rather than explicitly listed."
            },
            {
                "field": "kg.tripleStore",
                "reason": "Both Wikidata and DBpedia are used across rounds; represented as a combined value."
            },
            {
                "field": "output",
                "reason": "SemTab submissions are typically CSV; the paper does not explicitly specify the output format."
            },
            {
                "field": "userInterfaceTool",
                "reason": "Assumed CLI based on toolkit nature; UI specifics are not detailed."
            },
            {
                "field": "citations[8].ref",
                "reason": "Slug duplicates another 2021 Abdelmageed paper because both titles begin with 'Jentab'."
            },
            {
                "field": "citations[13].ref",
                "reason": "Zenodo/software entries have non-standard titles, making slugging ambiguous."
            },
            {
                "field": "supportTasks.predicateAnnotation",
                "reason": "The CPA selection heuristics are referenced but not described in detail."
            }
        ]
    },
    {
        "id": "2022_chen_linkingpark",
        "added": "",
        "year": 2022,
        "firstAuthor": "Chen",
        "authors": [
            "Shuang Chen",
            "Alperen Karaoglu",
            "Carina Negreanu",
            "Tingting Ma",
            "Jin-Ge Yao",
            "Jack Williams",
            "Feng Jiang",
            "Andy Gordon",
            "Chin-Yew Lin"
        ],
        "title": "LinkingPark: An automatic semantic table interpretation system",
        "venue": {
            "type": "journal",
            "acronym": "Web Semantics"
        },
        "nameOfApproach": "LinkingPark",
        "techniqueTags": [
            "rule-based"
        ],
        "coreTasks": {
            "cta": true,
            "cpa": true,
            "cea": true,
            "cnea": false
        },
        "supportTasks": {
            "dataPreparation": {
                "description": "Column analysis determines basic cell types and the subject column; normalisation includes spelling correction and unit conversion for matching literals.",
                "spellChecker": "Tailored mention spelling corrector (1 edit distance) triggered when dictionary lookup fails.",
                "unitsOfMeasurements": "Unit conversion for numerical properties (e.g., length, area, volume, frequency, mass, temperature) and ±10-day tolerance for dates."
            },
            "columnClassification": "Classifies columns by basic data type (int/float/datetime/string) to support downstream modules.",
            "subjectDetection": "Heuristic: choose the leftmost column with string cells as the subject column.",
            "datatypeAnnotation": "Basic cell typing used for literal property matching; no explicit KG datatype output.",
            "typeAnnotation": "Heuristic voting over types of linked entities with tie-breaking by AverageLevel, Population and InstanceRank.",
            "predicateAnnotation": "Property linking computes entity/literal property distributions across column pairs and selects the most supported KG property.",
            "nilAnnotation": "Supports NIL detection by score thresholding (not evaluated in SemTab).",
            "entityLinking": {
                "description": "Cascade candidate generation plus iterative classification for disambiguation using lexical similarity, row-wise property support, column-wise type consistency and entity popularity.",
                "candidateGeneration": "Offline alias map; in-memory dictionary lookup with 1-edit spelling corrector; fallback fuzzy search over a word- and character-trigram BM25 index.",
                "entityDisambiguation": "Iterative Classification Algorithm combining lexical similarity, row support from property matches, column similarity via property/type features, with popularity-based tie-breaking."
            }
        },
        "mainMethod": {
            "type": "unsupervised",
            "technique": "rule-based"
        },
        "revision": {
            "type": "fully automated",
            "description": "End-to-end automatic pipeline; an Excel Add-in and RESTful API expose results to users but no manual post-correction is required."
        },
        "domain": {
            "domain": "independent",
            "type": "generic"
        },
        "validation": {
            "goldStandard": "SemTab 2020 (AG Round1–4) and Tough Tables (2T)",
            "metrics": [
                "Precision",
                "Recall",
                "F1"
            ]
        },
        "code": "https://aka.ms/XLKG",
        "license": "Not Specified",
        "inputs": {
            "typeOfTable": "relational tables",
            "tableSources": [
                "web",
                "spreadsheet"
            ]
        },
        "kg": {
            "tripleStore": "Wikidata",
            "index": "Alias map and Elasticsearch fuzzy index; key–value KG access (in-memory Redis or disk-backed RocksDB)."
        },
        "output": "",
        "applicationPurpose": "Table annotation, semantic flash fill, table fact checking",
        "userInterfaceTool": "RESTful API; Excel Add-in",
        "checkedByAuthor": "",
        "checkedByAi": true,
        "doi": "https://doi.org/10.1016/j.websem.2022.100733",
        "citations": [
            {
                "ref": "2020_chen_linkingpark",
                "title": "LinkingPark: An integrated approach for semantic table interpretation"
            },
            {
                "ref": "2020_jimenez-ruiz_results",
                "title": "Results of semtab 2020"
            },
            {
                "ref": "2020_cutrona_tough",
                "title": "Tough tables: Carefully evaluating entity linking for tabular data"
            },
            {
                "ref": "2020_shigapov_bbw",
                "title": "bbw: Matching CSV to wikidata via meta-lookup"
            },
            {
                "ref": "2021_abdelmageed_jentab-2",
                "title": "JenTab: A toolkit for semantic table annotations"
            },
            {
                "ref": "2020_nguyen_mtab4wikidata",
                "title": "MTab4Wikidata at SemTab 2020: Tabular data annotation with wikidata"
            },
            {
                "ref": "2017_zhang_effective",
                "title": "Effective and efficient semantic table interpretation using TableMiner+"
            },
            {
                "ref": "2010_limaye_annotating",
                "title": "Annotating and searching web tables using entities, types and relationships"
            },
            {
                "ref": "2014_vrandecic_wikidata",
                "title": "Wikidata: a free collaborative knowledgebase"
            },
            {
                "ref": "2020_jimenez-ruiz_semtab2019",
                "title": "SemTab 2019: Resources to benchmark tabular data to knowledge graph matching systems"
            },
            {
                "ref": "2020_huynh_dagobah",
                "title": "DAGOBAH: Enhanced scoring algorithms for scalable annotations of tabular data"
            },
            {
                "ref": "2021_nguyen_demonstration",
                "title": "Demonstration of MTab: Tabular data annotation with knowledge graphs"
            }
        ],
        "uncertainFields": [
            {
                "field": "techniqueTags",
                "reason": "The system is unsupervised and largely heuristic; whether to tag it as 'ontology-driven' is arguable since it exploits Wikidata types and properties but is not framed as an ontology-driven method."
            },
            {
                "field": "output",
                "reason": "The paper describes annotations via API/Excel and SemTab submissions, but no explicit serialisation format (e.g., RDF/JSON-LD) is specified."
            },
            {
                "field": "supportTasks.datatypeAnnotation",
                "reason": "They use basic typing for literals and property-value matching, but do not present a dedicated datatype-annotation module that outputs KG datatypes."
            },
            {
                "field": "revision.type",
                "reason": "Although an Excel Add-in is provided for interaction, it appears to be for consumption rather than a post-hoc correction step."
            },
            {
                "field": "inputs.tableSources",
                "reason": "Evaluation uses automatically generated and real web tables; spreadsheets are supported via the Excel add-in, but exact source coverage is not exhaustively specified."
            },
            {
                "field": "citations",
                "reason": "The list is not exhaustive relative to the full bibliography of the paper."
            }
        ]
    },
    {
        "id": "2022_deng_turl",
        "added": "",
        "year": 2022,
        "firstAuthor": "Deng",
        "authors": [
            "Xiang Deng",
            "Huan Sun",
            "Alyssa Lees",
            "You Wu",
            "Cong Yu"
        ],
        "title": "TURL: Table Understanding through Representation Learning",
        "venue": {
            "type": "journal",
            "acronym": "SIGMOD Record"
        },
        "nameOfApproach": "TURL",
        "techniqueTags": [
            "transformer",
            "embeddings"
        ],
        "coreTasks": {
            "cta": true,
            "cpa": true,
            "cea": true,
            "cnea": false
        },
        "supportTasks": {
            "dataPreparation": {
                "description": "Pre-processed Wikipedia tables by concatenating page/section titles with captions, normalising entity mentions via hyperlinks, and filtering/heuristically detecting subject columns.",
                "spellChecker": "",
                "unitsOfMeasurements": ""
            },
            "columnClassification": "",
            "subjectDetection": "Heuristic subject column detection used when constructing relational tables.",
            "datatypeAnnotation": "",
            "typeAnnotation": "Fine-tuned model predicts semantic types for columns.",
            "predicateAnnotation": "Fine-tuned model predicts relations between subject–object column pairs.",
            "nilAnnotation": "",
            "entityLinking": {
                "description": "Entity linking via candidate generation from Wikidata Lookup and neural ranking using contextualised table representations.",
                "candidateGeneration": "Wikidata Lookup service with names/descriptions; type info from DBpedia.",
                "entityDisambiguation": "Ranking candidates using TURL representations and cross-entropy fine-tuning."
            }
        },
        "mainMethod": {
            "type": "hybrid",
            "technique": "Transformer with self-supervised pre-training and task-specific fine-tuning"
        },
        "revision": {
            "type": "fully automated",
            "description": "Outputs are produced automatically after pre-training and fine-tuning; an optional score reweighting with lookup popularity was explored."
        },
        "domain": {
            "domain": "independent",
            "type": "generic"
        },
        "validation": {
            "goldStandard": "WikiGS, T2D, held-out Wikipedia tables; Freebase-derived type/relation annotations.",
            "metrics": [
                "Precision",
                "Recall",
                "F1",
                "Accuracy",
                "MAP",
                "P@k"
            ]
        },
        "code": "https://github.com/sunlab-osu/TURL",
        "license": "Apache License 2.0",
        "inputs": {
            "typeOfTable": "Web tables (relational tables)",
            "tableSources": [
                "web",
                "wiki"
            ]
        },
        "kg": {
            "tripleStore": "Wikidata; Freebase; DBpedia",
            "index": "Wikidata Lookup and corpus-level header/entity co-occurrence indices"
        },
        "output": "",
        "applicationPurpose": "Universal pre-trained model for table interpretation (CEA/CTA/CPA) and augmentation (row population, cell filling, schema augmentation).",
        "userInterfaceTool": "",
        "checkedByAuthor": "",
        "checkedByAi": true,
        "doi": "https://doi.org/10.14778/3430915.3430921",
        "citations": [
            {
                "ref": "2020_deng_turl",
                "title": "TURL: Table understanding through representation learning"
            },
            {
                "ref": "2019_devlin_bert",
                "title": "BERT: Pre-training of deep bidirectional transformers for language understanding"
            },
            {
                "ref": "2020_herzig_tapas",
                "title": "TAPAS: Weakly supervised table parsing via pre-training"
            },
            {
                "ref": "2019_hulsebos_sherlock",
                "title": "Sherlock: A deep learning approach to semantic data type detection"
            },
            {
                "ref": "2017_zhang_entitables",
                "title": "EntiTables: Smart assistance for entity-focused tables"
            },
            {
                "ref": "2019_zhang_auto-completion",
                "title": "Auto-completion for data cells in relational tables"
            },
            {
                "ref": "2016_lehmberg_a",
                "title": "A large public corpus of web tables containing time and context metadata"
            },
            {
                "ref": "2015_ritze_matching",
                "title": "Matching HTML tables to DBpedia"
            },
            {
                "ref": "2017_efthymiou_matching",
                "title": "Matching web tables with knowledge base entities: From entity lookups to entity embeddings"
            },
            {
                "ref": "2019_zhang_ernie",
                "title": "ERNIE: Enhanced language representation with informative entities"
            },
            {
                "ref": "2008_cafarella_webtables",
                "title": "WebTables: exploring the power of tables on the web"
            },
            {
                "ref": "2019_deng_table2vec",
                "title": "Table2Vec: Neural word and entity embeddings for table population and retrieval"
            },
            {
                "ref": "2017_zhang_effective",
                "title": "Effective and efficient semantic table interpretation using TableMiner+"
            },
            {
                "ref": "2010_limaye_annotating",
                "title": "Annotating and searching web tables using entities, types and relationships"
            },
            {
                "ref": "2021_wang_retrieving",
                "title": "Retrieving complex tables with multi-granular graph representation learning"
            },
            {
                "ref": "2020_yin_pretraining",
                "title": "Pretraining for joint understanding of textual and tabular data"
            },
            {
                "ref": "2021_deng_structure-grounded",
                "title": "Structure-grounded pretraining for text-to-SQL"
            },
            {
                "ref": "2020_yu_grappa",
                "title": "GRAPPA: Grammar-augmented pre-training for table semantic parsing"
            },
            {
                "ref": "2022_xie_unifiedskg",
                "title": "UnifiedSKG: Unifying and multi-tasking structured knowledge grounding with text-to-text language models"
            },
            {
                "ref": "2019_chen_learning",
                "title": "Learning semantic annotations for tabular data"
            },
            {
                "ref": "2018_chen_colnet",
                "title": "ColNet: Embedding the semantics of web tables for column type prediction"
            }
        ],
        "uncertainFields": [
            {
                "field": "venue.acronym",
                "reason": "SIGMOD Record is a journal name rather than an acronym; no standard short acronym is provided in the paper."
            },
            {
                "field": "kg.tripleStore",
                "reason": "Multiple KGs (Wikidata, Freebase, DBpedia) are involved across tasks; the field expects a single value."
            },
            {
                "field": "output",
                "reason": "The paper reports predictions for tasks but does not specify a serialisation format such as RDF or JSON-LD."
            },
            {
                "field": "license",
                "reason": "The licence of the released code is not stated in the paper."
            },
            {
                "field": "validation.goldStandard",
                "reason": "Summarised multiple datasets; the paper spans several benchmarks and held-out sets."
            },
            {
                "field": "userInterfaceTool",
                "reason": "No UI/tool is described; code-only release is implied."
            }
        ]
    },
    {
        "id": "2022_gottschalk_tab2kg",
        "added": "",
        "year": 2022,
        "firstAuthor": "Gottschalk",
        "authors": [
            "Simon Gottschalk",
            "Elena Demidova"
        ],
        "title": "Tab2KG: Semantic table interpretation with lightweight semantic profiles",
        "venue": {
            "type": "journal",
            "acronym": "SWJ"
        },
        "nameOfApproach": "Tab2KG",
        "techniqueTags": [
            "ontology-driven"
        ],
        "coreTasks": {
            "cta": true,
            "cpa": true,
            "cea": false,
            "cnea": false
        },
        "supportTasks": {
            "dataPreparation": {
                "description": "Pre-processing includes column data type identification, key column detection and identifier generation to enable mapping and RML materialisation.",
                "spellChecker": "",
                "unitsOfMeasurements": ""
            },
            "columnClassification": "Identify fine-grained column data types (text, numeric, boolean, temporal, spatial) to separate literal vs entity-related columns.",
            "subjectDetection": "",
            "datatypeAnnotation": "Map literal columns to data type relations via similarity between table and domain profiles.",
            "typeAnnotation": "Assign classes to named-entity columns using domain ontology class relations during graph creation.",
            "predicateAnnotation": "Infer properties between columns by greedy selection over candidate mappings constrained by the domain ontology.",
            "nilAnnotation": "",
            "entityLinking": {
                "description": "",
                "candidateGeneration": "",
                "entityDisambiguation": ""
            }
        },
        "mainMethod": {
            "type": "supervised",
            "technique": "Siamese neural network (one-shot learning) over profile features",
            "supervision": {
                "type": "supervised"
            }
        },
        "revision": {
            "type": "fully automated",
            "description": "End-to-end automatic mapping and data graph materialisation; no user interaction in the loop."
        },
        "domain": {
            "domain": "independent",
            "type": ""
        },
        "validation": {
            "goldStandard": "GitHub (synthetic), Soccer, Weapon Ads, SemTab, SemTab Easy",
            "metrics": [
                "Accuracy"
            ]
        },
        "code": "https://github.com/sgottsch/Tab2KG",
        "license": "MIT License",
        "inputs": {
            "typeOfTable": "CSV",
            "tableSources": [
                "web",
                "wiki"
            ]
        },
        "kg": {
            "tripleStore": "DBpedia",
            "index": ""
        },
        "output": "RDF",
        "applicationPurpose": "Transform tabular data into semantic data graphs for data analytics workflows.",
        "userInterfaceTool": "",
        "checkedByAuthor": "",
        "checkedByAi": true,
        "doi": "https://doi.org/10.3233/SW-222993",
        "citations": [
            {
                "ref": "2019_chen_colnet",
                "title": "ColNet: Embedding the semantics of web tables for column type prediction"
            },
            {
                "ref": "2016_pham_semantic",
                "title": "Semantic labeling: A domain-independent approach"
            },
            {
                "ref": "2015_ritze_matching",
                "title": "Matching HTML tables to DBpedia"
            },
            {
                "ref": "2017_zhang_effective",
                "title": "Effective and efficient semantic table interpretation using TableMiner+"
            }
        ],
        "uncertainFields": [
            {
                "field": "license",
                "reason": "Paper is CC BY 4.0, but the software repository licence is not confirmed; using Not Specified for the approach."
            },
            {
                "field": "kg.tripleStore",
                "reason": "Approach is domain-agnostic and evaluated with schema.org-derived ontologies and DBpedia; DBpedia is listed as a representative target KG."
            },
            {
                "field": "inputs.tableSources",
                "reason": "Datasets span multiple origins; web and wiki are included as the most representative but may not be exhaustive."
            },
            {
                "field": "venue.acronym",
                "reason": "Semantic Web journal is sometimes abbreviated as SWJ; other acronyms may be used in some bibliographies."
            },
            {
                "field": "supportTasks.columnClassification",
                "reason": "The paper performs fine-grained data type detection rather than explicit NE/LIT classification; mapping to this sub-task is interpretative."
            },
            {
                "field": "domain.domain",
                "reason": "The method generalises across domains but requires a provided domain ontology; classified here as independent."
            },
            {
                "field": "citations",
                "reason": "Only key related works are listed; not an exhaustive reproduction of the full reference list."
            }
        ]
    },
    {
        "id": "2023_henriksen_semtex",
        "added": "",
        "year": 2023,
        "firstAuthor": "Henriksen",
        "authors": [
            "Emil G. Henriksen",
            "Alan M. Khorsid",
            "Esben Nielsen",
            "Adam M. Stück",
            "Andreas S. Sørensen",
            "Olivier Pelgrin"
        ],
        "title": "SemTex: A Hybrid Approach for Semantic Table Interpretation",
        "venue": {
            "type": "workshop",
            "acronym": "SemTab"
        },
        "nameOfApproach": "SemTex",
        "techniqueTags": [
            "ontology-driven"
        ],
        "coreTasks": {
            "cta": true,
            "cpa": true,
            "cea": true,
            "cnea": false
        },
        "supportTasks": {
            "dataPreparation": {
                "description": "Preprocess CSVs; normalise text/punctuation; spell-check mentions with Bing Search API using an 86% Levenshtein threshold. ",
                "spellChecker": "Bing Search API. ",
                "unitsOfMeasurements": ""
            },
            "columnClassification": "Entity columns identified from SemTab target files; not a general classifier (may slightly boost results). ",
            "subjectDetection": "Assumes first column is the subject; alternatively selects the column with the highest accumulated candidate score. ",
            "datatypeAnnotation": "",
            "typeAnnotation": "Chooses the 'instance of' object with largest overlap among CEA results per column; ties broken by first seen. ",
            "predicateAnnotation": "Counts properties per subject–column pair and selects the highest-frequency property (deduplicating per cell). ",
            "nilAnnotation": "",
            "entityLinking": {
                "description": "Subject Column Approach with candidate scoring (Levenshtein for text; normalised absolute difference for numbers/dates) plus ML fallback. ",
                "candidateGeneration": "MediaWiki Action API (wbsearchentities, query) over preprocessed mentions to gather candidates with titles, descriptions and statements. ",
                "entityDisambiguation": "CatBoost gradient boosting over 17 textual and numerical features to choose among equal-scoring candidates. "
            }
        },
        "mainMethod": {
            "type": "hybrid",
            "technique": "ontology-driven + gradient boosting (CatBoost)"
        },
        "revision": {
            "type": "fully automated",
            "description": "Pipeline runs without user intervention; a low-confidence review phase is suggested only as future work. "
        },
        "domain": {
            "domain": "independent",
            "type": "generic"
        },
        "validation": {
            "goldStandard": "SemTab 2022 & 2023 Round 1 (WikidataTablesR1); evaluated with F1. ",
            "metrics": [
                "F1"
            ]
        },
        "code": "",
        "license": "Not Specified",
        "inputs": {
            "typeOfTable": "CSV",
            "tableSources": [
                "spreadsheet"
            ]
        },
        "kg": {
            "tripleStore": "Wikidata",
            "index": "MediaWiki Action API (wbsearchentities, query)"
        },
        "output": "",
        "applicationPurpose": "SemTab participation: annotate tables with entities, types and properties using Wikidata. ",
        "userInterfaceTool": "",
        "checkedByAuthor": "",
        "checkedByAi": true,
        "doi": "",
        "citations": [
            {
                "ref": "2022_cremaschi_s-elbat",
                "title": "s-elbat: A semantic interpretation approach for messy table-s"
            },
            {
                "ref": "2022_li_kgcode-tab",
                "title": "Kgcode-tab results for semtab 2022"
            },
            {
                "ref": "2018_dorogush_catboost",
                "title": "Catboost: gradient boosting with categorical features support"
            },
            {
                "ref": "2020_schweter_flert",
                "title": "FLERT: document-level features for named entity recognition"
            }
        ],
        "uncertainFields": [
            {
                "field": "venue.acronym",
                "reason": "Paper appears in CEUR-WS for SemTab co-located with ISWC; acronym could be interpreted as SemTab or ISWC Workshop."
            },
            {
                "field": "license",
                "reason": "The paper licence (CC BY 4.0) is stated, but no software/code licence is provided; treated as Not Specified."
            },
            {
                "field": "output",
                "reason": "Submission format is not explicitly stated, though SemTab typically uses CSV; left blank to avoid assumptions."
            },
            {
                "field": "doi",
                "reason": "CEUR-WS papers often lack DOIs and none is shown in the paper."
            },
            {
                "field": "kg.index",
                "reason": "Authors use the MediaWiki Action API rather than a bespoke index; mapping this to an 'index' may be approximate."
            },
            {
                "field": "supportTasks.columnClassification",
                "reason": "Entity column detection leverages SemTab targets rather than a general algorithm, which may not generalise."
            }
        ]
    },
    {
        "id": "2022_huynh_from",
        "added": "",
        "year": 2022,
        "firstAuthor": "Huynh",
        "authors": [
            "Viet-Phi Huynh",
            "Yoan Chabot",
            "Thomas Labbé",
            "Jixiong Liu",
            "Raphaël Troncy"
        ],
        "title": "From Heuristics to Language Models: A Journey Through the Universe of Semantic Table Interpretation with DAGOBAH",
        "venue": {
            "type": "workshop",
            "acronym": "SemTab"
        },
        "nameOfApproach": "DAGOBAH SL 2022",
        "techniqueTags": [
            "rule-based",
            "embeddings",
            "transformer"
        ],
        "coreTasks": {
            "cta": true,
            "cpa": true,
            "cea": true,
            "cnea": false
        },
        "supportTasks": {
            "dataPreparation": {
                "description": "Pre-processing detects table orientation, headers, and primitive column types; includes pipeline optimisations for speed and scalability.",
                "spellChecker": "",
                "unitsOfMeasurements": ""
            },
            "columnClassification": "Heuristics determine NE vs literal columns and primitive types to guide CTA/CEA.",
            "subjectDetection": "",
            "datatypeAnnotation": "Detects fine-grained literal types (e.g., numbers, dates) to support CPA.",
            "typeAnnotation": "Assigns KG classes to columns using table context and KG information.",
            "predicateAnnotation": "Predicts KG properties between column pairs using contextual signals.",
            "nilAnnotation": "",
            "entityLinking": {
                "description": "Links cells to KG entities via alias-table lookup and context-aware scoring, with optional header–description cross-encoder.",
                "candidateGeneration": "Elasticsearch-based lookup over enriched alias tables (Wikipedia, Mewsli, Wikilinks, WikiDiverse) with fuzzy, BM25, and PageRank signals.",
                "entityDisambiguation": "Combines table-context scoring with a sigmoid on prior lookup scores; optionally applies an ELECTRA/BERT cross-encoder on headers vs entity descriptions."
            }
        },
        "mainMethod": {
            "type": "hybrid",
            "technique": "Heuristics + transformer cross-encoder + knowledge graph embeddings"
        },
        "revision": {
            "type": "fully automated",
            "description": "End-to-end automatic annotation; a Web UI can be used to visualise results and optionally enrich tables/KGs."
        },
        "domain": {
            "domain": "independent",
            "type": "generic"
        },
        "validation": {
            "goldStandard": "SemTab 2022 corpora (HardTables, ToughTables, BiodivTab, GitTables)",
            "metrics": [
                "Precision",
                "F1"
            ]
        },
        "code": "https://developer.orange.com/apis/table-annotation",
        "license": "Not Specified",
        "inputs": {
            "typeOfTable": "Web tables and CSV",
            "tableSources": []
        },
        "kg": {
            "tripleStore": "Wikidata; DBpedia",
            "index": "Elasticsearch alias index with BM25 and PageRank scoring"
        },
        "output": "",
        "applicationPurpose": "Semantic interpretation of tables for CEA/CTA/CPA, with enrichment of tables and knowledge graphs; SemTab 2022 participation.",
        "userInterfaceTool": "Web UI (DAGOBAH UI) and API",
        "checkedByAuthor": "",
        "checkedByAi": true,
        "doi": "",
        "citations": [
            {
                "ref": "2022_liu_from",
                "title": "From Tabular Data to Knowledge Graphs: A Survey of Semantic Table Interpretation Tasks and Methods"
            },
            {
                "ref": "2021_huynh_dagobah",
                "title": "DAGOBAH: Table and Graph Contexts for Efficient Semantic Annotation of Tabular Data"
            },
            {
                "ref": "2022_liu_radar",
                "title": "Radar Station: Using KG Embeddings for Semantic Table Interpretation and Entity Disambiguation"
            },
            {
                "ref": "2010_limaye_annotating",
                "title": "Annotating and searching web tables using entities, types and relationships"
            },
            {
                "ref": "2016_lehmberg_a",
                "title": "A large public corpus of web tables containing time and context metadata"
            },
            {
                "ref": "2020_cutrona_tough",
                "title": "Tough tables: Carefully evaluating entity linking for tabular data"
            },
            {
                "ref": "2019_devlin_bert",
                "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"
            },
            {
                "ref": "2020_clark_electra",
                "title": "ELECTRA: Pre-training text encoders as discriminators rather than generators"
            },
            {
                "ref": "2019_reimers_sentence",
                "title": "Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks"
            },
            {
                "ref": "2018_moritz_ray",
                "title": "Ray: A distributed framework for emerging AI applications"
            },
            {
                "ref": "2022_deng_turl",
                "title": "TURL: Table Understanding through Representation Learning"
            },
            {
                "ref": "2020_herzig_tapas",
                "title": "TAPAS: Weakly supervised table parsing via pre-training"
            },
            {
                "ref": "2020_yin_tabert",
                "title": "TaBERT: Pretraining for joint understanding of textual and tabular data"
            },
            {
                "ref": "2017_efthymiou_matching",
                "title": "Matching web tables with knowledge base entities: from entity lookups to entity embeddings"
            },
            {
                "ref": "2019_chabot_dagobah",
                "title": "DAGOBAH: an end-to-end context-free tabular data semantic annotation system"
            }
        ],
        "uncertainFields": [
            {
                "field": "license",
                "reason": "Paper licence is CC BY 4.0, but the software licence for DAGOBAH SL 2022 is not specified."
            },
            {
                "field": "inputs.typeOfTable",
                "reason": "Exact accepted formats are not exhaustively listed; SemTab datasets are used but formats vary."
            },
            {
                "field": "inputs.tableSources",
                "reason": "The paper does not explicitly enumerate source categories for input tables."
            },
            {
                "field": "kg.index",
                "reason": "Implementation details beyond Elasticsearch/BM25/PageRank are not fully specified."
            },
            {
                "field": "output",
                "reason": "No explicit output serialisation format is stated."
            },
            {
                "field": "citations",
                "reason": "List may be incomplete relative to the full reference section."
            },
            {
                "field": "venue.acronym",
                "reason": "Published in CEUR-WS for the SemTab 2022 workshop; using the workshop acronym may be ambiguous."
            },
            {
                "field": "techniqueTags",
                "reason": "Ontology-driven tag is omitted; although KGs are used, the approach is not described as ontology-driven explicitly."
            },
            {
                "field": "doi",
                "reason": "CEUR-WS papers typically lack DOIs; none is provided in the text."
            }
        ]
    },
    {
        "id": "2022_suhara_annotating",
        "added": "",
        "year": 2022,
        "firstAuthor": "Suhara",
        "authors": [
            "Yoshihiko Suhara",
            "Jinfeng Li",
            "Yuliang Li",
            "Dan Zhang",
            "Çağatay Demiralp",
            "Chen Chen",
            "Wang-Chiew Tan"
        ],
        "title": "Annotating Columns with Pre-trained Language Models",
        "venue": {
            "type": "conference",
            "acronym": "SIGMOD"
        },
        "nameOfApproach": "Doduo",
        "techniqueTags": [
            "transformer"
        ],
        "coreTasks": {
            "cta": true,
            "cpa": true,
            "cea": false,
            "cnea": false
        },
        "supportTasks": {
            "dataPreparation": {
                "description": "Serialises whole tables into token sequences with per-column [CLS] tokens; tokenisation and max-tokens truncation per column are applied. ",
                "spellChecker": "",
                "unitsOfMeasurements": ""
            },
            "columnClassification": "",
            "subjectDetection": "",
            "datatypeAnnotation": "",
            "typeAnnotation": "Predicts semantic column types (CTA).",
            "predicateAnnotation": "Predicts semantic relations between column pairs (CPA).",
            "nilAnnotation": "",
            "entityLinking": {
                "description": "",
                "candidateGeneration": "",
                "entityDisambiguation": ""
            }
        },
        "mainMethod": {
            "type": "supervised",
            "technique": "transformer",
            "supervision": {
                "type": "supervised"
            }
        },
        "revision": {
            "type": "fully automated",
            "description": "End-to-end multi-task fine-tuning of a pre-trained Transformer; predictions are produced without user intervention. "
        },
        "domain": {
            "domain": "independent",
            "type": ""
        },
        "validation": {
            "goldStandard": "WikiTable (Freebase types/relations) and VizNet (DBpedia types). ",
            "metrics": [
                "Precision",
                "Recall",
                "F1",
                "Micro-F1",
                "Macro-F1"
            ]
        },
        "code": "https://github.com/megagonlabs/doduo",
        "license": "Apache License 2.0",
        "inputs": {
            "typeOfTable": "Web tables",
            "tableSources": [
                "web",
                "wiki"
            ]
        },
        "kg": {
            "tripleStore": "",
            "index": ""
        },
        "output": "",
        "applicationPurpose": "Unified column annotation (types and relations) for table understanding and downstream data-management tasks. ",
        "userInterfaceTool": "",
        "checkedByAuthor": "",
        "checkedByAi": true,
        "doi": "https://doi.org/10.1145/3514221.3517906",
        "citations": [
            {
                "ref": "2019_hulsebos_sherlock",
                "title": "Sherlock: A Deep Learning Approach to Semantic Data Type Detection"
            },
            {
                "ref": "2020_zhang_sato",
                "title": "Sato: Contextual Semantic Type Detection in Tables"
            },
            {
                "ref": "2020_deng_turl",
                "title": "TURL: Table Understanding through Representation Learning"
            },
            {
                "ref": "2020_yin_tabert",
                "title": "TaBERT: Pretraining for Joint Understanding of Textual and Tabular Data"
            },
            {
                "ref": "2020_herzig_tapas",
                "title": "TaPas: Weakly Supervised Table Parsing via Pre-training"
            }
        ],
        "uncertainFields": [
            {
                "field": "license",
                "reason": "No explicit software licence is mentioned in the paper; repository licence not verified here."
            },
            {
                "field": "kg.tripleStore",
                "reason": "Training labels align with Freebase/DBpedia types, but the approach does not query a KG or require a triple store. "
            },
            {
                "field": "output",
                "reason": "The paper does not state a specific export/serialisation format for predictions."
            },
            {
                "field": "userInterfaceTool",
                "reason": "A toolbox is released, but no specific CLI/Web UI is described. "
            },
            {
                "field": "inputs.tableSources",
                "reason": "Evaluations use Wikipedia tables and WebTables (VizNet); represented here as 'web' and 'wiki'. "
            },
            {
                "field": "validation.goldStandard",
                "reason": "Dataset names and label sources are summarised from the text; exact naming conventions may vary. "
            },
            {
                "field": "supportTasks.typeAnnotation",
                "reason": "Mapped paper's 'column type prediction' to CTA terminology."
            },
            {
                "field": "supportTasks.predicateAnnotation",
                "reason": "Mapped paper's 'column relation prediction' to CPA terminology."
            },
            {
                "field": "domain.type",
                "reason": "Approach targets general tables; left empty to reflect domain independence."
            }
        ]
    },
    {
        "id": "2023_baazouzi_kepler-asi",
        "added": "",
        "year": 2023,
        "firstAuthor": "Baazouzi",
        "authors": [
            "Wiem Baazouzi",
            "Marouen Kachroudi",
            "Sami Faiz"
        ],
        "title": "Kepler-aSI at SemTab 2023",
        "venue": {
            "type": "challenge",
            "acronym": "SemTab"
        },
        "nameOfApproach": "Kepler-aSI",
        "techniqueTags": [
            "rule-based",
            "ontology-driven"
        ],
        "coreTasks": {
            "cta": true,
            "cpa": true,
            "cea": true,
            "cnea": false
        },
        "supportTasks": {
            "dataPreparation": {
                "description": "Preprocessing with text cleaning, language detection and unit/regex detection; spelling correction and normalisation to lower case.",
                "spellChecker": "TextBlob; PySpellChecker",
                "unitsOfMeasurements": "area, currency, density, electric current, energy, flow rate, force, frequency, energy efficiency, information unit, length, mass, numbers, population density, power, pressure, speed, temperature, time, torque, voltage, volume"
            },
            "columnClassification": "",
            "subjectDetection": "",
            "datatypeAnnotation": "",
            "typeAnnotation": "SPARQL-based CTA using Wikidata/DBpedia semantics (e.g., instanceOf P31, subclassOf P279, partOf P361).",
            "predicateAnnotation": "SPARQL-based CPA to find properties linking entity columns within rows.",
            "nilAnnotation": "",
            "entityLinking": {
                "description": "CEA via SPARQL lookups over KG; leverages CTA outputs.",
                "candidateGeneration": "Generate entity candidates from KG APIs/SPARQL using cell contents and descriptions.",
                "entityDisambiguation": "Resolve ambiguities using column context and CTA-derived types."
            }
        },
        "mainMethod": {
            "type": "unsupervised",
            "technique": "rule-based"
        },
        "revision": {
            "type": "fully automated",
            "description": "Annotations are produced automatically via SPARQL queries and deterministic filters; no user-in-the-loop editing during evaluation."
        },
        "domain": {
            "domain": "independent",
            "type": ""
        },
        "validation": {
            "goldStandard": "SemTab 2023 datasets (e.g., WikidataTables, SOTAB, tFood)",
            "metrics": [
                "Precision",
                "Recall",
                "F1"
            ]
        },
        "code": "",
        "license": "Not Specified",
        "inputs": {
            "typeOfTable": "Web tables",
            "tableSources": []
        },
        "kg": {
            "tripleStore": "Wikidata; DBpedia",
            "index": ""
        },
        "output": "",
        "applicationPurpose": "Participation in SemTab 2023 to annotate tabular data with KG semantics.",
        "userInterfaceTool": "",
        "checkedByAuthor": "",
        "checkedByAi": true,
        "doi": "",
        "citations": [
            {
                "ref": "2019_chen_colnet",
                "title": "ColNet: Embedding the semantics of web tables for column type prediction"
            },
            {
                "ref": "2018_malyshev_getting",
                "title": "Getting the most out of Wikidata: Semantic technology usage in Wikipedia’s knowledge graph"
            },
            {
                "ref": "2022_baazouzi_a",
                "title": "A matching approach to confer semantics over tabular data based on knowledge graphs"
            },
            {
                "ref": "2022_baazouzi_towards",
                "title": "Towards an efficient fairification approach of tabular data with knowledge graph models"
            },
            {
                "ref": "2020_baazouzi_kepler-asi",
                "title": "Kepler-asi: Kepler as a semantic interpreter."
            },
            {
                "ref": "2021_baazouzi_kepler-asi",
                "title": "Kepler-asi at SemTab 2021."
            },
            {
                "ref": "2022_baazouzi_yet",
                "title": "Yet another milestone for Kepler-asi at SemTab 2022"
            },
            {
                "ref": "2020_jimenez-ruiz_results",
                "title": "Results of SemTab 2020"
            }
        ],
        "uncertainFields": [
            {
                "field": "doi",
                "reason": "No DOI is stated; CEUR-WS challenge papers typically lack DOIs."
            },
            {
                "field": "code",
                "reason": "No repository or download link is mentioned."
            },
            {
                "field": "output",
                "reason": "The exported output format is not specified."
            },
            {
                "field": "userInterfaceTool",
                "reason": "No UI or tool front-end is described."
            },
            {
                "field": "inputs.tableSources",
                "reason": "Exact sources of input tables are not explicitly enumerated beyond challenge datasets."
            },
            {
                "field": "kg.index",
                "reason": "No indexing layer is described; only SPARQL endpoints/APIs are referenced."
            },
            {
                "field": "validation.goldStandard",
                "reason": "Gold standard names are summarised; precise identifiers for each task/round are not fully listed."
            },
            {
                "field": "supportTasks.columnClassification",
                "reason": "Column classification is not explicitly described as a separate sub-task."
            },
            {
                "field": "supportTasks.subjectDetection",
                "reason": "Subject column detection is not explicitly addressed."
            },
            {
                "field": "supportTasks.datatypeAnnotation",
                "reason": "Datatype annotation is not explicitly described."
            },
            {
                "field": "license",
                "reason": "Paper licence is CC BY 4.0, but the approach/code licence is unspecified."
            }
        ]
    },
    {
        "id": "2023_dasoulas_torchictab",
        "added": "",
        "year": 2023,
        "firstAuthor": "Dasoulas",
        "authors": [
            "Ioannis Dasoulas",
            "Duo Yang",
            "Xuemin Duan",
            "Anastasia Dimou"
        ],
        "title": "TorchicTab: Semantic Table Annotation with Wikidata and Language Models",
        "venue": {
            "type": "workshop",
            "acronym": "SemTab"
        },
        "nameOfApproach": "TorchicTab",
        "techniqueTags": [
            "rule-based",
            "transformer"
        ],
        "coreTasks": {
            "cta": true,
            "cpa": true,
            "cea": true,
            "cnea": false
        },
        "supportTasks": {
            "dataPreparation": {
                "description": "Pre-processing removes non-cell tokens/HTML and fixes encodings; structural annotations then mark NE vs L columns using regex and SpaCy with majority voting.",
                "spellChecker": "",
                "unitsOfMeasurements": ""
            },
            "columnClassification": "NE vs L column detection via regex and SpaCy, labelled by majority voting across cells.",
            "subjectDetection": "Subject column inferred from table context; for subject-less tables, topic detection leverages RDF triples and contextual similarity.",
            "datatypeAnnotation": "",
            "typeAnnotation": "Column types selected via P31/P279 hierarchies with majority voting and type-distance minimisation.",
            "predicateAnnotation": "Properties ranked by majority voting combining property frequency and candidate context scores to choose relations between columns.",
            "nilAnnotation": "",
            "entityLinking": {
                "description": "Cells in NE-columns linked to KG entities using multi-strategy candidate search and context-aware ranking.",
                "candidateGeneration": "Elasticsearch index over Wikidata labels/aliases plus Wikidata API; complete, fuzzy, token, and token-combination lookups.",
                "entityDisambiguation": "Literal similarity (Levenshtein, BM25) combined with contextual similarity from candidate sub-graphs (row-wise evidence) to score and rank candidates."
            }
        },
        "mainMethod": {
            "type": "hybrid",
            "technique": "Heuristic rule-based RDF graph analysis plus transformer fine-tuning (DODUO) for CTA/CPA classification"
        },
        "revision": {
            "type": "fully automated",
            "description": "Annotations are produced automatically using heuristic scoring and majority voting without human-in-the-loop post-editing."
        },
        "domain": {
            "domain": "independent",
            "type": "generic"
        },
        "validation": {
            "goldStandard": "SemTab 2023 datasets (Wikidata, tFood, Column-Qualifier) and SOTAB (Schema.org, DBpedia)",
            "metrics": [
                "Precision",
                "Recall",
                "F1",
                "Macro-F1",
                "Micro-F1"
            ]
        },
        "code": "",
        "license": "Not Specified",
        "inputs": {
            "typeOfTable": "CSV",
            "tableSources": [
                "web",
                "wiki"
            ]
        },
        "kg": {
            "tripleStore": "Wikidata; DBpedia; Schema.org",
            "index": "Elasticsearch over Wikidata; SPARQL endpoint and Wikipedia API for retrieval"
        },
        "output": "",
        "applicationPurpose": "Semantic annotation of tables for CEA/CTA/CPA across diverse datasets",
        "userInterfaceTool": "",
        "checkedByAuthor": "",
        "checkedByAi": true,
        "doi": "",
        "citations": [
            {
                "ref": "2017_zhang_effective",
                "title": "Effective and Efficient Semantic Table Interpretation using TableMiner+"
            },
            {
                "ref": "2010_limaye_annotating",
                "title": "Annotating and Searching Web Tables Using Entities, Types and Relationships"
            },
            {
                "ref": "2020_jimenez-ruiz_semtab",
                "title": "SemTab 2019: Resources to benchmark tabular data to knowledge graph matching systems"
            },
            {
                "ref": "2021_cutrona_results",
                "title": "Results of SemTab 2021"
            },
            {
                "ref": "2022_abdelmageed_results",
                "title": "Results of SemTab 2022"
            },
            {
                "ref": "2022_suhara_annotating",
                "title": "Annotating Columns with Pre-trained Language Models"
            },
            {
                "ref": "2022_korini_sotab",
                "title": "SOTAB: The WDC Schema.org Table Annotation Benchmark"
            },
            {
                "ref": "2023_abdelmageed_tfood",
                "title": "tFood: Semantic Table Annotations Benchmark for Food Domain"
            },
            {
                "ref": "2019_devlin_bert",
                "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"
            },
            {
                "ref": "2014_vrandecic_wikidata",
                "title": "Wikidata: A Free Collaborative Knowledgebase"
            },
            {
                "ref": "2007_auer_dbpedia",
                "title": "DBpedia: A nucleus for a web of open data"
            },
            {
                "ref": "2016_guha_schema.org",
                "title": "Schema.org: Evolution of Structured Data on the Web"
            },
            {
                "ref": "2022_liu_from",
                "title": "From tabular data to knowledge graphs: A survey of semantic table interpretation tasks and methods"
            },
            {
                "ref": "2022_huynh_from",
                "title": "From Heuristics to Language Models: A Journey Through the Universe of Semantic Table Interpretation with DAGOBAH"
            },
            {
                "ref": "2019_nguyen_mtab",
                "title": "Mtab: Matching Tabular Data to Knowledge Graph using Probability Models"
            }
        ],
        "uncertainFields": [
            {
                "field": "doi",
                "reason": "The CEUR-WS workshop paper appears to have no DOI stated; none found in the text."
            },
            {
                "field": "code",
                "reason": "No repository or project page is referenced in the paper text available."
            },
            {
                "field": "output",
                "reason": "The submission/output format is not explicitly described."
            },
            {
                "field": "inputs.typeOfTable",
                "reason": "SemTab datasets are typically CSV, but the paper does not explicitly specify the file format."
            },
            {
                "field": "kg.tripleStore",
                "reason": "While Wikidata is primary, DBpedia/Schema.org are used as label spaces for classification; exact triple store usage beyond Wikidata is not strictly detailed."
            },
            {
                "field": "supportTasks.datatypeAnnotation",
                "reason": "Datatype annotation as a separate sub-task is not clearly specified."
            },
            {
                "field": "userInterfaceTool",
                "reason": "No UI or tool front-end is mentioned."
            },
            {
                "field": "techniqueTags",
                "reason": "Tagged as rule-based and transformer based on heuristic scoring and BERT fine-tuning; ontology-driven use is implicit but not emphasised."
            }
        ]
    },
    {
        "id": "2023_khatiwada_santos",
        "added": "",
        "year": 2023,
        "firstAuthor": "Khatiwada",
        "authors": [
            "Aamod Khatiwada",
            "Grace Fan",
            "Roee Shraga",
            "Zixuan Chen",
            "Wolfgang Gatterbauer",
            "Renée J. Miller",
            "Mirek Riedewald"
        ],
        "title": "SANTOS: Relationship-based Semantic Table Union Search",
        "venue": {
            "type": "journal",
            "acronym": "PACMMOD"
        },
        "nameOfApproach": "SANTOS",
        "techniqueTags": [
            "ontology-driven"
        ],
        "coreTasks": {
            "cta": false,
            "cpa": false,
            "cea": false,
            "cnea": false
        },
        "supportTasks": {
            "dataPreparation": {
                "description": "",
                "spellChecker": "",
                "unitsOfMeasurements": ""
            },
            "columnClassification": "",
            "subjectDetection": "",
            "datatypeAnnotation": "",
            "typeAnnotation": "",
            "predicateAnnotation": "",
            "nilAnnotation": "",
            "entityLinking": {
                "description": "",
                "candidateGeneration": "",
                "entityDisambiguation": ""
            }
        },
        "mainMethod": {
            "type": "unsupervised",
            "technique": "ontology-driven graph matching"
        },
        "revision": {
            "type": "fully automated",
            "description": "Unionability scoring and top-k search are computed automatically using a KB and a synthesized KB; no user-in-the-loop is required."
        },
        "domain": {
            "domain": "independent",
            "type": "generic/open data lakes"
        },
        "validation": {
            "goldStandard": "Adapted TUS benchmark; SANTOS SMALL and LARGE open-data benchmarks",
            "metrics": [
                "MAP@k",
                "P@k",
                "R@k"
            ]
        },
        "code": "https://github.com/northeastern-datalab/santos",
        "license": "BSD 3-Clause \"New\" or \"Revised\" License",
        "inputs": {
            "typeOfTable": "data lake tables (CSV/open data)",
            "tableSources": [
                "gov-open-data"
            ]
        },
        "kg": {
            "tripleStore": "YAGO 4",
            "index": "Inverted node/edge indices and a synthesized relationship dictionary over value pairs"
        },
        "output": "Ranked list of unionable tables",
        "applicationPurpose": "Discovery of unionable tables in data lakes using column and relationship semantics",
        "userInterfaceTool": "",
        "checkedByAuthor": "",
        "checkedByAi": true,
        "doi": "https://doi.org/10.1145/3588689",
        "citations": [
            {
                "ref": "2018_nargesian_table",
                "title": "Table Union Search on Open Data"
            },
            {
                "ref": "2020_bogatu_dataset",
                "title": "Dataset Discovery in Data Lakes"
            },
            {
                "ref": "2020_deng_turl",
                "title": "TURL: Table Understanding through Representation Learning"
            },
            {
                "ref": "2011_venetis_recovering",
                "title": "Recovering Semantics of Tables on the Web"
            },
            {
                "ref": "2020_pellissier_yago",
                "title": "YAGO 4: A Reason-able Knowledge Base"
            },
            {
                "ref": "2012_sarma_finding",
                "title": "Finding Related Tables"
            }
        ],
        "uncertainFields": [
            {
                "field": "venue.acronym",
                "reason": "The paper appears in Proceedings of the ACM on Management of Data; the common acronym is PACMMOD but the paper itself does not explicitly state the acronym."
            },
            {
                "field": "techniqueTags",
                "reason": "SANTOS combines KB-driven semantics with synthesized KBs; it is ontology-driven but could be interpreted as partially rule-based."
            },
            {
                "field": "inputs.typeOfTable",
                "reason": "Tables are from open data lakes (often CSV), but the exact file formats are not exhaustively specified."
            },
            {
                "field": "kg.tripleStore",
                "reason": "YAGO 4 is the knowledge base used; the schema field is named 'tripleStore' though the paper refers to a KB rather than a specific SPARQL endpoint."
            },
            {
                "field": "validation.goldStandard",
                "reason": "Benchmark names are summarised; the exact formal names used by the authors may differ slightly."
            },
            {
                "field": "userInterfaceTool",
                "reason": "No UI is described; it may be a library/CLI only, but the paper does not state this explicitly."
            },
            {
                "field": "output",
                "reason": "The system returns ranked unionable tables; the output format (e.g., API/JSON) is not specified."
            },
            {
                "field": "license",
                "reason": "The repository is public but the paper does not state the code licence."
            }
        ]
    },
    {
        "id": "2023_mehryar_semantic",
        "added": "",
        "year": 2023,
        "firstAuthor": "Mehryar",
        "authors": [
            "Shervin Mehryar",
            "Remzi Celebi"
        ],
        "title": "Semantic Annotation of Tabular Data for Machine-to-Machine Interoperability via Neuro-Symbolic Anchoring",
        "venue": {
            "type": "workshop",
            "acronym": "SemTab"
        },
        "nameOfApproach": "MUT2KG",
        "techniqueTags": [
            "embeddings",
            "ontology-driven",
            "transformer"
        ],
        "coreTasks": {
            "cta": true,
            "cpa": true,
            "cea": true,
            "cnea": false
        },
        "supportTasks": {
            "dataPreparation": {
                "description": "Query source KGs to extract relevant subgraphs and generate ontology/table triples; encode table text with pretrained transformers and build alignment anchors.",
                "spellChecker": "",
                "unitsOfMeasurements": ""
            },
            "columnClassification": "",
            "subjectDetection": "",
            "datatypeAnnotation": "",
            "typeAnnotation": "Map columns to KG classes via neuro-symbolic embedding aligned with ontology concepts.",
            "predicateAnnotation": "Predict KG properties between column pairs using anchored embeddings and queried candidates.",
            "nilAnnotation": "",
            "entityLinking": {
                "description": "Link cells to KG entities using query-based candidate retrieval and alignment with learned embeddings.",
                "candidateGeneration": "Retrieve candidates from KGs (e.g., via rdf:type and lookup over DBpedia/Wikidata/Schema.org) inspired by SemInt/JenTab.",
                "entityDisambiguation": "Majority voting and embedding-based consistency within the anchored vector spaces."
            }
        },
        "mainMethod": {
            "type": "hybrid",
            "technique": "neuro-symbolic (ontology-driven queries + embeddings + transformer encoders)"
        },
        "revision": {
            "type": "fully automated",
            "description": "Outputs are produced automatically without user-in-the-loop validation."
        },
        "domain": {
            "domain": "independent",
            "type": ""
        },
        "validation": {
            "goldStandard": "SemTab 2023 (Schema.org, DBpedia, Wikidata datasets)",
            "metrics": [
                "Precision",
                "F1"
            ]
        },
        "code": "",
        "license": "Not Specified",
        "inputs": {
            "typeOfTable": "Tabular data (SemTab 2023 tables)",
            "tableSources": [
                "wiki"
            ]
        },
        "kg": {
            "tripleStore": "DBpedia; Schema.org; Wikidata",
            "index": ""
        },
        "output": "",
        "applicationPurpose": "Improve machine-to-machine interoperability by semantically annotating tables (columns, properties, qualifiers).",
        "userInterfaceTool": "",
        "checkedByAuthor": "",
        "checkedByAi": true,
        "doi": "",
        "citations": [
            {
                "ref": "2019_rosso_revisiting",
                "title": "Revisiting text and knowledge graph joint embeddings: The amount of shared information matters!"
            },
            {
                "ref": "2022_sharma_semint",
                "title": "SemInt at SemTab 2022"
            },
            {
                "ref": "2020_abdelmageed_jentab",
                "title": "JenTab: Matching tabular data to knowledge graphs."
            },
            {
                "ref": "2020_deng_turl",
                "title": "TURL: Table understanding through representation learning"
            },
            {
                "ref": "2019_hulsebos_sherlock",
                "title": "Sherlock: A deep learning approach to semantic data type detection"
            },
            {
                "ref": "2023_delong_neurosymbolic",
                "title": "Neurosymbolic AI for reasoning on graph structures: A survey"
            },
            {
                "ref": "2020_yin_tabert",
                "title": "TaBERT: Pretraining for joint understanding of textual and tabular data"
            },
            {
                "ref": "2021_hao_universal",
                "title": "Universal representation learning of knowledge bases by jointly embedding instances and ontological concepts"
            },
            {
                "ref": "2013_bordes_translating",
                "title": "Translating embeddings for modeling multi-relational data"
            },
            {
                "ref": "2019_sanh_distilbert",
                "title": "DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter"
            },
            {
                "ref": "2022_mehryar_improving",
                "title": "Improving transitive embeddings in neural reasoning tasks via knowledge-based policy networks"
            },
            {
                "ref": "2021_chu_knowledge-aware",
                "title": "Knowledge-aware multi-center clinical dataset adaptation: Problem, method, and application"
            },
            {
                "ref": "2022_bakker_semantic",
                "title": "Semantic role labelling for Dutch law texts"
            },
            {
                "ref": "2023_louis_finding",
                "title": "Finding the law: Enhancing statutory article retrieval via graph neural networks"
            },
            {
                "ref": "2023_yilmaz_fso",
                "title": "FSO: Food safety monitoring ontology"
            }
        ],
        "uncertainFields": [
            {
                "field": "venue.type",
                "reason": "The paper appears in CEUR-WS for the SemTab'23 event (a challenge-style workshop), which could be labelled as either 'workshop' or 'challenge'."
            },
            {
                "field": "kg.tripleStore",
                "reason": "Multiple KGs are used (DBpedia, Schema.org, Wikidata) but the field accepts a single string; listed all in one string."
            },
            {
                "field": "output",
                "reason": "No explicit output serialisation format (e.g., RDF/CSV) is specified."
            },
            {
                "field": "code",
                "reason": "No repository or download link is mentioned."
            },
            {
                "field": "doi",
                "reason": "CEUR-WS papers often have no DOI; none is stated in the paper."
            },
            {
                "field": "inputs.tableSources",
                "reason": "Tables originate from SemTab 2023 datasets; assumed wiki-based extractions but the source mix is not exhaustively detailed."
            },
            {
                "field": "coreTasks.cea",
                "reason": "CEA is evaluated in the first setting via query-based annotating; the primary contribution focuses on CTA/CPA/CQA."
            }
        ]
    },
    {
        "id": "2023_parmar_dreifluss",
        "added": "",
        "year": 2023,
        "firstAuthor": "Parmar",
        "authors": [
            "Vishvapalsinhji Parmar",
            "Alsayed Algergawy"
        ],
        "title": "DREIFLUSS: A Minimalist Approach for Table Matching",
        "venue": {
            "type": "challenge",
            "acronym": "SemTab"
        },
        "nameOfApproach": "DREIFLUSS",
        "techniqueTags": [
            "ontology-driven"
        ],
        "coreTasks": {
            "cta": true,
            "cpa": true,
            "cea": false,
            "cnea": false
        },
        "supportTasks": {
            "dataPreparation": {
                "description": "Parsed CSV/JSON datasets, concatenated relevant values, exploded lists into rows, and vectorised text with CountVectorizer to create features.",
                "spellChecker": "",
                "unitsOfMeasurements": ""
            },
            "columnClassification": "",
            "subjectDetection": "",
            "datatypeAnnotation": "",
            "typeAnnotation": "Predicted KG classes for columns (CTA) using logistic regression over tokenised data values.",
            "predicateAnnotation": "Predicted relations between main and other columns (CPA) using logistic regression on value pairs.",
            "nilAnnotation": "",
            "entityLinking": {
                "description": "",
                "candidateGeneration": "",
                "entityDisambiguation": ""
            }
        },
        "mainMethod": {
            "type": "supervised",
            "technique": "logistic regression",
            "supervision": {
                "type": "supervised"
            }
        },
        "revision": {
            "type": "fully automated",
            "description": "End-to-end predictions are produced automatically for CTA/CPA with no manual post-editing. "
        },
        "domain": {
            "domain": "independent",
            "type": ""
        },
        "validation": {
            "goldStandard": "SemTab 2023 Round 2 CTA/CPA datasets (DBpedia/Schema.org); metrics reported on internal split and SemTab test set (Table 6). ",
            "metrics": [
                "Precision",
                "Recall",
                "F1"
            ]
        },
        "code": "https://github.com/vishvapalsinh/cta-cpa-schemaorg-dbpedia",
        "license": "MIT License",
        "inputs": {
            "typeOfTable": "Web tables",
            "tableSources": [
                "web"
            ]
        },
        "kg": {
            "tripleStore": "DBpedia; Schema.org",
            "index": ""
        },
        "output": "",
        "applicationPurpose": "Table matching (CTA/CPA) for data integration and knowledge discovery. ",
        "userInterfaceTool": "",
        "checkedByAuthor": "",
        "checkedByAi": true,
        "doi": "",
        "citations": [
            {
                "ref": "2023_shigarov_table",
                "title": "Table understanding: Problem overview"
            },
            {
                "ref": "2009_bizer_dbpedia",
                "title": "Dbpedia - A crystallization point for the web of data"
            },
            {
                "ref": "2015_guha_schemaorg",
                "title": "Schema.org: Evolution of structured data on the web"
            },
            {
                "ref": "2019_oliveira_adog",
                "title": "ADOG - annotating data with ontologies and graphs"
            },
            {
                "ref": "2019_cremaschi_mantistable",
                "title": "Mantistable: an automatic approach for the semantic table interpretation"
            },
            {
                "ref": "2019_thawani_entity",
                "title": "Entity linking to knowledge graphs to infer column types and properties"
            },
            {
                "ref": "2020_huynh_dagobah",
                "title": "DAGOBAH: enhanced scoring algorithms for scalable annotations of tabular data"
            },
            {
                "ref": "2020_abdelmageed_jentab",
                "title": "Jentab: Matching tabular data to knowledge graphs"
            },
            {
                "ref": "2021_huynh_dagobah",
                "title": "DAGOBAH: table and graph contexts for efficient semantic annotation of tabular data"
            },
            {
                "ref": "2021_avogadro_mantistable",
                "title": "Mantistable V: A novel and efficient approach to semantic table interpretation"
            },
            {
                "ref": "2022_korini_sotab",
                "title": "SOTAB: the WDC schema.org table annotation benchmark"
            },
            {
                "ref": "2022_marzocchi_mammotab",
                "title": "Mammotab: A giant and comprehensive dataset for semantic table interpretation"
            },
            {
                "ref": "2022_cremaschi_selbat",
                "title": "s-elbat: A semantic interpretation approach for messy table-s"
            }
        ],
        "uncertainFields": [
            {
                "field": "venue.type",
                "reason": "The paper appears in CEUR-WS proceedings of the SemTab’23 event, which is both a challenge and a workshop; we chose \"challenge\"."
            },
            {
                "field": "inputs.typeOfTable",
                "reason": "Datasets are provided as JSON/CSV derived from web tables; \"Web tables\" captures the source but format specifics are not explicitly standardised."
            },
            {
                "field": "kg.tripleStore",
                "reason": "Both DBpedia and Schema.org are used; the single-string field lists both separated by a semicolon."
            },
            {
                "field": "output",
                "reason": "No explicit output serialisation format (e.g., RDF/CSV) for predictions is stated."
            },
            {
                "field": "doi",
                "reason": "CEUR-WS papers often lack DOIs and none is given in the paper."
            },
            {
                "field": "license",
                "reason": "The approach/code license is not specified in the paper text."
            }
        ]
    },
    {
        "id": "2023_sun_reca",
        "added": "",
        "year": 2023,
        "firstAuthor": "Sun",
        "authors": [
            "Yushi Sun",
            "Hao Xin",
            "Lei Chen"
        ],
        "title": "RECA: Related Tables Enhanced Column Semantic Type Annotation Framework",
        "venue": {
            "type": "journal",
            "acronym": "PVLDB"
        },
        "nameOfApproach": "RECA",
        "techniqueTags": [
            "transformer"
        ],
        "coreTasks": {
            "cta": true,
            "cpa": false,
            "cea": false,
            "cnea": false
        },
        "supportTasks": {
            "dataPreparation": {
                "description": "Named-entity tagging and construction of a named-entity schema; filtering and aligning related/sub-related tables to create inter-table context.",
                "spellChecker": "",
                "unitsOfMeasurements": ""
            },
            "columnClassification": "",
            "subjectDetection": "",
            "datatypeAnnotation": "",
            "typeAnnotation": "Predicts semantic types for target columns using BERT-based encoding enriched with inter-table context.",
            "predicateAnnotation": "",
            "nilAnnotation": "",
            "entityLinking": {
                "description": "",
                "candidateGeneration": "",
                "entityDisambiguation": ""
            }
        },
        "mainMethod": {
            "type": "supervised",
            "technique": "transformer",
            "supervision": {
                "type": "supervised"
            }
        },
        "revision": {
            "type": "fully automated",
            "description": "Fully automated learning-based annotation; no manual post-editing is reported."
        },
        "domain": {
            "domain": "independent",
            "type": "web tables"
        },
        "validation": {
            "goldStandard": "SemTab2019 and WebTables datasets",
            "metrics": [
                "Weighted-F1",
                "Macro-F1"
            ]
        },
        "code": "https://github.com/ysunbp/RECA-paper",
        "license": "MIT License",
        "inputs": {
            "typeOfTable": "Web tables",
            "tableSources": [
                "web"
            ]
        },
        "output": "",
        "applicationPurpose": "Improve column semantic type annotation for schema matching, data cleaning, and data integration.",
        "userInterfaceTool": "",
        "checkedByAuthor": "",
        "checkedByAi": true,
        "doi": "https://doi.org/10.14778/3583140.3583149",
        "citations": [
            {
                "ref": "2015_backurs_edit",
                "title": "Edit distance cannot be computed in strongly subquadratic time (unless SETH is false)"
            },
            {
                "ref": "2020_deng_turl",
                "title": "TURL: table understanding through representation learning"
            },
            {
                "ref": "2020_cutrona_tough",
                "title": "Tough tables: Carefully evaluating entity linking for tabular data"
            },
            {
                "ref": "2022_cutrona_results",
                "title": "Results of SemTab 2021"
            },
            {
                "ref": "",
                "title": ""
            }
        ],
        "uncertainFields": [
            {
                "field": "license",
                "reason": "The repository’s software licence is not stated in the paper; code licence may exist in the repo but is not specified in the text."
            },
            {
                "field": "output",
                "reason": "The paper does not state an exported output format (e.g., RDF, CSV); it reports predictions of column semantic types."
            },
            {
                "field": "validation.goldStandard",
                "reason": "Dataset naming conventions vary (e.g., 'SemTab2019' vs 'Semtab2019'); both datasets are referenced but formal GS names are not standardised in the text."
            },
            {
                "field": "inputs.typeOfTable",
                "reason": "Tables are web-extracted; the exact file format (HTML, CSV) is not explicitly constrained."
            },
            {
                "field": "userInterfaceTool",
                "reason": "No UI or tool front-end is described; left empty pending confirmation."
            }
        ]
    },
    {
        "id": "2024_feuer_archetype",
        "added": "",
        "year": 2024,
        "firstAuthor": "Feuer",
        "authors": [
            "Benjamin Feuer",
            "Yurong Liu",
            "Chinmay Hegde",
            "Juliana Freire"
        ],
        "title": "ArcheType: A Novel Framework for Open-Source Column Type Annotation using Large Language Models",
        "venue": {
            "type": "journal",
            "acronym": "PVLDB"
        },
        "nameOfApproach": "ArcheType",
        "techniqueTags": [
            "transformer",
            "rule-based",
            "embeddings"
        ],
        "coreTasks": {
            "cta": true,
            "cpa": false,
            "cea": false,
            "cnea": false
        },
        "supportTasks": {
            "dataPreparation": {
                "description": "Context sampling and prompt serialisation to form model inputs; label remapping for normalising LLM outputs.",
                "spellChecker": "",
                "unitsOfMeasurements": ""
            },
            "columnClassification": "",
            "subjectDetection": "",
            "datatypeAnnotation": "",
            "typeAnnotation": "Maps columns to semantic types (e.g., schema.org classes) via zero-shot or fine-tuned LLM classification with label remapping.",
            "predicateAnnotation": "",
            "nilAnnotation": "",
            "entityLinking": {
                "description": "",
                "candidateGeneration": "",
                "entityDisambiguation": ""
            }
        },
        "mainMethod": {
            "type": "hybrid",
            "technique": "Transformer-based LLMs with rule-based and embedding-based label remapping"
        },
        "revision": {
            "type": "fully automated",
            "description": "Outputs are post-processed automatically via label remapping (e.g., CONTAINS+RESAMPLE and simple rules); no user-in-the-loop editing."
        },
        "domain": {
            "domain": "independent",
            "type": "generic"
        },
        "validation": {
            "goldStandard": "SOTAB-91; SOTAB-27; T2D; Efthymiou 2017; VizNet-CHORUS; D4Tables; AmstrTables; PubchemTables",
            "metrics": [
                "Micro-F1",
                "Weighted-F1",
                "Accuracy"
            ]
        },
        "code": "https://github.com/penfever/ArcheType",
        "license": "MIT License",
        "inputs": {
            "typeOfTable": "Relational tables",
            "tableSources": [
                "web",
                "gov-open-data",
                "scientific"
            ]
        },
        "kg": {
            "tripleStore": "Schema.org",
            "index": ""
        },
        "output": "",
        "applicationPurpose": "Open-set column type annotation for data cleaning, schema matching, and data discovery.",
        "userInterfaceTool": "",
        "usesLLM": {
            "modelName": "LLaMA-7B; T5; UL2; GPT-3.5; GPT-4",
            "prompting": "zero-shot"
        },
        "checkedByAuthor": "",
        "checkedByAi": true,
        "doi": "https://doi.org/10.14778/3665844.3665857",
        "citations": [
            {
                "ref": "2022_suhara_annotating",
                "title": "Annotating Columns with Pre-Trained Language Models"
            },
            {
                "ref": "2022_deng_turl",
                "title": "TURL: Table Understanding through Representation Learning"
            },
            {
                "ref": "2019_hulsebos_sherlock",
                "title": "Sherlock: A Deep Learning Approach to Semantic Data Type Detection"
            },
            {
                "ref": "2023_kayali_chorus",
                "title": "CHORUS: foundation models for unified data discovery and exploration"
            },
            {
                "ref": "2023_korini_column",
                "title": "Column type annotation using ChatGPT"
            },
            {
                "ref": "2022_korini_sotab",
                "title": "SOTAB: The WDC Schema.org Table Annotation Benchmark"
            },
            {
                "ref": "2019_chen_learning",
                "title": "Learning Semantic Annotations for Tabular Data"
            },
            {
                "ref": "2017_efthymiou_matching",
                "title": "Matching web tables with knowledge base entities: from entity lookups to entity embeddings"
            },
            {
                "ref": "2015_fu_pubchemrdf",
                "title": "PubChemRDF: towards the semantic annotation of PubChem compound and substance databases"
            },
            {
                "ref": "2024_dell_american",
                "title": "American stories: A large-scale structured text dataset of historical US newspapers"
            },
            {
                "ref": "2023_touvron_llama",
                "title": "LLaMA: Open and efficient foundation language models"
            },
            {
                "ref": "2023_tay_ul2",
                "title": "UL2: Unifying Language Learning Paradigms"
            }
        ],
        "uncertainFields": [
            {
                "field": "kg.tripleStore",
                "reason": "CTA labels mostly use schema.org (SOTAB) but other datasets mention DBpedia/PubChem; the primary KG may vary per benchmark."
            },
            {
                "field": "output",
                "reason": "The paper does not specify an output serialisation format for predictions (e.g., RDF/CSV/JSON-LD)."
            },
            {
                "field": "inputs.tableSources",
                "reason": "Sources span multiple datasets (web, NYC Open Data, PubChem, newspapers); exact enumeration per benchmark is not fully detailed."
            },
            {
                "field": "license",
                "reason": "The PDF states a CC BY-NC-ND 4.0 paper licence; the software repository’s code licence is not specified in the paper."
            },
            {
                "field": "usesLLM.modelName",
                "reason": "Multiple models are used (LLAMA-7B, T5, UL2, GPT-3.5/4); a single canonical model for the approach is not designated."
            },
            {
                "field": "userInterfaceTool",
                "reason": "No explicit UI/CLI is described; only a framework and code repository are mentioned."
            },
            {
                "field": "validation.goldStandard",
                "reason": "The paper evaluates on several benchmarks; the exact set per experiment varies across sections."
            }
        ]
    },
    {
        "id": "2020_khurana_semantic",
        "added": "",
        "year": 2020,
        "firstAuthor": "Khurana",
        "authors": [
            "Udayan Khurana",
            "Sainyam Galhotra"
        ],
        "title": "Semantic Annotation for Tabular Data",
        "venue": {
            "type": "journal",
            "acronym": "arXiv"
        },
        "nameOfApproach": "C2",
        "techniqueTags": [
            "embeddings",
            "ontology-driven"
        ],
        "coreTasks": {
            "cta": true,
            "cpa": false,
            "cea": false,
            "cnea": false
        },
        "supportTasks": {
            "dataPreparation": {
                "description": "Build inverted entity–concept counts, numeric interval trees, and regex-based pattern trees; apply smoothing and belief sharing. ",
                "spellChecker": "",
                "unitsOfMeasurements": ""
            },
            "columnClassification": "Categorises columns as categorical, numerical, or mixed-type to select appropriate estimators. ",
            "subjectDetection": "",
            "datatypeAnnotation": "",
            "typeAnnotation": "Maps each column to a KG concept via piecewise maximum-likelihood estimation across multiple sources. ",
            "predicateAnnotation": "",
            "nilAnnotation": "",
            "entityLinking": {
                "description": "",
                "candidateGeneration": "",
                "entityDisambiguation": ""
            }
        },
        "mainMethod": {
            "type": "unsupervised",
            "technique": "Maximum likelihood estimation with ensembles across heterogeneous sources. "
        },
        "revision": {
            "type": "fully automated",
            "description": "Fully automatic estimation and ranking with programmatic tuple validation and belief sharing; no user-in-the-loop. "
        },
        "domain": {
            "domain": "independent",
            "type": "general"
        },
        "validation": {
            "goldStandard": "Limaye, Semantification, SemTab (Rounds 1–4), T2Dv2, ISWC 2017, and a Manyeyes subset. ",
            "metrics": [
                "Accuracy",
                "Top-1 Accuracy",
                "Top-k Accuracy"
            ]
        },
        "code": "",
        "license": "Not Specified",
        "inputs": {
            "typeOfTable": "Web tables and CSV",
            "tableSources": [
                "web",
                "wiki"
            ]
        },
        "kg": {
            "tripleStore": "DBpedia and Wikidata",
            "index": "Inverted entity–concept count index; numerical interval tree; composite pattern (regex) tree; column co-occurrence & tuple-validation index. "
        },
        "output": "",
        "applicationPurpose": "Column type annotation for data integration, cleaning, search, and feature engineering/model building. ",
        "userInterfaceTool": "",
        "checkedByAuthor": "",
        "checkedByAi": true,
        "doi": "",
        "citations": [
            {
                "ref": "2019_chen_colnet",
                "title": "Colnet: Embedding the semantics of web tables for column type prediction"
            },
            {
                "ref": "2019_chen_learning",
                "title": "Learning Semantic Annotations for Tabular Data"
            },
            {
                "ref": "2019_hulsebos_sherlock",
                "title": "Sherlock: A Deep Learning Approach to Semantic Data Type Detection"
            },
            {
                "ref": "2019_zhang_sato",
                "title": "Sato: Contextual Semantic Type Detection in Tables"
            },
            {
                "ref": "2010_limaye_annotating",
                "title": "Annotating and searching web tables using entities, types and relationships"
            },
            {
                "ref": "2017_efthymiou_matching",
                "title": "Matching web tables with knowledge base entities: from entity lookups to entity embeddings"
            },
            {
                "ref": "2020_jimenez-ruiz_semtab",
                "title": "SemTab 2019: Resources to Benchmark Tabular Data to Knowledge Graph Matching Systems"
            },
            {
                "ref": "2016_lehmberg_a",
                "title": "A large public corpus of web tables containing time and context metadata"
            },
            {
                "ref": "2013_deng_scalable",
                "title": "Scalable column concept determination for web tables using large knowledge bases"
            },
            {
                "ref": "2011_venetis_recovering",
                "title": "Recovering semantics of tables on the web"
            },
            {
                "ref": "2016_neumaier_multi-level",
                "title": "Multi-level semantic labelling of numerical values"
            },
            {
                "ref": "2019_galhotra_automated",
                "title": "Automated Feature Enhancement for Predictive Modeling using External Knowledge"
            },
            {
                "ref": "2019_hu_viznet",
                "title": "VizNet: Towards a large-scale visualization learning and benchmarking repository"
            },
            {
                "ref": "2020_zhang_finding",
                "title": "Finding Related Tables in Data Lakes for Interactive Data Science"
            },
            {
                "ref": "2018_kacprzak_making",
                "title": "Making sense of numerical data-semantic labelling of web tables"
            }
        ],
        "uncertainFields": [
            {
                "field": "venue.type",
                "reason": "The paper appears as an arXiv preprint; mapped to 'journal' for schema compliance. "
            },
            {
                "field": "kg.tripleStore",
                "reason": "Both DBpedia and Wikidata are used; the field accepts a single string, so both are combined. "
            },
            {
                "field": "inputs.tableSources",
                "reason": "Approach targets generic structured data; web and Wikipedia tables are certain, other sources are possible. "
            },
            {
                "field": "output",
                "reason": "No explicit serialisation/format of outputs is stated in the paper. "
            },
            {
                "field": "code",
                "reason": "No repository or download link is provided in the text. "
            },
            {
                "field": "userInterfaceTool",
                "reason": "No UI or tool front-end is mentioned. "
            },
            {
                "field": "doi",
                "reason": "A DOI is not indicated for this arXiv version. "
            },
            {
                "field": "techniqueTags",
                "reason": "Embeddings (Word2Vec) and KG use are explicit; other tags like rule-based are avoided though regex patterns are used. "
            }
        ]
    },
    {
        "id": "2021_avogadro_mantistable",
        "added": "",
        "year": 2021,
        "firstAuthor": "Avogadro",
        "authors": [
            "Roberto Avogadro",
            "Marco Cremaschi"
        ],
        "title": "MantisTable V: a novel and efficient approach to Semantic Table Interpretation",
        "venue": {
            "type": "workshop",
            "acronym": ""
        },
        "nameOfApproach": "MantisTable V",
        "techniqueTags": [
            "rule-based",
            "ontology-driven"
        ],
        "coreTasks": {
            "cta": true,
            "cpa": true,
            "cea": true,
            "cnea": false
        },
        "supportTasks": {
            "dataPreparation": {
                "description": "Tokenisation and normalisation of table cells; candidates fetched once per unique cell via LamAPI lookup to reduce repeated queries. ",
                "spellChecker": "",
                "unitsOfMeasurements": ""
            },
            "columnClassification": "RegexTypes used to detect literal columns and distinguish NE-columns vs L-columns. ",
            "subjectDetection": "Identifies S-column among NE-columns (main column all others refer to). ",
            "datatypeAnnotation": "Assigns datatypes from the KG to L-columns. ",
            "typeAnnotation": "Associates NE-columns with KG concepts (CTA output). ",
            "predicateAnnotation": "Finds relations (predicates) between S-column and other columns (CPA output). ",
            "nilAnnotation": "",
            "entityLinking": {
                "description": "Generates and ranks entity candidates for cells; final re-ranking (revision) enforces coherence across columns and predicates. ",
                "candidateGeneration": "LamAPI Lookup service over indexed DBpedia/Wikidata dumps (full-text and by ID). ",
                "entityDisambiguation": "Automated revision stage reorders candidates to ensure global table-level consistency. "
            }
        },
        "mainMethod": {
            "type": "unsupervised",
            "technique": "rule-based"
        },
        "revision": {
            "type": "semi automated",
            "description": "Automated revision re-ranks candidates for global consistency; optional user edits and exports supported via tUI Web UI. "
        },
        "domain": {
            "domain": "independent",
            "type": "generic"
        },
        "validation": {
            "goldStandard": "Evaluated on T2Dv2 WebTables GS and SemTab (2020 Round 3 '2T'; 2021 Hard Table Rounds 2–3), with reported F1 and Precision; best CTA on SemTab2021 GitTable. ",
            "metrics": [
                "Precision",
                "F1"
            ]
        },
        "code": "https://bitbucket.org/disco_unimib/mantistable-v/",
        "license": "Apache License 2.0",
        "inputs": {
            "typeOfTable": "Web tables",
            "tableSources": [
                "web"
            ]
        },
        "kg": {
            "tripleStore": "DBpedia; Wikidata",
            "index": "LamAPI indexes over DBpedia/Wikidata using Elasticsearch and MongoDB. "
        },
        "output": "CSV; JSON-LD; RDF/XML; RDF/N-Triples; R2RML. ",
        "applicationPurpose": "Complete STI pipeline (CTA, CPA, CEA) with efficient KG querying via LamAPI and a Web UI to manage and review annotations.",
        "userInterfaceTool": "tUI (Web UI). ",
        "checkedByAuthor": "",
        "checkedByAi": true,
        "doi": "",
        "citations": [
            {
                "ref": "2020_cremaschi_mantistable",
                "title": "Mantistable se: an efficient approach for the semantic table interpretation"
            },
            {
                "ref": "2020_cremaschi_a",
                "title": "A fully automated approach to a complete semantic table interpretation"
            },
            {
                "ref": "2020_cutrona_tough",
                "title": "Tough tables: Carefully evaluating entity linking for tabular data"
            },
            {
                "ref": "2020_ilievski_kgtk",
                "title": "KGTK: A toolkit for large knowledge graph manipulation and analysis"
            },
            {
                "ref": "2020_jimenez-ruiz_results",
                "title": "Results of SemTab 2020"
            },
            {
                "ref": "2017_zhang_effective",
                "title": "Effective and efficient semantic table interpretation using TableMiner+"
            }
        ],
        "uncertainFields": [
            {
                "field": "venue.type",
                "reason": "The PDF does not explicitly state the publication venue; 'workshop' is inferred from the format and copyright note. "
            },
            {
                "field": "venue.acronym",
                "reason": "No venue acronym appears in the paper text provided."
            },
            {
                "field": "doi",
                "reason": "No DOI is indicated in the PDF; CEUR-style papers often lack DOIs."
            },
            {
                "field": "license",
                "reason": "Paper license is CC BY 4.0, but code licence is not specified; field set to 'Not Specified'. "
            },
            {
                "field": "inputs.typeOfTable",
                "reason": "The approach targets generic relational tables; 'Web tables' is chosen due to T2Dv2 but file format is not strictly specified. "
            },
            {
                "field": "kg.tripleStore",
                "reason": "DBpedia and Wikidata are used as KGs; the term 'tripleStore' here summarises the KG choices rather than a specific hosting endpoint. "
            }
        ]
    },
    {
        "id": "2020_cremaschi_mantistable",
        "added": "",
        "year": 2020,
        "firstAuthor": "Cremaschi",
        "authors": [
            "Marco Cremaschi",
            "Roberto Avogadro",
            "Andrea Barazzetti",
            "David Chieregato"
        ],
        "title": "MantisTable SE: an Efficient Approach for the Semantic Table Interpretation",
        "venue": {
            "type": "workshop",
            "acronym": "SemTab"
        },
        "nameOfApproach": "MantisTable SE",
        "techniqueTags": [
            "rule-based",
            "ontology-driven"
        ],
        "coreTasks": {
            "cta": true,
            "cpa": true,
            "cea": true,
            "cnea": false
        },
        "supportTasks": {
            "dataPreparation": {
                "description": "Tokenisation and normalisation of cells; removal of parentheses and their contents; handling of special characters.",
                "spellChecker": "",
                "unitsOfMeasurements": ""
            },
            "columnClassification": "Regex-based detection of literal datatypes (e.g., BOOLEAN, DATE, EMAIL, GEOCORDS, INTEGER, REAL, ISBN, URL) to mark LIT vs NE columns.",
            "subjectDetection": "Content-based scoring to identify the subject column among NE-columns; often bypassed since SemTab targets were provided.",
            "datatypeAnnotation": "Similarity for numeric/string/date literals against KG values using Gaussian, Levenshtein, and Jaccard-based measures.",
            "typeAnnotation": "Column concepts selected via frequency of candidate concepts and graph connectivity; prefers the most specific concept.",
            "predicateAnnotation": "Predicates ranked by relative frequency across candidate entity pairs for a column pair; used to re-rank entities.",
            "nilAnnotation": "",
            "entityLinking": {
                "description": "Label-based candidate generation and scoring (edit distance/Jaccard) with table-wide coherence re-ranking.",
                "candidateGeneration": "LamAPI label matching over ElasticSearch indices for DBpedia/Wikidata.",
                "entityDisambiguation": "Levenshtein/Jaccard scoring with CPA/CTA-informed re-ranking and a final automated revision phase."
            }
        },
        "mainMethod": {
            "type": "unsupervised",
            "technique": "ontology-driven"
        },
        "revision": {
            "type": "fully automated",
            "description": "Final reordering ensures coherence between selected entities, predicates, and concepts across columns; no user edits required."
        },
        "domain": {
            "domain": "independent",
            "type": "generic"
        },
        "validation": {
            "goldStandard": "SemTab 2020 (Rounds 1–3)",
            "metrics": [
                "Precision",
                "F1"
            ]
        },
        "code": "https://bitbucket.org/disco_unimib/mantistable-4",
        "license": "Apache License 2.0",
        "inputs": {
            "typeOfTable": "well-formed relational tables",
            "tableSources": []
        },
        "kg": {
            "tripleStore": "DBpedia; Wikidata",
            "index": "LamAPI (ElasticSearch + Redis) indices for labels, predicates, objects, and concepts"
        },
        "output": "",
        "applicationPurpose": "Efficient STI pipeline and tooling (LamAPI) to annotate tables and support SemTab evaluation.",
        "userInterfaceTool": "Web UI (Django) with Docker/Celery and MongoDB backend",
        "checkedByAuthor": "",
        "checkedByAi": true,
        "doi": "",
        "citations": [
            {
                "ref": "2008_cafarella_webtables",
                "title": "Webtables: Exploring the power of tables on the web"
            },
            {
                "ref": "2020_cremaschi_a",
                "title": "A fully automated approach to a complete semantic table interpretation"
            },
            {
                "ref": "2019_fetahu_tablenet",
                "title": "Tablenet: An approach for determining fine-grained relations for Wikipedia tables"
            },
            {
                "ref": "2020_jimenez-ruiz_semtab",
                "title": "Semtab 2019: Resources to benchmark tabular data to knowledge graph matching systems"
            },
            {
                "ref": "2016_lehmberg_a",
                "title": "A large public corpus of web tables containing time and context metadata"
            },
            {
                "ref": "2017_zhang_effective",
                "title": "Effective and efficient semantic table interpretation using TableMiner+"
            }
        ],
        "uncertainFields": [
            {
                "field": "venue.type",
                "reason": "The PDF looks like CEUR-WS working notes; treated as workshop but the exact venue type is not explicitly stated."
            },
            {
                "field": "venue.acronym",
                "reason": "Set to \"SemTab\" based on challenge context; the acronym is not explicitly printed as venue in the text."
            },
            {
                "field": "doi",
                "reason": "No DOI is shown for this paper in the PDF."
            },
            {
                "field": "output",
                "reason": "Export phase is described but no serialisation format (e.g., CSV, RDF) is specified."
            },
            {
                "field": "inputs.tableSources",
                "reason": "Table sources (web/wiki/spreadsheet, etc.) are not explicitly listed."
            },
            {
                "field": "license",
                "reason": "The paper mentions open-source code but does not state the software licence."
            }
        ]
    },
    {
        "id": "2022_cremaschi_s-elbat",
        "added": "",
        "year": 2022,
        "firstAuthor": "Cremaschi",
        "authors": [
            "Marco Cremaschi",
            "Roberto Avogadro",
            "David Chieregato"
        ],
        "title": "s-elBat: a Semantic Interpretation Approach for Messy taBle-s",
        "venue": {
            "type": "workshop",
            "acronym": "SemTab"
        },
        "nameOfApproach": "s-elBat",
        "techniqueTags": [
            "rule-based",
            "ontology-driven"
        ],
        "coreTasks": {
            "cta": true,
            "cpa": true,
            "cea": true,
            "cnea": false
        },
        "supportTasks": {
            "dataPreparation": {
                "description": "Lowercasing; column classification into NE/LIT; optional subject column detection; mention extraction.",
                "spellChecker": "",
                "unitsOfMeasurements": ""
            },
            "columnClassification": "Classifies columns as NE-columns or LIT-columns prior to EL/typing.",
            "subjectDetection": "Identifies a potential subject (S-) column to speed up annotation.",
            "datatypeAnnotation": "Compares literal/date/number values for relation checks during CEA/CPA.",
            "typeAnnotation": "Selects column types by aggregating most frequent types of winning entities.",
            "predicateAnnotation": "Aggregates candidate predicates by frequency to label column pairs.",
            "nilAnnotation": "",
            "entityLinking": {
                "description": "IR-based ER via LamAPI (lookup with fuzzy/3-grams/type filters) followed by feature-based ED.",
                "candidateGeneration": "LamAPI Lookup over DBpedia/Wikidata with ElasticSearch, fuzzy matching and n-grams; type-based filtering.",
                "entityDisambiguation": "Ranks candidates using a weighted feature vector (string similarity, Jaccard, object/relation/literal signals) and, in revision, CTA/CPA-aware features."
            }
        },
        "mainMethod": {
            "type": "unsupervised",
            "technique": "rule-based"
        },
        "revision": {
            "type": "fully automated",
            "description": "Re-runs low-confidence mentions with constraints on types/predicates; thresholding (e.g., 0.4) minimises inner error while improving precision."
        },
        "domain": {
            "domain": "independent",
            "type": "general-purpose"
        },
        "validation": {
            "goldStandard": "HardTable 2022 (R1, R2) and 2T 2022",
            "metrics": [
                "Precision",
                "F1"
            ]
        },
        "code": "https://bitbucket.org/disco_unimib/s-elbat/",
        "license": "Apache-2.0",
        "inputs": {
            "typeOfTable": "Relational tables with headers",
            "tableSources": []
        },
        "kg": {
            "tripleStore": "DBpedia, Wikidata",
            "index": "ElasticSearch (IB similarity) via LamAPI"
        },
        "output": "JSON",
        "applicationPurpose": "Data enrichment and KG construction from tabular data",
        "userInterfaceTool": "",
        "checkedByAuthor": "",
        "checkedByAi": true,
        "doi": "",
        "citations": [
            {
                "ref": "2020_cremaschi_fully",
                "title": "A fully automated approach to a complete semantic table interpretation"
            },
            {
                "ref": "2020_jimenezruiz_results",
                "title": "Results of SemTab 2020"
            },
            {
                "ref": "2022_cutrona_results",
                "title": "Results of SemTab 2021"
            },
            {
                "ref": "2020_cutrona_tough",
                "title": "Tough Tables: Carefully evaluating entity linking for tabular data"
            },
            {
                "ref": "2021_avogadro_mantistable",
                "title": "MantisTable V: A novel and efficient approach to semantic table interpretation."
            },
            {
                "ref": "2020_cremaschi_mantistable",
                "title": "MantisTable SE: an efficient approach for the semantic table interpretation."
            },
            {
                "ref": "2015_shen_entity",
                "title": "Entity linking with a knowledge base: Issues, techniques, and solutions"
            },
            {
                "ref": "2013_hachey_evaluating",
                "title": "Evaluating entity linking with Wikipedia"
            },
            {
                "ref": "2022_avogadro_lamapi",
                "title": "LamAPI: a comprehensive tool for string-based entity retrieval with type-based filters"
            },
            {
                "ref": "2022_marzocchi_mammotab",
                "title": "MammoTab: a giant and comprehensive dataset for semantic table interpretation"
            }
        ],
        "uncertainFields": [
            {
                "field": "year",
                "reason": "PDF header indicates 2022, but the file name suggests 2015; adopted the in-paper year."
            },
            {
                "field": "title",
                "reason": "The paper stylises 'taBle-s' across line breaks; normalised minimally but exact capitalisation may vary."
            },
            {
                "field": "venue.acronym",
                "reason": "Paper appears in CEUR-WS for the SemTab 2022 workshop/challenge; acronym could also be expressed as 'SemTab2022'."
            },
            {
                "field": "coreTasks.cnea",
                "reason": "NIL mentions are discussed and low-confidence handled as 'No-annotation', but explicit CNEA labelling is not clearly claimed."
            },
            {
                "field": "inputs.tableSources",
                "reason": "Datasets are named (2T, HardTable) but the original table source types are not explicitly specified."
            },
            {
                "field": "output",
                "reason": "A JSON API format is shown; other exports (e.g., CSV/RDF) are not explicitly confirmed for this tool."
            },
            {
                "field": "userInterfaceTool",
                "reason": "LamAPI is described as a service; a specific UI/CLI is not detailed."
            }
        ]
    },
    {
        "id": "2024_zhang_tablellama",
        "added": "",
        "year": 2024,
        "firstAuthor": "Zhang",
        "authors": [
            "Tianshu Zhang",
            "Xiang Yue",
            "Yifei Li",
            "Huan Sun"
        ],
        "title": "TableLlama: Towards Open Large Generalist Models for Tables",
        "venue": {
            "type": "journal",
            "acronym": "arXiv"
        },
        "nameOfApproach": "TableLlama",
        "techniqueTags": [
            "transformer"
        ],
        "coreTasks": {
            "cta": true,
            "cpa": true,
            "cea": true,
            "cnea": false
        },
        "supportTasks": {
            "dataPreparation": {
                "description": "Constructs the TableInstruct dataset by unifying task formats, serialising tables with metadata, and writing task-specific instructions; fine-tunes a long-context LLM (LongLoRA) on these instances.",
                "spellChecker": "",
                "unitsOfMeasurements": ""
            },
            "columnClassification": "",
            "subjectDetection": "",
            "datatypeAnnotation": "",
            "typeAnnotation": "Annotates column semantic types using instruction-tuned prompts and candidate sets.",
            "predicateAnnotation": "Predicts relations between column pairs framed as relation-extraction over Freebase-type candidates.",
            "nilAnnotation": "",
            "entityLinking": {
                "description": "Links table cell mentions to Wikidata entities using instruction-tuned generation over provided candidates.",
                "candidateGeneration": "Supplies large candidate pools with names, descriptions and types from Wikidata.",
                "entityDisambiguation": "Selects the most appropriate entity by reasoning over descriptions and table context."
            }
        },
        "mainMethod": {
            "type": "supervised",
            "technique": "transformer",
            "supervision": {
                "type": "supervised"
            }
        },
        "revision": {
            "type": "fully automated",
            "description": "Model outputs are produced end-to-end by an instruction-tuned LLM without post-editing."
        },
        "domain": {
            "domain": "independent",
            "type": "general"
        },
        "validation": {
            "goldStandard": "Evaluation across multiple datasets (e.g., TURL, HiTab, FeTaQA, TabFact, FEVEROUS, HybridQA, ToTTo, WikiSQL, WikiTQ).",
            "metrics": [
                "Micro-F1",
                "Accuracy",
                "MAP"
            ]
        },
        "code": "https://osu-nlp-group.github.io/TableLlama/",
        "license": "Not Specified",
        "inputs": {
            "typeOfTable": "Web tables and spreadsheets",
            "tableSources": [
                "wiki",
                "scientific"
            ]
        },
        "kg": {
            "tripleStore": "Wikidata",
            "index": "Freebase types used for column/relation labels; entity candidates and metadata indexed from Wikidata."
        },
        "output": "text",
        "applicationPurpose": "Generalist table understanding across interpretation, augmentation, QA and fact verification.",
        "userInterfaceTool": "",
        "usesLLM": {
            "modelName": "Llama 2 7B (LongLoRA)"
        },
        "checkedByAuthor": "",
        "checkedByAi": true,
        "doi": "https://doi.org/10.48550/arXiv.2311.09206",
        "citations": [
            {
                "ref": "2020_deng_turl",
                "title": "TURL: Table understanding through representation learning"
            },
            {
                "ref": "2021_wang_tuta",
                "title": "TUTA: Tree-based Transformers for generally structured table pretraining"
            },
            {
                "ref": "2020_yin_tabert",
                "title": "TaBERT: Pretraining for joint understanding of textual and tabular data"
            },
            {
                "ref": "2022_cheng_hitab",
                "title": "HiTab: A hierarchical table dataset for question answering and natural language generation"
            },
            {
                "ref": "2022_nan_fetaqa",
                "title": "FeTaQA: Free-form Table Question Answering"
            },
            {
                "ref": "2020_chen_tabfact",
                "title": "TabFact: A Large-scale Dataset for Table-based Fact Verification"
            },
            {
                "ref": "2020_chen_hybridqa",
                "title": "HybridQA: A Dataset of Multi-hop Question Answering over Tabular and Textual Data"
            },
            {
                "ref": "2017_zhong_seq2sql",
                "title": "Seq2SQL: Generating Structured Queries from Natural Language using Reinforcement Learning"
            },
            {
                "ref": "2015_pasupat_compositional",
                "title": "Compositional semantic parsing on semi-structured tables"
            },
            {
                "ref": "2022_liu_tapex",
                "title": "TAPEX: Table Pre-training via Learning a Neural SQL Executor"
            },
            {
                "ref": "2021_aly_the",
                "title": "The FEVEROUS shared task"
            },
            {
                "ref": "2022_xie_unifiedskg",
                "title": "UnifiedSKG: Unifying and multi-tasking structured knowledge grounding with text-to-text language models"
            },
            {
                "ref": "2023_chen_longlora",
                "title": "LongLoRA: Efficient fine-tuning of long-context large language models"
            },
            {
                "ref": "2023_touvron_llama",
                "title": "Llama 2: Open foundation and fine-tuned chat models"
            },
            {
                "ref": "2023_li_table",
                "title": "Table-GPT: Table-tuned GPT for diverse table tasks"
            },
            {
                "ref": "2020_herzig_tapas",
                "title": "TaPas: Weakly supervised table parsing via pre-training"
            }
        ],
        "uncertainFields": [
            {
                "field": "venue.type",
                "reason": "The work appears as an arXiv preprint; mapped to \"journal\" due to schema constraints."
            },
            {
                "field": "kg.tripleStore",
                "reason": "Both Freebase (for types/relations) and Wikidata (for entities) are used; a single value was required."
            },
            {
                "field": "validation.metrics",
                "reason": "Paper also reports BLEU and execution accuracy, which are outside the allowed metric list."
            },
            {
                "field": "output",
                "reason": "Outputs are free-text predictions rather than a structured serialization like RDF."
            },
            {
                "field": "code",
                "reason": "URL points to the project page linking to resources, not a direct repository."
            },
            {
                "field": "doi",
                "reason": "Used the arXiv DOI; a later archival venue (if any) could assign a different DOI."
            },
            {
                "field": "inputs.tableSources",
                "reason": "Spreadsheets are from statistical scientific reports; \"scientific\" chosen among the available enums."
            },
            {
                "field": "supportTasks.predicateAnnotation",
                "reason": "Mapped from relation extraction to CPA terminology; exact equivalence may vary."
            },
            {
                "field": "supportTasks.typeAnnotation",
                "reason": "Mapped from column type annotation to CTA terminology."
            },
            {
                "field": "usesLLM.modelName",
                "reason": "Model described as Llama 2 (7B) with LongLoRA; exact naming may vary across releases."
            },
            {
                "field": "domain.type",
                "reason": "The approach is cross-domain; labeled as \"general\"."
            },
            {
                "field": "license",
                "reason": "The paper does not state a licence for code/model within the text."
            }
        ]
    },
    {
        "id": "2024_nguyen_mtab4d",
        "added": "",
        "year": 2024,
        "firstAuthor": "Nguyen",
        "authors": [
            "Phuc Nguyen",
            "Natthawut Kertkeidkachorn",
            "Ryutaro Ichise",
            "Hideaki Takeda"
        ],
        "title": "MTab4D: Semantic annotation of tabular data with DBpedia",
        "venue": {
            "type": "journal",
            "acronym": "Semantic Web"
        },
        "nameOfApproach": "MTab4D",
        "techniqueTags": [
            "rule-based",
            "embeddings",
            "ontology-driven"
        ],
        "coreTasks": {
            "cta": true,
            "cpa": true,
            "cea": true,
            "cnea": false
        },
        "supportTasks": {
            "dataPreparation": {
                "description": "Pre-processing includes cell normalisation, datatype prediction for cells/columns, header detection, subject column prediction, and matching target prediction. ",
                "spellChecker": "SymSpell-based hashing for fuzzy search (for candidate filtering). ",
                "unitsOfMeasurements": ""
            },
            "columnClassification": "Predict NE vs literal columns by majority voting over cell datatypes. ",
            "subjectDetection": "Heuristics over NE columns (uniqueness score, length constraints, left-most tie-break) to pick the subject column. ",
            "datatypeAnnotation": "Predicts cell and column datatypes (named-entity vs literal) using spaCy tags and heuristics. ",
            "typeAnnotation": "Aggregates signals (entity search votes, NER-to-class maps, header similarity, numerical-column inferences) to assign DBpedia classes. ",
            "predicateAnnotation": "Generates candidate properties via entity–entity link checks and value-based matching for literal columns, then aggregates across rows. ",
            "nilAnnotation": "",
            "entityLinking": {
                "description": "Links cells to DBpedia entities using a pipeline of search + disambiguation with aggregated signals. ",
                "candidateGeneration": "Keyword (BM25), fuzzy (edit distance with SymSpell filtering), and aggregation search over DBpedia 2016-10 dump. ",
                "entityDisambiguation": "Combines search scores, column type confidence, lexical similarity, and row-wise value matching to select the top entity. "
            }
        },
        "mainMethod": {
            "type": "unsupervised",
            "technique": "Rule-based aggregation with ontology constraints and embedding-based numerical matching (EmbNum+)."
        },
        "revision": {
            "type": "fully automated",
            "description": "Annotations are produced automatically by the pipeline; no post-hoc user editing is required. "
        },
        "domain": {
            "domain": "independent",
            "type": ""
        },
        "validation": {
            "goldStandard": "SemTab 2019 (original) and adapted SemTab 2019 with DBpedia 2016-10. ",
            "metrics": [
                "Precision",
                "Recall",
                "F1"
            ]
        },
        "code": "https://github.com/phucty/mtab4dbpedia",
        "license": "CC BY 4.0",
        "inputs": {
            "typeOfTable": "Excel, CSV, TSV, Markdown tables",
            "tableSources": [
                "web",
                "spreadsheet",
                "wiki"
            ]
        },
        "kg": {
            "tripleStore": "DBpedia",
            "index": "Elasticsearch keyword BM25, fuzzy edit-distance search, and aggregation over the DBpedia 2016-10 dump. "
        },
        "output": "",
        "applicationPurpose": "Semantic annotation of tabular data with DBpedia; reproducible benchmarking resources and public services (APIs/UI). ",
        "userInterfaceTool": "Web UI and REST APIs (mtab4d.kgraph.jp). ",
        "checkedByAuthor": "",
        "checkedByAi": true,
        "doi": "https://doi.org/10.3233/SW-223098",
        "citations": [
            {
                "ref": "2010_limaye_annotating",
                "title": "Annotating and searching web tables using entities, types and relationships"
            },
            {
                "ref": "2020_jimenez-ruiz_semtab",
                "title": "SemTab 2019: Resources to benchmark tabular data to knowledge graph matching systems"
            },
            {
                "ref": "2017_zhang_effective",
                "title": "Effective and efficient semantic table interpretation using TableMiner+"
            },
            {
                "ref": "2019_cremaschi_mantistable",
                "title": "MantisTable: An automatic approach for the semantic table interpretation"
            },
            {
                "ref": "2020_cremaschi_a",
                "title": "A fully automated approach to a complete semantic table interpretation"
            },
            {
                "ref": "2017_efthymiou_matching",
                "title": "Matching web tables with knowledge base entities: From entity lookups to entity embeddings"
            }
        ],
        "uncertainFields": [
            {
                "field": "venue.acronym",
                "reason": "The paper is published in the Semantic Web journal, but an official acronym (e.g., “SWJ”) is not explicitly stated in the text; we used the journal name."
            },
            {
                "field": "techniqueTags",
                "reason": "Tags are inferred from described components (heuristics, ontology signals, EmbNum+); the paper does not explicitly label them using this taxonomy."
            },
            {
                "field": "output",
                "reason": "The paper and site describe APIs and interfaces but do not specify a canonical export format for annotations."
            },
            {
                "field": "userInterfaceTool",
                "reason": "The interface is referred to as a ‘graphical interface’ and APIs, without a specific tool name beyond the site; phrasing may vary."
            },
            {
                "field": "inputs.tableSources",
                "reason": "Supports multiple table formats; mapping to the enumerated source categories involves interpretation."
            },
            {
                "field": "kg.index",
                "reason": "Summarises several modules and parameters; implementation details may be more granular than captured here."
            },
            {
                "field": "validation.metrics",
                "reason": "CTA evaluation in the paper also uses AH/AP, which are not allowed by this schema; only standard metrics are listed."
            },
            {
                "field": "supportTasks.datatypeAnnotation",
                "reason": "The system performs datatype prediction; aligning it to the ‘Datatype Annotation’ sub-task is interpretative."
            },
            {
                "field": "license",
                "reason": "‘CC BY 4.0’ refers to the article’s licence; the code repository’s specific licence is not stated in the paper."
            }
        ]
    },
    {
        "id": "2024_korini_column",
        "added": "",
        "year": 2024,
        "firstAuthor": "Korini",
        "authors": [
            "Keti Korini",
            "Christian Bizer"
        ],
        "title": "Column Property Annotation using Large Language Models",
        "venue": {
            "type": "workshop",
            "acronym": ""
        },
        "nameOfApproach": "",
        "techniqueTags": [
            "transformer",
            "embeddings"
        ],
        "coreTasks": {
            "cta": true,
            "cpa": true,
            "cea": false,
            "cnea": false
        },
        "supportTasks": {
            "dataPreparation": {
                "description": "Tables are provided from benchmark datasets; prompts sometimes use the first five rows and fill missing cells from later rows to form the input.",
                "spellChecker": "",
                "unitsOfMeasurements": ""
            },
            "columnClassification": "",
            "subjectDetection": "",
            "datatypeAnnotation": "",
            "typeAnnotation": "LLMs (zero-shot/few-shot and fine-tuned) assign column types from a given vocabulary (e.g., schema.org, DBpedia).",
            "predicateAnnotation": "LLMs predict column-to-column relationships (CPA) from a given candidate property set.",
            "nilAnnotation": "",
            "entityLinking": {
                "description": "",
                "candidateGeneration": "",
                "entityDisambiguation": ""
            }
        },
        "mainMethod": {
            "type": "hybrid",
            "technique": "transformer"
        },
        "revision": {
            "type": "fully automated",
            "description": "Predictions are generated automatically by LLMs; no user-in-the-loop correction is described."
        },
        "domain": {
            "domain": "independent",
            "type": ""
        },
        "validation": {
            "goldStandard": "SOTAB V2 CPA; T2Dv2 CPA; SOTAB V2 CTA; T2Dv2 CTA",
            "metrics": [
                "Micro-F1"
            ]
        },
        "code": "https://github.com/wbsg-uni-mannheim/TabAnnGPT",
        "license": "Not Specified",
        "inputs": {
            "typeOfTable": "Web tables",
            "tableSources": [
                "web"
            ]
        },
        "kg": {
            "tripleStore": "DBpedia; schema.org",
            "index": ""
        },
        "output": "",
        "applicationPurpose": "Improve CPA (and CTA) for downstream data search, data integration, and knowledge graph enrichment.",
        "userInterfaceTool": "",
        "usesLLM": {
            "modelName": "GPT-3.5; GPT-4; SOLAR-70B",
            "prompting": "few-shot"
        },
        "checkedByAuthor": "",
        "checkedByAi": true,
        "doi": "",
        "citations": [
            {
                "ref": "2007_auer_dbpedia",
                "title": "Dbpedia: A nucleus for a web of open data"
            },
            {
                "ref": "2018_cannaviccio_towards",
                "title": "Towards annotating relational data on the web with language models"
            },
            {
                "ref": "2020_deng_turl",
                "title": "TURL: Table understanding through representation learning"
            },
            {
                "ref": "2019_devlin_bert",
                "title": "BERT: Pre-training of deep bidirectional transformers for language understanding"
            },
            {
                "ref": "2023_feuer_archetype",
                "title": "ArcheType: A Novel Framework for Open-Source Column Type Annotation using Large Language Models"
            },
            {
                "ref": "2020_jiao_tinybert",
                "title": "TinyBERT: Distilling BERT for natural language understanding"
            },
            {
                "ref": "2020_jimenez-ruiz_semtab",
                "title": "SemTab 2019: Resources to benchmark tabular data to knowledge graph matching systems"
            },
            {
                "ref": "2023_kayali_chorus",
                "title": "CHORUS: Foundation Models for Unified Data Discovery and Exploration"
            },
            {
                "ref": "2023_korini_column",
                "title": "Column type annotation using ChatGPT"
            },
            {
                "ref": "2022_korini_sotab",
                "title": "SOTAB: The WDC schema.org table annotation benchmark"
            },
            {
                "ref": "2023_li_table-gpt",
                "title": "Table-GPT: Table-tuned GPT for Diverse Table Tasks"
            },
            {
                "ref": "2010_limaye_annotating",
                "title": "Annotating and searching web tables using entities, types and relationships"
            },
            {
                "ref": "2022_liu_what",
                "title": "What makes good in-context examples for GPT-3?"
            },
            {
                "ref": "2023_liu_from",
                "title": "From tabular data to knowledge graphs: A survey of semantic table interpretation tasks and methods"
            },
            {
                "ref": "2019_liu_dagobah",
                "title": "DAGOBAH: an end-to-end context-free tabular data semantic annotation system"
            },
            {
                "ref": "2019_nguyen_mtab",
                "title": "Mtab: Matching tabular data to knowledge graph using probability models"
            },
            {
                "ref": "2022_ouyang_training",
                "title": "Training language models to follow instructions with human feedback"
            },
            {
                "ref": "2015_ritze_matching",
                "title": "Matching HTML tables to DBpedia"
            },
            {
                "ref": "2022_suhara_annotating",
                "title": "Annotating columns with pre-trained language models"
            },
            {
                "ref": "2023_touvron_llama",
                "title": "Llama 2: Open foundation and fine-tuned chat models"
            },
            {
                "ref": "2011_venetis_recovering",
                "title": "Recovering semantics of tables on the web"
            },
            {
                "ref": "2023_ye_complementary",
                "title": "Complementary explanations for effective in-context learning"
            },
            {
                "ref": "2023_zhang_tablellama",
                "title": "TableLlama: Towards Open Large Generalist Models for Tables"
            },
            {
                "ref": "2023_zhao_a",
                "title": "A Survey of Large Language Models"
            }
        ],
        "uncertainFields": [
            {
                "field": "venue.type",
                "reason": "The paper text provided does not explicitly state the venue type; assuming a workshop publication."
            },
            {
                "field": "venue.acronym",
                "reason": "Acronym of the venue is not stated in the text."
            },
            {
                "field": "doi",
                "reason": "No DOI is indicated in the paper; CEUR-style workshops often lack DOIs."
            },
            {
                "field": "kg.tripleStore",
                "reason": "CPA uses schema.org (a vocabulary) for SOTAB and DBpedia for T2Dv2; listing both may not reflect a single triple store."
            },
            {
                "field": "output",
                "reason": "The output serialisation format of predictions is not specified."
            },
            {
                "field": "usesLLM.prompting",
                "reason": "Both zero-shot and few-shot prompting are used; the schema allows a single value."
            },
            {
                "field": "supportTasks.typeAnnotation",
                "reason": "CTA is evaluated, but the work centres on CPA; summarised conservatively."
            }
        ]
    },
    {
        "id": "2024_parmar_wikidata-driven",
        "added": "",
        "year": 2024,
        "firstAuthor": "Parmar",
        "authors": [
            "Vishvapalsinhji Parmar",
            "Alsayed Algergawy"
        ],
        "title": "Wikidata-Driven CEA and CTA for Life Sciences Table Matching extending DREIFLUSS",
        "venue": {
            "type": "workshop",
            "acronym": "SemTab"
        },
        "nameOfApproach": "",
        "techniqueTags": [
            "ontology-driven"
        ],
        "coreTasks": {
            "cta": true,
            "cpa": false,
            "cea": true,
            "cnea": false
        },
        "supportTasks": {
            "dataPreparation": {
                "description": "CSV tables are loaded; cell texts are trimmed, deduplicated and cleaned; for multi-valued cells only the first value is retained to reduce ambiguity. ",
                "spellChecker": "",
                "unitsOfMeasurements": ""
            },
            "columnClassification": "",
            "subjectDetection": "",
            "datatypeAnnotation": "",
            "typeAnnotation": "Column values are mapped to Wikidata classes via API lookups and aggregation over related IDs (e.g., P31/P279) with frequency-based selection. ",
            "predicateAnnotation": "",
            "nilAnnotation": "",
            "entityLinking": {
                "description": "Cell values are linked to Wikidata by constructing URIs from IDs returned by the Wikidata API, with caching and rate limiting. ",
                "candidateGeneration": "Wikidata API search (label-based lookup) with local caching. ",
                "entityDisambiguation": "Top result selection from API response; heuristics kept minimal to prioritise precision and speed. "
            }
        },
        "mainMethod": {
            "type": "unsupervised",
            "technique": "ontology-driven"
        },
        "revision": {
            "type": "fully automated",
            "description": "No manual post-editing reported; the pipeline runs automatically with API-based annotation and heuristic aggregation. "
        },
        "domain": {
            "domain": "dependent",
            "type": "life sciences (biodiversity, biomedicine). "
        },
        "validation": {
            "goldStandard": "SemTab 2024 Accuracy Track Round 2 datasets: tBiodivL and tBiomedL (horizontal/entity targets). ",
            "metrics": [
                "F1",
                "Precision"
            ]
        },
        "code": "https://github.com/DKEPassau/CEACTA24",
        "license": "MIT License",
        "inputs": {
            "typeOfTable": "CSV",
            "tableSources": [
                "scientific",
                "spreadsheet"
            ]
        },
        "kg": {
            "tripleStore": "Wikidata",
            "index": "Wikidata API search with local cache"
        },
        "output": "CSV",
        "applicationPurpose": "Knowledge-graph-driven table matching and annotation (CEA/CTA) for SemTab 2024 datasets, focusing on accuracy and scalability. ",
        "userInterfaceTool": "",
        "checkedByAuthor": "",
        "checkedByAi": true,
        "doi": "",
        "citations": [
            {
                "ref": "2023_shigarov_table",
                "title": "Table understanding: Problem overview"
            },
            {
                "ref": "2023_parmar_dreifluss",
                "title": "DREIFLUSS: A minimalist approach for table matching"
            },
            {
                "ref": "2009_bizer_dbpedia",
                "title": "Dbpedia - A crystallization point for the web of data"
            },
            {
                "ref": "2015_guha_schemaorg",
                "title": "Schema.org: Evolution of structured data on the web"
            },
            {
                "ref": "2019_oliveira_adog",
                "title": "ADOG - annotating data with ontologies and graphs"
            },
            {
                "ref": "2019_cremaschi_mantistable",
                "title": "Mantistable: an automatic approach for the semantic table interpretation"
            },
            {
                "ref": "2019_thawani_entity",
                "title": "Entity linking to knowledge graphs to infer column types and properties"
            },
            {
                "ref": "2020_huynh_dagobah",
                "title": "DAGOBAH: enhanced scoring algorithms for scalable annotations of tabular data"
            },
            {
                "ref": "2020_abdelmageed_jentab",
                "title": "Jentab: Matching tabular data to knowledge graphs"
            },
            {
                "ref": "2021_huynh_dagobah",
                "title": "DAGOBAH: table and graph contexts for efficient semantic annotation of tabular data"
            },
            {
                "ref": "2021_avogadro_mantistable",
                "title": "Mantistable V: A novel and efficient approach to semantic table interpretation"
            },
            {
                "ref": "2022_cremaschi_s-elbat",
                "title": "s-elbat: A semantic interpretation approach for messy table-s"
            },
            {
                "ref": "2022_korini_sotab",
                "title": "SOTAB: the WDC schema.org table annotation benchmark"
            },
            {
                "ref": "2022_marzocchi_mammotab",
                "title": "Mammotab: A giant and comprehensive dataset for semantic table interpretation"
            }
        ],
        "uncertainFields": [
            {
                "field": "venue.acronym",
                "reason": "Paper appears in CEUR-WS under the SemTab’24 challenge; using 'SemTab' as acronym may conflate challenge vs workshop naming. "
            },
            {
                "field": "license",
                "reason": "The GitHub repository is cited, but the specific code licence is not stated in the paper; therefore set to Not Specified. "
            },
            {
                "field": "doi",
                "reason": "CEUR-WS papers often lack a DOI and none is visible in the PDF; left empty. "
            },
            {
                "field": "inputs.tableSources",
                "reason": "Datasets are CSV from Zenodo and life-science corpora; mapped to 'scientific' and 'spreadsheet', but exact source categorisation is not explicitly labelled. "
            },
            {
                "field": "output",
                "reason": "Outputs are described as annotated DataFrames and files; CSV is inferred but not explicitly standardised as the final export format. "
            },
            {
                "field": "nameOfApproach",
                "reason": "No explicit new system name beyond extending DREIFLUSS; repository name (CEACTA24) might imply a name but is not formalised. "
            },
            {
                "field": "techniqueTags[0]",
                "reason": "Classified as 'ontology-driven' since it relies on Wikidata querying; alternative labelling as 'rule-based' could also be argued. "
            },
            {
                "field": "mainMethod.technique",
                "reason": "Described as API/graph lookups with heuristics; 'ontology-driven' chosen though other phrasing (e.g., rule-based) might fit. "
            }
        ]
    },
    {
        "id": "2025_cremaschi_steellm",
        "added": "",
        "year": 2025,
        "firstAuthor": "Cremaschi",
        "authors": [
            "Marco Cremaschi",
            "Fabio D’Adda",
            "Andrea Maurino"
        ],
        "title": "stEELlm: An LLM for Generating Semantic Annotations of Tabular Data",
        "venue": {
            "type": "journal",
            "acronym": "TIST"
        },
        "nameOfApproach": "stEELlm",
        "techniqueTags": [
            "transformer"
        ],
        "coreTasks": {
            "cta": false,
            "cpa": false,
            "cea": true,
            "cnea": false
        },
        "supportTasks": {
            "dataPreparation": {
                "description": "Preprocessing includes removing Wikidata URL prefixes, cleaning Unicode artefacts, and lowercasing table/annotation text.",
                "spellChecker": "",
                "unitsOfMeasurements": ""
            },
            "columnClassification": "",
            "subjectDetection": "",
            "datatypeAnnotation": "",
            "typeAnnotation": "",
            "predicateAnnotation": "",
            "nilAnnotation": "",
            "entityLinking": {
                "description": "Entity candidates are retrieved and the model disambiguates to a single Wikidata QID for each mention.",
                "candidateGeneration": "String-based entity retrieval via LamAPI over Wikidata.",
                "entityDisambiguation": "Fine-tuned Mixtral 8x7B selects the best candidate using label matching and tabular context."
            }
        },
        "mainMethod": {
            "type": "supervised",
            "technique": "fine-tuned transformer (Mixtral 8x7B)",
            "supervision": {
                "type": "supervised"
            }
        },
        "revision": {
            "type": "fully automated",
            "description": "System produces annotations automatically; outputs are parsed programmatically without manual post-editing."
        },
        "domain": {
            "domain": "independent",
            "type": ""
        },
        "validation": {
            "goldStandard": "WikidataTables 2023 (validation), HardTables 2022, and SemTab 2020 (R1–R4). ",
            "metrics": [
                "Precision",
                "Recall",
                "F1"
            ]
        },
        "code": "https://github.com/unimib-datAI/steellm/",
        "license": "GNU Affero General Public License v3.0",
        "inputs": {
            "typeOfTable": "CSV",
            "tableSources": [
                "wiki"
            ]
        },
        "kg": {
            "tripleStore": "Wikidata",
            "index": "LamAPI lookup index for Wikidata"
        },
        "output": "CSV",
        "applicationPurpose": "Cell-Entity Annotation (CEA) for table-to-KG matching to support data enrichment and KG construction/extension. ",
        "userInterfaceTool": "",
        "usesLLM": {
            "modelName": "Mixtral 8x7B Instruct",
            "prompting": "few-shot"
        },
        "checkedByAuthor": "",
        "checkedByAi": true,
        "doi": "https://doi.org/10.1145/3719206",
        "citations": [],
        "uncertainFields": [
            {
                "field": "venue.acronym",
                "reason": "The journal is ACM Transactions on Intelligent Systems and Technology; acronym could be given as TIST or ACM TIST."
            },
            {
                "field": "inputs.tableSources",
                "reason": "Tables are generated from Wikidata via SPARQL; classified here as \"wiki\" but could also be considered generic web-derived."
            },
            {
                "field": "usesLLM.prompting",
                "reason": "Few-shot prompting is used in GPT-4 experiments; the fine-tuned model itself does not require few-shot at inference."
            },
            {
                "field": "userInterfaceTool",
                "reason": "No explicit UI/tool is described; implementation appears to be code/scripts."
            },
            {
                "field": "validation.goldStandard",
                "reason": "Summarised GS names; exact subsets/rounds per experiment may vary across sections."
            },
            {
                "field": "citations",
                "reason": "Full bibliography not extracted in this pass; leaving the list empty avoids introducing potentially incorrect references."
            }
        ]
    },
    {
        "id": "2023_dorodnykh_knowledge",
        "added": "",
        "year": 2023,
        "firstAuthor": "Dorodnykh",
        "authors": [
            "Nikita Dorodnykh",
            "Aleksandr Yurin"
        ],
        "title": "Knowledge Graph Engineering Based on Semantic Annotation of Tables",
        "venue": {
            "type": "journal",
            "acronym": "Computation"
        },
        "nameOfApproach": "TabbyLD2",
        "techniqueTags": [
            "rule-based",
            "embeddings",
            "ontology-driven",
            "transformer"
        ],
        "coreTasks": {
            "cta": true,
            "cpa": true,
            "cea": true,
            "cnea": false
        },
        "supportTasks": {
            "dataPreparation": {
                "description": "Data cleaning and normalisation of tabular content (e.g., Unicode fixes, removal of noise) prior to annotation.",
                "spellChecker": "",
                "unitsOfMeasurements": ""
            },
            "columnClassification": "NER- and pattern-based identification of Named-Entity vs Literal columns using Stanford NER, regexes, and Duckling.",
            "subjectDetection": "Heuristic scoring (uniqueness, average words per cell, empties, acronyms, header prepositions, left distance) to pick the subject column.",
            "datatypeAnnotation": "Maps literal NER classes to XML Schema datatypes for LIT-columns.",
            "typeAnnotation": "Aggregates majority voting over classes inferred from CEA, header–class string similarity, NER-to-class mapping, CNNs (ColNet), and a BERT-based model (Doduo), plus a coherence algorithm to refine column classes.",
            "predicateAnnotation": "Majority voting over candidate DBpedia properties between the subject column and other columns.",
            "nilAnnotation": "",
            "entityLinking": {
                "description": "Two-step EL: candidate generation and disambiguation combining multiple signals.",
                "candidateGeneration": "Exact/lexical lookups against DBpedia via SPARQL endpoint and DBpedia Lookup; top-k candidates retained.",
                "entityDisambiguation": "Weighted combination of string similarity (Levenshtein), NER-to-class compatibility, RDF2Vec embedding similarity, and context similarity (Doc2Vec using neighbouring cells and DBpedia comments)."
            }
        },
        "mainMethod": {
            "type": "hybrid",
            "technique": "Heuristics combined with knowledge-graph embeddings (RDF2Vec), CNNs (ColNet), and a BERT-based model (Doduo) for table understanding."
        },
        "revision": {
            "type": "semi automated",
            "description": "Automatic pipeline with optional user refinement via a GUI client; annotations can be inspected and adjusted before RDF generation."
        },
        "domain": {
            "domain": "independent",
            "type": ""
        },
        "validation": {
            "goldStandard": "T2Dv2 and SemTab 2T datasets; additional domain case studies",
            "metrics": [
                "Precision",
                "Recall",
                "F1",
                "Accuracy"
            ]
        },
        "code": "https://github.com/tabbydoc/tabbyld2",
        "license": "Not Specified",
        "inputs": {
            "typeOfTable": "CSV, XLSX, JSON relational tables",
            "tableSources": [
                "web",
                "pdf",
                "spreadsheet",
                "scientific",
                "wiki"
            ]
        },
        "kg": {
            "tripleStore": "DBpedia",
            "index": "DBpedia SPARQL Endpoint; DBpedia Lookup; KGvec2go embeddings"
        },
        "output": "RDF",
        "applicationPurpose": "Knowledge graph construction, population, and augmentation from tables via semantic annotation.",
        "userInterfaceTool": "Web UI (TabbyLD2-Client), REST API, CLI",
        "checkedByAuthor": "",
        "checkedByAi": true,
        "doi": "https://doi.org/10.3390/computation11090175",
        "citations": [
            {
                "ref": "2010_limaye_annotating",
                "title": "Annotating and Searching Web Tables Using Entities, Types and Relationships"
            },
            {
                "ref": "2017_zhang_effective",
                "title": "Effective and Efficient Semantic Table Interpretation using TableMiner+"
            },
            {
                "ref": "2019_chen_colnet",
                "title": "ColNet: Embedding the semantics of web tables for column type prediction"
            },
            {
                "ref": "2021_huynh_table",
                "title": "DAGOBAH: Table and Graph Contexts For Efficient Semantic Annotation Of Tabular Data"
            },
            {
                "ref": "2022_suhara_annotating",
                "title": "Annotating Columns with Pre-trained Language Models"
            },
            {
                "ref": "2019_ristoski_rdf2vec",
                "title": "RDF2Vec: RDF graph embeddings and their applications"
            },
            {
                "ref": "2020_deng_table",
                "title": "TURL: Table Understanding through Representation Learning"
            },
            {
                "ref": "2020_yin_tabert",
                "title": "TaBERT: Pretraining for Joint Understanding of Textual and Tabular Data"
            },
            {
                "ref": "2009_bizer_dbpedia",
                "title": "Dbpedia—A Crystallization Point for the Web of Data"
            }
        ],
        "uncertainFields": [
            {
                "field": "techniqueTags",
                "reason": "‘Transformer’ is inferred from the use of BERT-based models for CTA rather than bespoke LLM usage."
            },
            {
                "field": "coreTasks.cnea",
                "reason": "The system generates new entities when EL fails, which aligns with CNEA conceptually, but CNEA is not explicitly framed or evaluated as a task."
            },
            {
                "field": "license",
                "reason": "The repository is cited as open source, but the exact software licence was not stated in the paper."
            },
            {
                "field": "kg.index",
                "reason": "Listed services act as lookup/endpoints; the presence of a dedicated indexed mirror is not explicitly confirmed."
            },
            {
                "field": "inputs.tableSources",
                "reason": "Sources include Wikipedia and PubMed-derived tables; mapping to the provided enums may not fully capture all acquisition channels."
            },
            {
                "field": "validation.goldStandard",
                "reason": "The 2T dataset version/year and full GS details are not exhaustively enumerated in the abstracted content."
            },
            {
                "field": "userInterfaceTool",
                "reason": "The paper mentions a GUI client and REST API; exact feature set of the UI is summarised."
            },
            {
                "field": "mainMethod.technique",
                "reason": "Technique string summarises multiple components (heuristics, embeddings, CNNs, BERT) and is not a single formal algorithm name."
            }
        ]
    },
    {
        "id": "2023_foko_exploring",
        "added": "",
        "year": 2023,
        "firstAuthor": "Foko",
        "authors": [
            "Brice Foko",
            "Azanzi Jiomekong",
            "Hippolyte Tapamo",
            "Jérémy Buisson",
            "Sanju Tiwari"
        ],
        "title": "Exploring Naive Bayes Classifiers for Tabular Data to Knowledge Graph Matching",
        "venue": {
            "type": "workshop",
            "acronym": "SemTab"
        },
        "nameOfApproach": "",
        "techniqueTags": [],
        "coreTasks": {
            "cta": true,
            "cpa": true,
            "cea": true,
            "cnea": false
        },
        "supportTasks": {
            "dataPreparation": {
                "description": "Lowercasing, removal of special characters and stopwords, Porter stemming, and tokenisation prior to feature extraction.",
                "spellChecker": "",
                "unitsOfMeasurements": ""
            },
            "columnClassification": "",
            "subjectDetection": "",
            "datatypeAnnotation": "",
            "typeAnnotation": "Assign KG classes to columns using Naive Bayes over header and column-content features.",
            "predicateAnnotation": "Predict KG properties between column pairs via Naive Bayes using co-occurrence and relation features.",
            "nilAnnotation": "",
            "entityLinking": {
                "description": "Link table cells to KG entities with a Naive Bayes classifier using cell contents, entity labels and limited context.",
                "candidateGeneration": "Entities treated as class labels from the target KG; no separate retrieval step described.",
                "entityDisambiguation": "Select the entity with highest posterior from the Naive Bayes model."
            }
        },
        "mainMethod": {
            "type": "supervised",
            "technique": "Naive Bayes",
            "supervision": {
                "type": "supervised"
            }
        },
        "revision": {
            "type": "fully automated",
            "description": "Predictions are produced automatically by trained classifiers without user post-editing."
        },
        "domain": {
            "domain": "independent",
            "type": ""
        },
        "validation": {
            "goldStandard": "SemTab 2023 datasets: WikidataTables, tFood, SOTAB",
            "metrics": []
        },
        "code": "https://github.com/fokobrice3/STProbClass/tree/main/MNB_2023",
        "license": "Apache License 2.0",
        "inputs": {
            "typeOfTable": "CSV and JSON",
            "tableSources": [
                "wiki",
                "scientific",
                "web"
            ]
        },
        "kg": {
            "tripleStore": "Wikidata; DBpedia; Schema.org",
            "index": ""
        },
        "output": "",
        "applicationPurpose": "Table-to-KG matching for CTA, CEA, CPA and TTD in SemTab 2023.",
        "userInterfaceTool": "",
        "checkedByAuthor": "",
        "checkedByAi": true,
        "doi": "",
        "citations": [
            {
                "ref": "2020_oelen_creating",
                "title": "Creating a scholarly knowledge graph from survey article tables"
            },
            {
                "ref": "2022_jiomekong_a",
                "title": "A large scale corpus of food composition tables"
            },
            {
                "ref": "2011_ting_is",
                "title": "Is naïve bayes a good classifier for document classification?"
            },
            {
                "ref": "2020_shigapov_bbw",
                "title": "bbw: Matching csv to wikidata via meta-lookup"
            },
            {
                "ref": "2021_nguyen_semtab",
                "title": "Semtab 2021: Tabular data annotation with mtab tool"
            },
            {
                "ref": "2021_huynh_dagobah",
                "title": "Dagobah: Table and graph contexts for efficient semantic annotation of tabular data"
            },
            {
                "ref": "2022_jiomekong_towards",
                "title": "Towards an approach based on knowledge graph refinement for tabular data to knowledge graph matching"
            },
            {
                "ref": "2020_alsafy_multiclass",
                "title": "Multiclass classification methods: A review"
            },
            {
                "ref": "2022_jiomekong_combining",
                "title": "Combining Scrum and Model Driven Architecture for the development of the EPICAM platform"
            },
            {
                "ref": "2023_azanzi_combining",
                "title": "Combining Scrum and Model Driven Architecture for the development of an epidemiological surveillance software"
            },
            {
                "ref": "2021_ralph_empirical",
                "title": "Empirical standards for software engineering research"
            },
            {
                "ref": "2023_abdelmageed_tfood",
                "title": "tFood: Semantic Table Annotations Benchmark for Food Domain"
            }
        ],
        "uncertainFields": [
            {
                "field": "venue.acronym",
                "reason": "Paper states SemTab’23; acronym normalised to 'SemTab' without year."
            },
            {
                "field": "validation.metrics",
                "reason": "Specific evaluation metrics are not explicitly stated in the paper."
            },
            {
                "field": "output",
                "reason": "The output format of annotations is not specified."
            },
            {
                "field": "kg.tripleStore",
                "reason": "Multiple KGs (Wikidata, DBpedia, Schema.org) are used; field consolidated as a single string."
            },
            {
                "field": "inputs.tableSources[1]",
                "reason": "tFood is a scientific benchmark; source categories are inferred."
            },
            {
                "field": "inputs.tableSources[0]",
                "reason": "WikidataTables are assumed to be wiki-derived; not explicitly spelled out."
            },
            {
                "field": "userInterfaceTool",
                "reason": "No UI is described; left empty."
            },
            {
                "field": "doi",
                "reason": "CEUR-WS papers typically have no DOI; none is provided in the text."
            }
        ]
    },
    {
        "id": "2022_liu_radar",
        "added": "",
        "year": 2022,
        "firstAuthor": "Liu",
        "authors": [
            "Jixiong Liu",
            "Viet-Phi Huynh",
            "Yoan Chabot",
            "Raphael Troncy"
        ],
        "title": "Radar Station: Using KG Embeddings for Semantic Table Interpretation and Entity Disambiguation",
        "venue": {
            "type": "conference",
            "acronym": "ISWC"
        },
        "nameOfApproach": "Radar Station",
        "techniqueTags": [
            "embeddings"
        ],
        "coreTasks": {
            "cta": false,
            "cpa": false,
            "cea": true,
            "cnea": false
        },
        "supportTasks": {
            "dataPreparation": {
                "description": "Collects candidate entities and confidence scores from baseline STI systems and builds a column-wise context set for disambiguation.",
                "spellChecker": "",
                "unitsOfMeasurements": ""
            },
            "columnClassification": "",
            "subjectDetection": "",
            "datatypeAnnotation": "",
            "typeAnnotation": "",
            "predicateAnnotation": "",
            "nilAnnotation": "",
            "entityLinking": {
                "description": "Takes pre-generated CEA candidates and applies embedding-based, column-context disambiguation.",
                "candidateGeneration": "Inherited from baseline systems via lookup and string similarity (e.g., top-k candidates from DAGOBAH-SL, MTab, BBW).",
                "entityDisambiguation": "KD-tree KNN over KG embeddings (TransE/RotatE/DistMult/ComplEx) with a radar-like weighted score combined with initial candidate scores."
            }
        },
        "mainMethod": {
            "type": "hybrid",
            "technique": "Embedding-based disambiguation combined with heuristic candidate scores"
        },
        "revision": {
            "type": "fully automated",
            "description": "No user-in-the-loop; final labels are computed automatically by combining base scores with embedding signals."
        },
        "domain": {
            "domain": "independent",
            "type": ""
        },
        "validation": {
            "goldStandard": "T2D, Limaye, Tough Tables v2, ShortTables",
            "metrics": [
                "Precision"
            ]
        },
        "code": "https://github.com/Orange-OpenSource/radar-station",
        "license": "BSD 3-Clause License",
        "inputs": {
            "typeOfTable": "Web tables (relational)",
            "tableSources": [
                "web",
                "wiki"
            ]
        },
        "kg": {
            "tripleStore": "Wikidata",
            "index": ""
        },
        "output": "",
        "applicationPurpose": "Disambiguate ambiguous cell–entity annotations and improve STI accuracy.",
        "userInterfaceTool": "",
        "checkedByAuthor": "",
        "checkedByAi": true,
        "doi": "https://doi.org/10.1007/978-3-031-19433-7_29",
        "citations": [
            {
                "ref": "2010_limaye_annotating",
                "title": "Annotating and searching web tables using entities, types and relationships"
            },
            {
                "ref": "2017_efthymiou_matching",
                "title": "Matching web tables with knowledge base entities: from entity lookups to entity embeddings"
            },
            {
                "ref": "2020_cutrona_tough",
                "title": "Tough tables: carefully evaluating entity linking for tabular data"
            },
            {
                "ref": "2020_deng_turl",
                "title": "TURL: table understanding through representation learning"
            },
            {
                "ref": "2019_sun_rotate",
                "title": "RotatE: knowledge graph embedding by relational rotation in complex space"
            },
            {
                "ref": "2013_bordes_translating",
                "title": "Translating embeddings for modeling multi-relational data"
            },
            {
                "ref": "2016_trouillon_complex",
                "title": "Complex embeddings for simple link prediction"
            },
            {
                "ref": "2014_yang_embedding",
                "title": "Embedding entities and relations for learning and inference in knowledge bases"
            },
            {
                "ref": "2015_bhagavatula_tabel",
                "title": "TabEL: entity linking in web tables"
            },
            {
                "ref": "2019_chabot_dagobah",
                "title": "DAGOBAH: an end-to-end context-free tabular data semantic annotation system"
            },
            {
                "ref": "2020_nguyen_mtab4wikidata",
                "title": "Mtab4wikidata at SemTab 2020: tabular data annotation with Wikidata"
            },
            {
                "ref": "2020_shigapov_bbw",
                "title": "bbw: Matching CSV to Wikidata via meta-lookup"
            },
            {
                "ref": "2019_lerer_pytorch-biggraph",
                "title": "Pytorch-biggraph: a large scale graph embedding system"
            },
            {
                "ref": "2019_zhu_graphvite",
                "title": "GraphVite: a high-performance CPU-GPU hybrid system for node embedding"
            },
            {
                "ref": "2017_wang_knowledge",
                "title": "Knowledge graph embedding: a survey of approaches and applications"
            },
            {
                "ref": "2020_jimenez-ruiz_semtab",
                "title": "SemTab 2019: resources to benchmark tabular data to knowledge graph matching systems"
            },
            {
                "ref": "2017_ritze_matching",
                "title": "Matching web tables to DBpedia - a feature utility study"
            },
            {
                "ref": "2015_ritze_matching",
                "title": "Matching HTML tables to DBpedia"
            }
        ],
        "uncertainFields": [
            {
                "field": "license",
                "reason": "The paper references a GitHub repository, but no licence is stated in the manuscript."
            },
            {
                "field": "output",
                "reason": "The format of the produced annotations is not specified."
            },
            {
                "field": "inputs.tableSources[1]",
                "reason": "Limaye tables originate from Wikipedia, but the exact mix of sources across datasets is not fully detailed."
            },
            {
                "field": "validation.metrics[0]",
                "reason": "Results discuss both accuracy gains and precision; only Precision is explicitly defined in the evaluation section."
            },
            {
                "field": "kg.index",
                "reason": "Indexing details (e.g., search back-end) for the KG are not reported for Radar Station itself."
            },
            {
                "field": "userInterfaceTool",
                "reason": "No UI or tool interface is described."
            },
            {
                "field": "supportTasks.columnClassification",
                "reason": "Radar Station relies on baseline systems and does not state whether it performs this sub-task."
            },
            {
                "field": "supportTasks.dataPreparation.unitsOfMeasurements",
                "reason": "No explicit handling of measurement units is mentioned."
            }
        ]
    },
    {
        "id": "2013_zwicklbauer_towards",
        "added": "",
        "year": 2013,
        "firstAuthor": "Zwicklbauer",
        "authors": [
            "Stefan Zwicklbauer",
            "Christoph Einsiedler",
            "Michael Granitzer",
            "Christin Seifert"
        ],
        "title": "Towards Disambiguating Web Tables",
        "venue": {
            "type": "workshop",
            "acronym": ""
        },
        "nameOfApproach": "",
        "techniqueTags": [
            "rule-based",
            "ontology-driven"
        ],
        "coreTasks": {
            "cta": true,
            "cpa": false,
            "cea": false,
            "cnea": false
        },
        "supportTasks": {
            "dataPreparation": {
                "description": "Tables were extracted from Wikipedia and columns containing only numbers or complete sentences were removed.",
                "spellChecker": "",
                "unitsOfMeasurements": ""
            },
            "columnClassification": "",
            "subjectDetection": "",
            "datatypeAnnotation": "",
            "typeAnnotation": "Header types are inferred by aggregating the types of cell-level entity candidates in the same column.",
            "predicateAnnotation": "",
            "nilAnnotation": "",
            "entityLinking": {
                "description": "",
                "candidateGeneration": "",
                "entityDisambiguation": ""
            }
        },
        "mainMethod": {
            "type": "unsupervised",
            "technique": "rule-based"
        },
        "revision": {
            "type": "fully automated",
            "description": "Pipeline runs automatically without manual review."
        },
        "domain": {
            "domain": "independent",
            "type": ""
        },
        "validation": {
            "goldStandard": "50 Wikipedia tables with manually annotated column types (132 columns; 329 type labels).",
            "metrics": [
                "Macro-Precision",
                "Macro-Recall",
                "Macro-F1"
            ]
        },
        "code": "https://github.com/quhfus/table-disambiguation",
        "license": "Not Specified",
        "inputs": {
            "typeOfTable": "HTML tables (Wikipedia)",
            "tableSources": [
                "wiki"
            ]
        },
        "kg": {
            "tripleStore": "DBpedia",
            "index": ""
        },
        "output": "",
        "applicationPurpose": "Annotate table headers with semantic types to support web table disambiguation.",
        "userInterfaceTool": "",
        "checkedByAuthor": "",
        "checkedByAi": true,
        "doi": "",
        "citations": [
            {
                "ref": "2010_gonzalez_google",
                "title": "Google fusion tables: web-centered data management and collaboration"
            },
            {
                "ref": "2010_limaye_annotating",
                "title": "Annotating and searching web tables using entities, types and relationships"
            },
            {
                "ref": "2013_quercini_entity",
                "title": "Entity discovery and annotation in tables"
            },
            {
                "ref": "2011_venetis_recovering",
                "title": "Recovering semantics of tables on the web"
            },
            {
                "ref": "2013_zwicklbauer_do",
                "title": "Do we need entity-centric knowledge bases for entity disambiguation?"
            }
        ],
        "uncertainFields": [
            {
                "field": "venue.type",
                "reason": "The PDF does not state the publication venue; classifying it as a workshop is an informed guess based on format and lack of DOI."
            },
            {
                "field": "venue.acronym",
                "reason": "No venue acronym is visible in the paper."
            },
            {
                "field": "doi",
                "reason": "A DOI is not provided in the document."
            },
            {
                "field": "output",
                "reason": "The export/serialization format of the annotations is not specified."
            },
            {
                "field": "techniqueTags[1]",
                "reason": "Ontology usage is clear; whether to also label it rule-based vs purely ontology-driven is somewhat interpretative."
            },
            {
                "field": "code",
                "reason": "The linked GitHub resource is described as a dataset; it is unclear whether it includes full runnable code."
            }
        ]
    },
    {
        "id": "2021_abdelmageed_jentab-2",
        "added": "",
        "year": 2021,
        "firstAuthor": "Abdelmageed",
        "authors": [
            "Nora Abdelmageed",
            "Sirko Schindler"
        ],
        "title": "JenTab: A Toolkit for Semantic Table Annotations",
        "venue": {
            "type": "workshop",
            "acronym": "KGCW"
        },
        "nameOfApproach": "JenTab",
        "techniqueTags": [
            "rule-based",
            "embeddings",
            "ontology-driven"
        ],
        "coreTasks": {
            "cta": true,
            "cpa": true,
            "cea": true,
            "cnea": false
        },
        "supportTasks": {
            "dataPreparation": {
                "description": "Normalises cells (encoding fixes, punctuation removal, regex-based cleaning) and predicts column datatypes before annotation.",
                "spellChecker": "Autocorrect using word-vector based suggestions for misspellings and abbreviations.",
                "unitsOfMeasurements": "Extracts numeric values and units; applies tolerance checks for QUANTITY comparisons."
            },
            "columnClassification": "Determines OBJECT vs LITERAL (STRING/DATE/QUANTITY) columns to guide downstream modules.",
            "subjectDetection": "Identifies subject column and uses row context to propagate and constrain candidates.",
            "datatypeAnnotation": "Assigns fine-grained datatypes to literal columns to support CPA matching.",
            "typeAnnotation": "Derives CTA candidates from parents of CEA candidates and selects via LCS/majority and popularity.",
            "predicateAnnotation": "Retrieves and matches properties between subject/object columns using object/literal matching and fuzzy rules.",
            "nilAnnotation": "",
            "entityLinking": {
                "description": "Generates CEA candidates via multi-strategy label lookup and context-aware filtering/selection.",
                "candidateGeneration": "Label lookups with fuzzy/abbreviation handling, column- and row-based candidate expansion, and subject-driven propagation.",
                "entityDisambiguation": "Filters by row/column support, unmatched properties, string distance; selects by string similarity and contextual majority."
            }
        },
        "mainMethod": {
            "type": "unsupervised",
            "technique": "rule-based"
        },
        "revision": {
            "type": "fully automated",
            "description": "End-to-end automated pipeline; final annotations selected by built-in selection modules without user edits."
        },
        "domain": {
            "domain": "independent",
            "type": "generic"
        },
        "validation": {
            "goldStandard": "SemTab2020 datasets (Rounds 1–4, incl. Tough Tables 2T)",
            "metrics": [
                "Precision",
                "Recall",
                "F1"
            ]
        },
        "code": "https://github.com/fusion-jena/JenTab",
        "license": "Apache License 2.0",
        "inputs": {
            "typeOfTable": "CSV",
            "tableSources": [
                "wiki"
            ]
        },
        "kg": {
            "tripleStore": "Wikidata",
            "index": "Wikidata Lookup API and SPARQL endpoint with cached/precomputed lookups"
        },
        "output": "CSV",
        "applicationPurpose": "Toolkit to annotate large table corpora to a KG for entity, type, and property linking and to benchmark STA strategies.",
        "userInterfaceTool": "Web UI (Manager dashboard) and distributed runners",
        "checkedByAuthor": "",
        "checkedByAi": true,
        "doi": "https://doi.org/10.5281/zenodo.4730314",
        "citations": [
            {
                "ref": "2019_nguyen_mtab",
                "title": "MTab: Matching Tabular Data to Knowledge Graph using Probability Models"
            },
            {
                "ref": "2020_nguyen_mtab4wikidata",
                "title": "MTab4Wikidata at SemTab 2020: Tabular Data Annotation with Wikidata"
            },
            {
                "ref": "2019_chabot_dagobah",
                "title": "DAGOBAH: An end-to-end context-free tabular data semantic annotation system"
            },
            {
                "ref": "2020_shigapov_bbw",
                "title": "bbw: Matching csv to wikidata via meta-lookup"
            },
            {
                "ref": "2020_kim_generating",
                "title": "Generating conceptual subgraph from tabular data for knowledge graph matching"
            },
            {
                "ref": "2020_jimenez-ruiz_semtab",
                "title": "SemTab 2019: Resources to benchmark tabular data to knowledge graph matching systems"
            },
            {
                "ref": "2020_hassanzadeh_semtab",
                "title": "SemTab 2020: Semantic Web Challenge on Tabular Data to Knowledge Graph Matching Data Sets"
            },
            {
                "ref": "2020_cutrona_tough",
                "title": "Tough Tables: Carefully Evaluating Entity Linking for Tabular Data"
            },
            {
                "ref": "2019_chen_colnet",
                "title": "ColNet: Embedding the semantics of web tables for column type prediction"
            },
            {
                "ref": "2017_efthymiou_matching",
                "title": "Matching Web Tables with Knowledge Base Entities: From Entity Lookups to Entity Embeddings"
            },
            {
                "ref": "2010_limaye_annotating",
                "title": "Annotating and searching web tables using entities, types and relationships"
            }
        ],
        "uncertainFields": [
            {
                "field": "doi",
                "reason": "Workshop paper appears in CEUR-WS (typically without DOIs); using the authors' Zenodo record cited for KGCW 2021."
            },
            {
                "field": "inputs.typeOfTable",
                "reason": "Assumed CSV as per SemTab distributions; not explicitly stated in the text."
            },
            {
                "field": "license",
                "reason": "Licence not specified in the paper; repository licence not verified here."
            },
            {
                "field": "kg.index",
                "reason": "Indexing described conceptually (lookup/SPARQL caches) without a specific named index."
            },
            {
                "field": "userInterfaceTool",
                "reason": "Manager dashboard is mentioned but UI details are minimal."
            },
            {
                "field": "output",
                "reason": "SemTab submissions are CSV; the paper does not explicitly name the output format."
            },
            {
                "field": "citations",
                "reason": "Only a subset of references included; full bibliography not exhaustively extracted from the PDF."
            }
        ]
    }
]
