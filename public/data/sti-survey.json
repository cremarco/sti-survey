[
  {
    "id": "hignette2007an",
    "firstAuthor": "Hignette",
    "authors": [
      "Gaëlle Hignette",
      "Patrice Buche",
      "Juliette Dibie-Barthélemy",
      "Ollivier Haemmerlé"
    ],
    "year": 2007,
    "title": {
      "text": "An Ontology-Driven Annotation of Data Tables",
      "link": ""
    },
    "added": "",
    "conferenceJournal": "WISE",
    "nameOfApproach": "",
    "mainMethod": {
      "type": "Unsupervised",
      "technique": "rule-based / ontology-driven"
    },
    "domain": {
      "domain": "Dependent",
      "type": "food microbiology"
    },
    "coreTasks": {
      "cta": true,
      "cpa": true,
      "cea": false,
      "cnea": false
    },
    "supportTasks": {
      "dataPreparation": {
        "description": "",
        "spellChecker": "",
        "unitsOfMeasurements": ""
      },
      "subjectDetection": "",
      "columnClassification": "Datatypes for each column are collected. The approach uses features of values defined in the ontology for numeric types to recognize the type of numeric columns, and the terms from the taxonomies of the symbolic types to recognize the type of symbolic columns. Column titles are also used to compute the score and choose the type of the column.",
      "typeAnnotation": "The approach links each cell in symbolic columns to its corresponding type in the ontology, using cosine similarity between weighted vectors. A set of candidate types is defined and a proportion is used to obtain the definitive cell type. Numeric cells' type is obtained by assigning a score to each possible numeric type, according to the cell content, and choosing the highest scoring.",
      "predicateAnnotation": "The approach identifies relations by computing a similarity score for each predicate/relation in the ontology according to the table title and the column types.  ",
      "datatypeAnnotation": "The approach uses a set of manually defined rules to identify each cell's datatype as numeric, symbolic or unknown. A column is classified as symbolic if there are more cells classified as symbolic than numeric, numeric otherwise.",
      "entityLinking": {
        "description": "",
        "candidateGeneration": "",
        "entityDisambiguation": ""
      },
      "nilAnnotation": ""
    },
    "revision": {
      "type": "None",
      "description": ""
    },
    "validation": "Custom GS, 60 tables",
    "codeAvailability": "",
    "license": "Not specified",
    "inputs": {
      "typeOfTable": "Web table",
      "kg": {
        "tripleStore": "Personal ontologies",
        "index": ""
      }
    },
    "output": "XML",
    "checkedByAuthor": true,
    "checkedByAi": true,
    "doi": "https://doi.org/10.1007/978-3-540-77010-7_4",
    "citations": [
      {
        "ref": "buche2005fuzzy",
        "title": "fuzzy querying of incomplete, imprecise, and heterogeneously structured data in the relational model using ontologies and rules."
      },
      {
        "ref": "zanibbi2004a",
        "title": "a survey of table recognition: models, observations, transformations, and inferences."
      },
      {
        "ref": "pivk2004from",
        "title": "from tables to frames."
      },
      {
        "ref": "tenier2006instantiation",
        "title": "instantiation of relations for semantic annotation."
      },
      {
        "ref": "embley2002automatically",
        "title": "automatically extracting ontologically specified data from html tables of unknown structure."
      },
      {
        "ref": "freitag2000boosted",
        "title": "boosted wrapper induction."
      },
      {
        "ref": "baumgartner2001visual",
        "title": "visual web information extraction with Lixto."
      },
      {
        "ref": "gagliardi2005an",
        "title": "an automatic ontology-based approach to enrich tables semantically."
      },
      {
        "ref": "lin1998an",
        "title": "an information-theoretic definition of similarity."
      },
      {
        "ref": "hignette2006fuzzy",
        "title": "fuzzy semantic approach for data integration applied to risk in food: an example about the cold chain."
      },
      {
        "ref": "vanrijsbergen1979information",
        "title": "information retrieval, 2nd edition."
      },
      {
        "ref": "yangarber2002unsupervised",
        "title": "unsupervised learning of generalized names."
      },
      {
        "ref": "platt1999fast",
        "title": "fast training of support vector machines using sequential minimal optimization."
      },
      {
        "ref": "zadeh1965fuzzy",
        "title": "fuzzy sets."
      }
    ]
  },
  {
    "id": "hignette2009fuzzy",
    "firstAuthor": "Hignette",
    "year": 2009,
    "title": {
      "text": "Fuzzy Annotation of Web Data Tables Driven by a Domain Ontology",
      "link": ""
    },
    "added": "",
    "conferenceJournal": "ESWC",
    "nameOfApproach": "@Web",
    "mainMethod": {
      "type": "Unsupervised",
      "technique": "ontology-driven fuzzy similarity"
    },
    "domain": {
      "domain": "Dependent",
      "type": "food microbiology, chemical risk, aeronautics"
    },
    "coreTasks": {
      "cta": true,
      "cpa": true,
      "cea": false,
      "cnea": false
    },
    "supportTasks": {
      "dataPreparation": {
        "description": "",
        "spellChecker": "",
        "unitsOfMeasurements": ""
      },
      "subjectDetection": "",
      "columnClassification": "Datatypes for each column are collected; the approach computes a score of each symbolic type of the ontology for the column. This score is a combination of the score of the type for the column according to the column contents and the score of the type for the column according to the column title.",
      "typeAnnotation": "The approach links each cell in symbolic columns to its corresponding type in the ontology, using cosine similarity between weighted vectors. A set of candidate types is defined and a proportion is used to obtain the definitive cell type. Numeric cells' type is obtained by assigning a score to each possible numeric type, according to the cell content, and choosing the highest scoring.",
      "predicateAnnotation": "The approach identifies relations by computing a similarity score for each predicate/relation in the ontology according to the table title and the column types. ",
      "datatypeAnnotation": "The approach uses a set of manually defined rules to identify each cell's datatype as numeric, symbolic or unknown. A column is classified as symbolic if there are more cells classified as symbolic than numeric, numeric otherwise.",
      "entityLinking": {
        "description": " ",
        "candidateGeneration": "",
        "entityDisambiguation": ""
      },
      "nilAnnotation": ""
    },
    "revision": {
      "type": "None",
      "description": ""
    },
    "validation": "Custom GS, 60 tables",
    "codeAvailability": "",
    "license": "Not specified",
    "inputs": {
      "typeOfTable": "Web table (XML)",
      "kg": {
        "tripleStore": "Personal ontologies",
        "index": ""
      }
    },
    "output": "RDF",
    "checkedByAuthor": false,
    "checkedByAi": true,
    "doi": "10.1007/978-3-642-02121-3_47",
    "authors": [
      "Gaëlle Hignette",
      "Patrice Buche",
      "Juliette Dibie-Barthélemy",
      "Ollivier Haemmerlé"
    ],
    "citations": [
      {
        "ref": "rahm2001a",
        "title": "A survey of approaches to automatic schema matching"
      },
      {
        "ref": "buche2008flexible",
        "title": "Flexible querying of fuzzy rdf annotations using fuzzy conceptual graphs"
      },
      {
        "ref": "doan2003learning",
        "title": "Learning to match the schemas of data sources: A multistrategy approach"
      },
      {
        "ref": "liu2007tableseer",
        "title": "Tableseer: automatic table metadata extraction and searching in digital libraries"
      },
      {
        "ref": "cafarella2008uncovering",
        "title": "Uncovering the relational web"
      },
      {
        "ref": "cafarella2008webtables",
        "title": "Webtables: exploring the power of tables on the web"
      },
      {
        "ref": "pivk2004from",
        "title": "From tables to frames"
      },
      {
        "ref": "tenier2006instantiation",
        "title": "Instantiation of relations for semantic annotation"
      },
      {
        "ref": "embley2002automatically",
        "title": "Automatically extracting ontologically specified data from HTML tables of unknown structure"
      },
      {
        "ref": "noy2006defining",
        "title": "Defining n-ary relations on the semantic web"
      },
      {
        "ref": "hignette2007an",
        "title": "An ontology-driven annotation of data tables"
      },
      {
        "ref": "vanrijsbergen1979information",
        "title": "Information Retrieval"
      },
      {
        "ref": "platt1999fast",
        "title": "Fast training of support vector machines using sequential minimal optimization"
      },
      {
        "ref": "gagliardi2005an",
        "title": "An automatic ontology-based approach to enrich tables semantically"
      },
      {
        "ref": "zadeh1965fuzzy",
        "title": "Fuzzy sets"
      },
      {
        "ref": "zadeh1978fuzzy",
        "title": "Fuzzy sets as a basis for a theory of possibility"
      },
      {
        "ref": "dubois1997the",
        "title": "The three semantics of fuzzy sets"
      },
      {
        "ref": "cliver2004foodborne",
        "title": "Foodborne infections and intoxications"
      }
    ]
  },
  {
    "firstAuthor": "Tao",
    "year": 2009,
    "title": {
      "text": "Automatic hidden-web table interpretation, conceptualization, and semantic annotation",
      "link": ""
    },
    "added": "",
    "conferenceJournal": "DKE",
    "nameOfApproach": "TISP++ (Table Interpretation with Sibling Pages and Semantic Annotation)",
    "mainMethod": {
      "type": "Unsupervised",
      "technique": "structural pattern induction from sibling pages (tree-matching + regex patterns)"
    },
    "domain": {
      "domain": "Independent",
      "type": ""
    },
    "coreTasks": {
      "cta": false,
      "cpa": false,
      "cea": false,
      "cnea": false
    },
    "supportTasks": {
      "dataPreparation": {
        "description": "",
        "spellChecker": "",
        "unitsOfMeasurements": ""
      },
      "subjectDetection": "",
      "columnClassification": " ",
      "typeAnnotation": "",
      "predicateAnnotation": " ",
      "datatypeAnnotation": "",
      "entityLinking": {
        "description": "",
        "candidateGeneration": "",
        "entityDisambiguation": ""
      },
      "nilAnnotation": ""
    },
    "revision": {
      "type": "None",
      "description": ""
    },
    "validation": "Custom GS, 2526 tables",
    "codeAvailability": "",
    "license": "Not specified",
    "inputs": {
      "typeOfTable": "HTML tables",
      "kg": {
        "tripleStore": "Personal ontologies",
        "index": ""
      }
    },
    "output": "RDF/XML (OWL ontology + page annotations)",
    "checkedByAuthor": false,
    "checkedByAi": true,
    "id": "tao2009automatic",
    "doi": "https://doi.org/10.1016/j.datak.2009.02.010",
    "authors": [
      "Cui Tao",
      "David W. Embley"
    ],
    "citations": [
      {
        "ref": "almuhammed2007ontology",
        "title": "Ontology Aware Software Service Agents: Meeting Ordinary User Needs on the Semantic Web"
      },
      {
        "ref": "arasu2003extracting",
        "title": "Extracting structured data from web pages"
      },
      {
        "ref": "buitelaar2004ontolt",
        "title": "Ontolt: a Protégé plug-in for ontology extraction from text based on linguistic analysis"
      },
      {
        "ref": "chen2000mining",
        "title": "Mining tables from large scale HTML texts"
      },
      {
        "ref": "cimiano2004towards",
        "title": "Towards the self-annotating web"
      },
      {
        "ref": "cimiano2005text2onto",
        "title": "Text2Onto—a framework for ontology learning and data-driven change discovery"
      },
      {
        "ref": "cohen2002a",
        "title": "A flexible learning system for wrapping tables and lists in HTML documents"
      },
      {
        "ref": "crescenzi2001roadrunner",
        "title": "RoadRunner: towards automatic data extraction from large web sites"
      },
      {
        "ref": "dill2003a",
        "title": "A case for automated large-scale semantic annotation"
      },
      {
        "ref": "ding2006automatic",
        "title": "Automatic creation and simplified querying of semantic web content: an approach based on information-extraction ontologies"
      },
      {
        "ref": "ding2007enriching",
        "title": "Enriching OWL with instance recognition semantics for automated semantic annotation"
      },
      {
        "ref": "dingli2003automatic",
        "title": "Automatic semantic annotation using unsupervised information extraction and integration"
      },
      {
        "ref": "w3c2005dom",
        "title": "The W3C Architecture Domain"
      },
      {
        "ref": "embley1989nfql",
        "title": "NFQL: the natural forms query language"
      },
      {
        "ref": "embley2006table",
        "title": "Table processing paradigms: a research survey"
      },
      {
        "ref": "embley2002automatically",
        "title": "Automatically extracting ontologically specified data from HTML tables with unknown structure"
      },
      {
        "ref": "embley2005automating",
        "title": "Automating the extraction of data from HTML tables with unknown structure"
      },
      {
        "ref": "gale1962college",
        "title": "College admissions and the stability of marriage"
      },
      {
        "ref": "gatterbauer2006table",
        "title": "Table extraction using spatial reasoning on the CSS2 visual box model"
      },
      {
        "ref": "gatterbauer2007towards",
        "title": "Towards domain-independent information extraction from web tables"
      },
      {
        "ref": "handschuh2002s",
        "title": "S-CREAM—Semi-automatic CREAtion of Metadata"
      },
      {
        "ref": "holzinger2006using",
        "title": "Using ontologies for extracting product features from web pages"
      },
      {
        "ref": "ipeirotis2001probe",
        "title": "Probe, count, and classify: categorizing hidden web databases"
      },
      {
        "ref": "jena2008jena",
        "title": "Jena—A Semantic Web Framework for Java"
      },
      {
        "ref": "kogut2001aerodaml",
        "title": "AeroDAML: Applying information extraction to generate DAML annotations from web pages"
      },
      {
        "ref": "lerman2004using",
        "title": "Using the structure of web sites for automatic segmentation of tables"
      },
      {
        "ref": "lim1999an",
        "title": "An automated approach for retrieving hierarchical data from HTML tables"
      },
      {
        "ref": "navigli2004quantitative",
        "title": "Quantitative and qualitative evaluation of the OntoLearn ontology learning system"
      },
      {
        "ref": "noy2001creating",
        "title": "Creating semantic web contents with Protégé-2000"
      },
      {
        "ref": "pivk2006automatic",
        "title": "Automatic ontology generation from web tabular structures"
      },
      {
        "ref": "pivk2004from",
        "title": "From tables to frames"
      },
      {
        "ref": "popov2004kima",
        "title": "KIM—a semantic platform for information extraction and retrieval"
      },
      {
        "ref": "sparql2008query",
        "title": "SPARQL Query Language for RDF"
      },
      {
        "ref": "spyns2002ontoweb",
        "title": "OntoWeb—a semantic web community portal"
      },
      {
        "ref": "tai1979the",
        "title": "The tree-to-tree correction problem"
      },
      {
        "ref": "tao2007automatic",
        "title": "Automatic hidden-web table interpretation by sibling page comparison"
      },
      {
        "ref": "tao2007seed",
        "title": "Seed-based generation of personalized bio-ontologies for information extraction"
      },
      {
        "ref": "tengli2004learning",
        "title": "Learning table extraction from examples"
      },
      {
        "ref": "tijerino2004toward",
        "title": "Toward ontology generation from tables"
      },
      {
        "ref": "vargas-vera2002mnm",
        "title": "MnM: Ontology driven semi-automatic and automatic support for semantic markup"
      },
      {
        "ref": "wang1996tabular",
        "title": "Tabular Abstraction, Editing, and Formatting"
      },
      {
        "ref": "wang2002a",
        "title": "A machine learning based approach for table detection on the web"
      },
      {
        "ref": "wang2006towards",
        "title": "Towards semi-automatic ontology building supported by large-scale knowledge acquisition"
      },
      {
        "ref": "wormbase2005worm",
        "title": "WormBase!"
      },
      {
        "ref": "xpath2006xml",
        "title": "XML Path Language (XPath)"
      },
      {
        "ref": "yang1991identifying",
        "title": "Identifying syntactic differences between two programs"
      },
      {
        "ref": "zanibbi2004a",
        "title": "A survey of table recognition"
      },
      {
        "ref": "zhai2005web",
        "title": "Web data extraction based on partial tree alignment"
      }
    ]
  },
  {
    "firstAuthor": "Limaye",
    "year": 2010,
    "title": {
      "text": "Annotating and Searching Web Tables Using Entities, Types and Relationships",
      "link": ""
    },
    "added": "",
    "conferenceJournal": "VLDB",
    "nameOfApproach": "",
    "mainMethod": {
      "type": "Supervised",
      "technique": "structured learning"
    },
    "domain": {
      "domain": "Independent",
      "type": ""
    },
    "coreTasks": {
      "cta": true,
      "cpa": true,
      "cea": true,
      "cnea": false
    },
    "supportTasks": {
      "dataPreparation": {
        "description": "",
        "spellChecker": "",
        "unitsOfMeasurements": ""
      },
      "subjectDetection": "",
      "columnClassification": " ",
      "typeAnnotation": "The approach defines a vector of features composed by TFIDF cosine similarity between label in the header and label of concept",
      "predicateAnnotation": "The approach defines a vector of features related to the presence and the frequency of the relation between the entities [C/R]",
      "datatypeAnnotation": "",
      "entityLinking": {
        "description": "The approach define a vector of features composed by different similary measure, TFIDF cosine similarity, Jaccard between cell content and label of the entity [c]",
        "candidateGeneration": "lookup, YAGO catalog",
        "entityDisambiguation": "features, similarity"
      },
      "nilAnnotation": ""
    },
    "revision": {
      "type": "Fully automated",
      "description": "It mesures the compatibility of the annotations using a new set features: inverse document frequency (IDF), similarity/distance between E and T."
    },
    "validation": "",
    "codeAvailability": "",
    "license": "Not specified",
    "inputs": {
      "typeOfTable": "Web Table",
      "kg": {
        "tripleStore": "Yago",
        "index": ""
      }
    },
    "output": "none",
    "checkedByAuthor": false,
    "checkedByAi": true,
    "id": "limaye2010annotating",
    "doi": "https://doi.org/10.14778/1920841.1921005",
    "authors": [
      "Girija Limaye",
      "Sunita Sarawagi",
      "Soumen Chakrabarti"
    ],
    "citations": [
      {
        "ref": "ahuja1993network",
        "title": "Network Flows: Theory, Algorithms, and Applications"
      },
      {
        "ref": "bilenko2003adaptive",
        "title": "Adaptive name-matching in information integration"
      },
      {
        "ref": "bunescu2006using",
        "title": "Using encyclopedic knowledge for named entity disambiguation"
      },
      {
        "ref": "bunescu2005a",
        "title": "A shortest path dependency kernel for relation extraction"
      },
      {
        "ref": "cafarella2008webtables",
        "title": "WebTables: exploring the power of tables on the Web"
      },
      {
        "ref": "cafarella2008uncovering",
        "title": "Uncovering the relational Web"
      },
      {
        "ref": "chakrabarti2006optimizing",
        "title": "Optimizing scoring functions and indexes for proximity search in type-annotated corpora"
      },
      {
        "ref": "cheng2007entityrank",
        "title": "EntityRank: Searching entities directly and holistically"
      },
      {
        "ref": "cucerzan2007large-scale",
        "title": "Large-scale named entity disambiguation based on Wikipedia data"
      },
      {
        "ref": "dill2003semtag",
        "title": "SemTag and Seeker: Bootstrapping the semantic Web via automated semantic annotation"
      },
      {
        "ref": "guha2003tap",
        "title": "TAP: A semantic web test-bed"
      },
      {
        "ref": "gupta2009answering",
        "title": "Answering table augmentation queries from unstructured lists on the Web"
      },
      {
        "ref": "koller2009probabilistic",
        "title": "Probabilistic Graphical Models: Principles and Techniques"
      },
      {
        "ref": "kulkarni2009collective",
        "title": "Collective annotation of Wikipedia entities in Web text"
      },
      {
        "ref": "mihalcea2007wikify",
        "title": "Wikify!: linking documents to encyclopedic knowledge"
      },
      {
        "ref": "miller1993five",
        "title": "Five papers on WordNet"
      },
      {
        "ref": "milne2008learning",
        "title": "Learning to link with Wikipedia"
      },
      {
        "ref": "salton1983introduction",
        "title": "Introduction to Modern Information Retrieval"
      },
      {
        "ref": "sarawagi2008information",
        "title": "Information extraction"
      },
      {
        "ref": "singh2009curating",
        "title": "Curating and searching the annotated web"
      },
      {
        "ref": "suchanek2007yago",
        "title": "YAGO: A core of semantic knowledge unifying WordNet and Wikipedia"
      },
      {
        "ref": "tsochantaridis2005large",
        "title": "Large margin methods for structured and interdependent output variables"
      }
    ]
  },
  {
    "firstAuthor": "Mulwad",
    "year": 2010,
    "title": {
      "text": "T2LD: Interpreting and Representing Tables as Linked Data⋆",
      "link": ""
    },
    "added": "",
    "conferenceJournal": "ISWC",
    "nameOfApproach": "T2LD",
    "mainMethod": {
      "type": "Supervised",
      "technique": "SVM"
    },
    "domain": {
      "domain": "Independent",
      "type": ""
    },
    "coreTasks": {
      "cta": true,
      "cpa": true,
      "cea": true,
      "cnea": true
    },
    "supportTasks": {
      "dataPreparation": {
        "description": "",
        "spellChecker": "",
        "unitsOfMeasurements": ""
      },
      "subjectDetection": "",
      "columnClassification": " ",
      "typeAnnotation": "KBs are queried (e.g. Wikitology, DBpedia) to identify the best classes for each column",
      "predicateAnnotation": "The approach generates a set of candidate relations from the relations that exist between the strings in each row of the columns. ",
      "datatypeAnnotation": "",
      "entityLinking": {
        "description": "An additional query to Wikitology is submitted to retrieve the proper entity, using the class labels from the column as additional evidence. The top N entities are returned; a feature vector is created for each cell and the vectors are ranked using a SVM-rank classifier. Then, the highest scoring feature vector is enriched and a second SVM classifier decides whether to link the table cell to the top ranked entity.",
        "candidateGeneration": "lookup, wikitology",
        "entityDisambiguation": "features, ML"
      },
      "nilAnnotation": "If the evidence is not strong enough, the SVM classifier marks the cell as a new entity not present in the KB, enabling discovery of new entities.”"
    },
    "revision": {
      "type": "None",
      "description": ""
    },
    "validation": "",
    "codeAvailability": "",
    "license": "Not specified",
    "inputs": {
      "typeOfTable": "Web tables",
      "kg": {
        "tripleStore": "Wikitology, DBpedia",
        "index": ""
      }
    },
    "output": "N3",
    "checkedByAuthor": false,
    "checkedByAi": true,
    "id": "mulwad2010t2ld",
    "doi": "https://doi.org/10.5555/2878399.2878406",
    "authors": [
      "Varish Mulwad",
      "Tim Finin",
      "Zareen Syed",
      "Anupam Joshi"
    ],
    "citations": [
      {
        "ref": "finin2010creating",
        "title": "Creating and Exploiting a Web of Semantic Data"
      },
      {
        "ref": "cafarella2008webtables",
        "title": "Webtables: exploring the power of tables on the web"
      },
      {
        "ref": "mulwad2010t2ld",
        "title": "T2LD - An automatic framework for extracting, interpreting and representing tables as Linked Data"
      },
      {
        "ref": "sahoo2009a",
        "title": "A survey of current approaches for mapping of relational databases to rdf"
      },
      {
        "ref": "han2008rdf123",
        "title": "RDF123: from Spreadsheets to RDF"
      },
      {
        "ref": "syed2010exploiting",
        "title": "Exploiting a Web of Semantic Data for Interpreting Tables"
      },
      {
        "ref": "mulwad2010using",
        "title": "Using linked data to interpret tables"
      }
    ]
  },
  {
    "firstAuthor": "Syed",
    "year": 2010,
    "title": {
      "text": "Exploiting a Web of Semantic Data for Interpreting Tables",
      "link": ""
    },
    "added": "",
    "conferenceJournal": "WSC",
    "nameOfApproach": "Wikitology",
    "mainMethod": {
      "type": "Unsupervised",
      "technique": "lookup"
    },
    "domain": {
      "domain": "Independent",
      "type": ""
    },
    "coreTasks": {
      "cta": true,
      "cpa": true,
      "cea": true,
      "cnea": false
    },
    "supportTasks": {
      "dataPreparation": {
        "description": "",
        "spellChecker": "",
        "unitsOfMeasurements": ""
      },
      "subjectDetection": "The column with the 'title' label is assumed as subject",
      "columnClassification": "",
      "typeAnnotation": "The class for the column is obtained from the entities class",
      "predicateAnnotation": "A set of relations between a pair of entities is returned by Wikitology. The relation that appears most often in the column is selected.",
      "datatypeAnnotation": "",
      "entityLinking": {
        "description": "Each instance in the table is mapped to the title and redirect field in Wikitology using an IR index based on Lucene (= the title of Wikipedia articles and redirects). The table header is mapped to types from YAGO, DBpedia, Freebase, WordNet. Entity mention and column header mapped to the firstSentence field (first sentence in Wikipedia). In this way, WIkitology returns the top N possible Wikipedia entities for each string",
        "candidateGeneration": "lookup, Wikitology",
        "entityDisambiguation": "features, contextual inf"
      },
      "nilAnnotation": ""
    },
    "revision": {
      "type": "None",
      "description": ""
    },
    "validation": "",
    "codeAvailability": "",
    "license": "Not specified",
    "inputs": {
      "typeOfTable": "Wikipedia tables",
      "kg": {
        "tripleStore": "Wikitology",
        "index": "Lucene for concepts"
      }
    },
    "output": "RDF",
    "checkedByAuthor": false,
    "checkedByAi": true,
    "id": "syed2010exploiting",
    "doi": "",
    "authors": [
      "Zareen Syed",
      "Tim Finin",
      "Varish Mulwad",
      "Anupam Joshi"
    ],
    "citations": [
      {
        "ref": "auer2007dbpedia",
        "title": "DBpedia: A Nucleus for a Web of Open Data"
      },
      {
        "ref": "bernerslee1989information",
        "title": "Information Management: A Proposal"
      },
      {
        "ref": "bizer2009the",
        "title": "The Emerging Web of Linked Data"
      },
      {
        "ref": "bizer2003d2r",
        "title": "D2R Map - A Database to RDF Mapping Language"
      },
      {
        "ref": "cafarella2008web",
        "title": "Web tables: Exploring the power of tables on the web"
      },
      {
        "ref": "ding2004swoogle",
        "title": "Swoogle: A Search and Metadata Engine for the Semantic Web"
      },
      {
        "ref": "etzioni2008open",
        "title": "Open Information Extraction from the Web"
      },
      {
        "ref": "finin2009using",
        "title": "Using Wikitology for cross-document entity coreference resolution"
      },
      {
        "ref": "finin2010creating",
        "title": "Creating and Exploiting a Web of Semantic Data"
      },
      {
        "ref": "google2009squared",
        "title": "Google Squared – http://www.google.com/squared"
      },
      {
        "ref": "halevy2009the",
        "title": "The Unreasonable Effectiveness of Data"
      },
      {
        "ref": "han2008rdf123",
        "title": "RDF123: from Spreadsheets to RDF"
      },
      {
        "ref": "han2009finding",
        "title": "Finding Semantic Web Ontology Terms from Words"
      },
      {
        "ref": "hatcher2004lucene",
        "title": "Lucene in Action"
      },
      {
        "ref": "hu2007measuring",
        "title": "Measuring Article Quality in Wikipedia: Models and Evaluation"
      },
      {
        "ref": "hu2007discovering",
        "title": "Discovering Simple Mappings Between Relational Database Schemas and Ontologies"
      },
      {
        "ref": "lenat1990building",
        "title": "Building Large Knowledge Bases"
      },
      {
        "ref": "mcnamee2009hltcoe",
        "title": "HLTCOE Approaches to Knowledge Base Population at TAC 2009"
      },
      {
        "ref": "mcnamee2009overview",
        "title": "Overview of the TAC 2009 knowledge base population track"
      },
      {
        "ref": "parr2007tools",
        "title": "Tools for generating OWL and RDF for biodiversity data in spreadsheets and unstructured text"
      },
      {
        "ref": "suchanek2008yago",
        "title": "Yago: A Large Ontology from Wikipedia and WordNet"
      },
      {
        "ref": "syed2008wikipedia",
        "title": "Wikipedia as an Ontology for Describing Documents"
      },
      {
        "ref": "vanoirbeek1992formatting",
        "title": "Formatting Structured Tables"
      },
      {
        "ref": "wu2008automatically",
        "title": "Automatically Refining the Wikipedia Infobox Ontology"
      },
      {
        "ref": "ziegler2004threedecades",
        "title": "Three Decades of Data Integration - All Problems Solved?"
      },
      {
        "ref": "fellbaum1998wordnet",
        "title": "WordNet: An Electronic Lexical Database"
      }
    ]
  },
  {
    "firstAuthor": "Mulwad",
    "year": 2011,
    "title": {
      "text": "Automatically Generating Government Linked Data from Tables",
      "link": ""
    },
    "added": "",
    "conferenceJournal": "AAAI",
    "nameOfApproach": "",
    "mainMethod": {
      "type": "Supervised",
      "technique": "Markov Network, PGM"
    },
    "domain": {
      "domain": "Independent",
      "type": ""
    },
    "coreTasks": {
      "cta": true,
      "cpa": true,
      "cea": true,
      "cnea": true
    },
    "supportTasks": {
      "dataPreparation": {
        "description": "",
        "spellChecker": "",
        "unitsOfMeasurements": ""
      },
      "subjectDetection": "",
      "columnClassification": " ",
      "typeAnnotation": "The algorithm determines the class for a table column based on the class of the individual strings in the column [C]",
      "predicateAnnotation": "The relation between entities that gets majority vote is chosen as the relation between the columns [R]",
      "datatypeAnnotation": "",
      "entityLinking": {
        "description": "Using the predicted class labels for column, the algorithm collect entities. For every entities they create a feature vector, which are ranked using a SVM Rank classifier [C]",
        "candidateGeneration": "lookup, wikitology",
        "entityDisambiguation": "features, ML"
      },
      "nilAnnotation": "These feature vectors are ranked using an SVM-Rank classifier. If the evidence is not strong enough, it suggests that the table cell represents a new entity not present in the \\ac{kg}, which is useful for discovering new entities in the table."
    },
    "revision": {
      "type": "Semi automated",
      "description": "Human in the loop"
    },
    "validation": "Custom GS, 15 tables",
    "codeAvailability": "",
    "license": "Not specified",
    "inputs": {
      "typeOfTable": "CSV, XML",
      "kg": {
        "tripleStore": "DBpedia,Freebase,WordNet,Yago",
        "index": ""
      }
    },
    "output": "N3",
    "checkedByAuthor": false,
    "checkedByAi": true,
    "id": "mulwad2011automatically",
    "doi": "",
    "authors": [
      "Varish Mulwad",
      "Tim Finin",
      "Anupam Joshi"
    ],
    "citations": [
      {
        "ref": "bizer2009dbpedia",
        "title": "Dbpedia - a crystallization point for the web of data"
      },
      {
        "ref": "bizer2009the",
        "title": "The emerging web of linked data"
      },
      {
        "ref": "brickley2004rdf",
        "title": "RDF Vocabulary Description Language 1.0: RDF Schema"
      },
      {
        "ref": "cafarella2008webtables",
        "title": "Webtables: exploring the power of tables on the web"
      },
      {
        "ref": "dataset2009dataset",
        "title": "Dataset 1425 - Census of Agriculture Race, Ethnicity and Gender Profile Data"
      },
      {
        "ref": "ding2010twc",
        "title": "Twc data-gov corpus: incrementally generating linked government data from data.gov"
      },
      {
        "ref": "han2008rdf123",
        "title": "RDF123: from Spreadsheets to RDF"
      },
      {
        "ref": "koller2009probabilistic",
        "title": "Probabilistic Graphical Models: Principles and Techniques"
      },
      {
        "ref": "langegger2009xlwrap",
        "title": "Xlwrap - querying and integrating arbitrary spreadsheets with sparql"
      },
      {
        "ref": "limaye2010annotating",
        "title": "Annotating and searching web tables using entities, types and relationships"
      },
      {
        "ref": "mulwad2010t2ld",
        "title": "T2LD: Interpreting and Representing Tables as Linked Data"
      },
      {
        "ref": "mulwad2010using",
        "title": "Using linked data to interpret tables"
      },
      {
        "ref": "sackett1996evidence",
        "title": "Evidence based medicine: what it is and what it isn’t"
      },
      {
        "ref": "sahoo2009a",
        "title": "A survey of current approaches for mapping of relational databases to rdf"
      },
      {
        "ref": "syed2011creating",
        "title": "Creating and Exploiting a Hybrid Knowledge Base for Linked Data"
      },
      {
        "ref": "syed2010exploiting",
        "title": "Exploiting a Web of Semantic Data for Interpreting Tables"
      },
      {
        "ref": "venetis2011recovering",
        "title": "Recovering semantics of tables on the web"
      },
      {
        "ref": "wang2011understanding",
        "title": "Understanding tables on the web"
      },
      {
        "ref": "wu2011towards",
        "title": "Towards a probabilistic taxonomy of many concepts"
      }
    ]
  },
  {
    "firstAuthor": "Venetis",
    "year": 2011,
    "title": {
      "text": "Recovering Semantics of Tables on the Web",
      "link": ""
    },
    "added": "",
    "conferenceJournal": "VLDB",
    "nameOfApproach": "",
    "mainMethod": {
      "type": "Unsupervised",
      "technique": "lookup"
    },
    "domain": {
      "domain": "Independent",
      "type": ""
    },
    "coreTasks": {
      "cta": true,
      "cpa": true,
      "cea": false,
      "cnea": false
    },
    "supportTasks": {
      "dataPreparation": {
        "description": "",
        "spellChecker": "",
        "unitsOfMeasurements": ""
      },
      "subjectDetection": "Using the SVM method we were able to identify the subject column in 94% of the tables.",
      "columnClassification": " ",
      "typeAnnotation": "The column label is retrieved based on the isA database (instance, class). The boundaries of potential class label in the text are obtained by using the TnT POS tagger; To find the best class for a column, they maximize the probbaility of the values given the class label for the column.",
      "predicateAnnotation": "Given two columns, they look for corresponding pairs of values in the columns. If the relation R is extracted for many rows, then R is a likely relation represented by the column. They use TextRunner to extract triples to build a relation database. ",
      "datatypeAnnotation": "",
      "entityLinking": {
        "description": "",
        "candidateGeneration": "",
        "entityDisambiguation": ""
      },
      "nilAnnotation": ""
    },
    "revision": {
      "type": "Semi automated",
      "description": "To create a gold standard for labeling tables, a random sample of tables was taken. Tables without any class or relation labels assigned by the Majority algorithm with a permissive labeling threshold of 10% (R10) were removed. Tables with incorrectly identified subject columns or lacking meaningful concepts were manually eliminated. The remaining 168 tables were presented to human annotators along with the labels generated by the R10 algorithm"
    },
    "validation": "Custom GS",
    "codeAvailability": "",
    "license": "Not specified",
    "inputs": {
      "typeOfTable": "HTML tables",
      "kg": {
        "tripleStore": "Yago",
        "index": ""
      }
    },
    "output": "none",
    "checkedByAuthor": false,
    "checkedByAi": true,
    "id": "venetis2011recovering",
    "doi": "https://doi.org/10.14778/2002938.2002939",
    "authors": [
      "Petros Venetis",
      "Alon Y. Halevy",
      "Jayant Madhavan",
      "Marius Pasca",
      "Warren Shen",
      "Fei Wu",
      "Gengxin Miao",
      "Chung Wu"
    ],
    "citations": [
      {
        "ref": "banko2007open",
        "title": "Open Information Extraction from the Web"
      },
      {
        "ref": "banko2008the",
        "title": "The Tradeoffs Between Open and Traditional Relation Extraction"
      },
      {
        "ref": "boser1992a",
        "title": "A training algorithm for optimal margin classifiers"
      },
      {
        "ref": "brants2000tnt",
        "title": "TnT — A Statistical Part of Speech Tagger"
      },
      {
        "ref": "cafarella2009data",
        "title": "Data Integration for the Relational Web"
      },
      {
        "ref": "cafarella2008webtables",
        "title": "WebTables: Exploring the Power of Tables on the Web"
      },
      {
        "ref": "cafarella2008uncovering",
        "title": "Uncovering the Relational Web"
      },
      {
        "ref": "carmel2009enhancing",
        "title": "Enhancing Cluster Labeling Using Wikipedia"
      },
      {
        "ref": "cutting1993constant",
        "title": "Constant Interaction-Time Scatter/Gather Browsing of Very Large Document Collections"
      },
      {
        "ref": "downey2005a",
        "title": "A Probabilistic Model of Redundancy in Information Extraction"
      },
      {
        "ref": "elmeleegy2009harvesting",
        "title": "Harvesting Relational Tables from Lists on the Web"
      },
      {
        "ref": "gupta2009answering",
        "title": "Answering Table Augmentation Queries from Unstructured Lists on the Web"
      },
      {
        "ref": "hearst1992automatic",
        "title": "Automatic Acquisition of Hyponyms from Large Text Corpora"
      },
      {
        "ref": "ipeirotis2010dbrank",
        "title": "DBRank"
      },
      {
        "ref": "ives2009interactive",
        "title": "Interactive Data Integration through Smart Copy & Paste"
      },
      {
        "ref": "kushmerick1997wrapper",
        "title": "Wrapper Induction for Information Extraction"
      },
      {
        "ref": "limaye2010annotating",
        "title": "Annotating and Searching Web Tables Using Entities, Types and Relationships"
      },
      {
        "ref": "lin2009phrase",
        "title": "Phrase Clustering for Discriminative Learning"
      },
      {
        "ref": "mitchell1997machine",
        "title": "Machine Learning"
      },
      {
        "ref": "pasca2010the",
        "title": "The Role of Queries in Ranking Labeled Instances Extracted from Text"
      },
      {
        "ref": "pasca2008weakly",
        "title": "Weakly-Supervised Acquisition of Open-Domain Classes and Class Attributes from Web Documents and Query Logs"
      },
      {
        "ref": "pantel2006espresso",
        "title": "Espresso: Leveraging Generic Patterns for Automatically Harvesting Semantic Relations"
      },
      {
        "ref": "pennacchiotti2009entity",
        "title": "Entity Extraction via Ensemble Semantics"
      },
      {
        "ref": "ponzetto2009large",
        "title": "Large-Scale Taxonomy Mapping for Restructuring and Integrating Wikipedia"
      },
      {
        "ref": "snow2006semantic",
        "title": "Semantic Taxonomy Induction from Heterogenous Evidence"
      },
      {
        "ref": "suchanek2007yago",
        "title": "YAGO: a Core of Semantic Knowledge Unifying WordNet and Wikipedia"
      },
      {
        "ref": "talukdar2008weakly",
        "title": "Weakly-Supervised Acquisition of Labeled Class Instances using Graph Random Walks"
      },
      {
        "ref": "treeratpituk2006automatically",
        "title": "Automatically Labeling Hierarchical Clusters"
      },
      {
        "ref": "wang2008iterative",
        "title": "Iterative Set Expansion of Named Entities Using the Web"
      },
      {
        "ref": "wang2009automatic",
        "title": "Automatic Set Instance Extraction using the Web"
      },
      {
        "ref": "wu2008automatically",
        "title": "Automatically Refining the Wikipedia Infobox Ontology"
      }
    ]
  },
  {
    "firstAuthor": "Goel",
    "year": 2012,
    "title": {
      "text": "Exploiting Structure within Data for Accurate Labeling using Conditional Random Fields",
      "link": ""
    },
    "added": "",
    "conferenceJournal": "ICAI",
    "nameOfApproach": "",
    "mainMethod": {
      "type": "Supervised",
      "technique": "CRF"
    },
    "domain": {
      "domain": "Dependent",
      "type": "Weather forecast, flight status and geocoding"
    },
    "coreTasks": {
      "cta": true,
      "cpa": true,
      "cea": false,
      "cnea": false
    },
    "supportTasks": {
      "dataPreparation": {
        "description": "Strings are split at whitespaces and the resulting tokens are split so that the resultant parts are purely alphabetic, numeric or a single simbol character.",
        "spellChecker": "",
        "unitsOfMeasurements": ""
      },
      "subjectDetection": "",
      "columnClassification": " ",
      "typeAnnotation": "The approach uses a contitional random field CRM to learn the labeling function, usign a graph structure of the features of every token. To predict the most likely label assignment to the field nodes they use Viterbi Algorithm.",
      "predicateAnnotation": "The accuracy also increases when we exploit the relationship between the field labels and the token labels.",
      "datatypeAnnotation": "",
      "entityLinking": {
        "description": "",
        "candidateGeneration": "",
        "entityDisambiguation": ""
      },
      "nilAnnotation": ""
    },
    "revision": {
      "type": "None",
      "description": ""
    },
    "validation": "",
    "codeAvailability": "",
    "license": "Not specified",
    "inputs": {
      "typeOfTable": "Web tables",
      "kg": {
        "tripleStore": "",
        "index": ""
      }
    },
    "output": "CRF graph",
    "checkedByAuthor": false,
    "checkedByAi": true,
    "id": "goel2012exploiting",
    "doi": "",
    "authors": [
      "Aman Goel",
      "Craig A. Knoblock",
      "Kristina Lerman"
    ],
    "citations": [
      {
        "ref": "borkar2001automatic",
        "title": "Automatic segmentation of text into structured records"
      },
      {
        "ref": "doan2000learning",
        "title": "Learning source descriptions for data integration"
      },
      {
        "ref": "kschischang2001factor",
        "title": "Factor graphs and the sum-product algorithm"
      },
      {
        "ref": "lafferty2001conditional",
        "title": "Conditional random fields: Probabilistic models for segmenting and labeling sequence data"
      },
      {
        "ref": "lauritzen1988local",
        "title": "Local computations with probabilities on graphical structures and their application to expert systems"
      },
      {
        "ref": "lerman2004using",
        "title": "Using the structure of web sites for automatic segmentation of tables"
      },
      {
        "ref": "lerman2006semantic",
        "title": "Semantic labeling of online information sources"
      },
      {
        "ref": "liu1989on",
        "title": "On the limited memory method for large scale optimization"
      },
      {
        "ref": "nadeau2007a",
        "title": "A survey of named entity recognition and classification"
      },
      {
        "ref": "pearl1988probabilistic",
        "title": "Probabilistic Reasoning in Intelligent Systems"
      },
      {
        "ref": "pinto2003table",
        "title": "Table extraction using conditional random fields"
      },
      {
        "ref": "rabiner1989a",
        "title": "A tutorial on hidden markov models and selected applications in speech recognition"
      },
      {
        "ref": "sha2003shallow",
        "title": "Shallow parsing with conditional random fields"
      },
      {
        "ref": "sutton2007dynamic",
        "title": "Dynamic conditional random fields: Factorized probabilistic models for labeling and segmenting sequence data"
      },
      {
        "ref": "tang2006tree-structured",
        "title": "Tree-structured conditional random fields for semantic annotation"
      },
      {
        "ref": "viterbi1967error",
        "title": "Error bounds for convolutional codes and an asymptotically optimum decoding algorithm"
      },
      {
        "ref": "zhu20052d",
        "title": "2d conditional random fields for web information extraction"
      }
    ]
  },
  {
    "firstAuthor": "Knoblock",
    "year": 2012,
    "title": {
      "text": "Semi-automatically Mapping Structured Sources into the Semantic Web",
      "link": ""
    },
    "added": "",
    "conferenceJournal": "ESWC",
    "nameOfApproach": "Karma",
    "mainMethod": {
      "type": "Supervised",
      "technique": "CRF"
    },
    "domain": {
      "domain": "Independent",
      "type": ""
    },
    "coreTasks": {
      "cta": true,
      "cpa": true,
      "cea": false,
      "cnea": false
    },
    "supportTasks": {
      "dataPreparation": {
        "description": "",
        "spellChecker": "",
        "unitsOfMeasurements": ""
      },
      "subjectDetection": "",
      "columnClassification": " ",
      "typeAnnotation": "The approach uses a contitional random field CRF to learn the labeling function. It uses a feature vector that characterizes the syntactic structure of the column name and the value.",
      "predicateAnnotation": "Using the concept annotation, it creates different nodes. For each pair of nodes, it extracts the relation between them from the KG. To identify the right predicate,they use a Stiner Tree Algorithm for computing the minimal tree.",
      "datatypeAnnotation": "",
      "entityLinking": {
        "description": "",
        "candidateGeneration": "",
        "entityDisambiguation": ""
      },
      "nilAnnotation": ""
    },
    "revision": {
      "type": "Semi automated",
      "description": "The user can select the correct annotation using the UI. The system  considers the changes oparated by the users."
    },
    "validation": "",
    "codeAvailability": "https://github.com/usc-isi-i2/Web-Karma",
    "license": "Apache 2.0",
    "inputs": {
      "typeOfTable": "Data sources Ontologies Semantic Types (training dataset)",
      "kg": {
        "tripleStore": "Personal ontologies",
        "index": ""
      }
    },
    "output": "Source model (used to generate RDF)",
    "checkedByAuthor": false,
    "authors": [
      "Craig A. Knoblock",
      "Pedro Szekely",
      "José Luis Ambite",
      "Aman Goel",
      "Shubham Gupta",
      "Kristina Lerman",
      "Maria Muslea",
      "Mohsen Taheriyan",
      "Parag Mallick"
    ],
    "checkedByAi": true,
    "id": "knoblock2012semiautomatically",
    "doi": "https://doi.org/10.1007/978-3-642-30284-8_32",
    "citations": [
      {
        "ref": "alexe2011designing",
        "title": "Designing and refining schema mappings via data examples"
      },
      {
        "ref": "an2007a",
        "title": "A semantic approach to discovering schema mapping expressions"
      },
      {
        "ref": "arenas2010relational",
        "title": "Relational and XML Data Exchange"
      },
      {
        "ref": "barrasarodriguez2006upgrading",
        "title": "Upgrading relational legacy data to the semantic web"
      },
      {
        "ref": "becker2010extending",
        "title": "Extending smw+ with a linked data integration framework"
      },
      {
        "ref": "bellahsene2011schema",
        "title": "Schema Matching and Mapping"
      },
      {
        "ref": "bizer2010the",
        "title": "The R2R Framework: Publishing and Discovering Mappings on the Web"
      },
      {
        "ref": "bizer2006d2r",
        "title": "D2R Server–publishing relational databases on the semantic web"
      },
      {
        "ref": "das2011r2rml",
        "title": "R2RML: RDB to RDF Mapping Language"
      },
      {
        "ref": "doan2000learning",
        "title": "Learning source descriptions for data integration"
      },
      {
        "ref": "fagin2009clio",
        "title": "Clio: Schema mapping creation and data exchange"
      },
      {
        "ref": "fink2008owl",
        "title": "Owl as a target for information extraction systems"
      },
      {
        "ref": "friedman1999navigational",
        "title": "Navigational plans for data integration"
      },
      {
        "ref": "goel2011using",
        "title": "Using conditional random fields to exploit token structure and labels for accurate semantic annotation"
      },
      {
        "ref": "halevy2001answering",
        "title": "Answering queries using views: A survey"
      },
      {
        "ref": "jentzsch2009enabling",
        "title": "Enabling tailored therapeutics with linked data"
      },
      {
        "ref": "kou1981a",
        "title": "A fast algorithm for steiner trees"
      },
      {
        "ref": "lafferty2001conditional",
        "title": "Conditional random fields: Probabilistic models for segmenting and labeling sequence data"
      },
      {
        "ref": "lerman2006semantic",
        "title": "Semantic labeling of online information sources"
      },
      {
        "ref": "massmann2011evolution",
        "title": "Evolution of the coma match system"
      },
      {
        "ref": "shvaiko2005a",
        "title": "A Survey of Schema-Based Matching Approaches"
      },
      {
        "ref": "spanos2011bringing",
        "title": "Bringing relational databases into the semantic web: A survey"
      },
      {
        "ref": "tuchinda2011building",
        "title": "Building mashups by demonstration"
      }
    ]
  },
  {
    "firstAuthor": "Pimplikar",
    "year": 2012,
    "title": {
      "text": "Answering Table Queries on the Web using Column Keywords",
      "link": ""
    },
    "added": "",
    "conferenceJournal": "VLDB",
    "nameOfApproach": "WWT",
    "mainMethod": {
      "type": "Unsupervised",
      "technique": "Probabilistic Graphical Model"
    },
    "domain": {
      "domain": "Independent",
      "type": ""
    },
    "coreTasks": {
      "cta": false,
      "cpa": false,
      "cea": false,
      "cnea": false
    },
    "supportTasks": {
      "dataPreparation": {
        "description": "",
        "spellChecker": "",
        "unitsOfMeasurements": ""
      },
      "subjectDetection": "",
      "columnClassification": " ",
      "typeAnnotation": "A unified approach based on graphical models to jointly label columns is proposed. Each column has to be labeled with one of the keywords in the query; a similarity score is computed between the keywords and the header tokens/the context of the table. The TF-IDF weighted cosine similarity is computed between the query term and the header. The sum of the soft-maxed match reliability of each term in the query weighted by the TF-IDF score of the term is the similarity between the term and the rest of the table.",
      "predicateAnnotation": " ",
      "datatypeAnnotation": "",
      "entityLinking": {
        "description": "",
        "candidateGeneration": "",
        "entityDisambiguation": ""
      },
      "nilAnnotation": ""
    },
    "revision": {
      "type": "None",
      "description": ""
    },
    "validation": "25 Million tables",
    "codeAvailability": "",
    "license": "Not specified",
    "inputs": {
      "typeOfTable": "HTML tables",
      "kg": {
        "tripleStore": "",
        "index": "Lucene"
      }
    },
    "output": "Table + URI",
    "checkedByAuthor": false,
    "checkedByAi": true,
    "id": "pimplikar2012answering",
    "doi": "https://doi.org/10.14778/2336664.2336665",
    "authors": [
      "Rakesh Pimplikar",
      "Sunita Sarawagi"
    ],
    "citations": [
      {
        "ref": "Boykov2001Fast",
        "title": "Fast approximate energy minimization via graph cuts"
      },
      {
        "ref": "Cafarella2009Data",
        "title": "Data integration for the relational web"
      },
      {
        "ref": "Cafarella2008Webtables",
        "title": "Webtables: exploring the power of tables on the web"
      },
      {
        "ref": "Cafarella2008Uncovering",
        "title": "Uncovering the relational web"
      },
      {
        "ref": "Chakrabarti2010Enhancing",
        "title": "Enhancing search with structure"
      },
      {
        "ref": "Chekuri2001Approximation",
        "title": "Approximation algorithms for the metric labeling problem via a new linear programming formulation"
      },
      {
        "ref": "Crestan2011Web-scale",
        "title": "Web-scale table census and classification"
      },
      {
        "ref": "Doan2005Semantic",
        "title": "Semantic integration research in the database community: A brief survey"
      },
      {
        "ref": "Gupta2009Answering",
        "title": "Answering table augmentation queries from unstructured lists on the web"
      },
      {
        "ref": "Koller2009Probabilistic",
        "title": "Probabilistic graphical models: principles and techniques"
      },
      {
        "ref": "Kolmogorov2006Convergent",
        "title": "Convergent tree-reweighted message passing for energy minimization"
      },
      {
        "ref": "Pantel2009Web-scale",
        "title": "Web-scale distributional similarity and entity set expansion"
      },
      {
        "ref": "Papadimitriou1982Combinatorial",
        "title": "Combinatorial optimization: algorithms and complexity"
      },
      {
        "ref": "Pinto2003Table",
        "title": "Table extraction using conditional random fields"
      },
      {
        "ref": "Pound2010Expressive",
        "title": "Expressive and flexible access to web-extracted data: A keyword-based structured query language"
      },
      {
        "ref": "Rahm2001A",
        "title": "A survey of approaches to automatic schema matching"
      },
      {
        "ref": "Sarkas2010Structured",
        "title": "Structured annotations of web queries"
      },
      {
        "ref": "Sontag2008Tightening",
        "title": "Tightening LP relaxations for MAP using message passing"
      },
      {
        "ref": "Szeliski2006A",
        "title": "A comparative study of energy minimization methods for markov random fields"
      },
      {
        "ref": "Washtell2009A",
        "title": "A comparison of windowless and window-based computational association measures as predictors of syntagmatic human associations"
      },
      {
        "ref": "Yu2010Keyword",
        "title": "Keyword search in relational databases: A survey"
      }
    ]
  },
  {
    "firstAuthor": "Wang",
    "year": 2012,
    "title": {
      "text": "Understanding Tables on the Web",
      "link": ""
    },
    "added": "",
    "conferenceJournal": "ER",
    "nameOfApproach": "",
    "mainMethod": {
      "type": "Unsupervised",
      "technique": "pattern matching"
    },
    "domain": {
      "domain": "Independent",
      "type": ""
    },
    "coreTasks": {
      "cta": true,
      "cpa": true,
      "cea": true,
      "cnea": false
    },
    "supportTasks": {
      "dataPreparation": {
        "description": "",
        "spellChecker": "",
        "unitsOfMeasurements": ""
      },
      "subjectDetection": "",
      "columnClassification": "For each column, a concept is derived based on the assumption that entities in a column should belong to the same concept. A candidate schema is generated according to the header of each column; for each schema in the candidate schema list, they enumerate every column and compute a confidence score (they use Probase)",
      "typeAnnotation": "For a given concept, Probase is used to find its entities and its attributes and viceversa",
      "predicateAnnotation": "pattern includes two main factors: the relation between entity and concept, and the relation between attribute and concept.",
      "datatypeAnnotation": "",
      "entityLinking": {
        "description": "It uses the Probase taxonomy which is a probabilistic taxonomy. Column type is used to filter candidates",
        "candidateGeneration": "pattern matching",
        "entityDisambiguation": "features"
      },
      "nilAnnotation": "we can expand Probase by incorporating this new evidence in the same way as we encounter a new Hearst's pattern."
    },
    "revision": {
      "type": "None",
      "description": ""
    },
    "validation": "Custom, 200 Wikipedia tables",
    "codeAvailability": "",
    "license": "Not specified",
    "inputs": {
      "typeOfTable": "HTML tables",
      "kg": {
        "tripleStore": "Probase",
        "index": ""
      }
    },
    "output": "Entity-Attribute-Value statements (one statement per table row)",
    "checkedByAuthor": false,
    "checkedByAi": true,
    "id": "wang2012understanding",
    "doi": "https://doi.org/10.1007/978-3-642-34002-4_11",
    "authors": [
      "Jingjing Wang",
      "Haixun Wang",
      "Zhongyuan Wang",
      "Kenny Q. Zhu"
    ],
    "citations": [
      {
        "ref": "wu2012probase",
        "title": "Probase: A probabilistic taxonomy for text understanding"
      },
      {
        "ref": "lee2011web",
        "title": "Web scale taxonomy cleansing"
      },
      {
        "ref": "zhang2012a",
        "title": "A system for extracting top-k lists from the web"
      },
      {
        "ref": "liu2012automatic",
        "title": "Automatic taxonomy construction from keywords"
      },
      {
        "ref": "singh2002open",
        "title": "Open Mind Common Sense: Knowledge Acquisition from the General Public"
      },
      {
        "ref": "bollacker2008freebase",
        "title": "Freebase: a collaboratively created graph database for structuring human knowledge"
      },
      {
        "ref": "hearst1992automatic",
        "title": "Automatic acquisition of hyponyms from large text corpora"
      },
      {
        "ref": "song2011short",
        "title": "Short text conceptualization using a probabilistic knowledgebase"
      },
      {
        "ref": "cafarella2008webtables",
        "title": "Webtables: Exploring the power of tables on the web"
      },
      {
        "ref": "wang2002a",
        "title": "A machine learning based approach for table detection on the web"
      },
      {
        "ref": "yoshida2001a",
        "title": "A method to integrate tables of the world wide web"
      },
      {
        "ref": "chen2000mining",
        "title": "Mining tables from large scale html texts"
      },
      {
        "ref": "cafarella2008uncovering",
        "title": "Uncovering the relational web"
      },
      {
        "ref": "yakout2012infogather",
        "title": "Infogather: entity augmentation and attribute discovery by holistic matching with web tables"
      },
      {
        "ref": "syed2010exploiting",
        "title": "Exploiting a web of semantic data for interpreting tables"
      },
      {
        "ref": "auer2007dbpedia",
        "title": "DBpedia: A Nucleus for a Web of Open Data"
      },
      {
        "ref": "limaye2010annotating",
        "title": "Annotating and searching web tables using entities, types and relationships"
      },
      {
        "ref": "venetis2011recovering",
        "title": "Recovering semantics of tables on the web"
      },
      {
        "ref": "pasca2007organizing",
        "title": "Organizing and searching the world wide web of facts - step two: Harnessing the wisdom of the crowds"
      },
      {
        "ref": "bellare2007lightlysupervised",
        "title": "Lightly-supervised attribute extraction"
      },
      {
        "ref": "elmeleegy2009harvesting",
        "title": "Harvesting relational tables from lists on the web"
      },
      {
        "ref": "he2011seisa",
        "title": "Seisa: set expansion by iterative similarity aggregation"
      },
      {
        "ref": "pyreddy1997tintin",
        "title": "Tintin: A system for retrieval in text tables"
      },
      {
        "ref": "pinto2003table",
        "title": "Table extraction using conditional random fields"
      }
    ]
  },
  {
    "firstAuthor": "Buche",
    "year": 2013,
    "title": {
      "text": "Fuzzy Web Data Tables Integration Guided by an Ontological and Terminological Resource",
      "link": ""
    },
    "added": "",
    "conferenceJournal": "IEEE",
    "nameOfApproach": "ONDINE",
    "mainMethod": {
      "type": "Unsupervised",
      "technique": "lookup"
    },
    "domain": {
      "domain": "Independent",
      "type": "microbial risk, chemical risk, aeronautics"
    },
    "coreTasks": {
      "cta": true,
      "cpa": true,
      "cea": true,
      "cnea": true
    },
    "supportTasks": {
      "dataPreparation": {
        "description": "Retrieval of relevant Web documents and filtering by a human expert.",
        "spellChecker": "",
        "unitsOfMeasurements": "Units identified via Ontological and Terminological Resource (OTR)."
      },
      "subjectDetection": "Semi-automatic extraction of data tables from filtered Web documents.",
      "columnClassification": "Distinction between symbolic and numerical columns",
      "typeAnnotation": "A score for each column is computed leveraging: 1. The column title; 2. The column content (computed as term similarity between the terms in the column and the terms in the OTR). wrt the concepts that appear in the signature of the relations belonging to the OTR.",
      "predicateAnnotation": "Each relation in the OTR is scored, using a proportion of simple concepts in the signature of the relation which are represented by columns in the table.",
      "datatypeAnnotation": "Symbolic and numerical columns are distinguished, using knowledge in an Ontological and Terminological Resource (OTR) i.e., unit concepts. ",
      "entityLinking": {
        "description": "",
        "candidateGeneration": "Term similarity–based generation of concept candidates.",
        "entityDisambiguation": "Selection of top fuzzy matches for manual validation."
      },
      "nilAnnotation": "Annotation of unrecognized cells as nil based on threshold."
    },
    "revision": {
      "type": "None",
      "description": ""
    },
    "validation": "Custom, 90 tables",
    "codeAvailability": "",
    "license": "Not specified",
    "inputs": {
      "typeOfTable": "Domain specific Web tables",
      "kg": {
        "tripleStore": "Custom XML/RDF repository",
        "index": "SPARQL index"
      }
    },
    "output": "XML documents representing data tables; RDF annotations",
    "checkedByAuthor": false,
    "checkedByAi": true,
    "id": "buche2013fuzzy",
    "doi": "https://doi.org/10.1109/TKDE.2011.245",
    "authors": [
      "Patrice Buche",
      "Juliette Dibie-Barthelemy",
      "Liliana Ibanescu",
      "Lydie Soler"
    ],
    "citations": [
      {
        "ref": "buche2000towards",
        "title": "Towards a Unified Querying System of Both Structured and Semi-Structured Imprecise Data Using Fuzzy Views"
      },
      {
        "ref": "buche2005fuzzy",
        "title": "Fuzzy Querying of Incomplete, Imprecise, and Heterogeneously Structured Data in the Relational Model Using Ontologies and Rules"
      },
      {
        "ref": "hignette2007an",
        "title": "An Ontology-Driven Annotation of Data Tables"
      },
      {
        "ref": "hignette2009fuzzy",
        "title": "Fuzzy Annotation of Web Data Tables Driven by a Domain Ontology"
      },
      {
        "ref": "buche2009flexible",
        "title": "Flexible Sparql Querying of Web Data Tables Driven by an Ontology"
      },
      {
        "ref": "cimiano2011lexinfo",
        "title": "Lexinfo: A Declarative Model for the Lexicon-Ontology Interface"
      },
      {
        "ref": "mccrae2011linking",
        "title": "Linking Lexical Resources and Ontologies on the Semantic Web with Lemon"
      },
      {
        "ref": "declerck2010towards",
        "title": "Towards a Standardized Linguistic Annotation of the Textual Content of Labels in Knowledge Representation Systems"
      },
      {
        "ref": "reymonet2007modelling",
        "title": "Modelling Ontological and Terminological Resources in OWL DL"
      },
      {
        "ref": "roche2009ontoterminology",
        "title": "Ontoterminology - A New Paradigm for Terminology"
      },
      {
        "ref": "reymonet2009ontology",
        "title": "Ontology Based Information Retrieval: An Application to Automotive Diagnosis"
      },
      {
        "ref": "noy2012defining",
        "title": "Defining N-ary Relations on the Semantic Web W3C Working Group Note"
      },
      {
        "ref": "yangarber2002unsupervised",
        "title": "Unsupervised Learning of Generalized Names"
      },
      {
        "ref": "vanrijsbergen1979information",
        "title": "Information Retrieval"
      },
      {
        "ref": "platt1999fast",
        "title": "Fast Training of Support Vector Machines Using Sequential Minimal Optimization"
      },
      {
        "ref": "zadeh1965fuzzy",
        "title": "Fuzzy Sets"
      },
      {
        "ref": "zadeh1978fuzzy",
        "title": "Fuzzy Sets as a Basis for a Theory of Possibility"
      },
      {
        "ref": "dubois1997three",
        "title": "The Three Semantics of Fuzzy Sets"
      },
      {
        "ref": "dubois1988possibility",
        "title": "Possibility Theory - An Approach to Computerized Processing of Uncertainty"
      },
      {
        "ref": "baziz2006fuzzy",
        "title": "A Fuzzy Logic Approach to Information Retrieval Using a Ontology-Based Representation of Documents"
      },
      {
        "ref": "liu2007tableseer",
        "title": "Tableseer: Automatic Table Metadata Extraction and Searching in Digital Libraries"
      },
      {
        "ref": "cafarella2008uncovering",
        "title": "Uncovering the Relational Web"
      },
      {
        "ref": "cafarella2008webtables",
        "title": "Webtables: Exploring the Power of Tables on the Web"
      },
      {
        "ref": "vanassem2010converting",
        "title": "Converting and Annotating Quantitative Data Tables"
      },
      {
        "ref": "tenier2006instantiation",
        "title": "Instantiation of Relations for Semantic Annotation"
      },
      {
        "ref": "embley2002automatically",
        "title": "Automatically Extracting Ontologically Specified Data from HTML Tables of Unknown Structure"
      },
      {
        "ref": "campi2006fuzzy",
        "title": "A Fuzzy Extension for the Xpath Query Language"
      },
      {
        "ref": "hutardo2006relaxed",
        "title": "A Relaxed Approach to Rdf Querying"
      },
      {
        "ref": "corby2006searching",
        "title": "Searching the Semantic Web: Approximate Query Processing Based on Ontologies"
      },
      {
        "ref": "pan2008scalable",
        "title": "Scalable Querying Services over Fuzzy Ontologies"
      },
      {
        "ref": "buche2011flexible",
        "title": "Flexible Querying of Web Data to Simulate Bacterial Growth in Food"
      },
      {
        "ref": "rijgersberg2011how",
        "title": "How Semantics Can Improve Engineering Processes: A Case of Units Measure and Quantities"
      }
    ]
  },
  {
    "firstAuthor": "Cruz",
    "year": 2013,
    "title": {
      "text": "GIVA: A Semantic Framework for Geospatial and Temporal Data Integration, Visualization, and Analytics",
      "link": ""
    },
    "added": "",
    "conferenceJournal": "SIGSPATIAL",
    "nameOfApproach": "GIVA",
    "mainMethod": {
      "type": "Supervised",
      "technique": "AgreementMaker"
    },
    "domain": {
      "domain": "Dependent",
      "type": "Geospatial and Temporal Data Integration, Visualization, and Analytics"
    },
    "coreTasks": {
      "cta": true,
      "cpa": true,
      "cea": false,
      "cnea": false
    },
    "supportTasks": {
      "dataPreparation": {
        "description": "They translate the data into a common spatial data format.",
        "spellChecker": "",
        "unitsOfMeasurements": ""
      },
      "subjectDetection": "",
      "columnClassification": "They use string matching on the column header and perform random sampling on the values to find pattern similarities (to identify the column that contains spatial data).",
      "typeAnnotation": "",
      "predicateAnnotation": "Geospatial classification schemes can be modeles using a part-of or is-a relationship",
      "datatypeAnnotation": "",
      "entityLinking": {
        "description": "",
        "candidateGeneration": "",
        "entityDisambiguation": ""
      },
      "nilAnnotation": ""
    },
    "revision": {
      "type": "None",
      "description": ""
    },
    "validation": "",
    "codeAvailability": "",
    "license": "Not specified",
    "inputs": {
      "typeOfTable": "GML, KML, Shapefile, MapInfo TAB, HTML table, CSV, TSV",
      "kg": {
        "tripleStore": "OWLIM",
        "index": ""
      }
    },
    "output": "RDF",
    "checkedByAuthor": false,
    "checkedByAi": true,
    "id": "cruz2013giva",
    "doi": "https://doi.org/10.1145/2525314.2525324",
    "authors": [
      "Isabel F. Cruz",
      "Venkat R. Ganesh",
      "Claudio Caletti",
      "Pavan Reddy"
    ],
    "citations": [
      {
        "ref": "abiteboul1999tools",
        "title": "Tools for Data Translation and Integration"
      },
      {
        "ref": "cruz2012automatic",
        "title": "Automatic Configuration Selection Using Ontology Matching Task Profiling"
      },
      {
        "ref": "cruz2009agreementmaker",
        "title": "AgreementMaker: Efficient Matching for Large Real-World Schemas and Ontologies"
      },
      {
        "ref": "cruz2008structural",
        "title": "Structural Alignment Methods with Applications to Geospatial Ontologies"
      },
      {
        "ref": "cruz2009ontology",
        "title": "Ontology Driven Data Integration in Heterogeneous Networks"
      },
      {
        "ref": "dellavalle2010the",
        "title": "The Experience of Realizing a Semantic Web Urban Computing Application"
      },
      {
        "ref": "gdal2013gdal",
        "title": "GDAL - Geospatial Data Abstraction Library, Version 1.10.0"
      },
      {
        "ref": "hall2009the",
        "title": "The WEKA Data Mining Software: An Update"
      },
      {
        "ref": "kennedy2011the",
        "title": "The Study of Urban Metabolism and its Applications to Urban Planning and Design"
      },
      {
        "ref": "kiryakov2005owlim–a",
        "title": "OWLIM–A Pragmatic Semantic Repository for OWL"
      },
      {
        "ref": "knoblock2012semiautomatically",
        "title": "Semi-automatically Mapping Structured Sources into the Semantic Web"
      },
      {
        "ref": "maceachren1997exploratory",
        "title": "Exploratory Cartographic Visualization: Advancing the Agenda"
      },
      {
        "ref": "mccurley2001geospatial",
        "title": "Geospatial Mapping and Navigation of the Web"
      },
      {
        "ref": "middel2007a",
        "title": "A Framework for Visualizing Multivariate Geodata"
      },
      {
        "ref": "pfoser2005indeterminacy",
        "title": "Indeterminacy and Spatiotemporal Data: Basic Definitions and Case Study"
      },
      {
        "ref": "quinlan1993c4.5",
        "title": "C4.5: Programs for Machine Learning"
      },
      {
        "ref": "rishe2011geospatial",
        "title": "Geospatial Data Management with TerraFly"
      },
      {
        "ref": "wiegand2002querying",
        "title": "Querying Heterogeneous Land Use Data: Problems and Potential"
      },
      {
        "ref": "worboys1998computation",
        "title": "Computation with Imprecise Geospatial Data"
      }
    ]
  },
  {
    "firstAuthor": "Deng",
    "year": 2013,
    "title": {
      "text": "Scalable Column Concept Determination for Web Tables Using Large Knowledge Bases",
      "link": ""
    },
    "added": "",
    "conferenceJournal": "VLDB",
    "nameOfApproach": "",
    "mainMethod": {
      "type": "Unsupervised",
      "technique": "MapReduce-based similarity join"
    },
    "domain": {
      "domain": "Independent",
      "type": ""
    },
    "coreTasks": {
      "cta": true,
      "cpa": false,
      "cea": false,
      "cnea": false
    },
    "supportTasks": {
      "dataPreparation": {
        "description": "Compute signatures for entities and cell values using q-grams or prefix signatures in MapReduce",
        "spellChecker": "",
        "unitsOfMeasurements": ""
      },
      "subjectDetection": "",
      "columnClassification": " ",
      "typeAnnotation": "A similarity score between the column and the identified types is computed. They extend the MapReduce-based similarity joins to support scalable column concept determination. 1. For each column, the list of types that share at least one entity/cell  value with the column; 2. Compute top-k types of every column; 3. Compute the overlap similarity. Both exact-matching and fuzzy-matching similarity functions are employed.",
      "predicateAnnotation": " ",
      "datatypeAnnotation": "",
      "entityLinking": {
        "description": "Perform both exact and fuzzy matching between cell values and knowledge-base entities",
        "candidateGeneration": "Generate candidate entity matches via signature-based similarity (q-grams/prefixes)",
        "entityDisambiguation": "Compute maximum bipartite matching on (cell value, entity) pairs to disambiguate assignments"
      },
      "nilAnnotation": ""
    },
    "revision": {
      "type": "None",
      "description": ""
    },
    "validation": "",
    "codeAvailability": "",
    "license": "Not specified",
    "inputs": {
      "typeOfTable": "Web",
      "kg": {
        "tripleStore": "DBpedia, Freebase, Yago",
        "index": "Inverted index mapping entities to types"
      }
    },
    "output": "",
    "checkedByAuthor": false,
    "checkedByAi": true,
    "id": "deng2013scalable",
    "doi": "https://doi.org/10.14778/2536258.2536271",
    "authors": [
      "Dong Deng",
      "Yu Jiang",
      "Guoliang Li",
      "Jian Li",
      "Cong Yu"
    ],
    "citations": [
      {
        "ref": "abiteboul2012viewing",
        "title": "Viewing the web as a distributed knowledge base"
      },
      {
        "ref": "arasu2006efficient",
        "title": "Efficient exact set-similarity joins"
      },
      {
        "ref": "auer2007dbpedia",
        "title": "Dbpedia: A nucleus for a web of open data"
      },
      {
        "ref": "bloom1970space",
        "title": "Space/time trade-offs in hash coding with allowable errors"
      },
      {
        "ref": "bollacker2008freebase",
        "title": "Freebase: a collaboratively created graph database for structuring human knowledge"
      },
      {
        "ref": "cafarella2008webtables",
        "title": "Webtables: exploring the power of tables on the web"
      },
      {
        "ref": "chaudhuri2003robust",
        "title": "Robust and efficient fuzzy match for online data cleaning"
      },
      {
        "ref": "dean2004mapreduce",
        "title": "Mapreduce: Simplified data processing on large clusters"
      },
      {
        "ref": "elmeleegy2009harvesting",
        "title": "Harvesting relational tables from lists on the web"
      },
      {
        "ref": "google2012introducing",
        "title": "Introducing knowledge graph"
      },
      {
        "ref": "gravano2001approximate",
        "title": "Approximate string joins in a database (almost) for free"
      },
      {
        "ref": "guo2011item",
        "title": "ITEM: Extract and integrate entities from tabular data to RDF knowledge base"
      },
      {
        "ref": "gupta2009answering",
        "title": "Answering table augmentation queries from unstructured lists on the web"
      },
      {
        "ref": "han2008rdf123",
        "title": "Rdf123: From spreadsheets to rdf"
      },
      {
        "ref": "hignette2009fuzzy",
        "title": "Fuzzy annotation of web data tables driven by a domain ontology"
      },
      {
        "ref": "karypis1999multilevel",
        "title": "Multilevel k-way hypergraph partitioning"
      },
      {
        "ref": "kim2012parallel",
        "title": "Parallel top-k similarity join algorithms using mapreduce"
      },
      {
        "ref": "li2011pass-join",
        "title": "Pass-join: A partition-based method for similarity joins"
      },
      {
        "ref": "limaye2010annotating",
        "title": "Annotating and searching web tables using entities, types and relationships"
      },
      {
        "ref": "ling2013synthesizing",
        "title": "Synthesizing union tables from the web"
      },
      {
        "ref": "metwally2012v-smart-join",
        "title": "V-smart-join: A scalable mapreduce framework for all-pair similarity joins of multisets and vectors"
      },
      {
        "ref": "pimplikar2012answering",
        "title": "Answering table queries on the web using column keywords"
      },
      {
        "ref": "quercini2013entity",
        "title": "Entity discovery and annotation in tables"
      },
      {
        "ref": "sarawagi2004efficient",
        "title": "Efficient set joins on similarity predicates"
      },
      {
        "ref": "shanmugasund.2004payload",
        "title": "Payload attribution via hierarchical bloom filters"
      },
      {
        "ref": "suchanek2007yago",
        "title": "Yago: a core of semantic knowledge"
      },
      {
        "ref": "vanassem2010converting",
        "title": "Converting and annotating quantitative data tables"
      },
      {
        "ref": "venetis2011recovering",
        "title": "Recovering semantics of tables on the web"
      },
      {
        "ref": "vernica2010efficient",
        "title": "Efficient parallel set-similarity joins using mapreduce"
      },
      {
        "ref": "wang2010trie-join",
        "title": "Trie-join: Efficient trie-based string similarity joins with edit-distance constraints"
      },
      {
        "ref": "wang2011fast-join",
        "title": "Fast-join: An efficient method for fuzzy token matching based string similarity join"
      },
      {
        "ref": "wang2012can",
        "title": "Can we beat the prefix filtering?: an adaptive framework for similarity join and search"
      },
      {
        "ref": "wang2012understanding",
        "title": "Understanding tables on the web"
      },
      {
        "ref": "wu2012probase",
        "title": "Probase: a probabilistic taxonomy for text understanding"
      },
      {
        "ref": "xiao2008ed-join",
        "title": "Ed-join: an efficient algorithm for similarity joins with edit distance constraints"
      },
      {
        "ref": "xiao2008efficient",
        "title": "Efficient similarity joins for near duplicate detection"
      },
      {
        "ref": "yakout2012infogather",
        "title": "Infogather: entity augmentation and attribute discovery by holistic matching with web tables"
      },
      {
        "ref": "yu2012towards",
        "title": "Towards a high quality and web-scalable table search engine"
      }
    ]
  },
  {
    "firstAuthor": "Ermilov",
    "year": 2013,
    "title": {
      "text": "User-driven Semantic Mapping of Tabular Data",
      "link": ""
    },
    "added": "",
    "conferenceJournal": "I-SEMANTICS",
    "nameOfApproach": "CSV2RDF",
    "mainMethod": {
      "type": "Unsupervised",
      "technique": "pattern"
    },
    "domain": {
      "domain": "Independent",
      "type": ""
    },
    "coreTasks": {
      "cta": false,
      "cpa": true,
      "cea": false,
      "cnea": false
    },
    "supportTasks": {
      "dataPreparation": {
        "description": "",
        "spellChecker": "",
        "unitsOfMeasurements": ""
      },
      "subjectDetection": "",
      "columnClassification": " ",
      "typeAnnotation": "",
      "predicateAnnotation": " ",
      "datatypeAnnotation": "",
      "entityLinking": {
        "description": "",
        "candidateGeneration": "",
        "entityDisambiguation": ""
      },
      "nilAnnotation": ""
    },
    "revision": {
      "type": "Semi automated",
      "description": "The RDF mapping obtained from Sparqlify-CSV. A page is created for each resource on the mappings wiki, which uses the Semantic MediaWiki extension to allow for semantic annotations over the content of such pages."
    },
    "validation": "",
    "codeAvailability": "",
    "license": "Not specified",
    "inputs": {
      "typeOfTable": "CSV, TSV, XLS, XLSX",
      "kg": {
        "tripleStore": "none",
        "index": ""
      }
    },
    "output": "RDF",
    "checkedByAuthor": false,
    "checkedByAi": true,
    "id": "ermilov2013user",
    "doi": "https://doi.org/10.1145/2506182.2506196",
    "authors": [
      "Ivan Ermilov",
      "Sören Auer",
      "Claus Stadler"
    ],
    "citations": [
      {
        "ref": "auer2009triplify",
        "title": "Triplify: Light-weight linked data publication from relational databases"
      },
      {
        "ref": "bernerslee1998relational",
        "title": "Relational databases on the semantic web"
      },
      {
        "ref": "ding2009the",
        "title": "The data-gov wiki: A semantic web portal for linked government data"
      },
      {
        "ref": "ding2011twc",
        "title": "TWC LOGD: A portal for linked open government data ecosystems"
      },
      {
        "ref": "hurst2000the",
        "title": "The Interpretation of Tables in Texts"
      },
      {
        "ref": "kroetzsch2007semantic",
        "title": "Semantic wikipedia"
      },
      {
        "ref": "lebo2010converting",
        "title": "Converting governmental datasets into linked data"
      },
      {
        "ref": "maali2010enabling",
        "title": "Enabling interoperability of government data catalogues"
      },
      {
        "ref": "maali2012a",
        "title": "A publishing pipeline for linked government data"
      },
      {
        "ref": "mulwad2011automatically",
        "title": "Automatically Generating Government Linked Data from Tables"
      },
      {
        "ref": "pivk2007transforming",
        "title": "Transforming arbitrary tables into logical form with TARTAR"
      }
    ]
  },
  {
    "firstAuthor": "Mulwad",
    "year": 2013,
    "title": {
      "text": "Semantic Message Passing for Generating Linked Data from Tables",
      "link": ""
    },
    "added": "",
    "conferenceJournal": "ISWC",
    "nameOfApproach": "Semantic Message Passing",
    "mainMethod": {
      "type": "Supervised",
      "technique": "Markov Network"
    },
    "domain": {
      "domain": "Independent",
      "type": ""
    },
    "coreTasks": {
      "cta": true,
      "cpa": true,
      "cea": true,
      "cnea": false
    },
    "supportTasks": {
      "dataPreparation": {
        "description": "Acronyms are expanded and stylized literal values (e.g. phone numbers) are recognized",
        "spellChecker": "",
        "unitsOfMeasurements": ""
      },
      "subjectDetection": "",
      "columnClassification": "The query and rank module identifies a list of possible candidate assignments using data from DBpedia, YAGO and Wikitology. The column potential classes are the union of the classes of its cells (from DBpedia and YAGO).",
      "typeAnnotation": "The initial entities assigned to a column's cell values perform a majority voting over the YAGO and DBpedia class set to pick the top YAGO and DBpedia class. Each entity votes and increments the score of a class; the YAGO and DBpedia sets are then ordered and the top classes are considered. Each class is assigned a confidence score; if the score is below a certain threshold, the column header is assigned to NO-ANNOTATION",
      "predicateAnnotation": "The approach uses the links between pairs of entities to generate candidate relations. For a pair of cell values in the same row between two columns, the candidate entity sets for both cells are obtained. For each possible pairing, YAGO and DBpedia are queried to obtain relations in either direction. Also, relations between columns are considered.",
      "datatypeAnnotation": "We use a regular expression to distinguish string mentions, which probably refer to entities, and literal constants such as numbers and measurements, which probably do not. If the cell value is a literal constant,candidate entities are not generated and the cell is mapped to no-annotation.",
      "entityLinking": {
        "description": "A set of candidate entities for each cell is generated using Wikitology (which uses DBpedia, Wikipedia and YAGO). An entity ranker re-ranks a cell's candidate entities using an approach mutuated from literature. ",
        "candidateGeneration": "lookup, wikitology",
        "entityDisambiguation": "Naive Bayes classifier con feature di string-similarity e popularity"
      },
      "nilAnnotation": ""
    },
    "revision": {
      "type": "None",
      "description": ""
    },
    "validation": "Web Manual, Web Relation, Wiki Manual, Wiki Links",
    "codeAvailability": "",
    "license": "Not specified",
    "inputs": {
      "typeOfTable": "Web and Wikipedia HTML tables",
      "kg": {
        "tripleStore": "DBpedia,Yago,Wikitology",
        "index": ""
      }
    },
    "output": "RDF",
    "checkedByAuthor": false,
    "checkedByAi": true,
    "id": "mulwad2013semantic",
    "doi": "https://doi.org/10.1007/978-3-642-41338-4_22",
    "authors": [
      "Varish Mulwad",
      "Tim Finin",
      "Anupam Joshi"
    ],
    "citations": [
      {
        "ref": "bizer2009dbpedia",
        "title": "Dbpedia - a crystallization point for the web of data"
      },
      {
        "ref": "cafarella2008webtables",
        "title": "Webtables: exploring the power of tables on the web"
      },
      {
        "ref": "ding2010twc",
        "title": "TWC data-gov corpus: incrementally generating linked government data from data.gov"
      },
      {
        "ref": "dredze2010entity",
        "title": "Entity disambiguation for knowledge base population"
      },
      {
        "ref": "embley2006notes",
        "title": "Notes on contemporary table recognition"
      },
      {
        "ref": "han2008rdf123",
        "title": "RDF123: from Spreadsheets to RDF"
      },
      {
        "ref": "hurst2006towards",
        "title": "Towards a theory of tables"
      },
      {
        "ref": "koller2009probabilistic",
        "title": "Probabilistic Graphical Models: Principles and Techniques"
      },
      {
        "ref": "langegger2009xlwrap",
        "title": "Xlwrap - querying and integrating arbitrary spreadsheets with SPARQL"
      },
      {
        "ref": "limaye2010annotating",
        "title": "Annotating and searching web tables using entities, types and relationships"
      },
      {
        "ref": "mulwad2012a",
        "title": "A Domain Independent Framework for Extracting Linked Semantic Data from Tables"
      },
      {
        "ref": "mulwad2010using",
        "title": "Using linked data to interpret tables"
      },
      {
        "ref": "polfliet2010automated",
        "title": "Automated mapping generation for converting databases into linked data"
      },
      {
        "ref": "puranik2012a",
        "title": "A Specialist Approach for Classification of Column Data"
      },
      {
        "ref": "sahoo2009a",
        "title": "A survey of current approaches for mapping of relational databases to rdf"
      },
      {
        "ref": "suchanek2011paris",
        "title": "PARIS: Probabilistic Alignment of Relations, Instances, and Schema"
      },
      {
        "ref": "suchanek2007yago",
        "title": "Yago: A Core of Semantic Knowledge"
      },
      {
        "ref": "syed2011creating",
        "title": "Creating and Exploiting a Hybrid Knowledge Base for Linked Data"
      },
      {
        "ref": "vavliakis2010rdote",
        "title": "RDOTE- transforming relational databases into semantic web data"
      },
      {
        "ref": "venetis2011recovering",
        "title": "Recovering semantics of tables on the web"
      },
      {
        "ref": "wang2011understanding",
        "title": "Understanding tables on the web"
      },
      {
        "ref": "zagari2007comparison",
        "title": "Comparison of 1 and 2 weeks of omeprazole, amoxicillin and clarithromycin treatment for helicobacter pylori eradication: the hyper study"
      }
    ]
  },
  {
    "firstAuthor": "Munoz",
    "year": 2013,
    "title": {
      "text": "Triplifying Wikipedia's Tables",
      "link": ""
    },
    "added": "",
    "conferenceJournal": "LD4IE",
    "nameOfApproach": "",
    "mainMethod": {
      "type": "Unsupervised",
      "technique": "exact match"
    },
    "domain": {
      "domain": "Independent",
      "type": ""
    },
    "coreTasks": {
      "cta": false,
      "cpa": true,
      "cea": true,
      "cnea": false
    },
    "supportTasks": {
      "dataPreparation": {
        "description": "Each page Wikipedia containing HTML tables is cleaned and canonicalized before extracting tables fixing syntax mistakes using CyberNeko",
        "spellChecker": "",
        "unitsOfMeasurements": ""
      },
      "subjectDetection": "",
      "columnClassification": " ",
      "typeAnnotation": "",
      "predicateAnnotation": "DBpedia is queried for relationships that exist between entities in cells of the same row. All pairs are queried. An additional query is performed to find the relation between entities in a row and the subject of the page the table belongs to. They look for relations that hold in either direction.",
      "datatypeAnnotation": "",
      "entityLinking": {
        "description": "Each link in a cell is mapped to a DBpedia entity URI by following redirects and replacing namespace http://en.wikipedia.org/wiki/ to http://DBpedia.org/resource/",
        "candidateGeneration": "",
        "entityDisambiguation": "redirects"
      },
      "nilAnnotation": ""
    },
    "revision": {
      "type": "None",
      "description": ""
    },
    "validation": "They extract 250 triples from the set and manually annotate them to produce a GS to test the approach on.",
    "codeAvailability": "",
    "license": "Not specified",
    "inputs": {
      "typeOfTable": "Wikipedia tables",
      "kg": {
        "tripleStore": "DBpedia",
        "index": ""
      }
    },
    "output": "RDF",
    "checkedByAuthor": false,
    "checkedByAi": true,
    "id": "munoz2013triplifying",
    "doi": "",
    "authors": [
      "Emir Muñoz",
      "Aidan Hogan",
      "Alessandra Mileo"
    ],
    "citations": [
      {
        "ref": "bizer2009dbpedia",
        "title": "DBpedia – a crystallization point for the Web of Data"
      },
      {
        "ref": "cafarella2008webtables",
        "title": "WebTables: exploring the power of tables on the Web"
      },
      {
        "ref": "crestan2010fine",
        "title": "A fine-grained taxonomy of tables on the Web"
      },
      {
        "ref": "crestan2011webscale",
        "title": "Web-scale table census and classification"
      },
      {
        "ref": "das2012r2rml",
        "title": "R2RML: RDB to RDF Mapping Language"
      },
      {
        "ref": "ding2010datagov",
        "title": "Data-gov Wiki: Towards Linking Government Data"
      },
      {
        "ref": "gatterbauer2007towards",
        "title": "Towards domain-independent information extraction from Web tables"
      },
      {
        "ref": "hoffart2013yago2",
        "title": "YAGO2: A spatially and temporally enhanced knowledge base from Wikipedia"
      },
      {
        "ref": "hurst2001layout",
        "title": "Layout and language: Challenges for table understanding on the web"
      },
      {
        "ref": "limaye2010annotating",
        "title": "Annotating and searching web tables using entities, types and relationships"
      },
      {
        "ref": "mendes2011dbpediashotlight",
        "title": "DBpedia Spotlight: shedding light on the web of documents"
      },
      {
        "ref": "mika2008learning",
        "title": "Learning to Tag and Tagging to Learn: A Case Study on Wikipedia"
      },
      {
        "ref": "mika2009investigating",
        "title": "Investigating the semantic gap through query log analysis"
      },
      {
        "ref": "mulwad2010t2ld",
        "title": "T2LD: Interpreting and Representing Tables as Linked Data"
      },
      {
        "ref": "mulwad2010using",
        "title": "Using Linked Data to interpret tables"
      },
      {
        "ref": "pivk2007transforming",
        "title": "Transforming arbitrary tables into logical form with TARTAR"
      },
      {
        "ref": "syed2010exploiting",
        "title": "Exploiting a Web of Semantic Data for Interpreting Tables"
      },
      {
        "ref": "venetis2011recovering",
        "title": "Recovering semantics of tables on the Web"
      },
      {
        "ref": "wang2002machine",
        "title": "A machine learning based approach for table detection on the web"
      },
      {
        "ref": "yoshida2001method",
        "title": "A method to integrate tables of the World Wide Web"
      }
    ]
  },
  {
    "firstAuthor": "Quercini",
    "year": 2013,
    "title": {
      "text": "Entity Discovery and Annotation in Tables",
      "link": ""
    },
    "added": "",
    "conferenceJournal": "EDBT",
    "nameOfApproach": "",
    "mainMethod": {
      "type": "Unsupervised",
      "technique": "lookup"
    },
    "domain": {
      "domain": "Independent",
      "type": ""
    },
    "coreTasks": {
      "cta": false,
      "cpa": false,
      "cea": true,
      "cnea": false
    },
    "supportTasks": {
      "dataPreparation": {
        "description": "Spatial data are broken down into their components via the Google Geocoding API. To train the multiclass classifier they convert snippets to lowercase and tokenize. Then they remove stopwords and stem the reimainders with the Porter algorithm. Each token is then associated with its normalized frequency",
        "spellChecker": "",
        "unitsOfMeasurements": ""
      },
      "subjectDetection": "",
      "columnClassification": "Cells are scanned so as to eliminate those that are not likely to contain the names of entities of a given type. They look at the syntactic properties of the contents of each cell. They use regex to identify patterns of e.g. phone numbers, URLs, emails, or leverage GFT types to rule out the cells containing a specific type of information that is not necessary to identify a pre-determined type (e.g. cells that match the email pattern are excluded when identifying cells belonging to the restaurant type). ",
      "typeAnnotation": "They perform type (concepts in ontology) annotation at cell-level, so that each column can contain more than one type. Once the table has been annotated, based on the assumption that data types in a column are homogenous in well-formed tables, incorrect annotations are discarded",
      "predicateAnnotation": " ",
      "datatypeAnnotation": "regex",
      "entityLinking": {
        "description": "The approach first identifies row containing information on a specific type (obtained from an ontology) then determines the cells that contain the names of those entities. The multiclass classifier is trained on a training dataset (of snippets of positive examples of a pre-defined type) by: 1. Creating a set of entities from DBpedia belonging to categories that are manually identified as useful; 2. Collecting snippets from Bing; 3. 75% of the snippet corpus is training set, 25% is the test set.  After the text classifier (either SVM or Naive Bayes in experiments) has classified cells, spurious annotations are removed. ",
        "candidateGeneration": "",
        "entityDisambiguation": ""
      },
      "nilAnnotation": "Information about unknown entities is found on the Web so as to annotate them with the correct type. They use the content of the cell to query the Web and use the obtained results (which are links to Web pages+snippet) to determine whether the cell contains the name of an entity of a certain type. The result of a query is a snippet and they use a text classifier to determine whether the snippet describes an entity of a certain type. "
    },
    "revision": {
      "type": "None",
      "description": ""
    },
    "validation": "",
    "codeAvailability": "",
    "license": "Not specified",
    "inputs": {
      "typeOfTable": "40 Google Fusion Tables",
      "kg": {
        "tripleStore": "DBpedia",
        "index": ""
      }
    },
    "output": "RDF",
    "checkedByAuthor": true,
    "checkedByAi": true,
    "id": "quercini2013entity",
    "doi": "https://doi.org/10.1145/2452376.2452457",
    "authors": [
      "Gianluca Quercini",
      "Chantal Reynaud"
    ],
    "citations": [
      {
        "ref": "bizer2009dbpedia",
        "title": "DBpedia - A Crystallization Point for the Web of Data"
      },
      {
        "ref": "borges2007discovering",
        "title": "Discovering Geographic Locations in Web Pages Using Urban Addresses"
      },
      {
        "ref": "cafarella2008webtables",
        "title": "WebTables: Exploring the Power of Tables on the Web"
      },
      {
        "ref": "cimiano2005towards",
        "title": "Towards Large-scale, Open-domain and Ontology-based Named Entity Classification"
      },
      {
        "ref": "doan2011crowdsourcing",
        "title": "Crowdsourcing Systems on the World-Wide Web"
      },
      {
        "ref": "fleischman2002fine",
        "title": "Fine Grained Classification of Named Entities"
      },
      {
        "ref": "ganti2008entity",
        "title": "Entity Categorization over Large Document Collections"
      },
      {
        "ref": "giuliano2009fine-grained",
        "title": "Fine-grained Classification of Named Entities Exploiting Latent Semantic Kernels"
      },
      {
        "ref": "gonzalez2010google",
        "title": "Google Fusion Tables: Web-centered Data Management and Collaboration"
      },
      {
        "ref": "guo2011item",
        "title": "ITEM: Extract and Integrate Entities from Tabular Data to RDF Knowledge Base"
      },
      {
        "ref": "han2008rdf123",
        "title": "RDF123: From Spreadsheets to RDF"
      },
      {
        "ref": "hignette2009fuzzy",
        "title": "Fuzzy Annotation of Web Data Tables Driven by a Domain Ontology"
      },
      {
        "ref": "hsu2003a",
        "title": "A Practical Guide to Support Vector Classification"
      },
      {
        "ref": "limaye2010annotating",
        "title": "Annotating and Searching Web Tables Using Entities, Types and Relationships"
      },
      {
        "ref": "mulwad2011dc",
        "title": "DC proposal: Graphical Models and Probabilistic Reasoning for Generating Linked Data from Tables"
      },
      {
        "ref": "ni2010enhancing",
        "title": "Enhancing the Open-domain Classification of Named Entity Using Linked Open Data"
      },
      {
        "ref": "quercini2012facetted",
        "title": "Facetted Browsing of Extracted Fusion Tables Data for Digital Cities"
      },
      {
        "ref": "setz2012facetted",
        "title": "Facetted Search on Extracted Fusion Tables Data for Digital Cities"
      },
      {
        "ref": "suchanek2007yago",
        "title": "Yago: a Core of Semantic Knowledge"
      },
      {
        "ref": "vanassem2010converting",
        "title": "Converting and Annotating Quantitative Data Tables"
      },
      {
        "ref": "vanrijsbergen1980new",
        "title": "New models in probabilistic information retrieval"
      },
      {
        "ref": "venetis2011recovering",
        "title": "Recovering Semantics of Tables on the Web"
      },
      {
        "ref": "wang2012understanding",
        "title": "Understanding Tables on the Web"
      },
      {
        "ref": "wu2012probase",
        "title": "Probase: a Probabilistic Taxonomy for Text Understanding"
      },
      {
        "ref": "zicari2011google",
        "title": "Google Fusion Tables"
      }
    ]
  },
  {
    "firstAuthor": "Zhang",
    "year": 2013,
    "title": {
      "text": "InfoGather+: Semantic Matching and Annotation of Numeric and Time-Varying Attributes in Web Tables",
      "link": ""
    },
    "added": "",
    "conferenceJournal": "SIGMOD",
    "nameOfApproach": "InfoGather+",
    "mainMethod": {
      "type": "Unsupervised",
      "technique": "Markov random field inference (belief propagation)"
    },
    "domain": {
      "domain": "Independent",
      "type": ""
    },
    "coreTasks": {
      "cta": true,
      "cpa": false,
      "cea": false,
      "cnea": false
    },
    "supportTasks": {
      "dataPreparation": {
        "description": "",
        "spellChecker": "",
        "unitsOfMeasurements": "Extract and match unit/scale descriptors from headers and values (e.g., USD, bil, mil) using administrator‐defined rules."
      },
      "subjectDetection": "Identify the subject column (entity names) and split multi-column tables into EAB (entity–attribute binary) relations.",
      "columnClassification": "Compute PFStrings (tokens preceding/following numeric values) for unit inference across rows.",
      "typeAnnotation": "They infer label information from semantically matching columns of other Web tables. Given a set of pre-defined rules and: Case 1: a set of unit/scale descriptors (eg USD, EUR etc), they annotate the column with the value if it (or one of its synonyms) either appears in the header or column values. Case 2: a set of years strings, they annotate the column with the value if it occurs in the header or in the context of the table.",
      "predicateAnnotation": " ",
      "datatypeAnnotation": "",
      "entityLinking": {
        "description": "",
        "candidateGeneration": "",
        "entityDisambiguation": ""
      },
      "nilAnnotation": ""
    },
    "revision": {
      "type": "Fully automated",
      "description": ""
    },
    "validation": "Experiments conducted on three real-life datasets of Web tables,extracted from a recent snapshot of Microsoft Bing search engine",
    "codeAvailability": "",
    "license": "Not specified",
    "inputs": {
      "typeOfTable": "EAB (entity-attribute binary relationships) HTML Web tables ",
      "kg": {
        "tripleStore": "",
        "index": ""
      }
    },
    "output": "Semantic graph (unit/scale/year labels + X/S edges) and augmented table",
    "checkedByAuthor": false,
    "checkedByAi": true,
    "id": "zhang2013infogather",
    "doi": "https://doi.org/10.1145/2463676.2465276",
    "authors": [
      "Meihui Zhang",
      "Kaushik Chakrabarti"
    ],
    "citations": [
      {
        "ref": "cafarella2009data",
        "title": "Data integration for the relational web"
      },
      {
        "ref": "cafarella2008webtables",
        "title": "Webtables: exploring the power of tables on the web"
      },
      {
        "ref": "cafarella2008uncovering",
        "title": "Uncovering the relational web"
      },
      {
        "ref": "dhamankar2004imap",
        "title": "iMAP: discovering complex semantic matches between database schemas"
      },
      {
        "ref": "doan2005semantic",
        "title": "Semantic integration research in the database community: A brief survey"
      },
      {
        "ref": "kleinberg2002approximation",
        "title": "Approximation algorithms for classification problems with pairwise relationships: metric labeling and markov random fields"
      },
      {
        "ref": "koller2009probabilistic",
        "title": "Probabilistic Graphical Models: Principles and Techniques"
      },
      {
        "ref": "limaye2010annotating",
        "title": "Annotating and searching web tables using entities, types and relationships"
      },
      {
        "ref": "malewicz2010pregel",
        "title": "Pregel: a system for large-scale graph processing"
      },
      {
        "ref": "pimplikar2012answering",
        "title": "Answering table queries on the web using column keywords"
      },
      {
        "ref": "rahm2001a",
        "title": "A survey of approaches to automatic schema matching"
      },
      {
        "ref": "sarma2012finding",
        "title": "Finding related tables"
      },
      {
        "ref": "shao2012the",
        "title": "The Trinity Graph Engine"
      },
      {
        "ref": "talukdar2012coupled",
        "title": "Coupled temporal scoping of relational facts"
      },
      {
        "ref": "venetis2011recovering",
        "title": "Recovering semantics of tables on the web"
      },
      {
        "ref": "wang2011harvesting",
        "title": "Harvesting facts from textual web sources by constrained label propagation"
      },
      {
        "ref": "yakout2012infogather",
        "title": "InfoGather: entity augmentation and attribute discovery by holistic matching with web tables"
      }
    ]
  },
  {
    "firstAuthor": "Zwicklbauer",
    "year": 2013,
    "title": {
      "text": "Towards Disambiguating Web Tables",
      "link": ""
    },
    "added": "",
    "conferenceJournal": "ISWC",
    "nameOfApproach": "",
    "mainMethod": {
      "type": "Unsupervised",
      "technique": "features"
    },
    "domain": {
      "domain": "Independent",
      "type": ""
    },
    "coreTasks": {
      "cta": true,
      "cpa": false,
      "cea": false,
      "cnea": false
    },
    "supportTasks": {
      "dataPreparation": {
        "description": "",
        "spellChecker": "",
        "unitsOfMeasurements": ""
      },
      "subjectDetection": "",
      "columnClassification": " ",
      "typeAnnotation": "majority voting",
      "predicateAnnotation": " ",
      "datatypeAnnotation": "",
      "entityLinking": {
        "description": "",
        "candidateGeneration": "",
        "entityDisambiguation": ""
      },
      "nilAnnotation": ""
    },
    "revision": {
      "type": "None",
      "description": ""
    },
    "validation": "50 Wikipedia tables",
    "codeAvailability": "",
    "license": "Not specified",
    "inputs": {
      "typeOfTable": "DBpedia",
      "kg": {
        "tripleStore": "DBpedia",
        "index": ""
      }
    },
    "output": "",
    "checkedByAuthor": false,
    "checkedByAi": true,
    "id": "zwicklbauer2013towards",
    "doi": "https://doi.org/10.5555/2874399.2874451",
    "authors": [
      "Stefan Zwicklbauer",
      "Christoph Einsiedler",
      "Michael Granitzer",
      "Christin Seifert"
    ],
    "citations": [
      {
        "ref": "gonzalez2010google",
        "title": "Google fusion tables: web-centered data management and collaboration"
      },
      {
        "ref": "limaye2010annotating",
        "title": "Annotating and searching web tables using entities, types and relationships"
      },
      {
        "ref": "quercini2013entity",
        "title": "Entity discovery and annotation in tables"
      },
      {
        "ref": "venetis2011recovering",
        "title": "Recovering semantics of tables on the web"
      },
      {
        "ref": "zwicklbauer2013do",
        "title": "Do we need entity-centric knowledge bases for entity disambiguation?"
      }
    ]
  },
  {
    "firstAuthor": "Sekhavat",
    "year": 2014,
    "title": {
      "text": "Knowledge Base Augmentation using Tabular Data",
      "link": ""
    },
    "added": "",
    "conferenceJournal": "LDOW",
    "nameOfApproach": "",
    "mainMethod": {
      "type": "Unsupervised",
      "technique": "probabilistic model"
    },
    "domain": {
      "domain": "Independent",
      "type": ""
    },
    "coreTasks": {
      "cta": false,
      "cpa": true,
      "cea": false,
      "cnea": false
    },
    "supportTasks": {
      "dataPreparation": {
        "description": "",
        "spellChecker": "",
        "unitsOfMeasurements": ""
      },
      "subjectDetection": "",
      "columnClassification": " ",
      "typeAnnotation": "",
      "predicateAnnotation": "patty patterns",
      "datatypeAnnotation": "",
      "entityLinking": {
        "description": "Assumed pre-linked entities; exact string matching used for experiments",
        "candidateGeneration": "",
        "entityDisambiguation": ""
      },
      "nilAnnotation": ""
    },
    "revision": {
      "type": "None",
      "description": ""
    },
    "validation": "Ground truth from YAGO facts cross-checked with NELL triples extracted from ClueWeb09",
    "codeAvailability": "",
    "license": "Not specified",
    "inputs": {
      "typeOfTable": "",
      "kg": {
        "tripleStore": "YAGO",
        "index": "PATTY pattern index"
      }
    },
    "output": "Predicted relation instances <entity1, relation, entity2> (triples) – format not explicitly serialized",
    "checkedByAuthor": true,
    "checkedByAi": true,
    "id": "sekhavat2014knowledge",
  "doi": "",
  "authors": [
    "Yoones A. Sekhavat",
    "Francesco di Paolo",
    "Denilson Barbosa",
    "Paolo Merialdo"
  ],
  "citations": [
    { "ref": "adelfio2013schema", "title": "Schema extraction for tabular data on the web" },
    { "ref": "bizer2009linked", "title": "Linked data-the story so far" },
    { "ref": "bollacker2008freebase", "title": "Freebase: A collaboratively created graph database for structuring human knowledge" },
    { "ref": "cafarella2008webtables", "title": "Webtables: Exploring the power of tables on the web" },
    { "ref": "chen2013automatic", "title": "Automatic web spreadsheet data extraction" },
    { "ref": "ding2010data", "title": "Data-gov wiki: Towards linking government data" },
    { "ref": "fagin2003comparing", "title": "Comparing top k lists" },
    { "ref": "limaye2010annotating", "title": "Annotating and searching web tables using entities, types and relationships" },
    { "ref": "mintz2009distant", "title": "Distant supervision for relation extraction without labeled data" },
    { "ref": "mulwad2013semantic", "title": "Semantic Message Passing for Generating Linked Data from Tables" },
    { "ref": "munoz2013triplifying", "title": "Triplifying wikipedia’s tables" },
    { "ref": "nakashole2012patty", "title": "Patty: A taxonomy of relational patterns with semantic types" },
    { "ref": "shinyama2006preemptive", "title": "Preemptive information extraction using unrestricted relation discovery" },
    { "ref": "suchanek2007yago", "title": "Yago: A core of semantic knowledge" },
    { "ref": "talukdar2012acquiring", "title": "Acquiring temporal constraints between relations" },
    { "ref": "venetis2011recovering", "title": "Recovering semantics of tables on the web" },
    { "ref": "yosef2011aida", "title": "Aida: An online tool for accurate disambiguation of named entities in text and tables" },
    { "ref": "zhou2007tree", "title": "Tree Kernel-Based relation extraction with Context-Sensitive structured parse tree information" }
  ]
  },
  {
    "firstAuthor": "Taheriyan",
    "year": 2014,
    "title": {
      "text": "A Scalable Approach to Learn Semantic Models of Structured Sources",
      "link": ""
    },
    "added": "",
    "conferenceJournal": "IEEE",
    "nameOfApproach": "",
    "mainMethod": {
      "type": "Supervised",
      "technique": "CRF-based semantic labelling + weighted-graph search/ranking"
    },
    "domain": {
      "domain": "Independent",
      "type": ""
    },
    "coreTasks": {
      "cta": true,
      "cpa": true,
      "cea": false,
      "cnea": false
    },
    "supportTasks": {
      "dataPreparation": {
        "description": "",
        "spellChecker": "",
        "unitsOfMeasurements": ""
      },
      "subjectDetection": "",
      "columnClassification": " ",
      "typeAnnotation": "For each attribute in the data source, a set of candidate sematnic types (with confidence level) is collected and ranked. To learn semantic types, they use a supervised machine learning technique based on Conditional Random Fields (CRF) with features extracted from the attribute names and sample data from the new source. Type = ontology class or data-property + domain-class pair",
      "predicateAnnotation": "To learn relationships between types, the authors leverage previously built semantic models belonging to the same domain (e.g. museums) assuming that similar sources will share similar semantic models. To annotate relationships, they use a directed weighted graph 𝐺 built on top of the known semantic models and expanded using the semantic types 𝑇 and the domain ontology 𝑂; properties are weighted links between nodes. The algorithm used to construct 𝐺: 1. Adds known semantic models: each model is added if it is not a subgraph of already added components; 2. Adds semantic types, checking for each type if the graph contains a match for it; 3. Adds paths from the ontology, using the subclass hierarchy in the ontology",
      "datatypeAnnotation": "They assign a class to attributes whose values are URIs and assign a domain/data property pair to attributes containing literal values (see Type/concept annotation column)",
      "entityLinking": {
        "description": "",
        "candidateGeneration": "",
        "entityDisambiguation": ""
      },
      "nilAnnotation": ""
    },
    "revision": {
      "type": "Semi automated",
      "description": "We applied our approach on this dataset to find the candidate semantic models for each source and then compared the best suggested models with models created manually by domain experts"
    },
    "validation": "We evaluated our approach on a dataset of 29 museum data sources",
    "codeAvailability": "",
    "license": "Not specified",
    "inputs": {
      "typeOfTable": "Multiple sources modeled using the EDM, AAC, SKOS, Dublin Core Metadata Terms, FOAF, ORE, and ElementsGr2 ontologies",
      "kg": {
        "tripleStore": "",
        "index": ""
      }
    },
    "output": "Ranked semantic models (graphs) exported/publishable as RDF",
    "checkedByAuthor": true,
    "checkedByAi": true,
      "id": "taheriyan2014scalable",
      "doi": "https://doi.org/10.1109/ICSC.2014.13",
      "authors": [
        "Mohsen Taheriyan",
        "Craig A. Knoblock",
        "Pedro Szekely",
        "José Luis Ambite"
      ],
      "citations": [
        { "ref": "doan2012principles", "title": "Principles of Data Integration" },
        { "ref": "mulwad2013semantic", "title": "Semantic Message Passing for Generating Linked Data from Tables" },
        { "ref": "venetis2011recovering", "title": "Recovering Semantics of Tables on the Web" },
        { "ref": "limaye2010annotating", "title": "Annotating and Searching Web Tables Using Entities, Types and Relationships" },
        { "ref": "sheth2008semantics", "title": "Semantics Enhanced Services: METEOR-S, SAWSDL and SA-REST" },
        { "ref": "saquicela2011lightweight", "title": "Lightweight Semantic Annotation of Geospatial RESTful Services" },
        { "ref": "knoblock2012semi", "title": "Semi-Automatically Mapping Structured Sources into the Semantic Web" },
        { "ref": "taheriyan2013graph", "title": "A Graph-based Approach to Learn Semantic Descriptions of Data Sources" },
        { "ref": "goel2012exploiting", "title": "Exploiting Structure within Data for Accurate Labeling Using Conditional Random Fields" },
        { "ref": "szekely2013connecting", "title": "Connecting the Smithsonian American Art Museum to the Linked Data Cloud" },
        { "ref": "lafferty2001conditional", "title": "Conditional Random Fields: Probabilistic Models for Segmenting and Labeling Sequence Data" },
        { "ref": "winter1987steiner", "title": "Steiner Problem in Networks – A Survey" },
        { "ref": "kou1981fast", "title": "A Fast Algorithm for Steiner Trees" },
        { "ref": "rahm2001survey", "title": "A Survey of Approaches to Automatic Schema Matching" },
        { "ref": "dhamankar2004imap", "title": "iMAP: Discovering Complex Semantic Matches between Database Schemas" },
        { "ref": "bellahsene2011schema", "title": "Schema Matching and Mapping" },
        { "ref": "fagin2009clio", "title": "Clio: Schema Mapping Creation and Data Exchange" },
        { "ref": "alexe2011designing", "title": "Designing and Refining Schema Mappings via Data Examples" },
        { "ref": "an2007semantic", "title": "A Semantic Approach to Discovering Schema Mapping Expressions" },
        { "ref": "carman2007learning", "title": "Learning Semantic Definitions of Online Information Sources" },
        { "ref": "taheriyan2012rapidly", "title": "Rapidly Integrating Services into the Linked Data Cloud" }
      ]
  },
  {
    "firstAuthor": "Bhagavatula",
    "year": 2015,
    "title": {
      "text": "TabEL: Entity Linking in Web Tables",
      "link": ""
    },
    "added": "",
    "conferenceJournal": "ISWC",
    "nameOfApproach": "TabEL",
    "mainMethod": {
      "type": "Supervised",
      "technique": "Markov Network"
    },
    "domain": {
      "domain": "Independent",
      "type": ""
    },
    "coreTasks": {
      "cta": false,
      "cpa": false,
      "cea": true,
      "cnea": false
    },
    "supportTasks": {
      "dataPreparation": {
        "description": "",
        "spellChecker": "",
        "unitsOfMeasurements": ""
      },
      "subjectDetection": "",
      "columnClassification": " ",
      "typeAnnotation": "",
      "predicateAnnotation": " ",
      "datatypeAnnotation": "",
      "entityLinking": {
        "description": "TabEl performs EL in three steps: 1. Mention identification; 2. Entity candidate generation; 3. Disambiguation. It also relies on a prior estimate that a given string refers to a particular entity, using an estimate distribution from hyperlinks on the Web and in Wikipedia.  The number of in-links to an entity in Wikipedia is an indicator of its prominence",
        "candidateGeneration": "lookup, YAGO",
        "entityDisambiguation": "features, probabilistic"
      },
      "nilAnnotation": "TabEL demonstrates strong performance in identifying and disambiguating unlinked mentions in Wikipedia tables. Unlike previous experiments that removed all existing links, TabEL for this task retains the existing links."
    },
    "revision": {
      "type": "None",
      "description": ""
    },
    "validation": "WEB_MANUAL, WEB_MANUAL_FIXED, WIKI_LINKS, WIKI_LINKS_RANDOM, TABEL_35K",
    "codeAvailability": "http://websail-fe.cs.northwestern.edu/TabEL/ ",
    "license": "CCA 4.0",
    "inputs": {
      "typeOfTable": "HTML Web tables from the open Web and Wikipedia",
      "kg": {
        "tripleStore": "Yago",
        "index": ""
      }
    },
    "output": "Cell-level links to YAGO entities (URI) for each table mention",
    "checkedByAuthor": true,
    "checkedByAi": true,
    "id": "bhagavatula2015tabel",
  "doi": "https://doi.org/10.1007/978-3-319-25007-6_25",
  "authors": [
    "Chandra Sekhar Bhagavatula",
    "Thanapon Noraset",
    "Doug Downey"
  ],
  "citations": [
    { "ref": "cafarella2008webtables", "title": "Webtables: exploring the power of tables on the web" },
    { "ref": "buche2013fuzzy", "title": "Fuzzy web data tables integration guided by an ontological and terminological resource" },
    { "ref": "hignette2009fuzzy", "title": "Fuzzy annotation of web data tables driven by a domain ontology" },
    { "ref": "limaye2010annotating", "title": "Annotating and searching web tables using entities, types and relationships" },
    { "ref": "munoz2013triplifying", "title": "Triplifying wikipedia’s tables" },
    { "ref": "mulwad2011automatically", "title": "Automatically generating government linked data from tables" },
    { "ref": "mulwad2013semantic", "title": "Semantic message passing for generating linked data from tables" },
    { "ref": "mulwad2010t2ld", "title": "T2ld: Interpreting and representing tables as linked data" },
    { "ref": "syed2010exploiting", "title": "Exploiting a web of semantic data for interpreting tables" },
    { "ref": "venetis2011recovering", "title": "Recovering semantics of tables on the web" },
    { "ref": "wang2012understanding", "title": "Understanding tables on the web" },
    { "ref": "zhang2014start", "title": "Start small, build complete: Effective and efficient semantic table interpretation using tableminer" },
    { "ref": "suchanek2007yago", "title": "Yago: A core of semantic knowledge" },
    { "ref": "lu2003link", "title": "Link-based classification" },
    { "ref": "hoffart2011robust", "title": "Robust disambiguation of named entities in text" },
    { "ref": "hecht2012explanatory", "title": "Explanatory semantic relatedness and explicit spatialization for exploratory search" },
    { "ref": "witten2008effective", "title": "An effective, low-cost measure of semantic relatedness obtained from wikipedia links" },
    { "ref": "church1995one", "title": "One term or two?" },
    { "ref": "dohrn2011design", "title": "Design and implementation of the sweble wikitext parser" },
    { "ref": "spitkovsky2012cross", "title": "A cross-lingual dictionary for English Wikipedia concepts" },
    { "ref": "gupta2009answering", "title": "Answering table augmentation queries from unstructured lists on the web" },
    { "ref": "bunescu2006using", "title": "Using encyclopedic knowledge for named entity disambiguation" },
    { "ref": "cheng2013relational", "title": "Relational inference for wikification" },
    { "ref": "moro2014entity", "title": "Entity linking meets word sense disambiguation: A unified approach" },
    { "ref": "ling2014context", "title": "Context representation for named entity linking" },
    { "ref": "noraset2014websail", "title": "WebSail wikifier at ERD 2014" },
    { "ref": "cucerzan2007large", "title": "Large-scale named entity disambiguation based on Wikipedia data" },
    { "ref": "mendes2011dbpedia", "title": "DBpedia Spotlight: shedding light on the web of documents" },
    { "ref": "usbeck2014agdistis", "title": "AGDISTIS – graph-based disambiguation of named entities using linked data" },
    { "ref": "moro2014multilingual", "title": "Multilingual word sense disambiguation and entity linking for everybody" },
    { "ref": "steinmetz2013semantic", "title": "Semantic multimedia information retrieval based on contextual descriptions" },
    { "ref": "vanerp2013learning", "title": "Learning with the web: spotting named entities on the intersection of NERD and machine learning" },
    { "ref": "ferragina2010fast", "title": "Fast and accurate annotation of short texts with Wikipedia pages" },
    { "ref": "usbeck2015gerbil", "title": "GERBIL – general entity annotation benchmark framework" },
    { "ref": "munoz2014using", "title": "Using linked data to mine RDF from Wikipedia’s tables" },
    { "ref": "sekhavat2014knowledge", "title": "Knowledge base augmentation using tabular data" },
    { "ref": "syed2008wikitology", "title": "Wikitology: Using Wikipedia as an ontology" },
    { "ref": "dassarma2012finding", "title": "Finding related tables" },
    { "ref": "fan2014hybrid", "title": "A hybrid machine-crowdsourcing system for matching web tables" },
    { "ref": "bhagavatula2013methods", "title": "Methods for exploring and mining tables on Wikipedia" }
  ]
  },
  {
    "firstAuthor": "Ramnandan",
    "year": 2015,
    "title": {
      "text": "Assigning Semantic Labels to Data Sources",
      "link": ""
    },
    "added": "",
    "conferenceJournal": "ESWC",
    "nameOfApproach": "SemanticTyper",
    "mainMethod": {
      "type": "Supervised",
      "technique": "TF-IDF cosine similarity (text) + Kolmogorov–Smirnov test (numeric)"
    },
    "domain": {
      "domain": "Independent",
      "type": ""
    },
    "coreTasks": {
      "cta": true,
      "cpa": false,
      "cea": false,
      "cnea": false
    },
    "supportTasks": {
      "dataPreparation": {
        "description": "",
        "spellChecker": "",
        "unitsOfMeasurements": ""
      },
      "subjectDetection": "",
      "columnClassification": "For textual data, the authors use the TF-IDFbased approach and for numeric data, they use the Kolmogorov-Smirnov (KS) statistical hypothesis test. In order to resolve column heterogeneity the authors adopted the rule that in the training data, if for a semantic label the fraction of pure numeric data values is below 60%, it is trained as textual data (and hence indexed as document). If the fraction of numeric values is above 80%, it is trained as purely numeric data (its distribution is extracted to be used in KS test) after discarding textual data values. In the other case (if the fraction is between 60% and 80%), the data is trained as both textual and numeric data (it is both indexed as a document and its ",
      "typeAnnotation": "TF-IDF",
      "predicateAnnotation": " ",
      "datatypeAnnotation": "Kolmogorov–Smirnov test",
      "entityLinking": {
        "description": "",
        "candidateGeneration": "",
        "entityDisambiguation": ""
      },
      "nilAnnotation": ""
    },
    "revision": {
      "type": "Semi automated",
      "description": ""
    },
    "validation": "Evaluated on 29 museum sources (textual), 30 DBpedia city properties (numeric), and mixed weather / phone-book / flight-status datasets",
    "codeAvailability": "https://github.com/usc-isi-i2/eswc-2015-semantic-typing",
    "license": "Apache 2.0",
    "inputs": {
      "typeOfTable": "Tables (e.g., CSV/spreadsheet) and hierarchical files (XML, JSON)",
      "kg": {
        "tripleStore": "",
        "index": "None (labels indexed locally with Lucene)"
      }
    },
    "output": "Top-k semantic labels with confidence scores for each attribute",
    "checkedByAuthor": true,
    "checkedByAi": true,
    "id": "ramnandan2015assigning",
    "doi": "https://doi.org/10.1007/978-3-319-18818-8_25",
    "authors": [
      "S.K. Ramnandan",
      "Amol Mittal",
      "Craig A. Knoblock",
      "Pedro Szekely"
    ],
    "citations": [
      { "ref": "ambite2009automatically",   "title": "Automatically Constructing Semantic Web Services from Online Sources" },
      { "ref": "cafarella2008webtables",    "title": "Webtables: Exploring the power of tables on the web" },
      { "ref": "craswell2009mean",          "title": "Mean reciprocal rank" },
      { "ref": "doan2003learning",          "title": "Learning to match schemas of data sources: a multistrategy approach" },
      { "ref": "goel2012exploiting",        "title": "Exploiting structure within data for accurate labeling using conditional random fields" },
      { "ref": "lehmann2005testing",        "title": "Testing Statistical Hypotheses" },
      { "ref": "li1994semantic",            "title": "Semantic integration in heterogeneous databases using neural networks" },
      { "ref": "limaye2010annotating",      "title": "Annotating and searching web tables using entities, types and relationships" },
      { "ref": "mulwad2013semantic",        "title": "Semantic message passing for generating linked data from tables" },
      { "ref": "noy2004semantic",           "title": "Semantic integration: a survey of ontology-based approaches" },
      { "ref": "sequeda2012on",             "title": "On directly mapping relational databases to RDF and OWL" },
      { "ref": "stonebraker2013data",       "title": "Data curation at scale: the data tamer system" },
      { "ref": "syed2010exploiting",        "title": "Exploiting a web of semantic data for interpreting tables" },
      { "ref": "taheriyan2014a",            "title": "A Scalable Approach to Learn Semantic Models of Structured Sources" },
      { "ref": "venetis2011recovering",     "title": "Recovering semantics of tables on the web" }
    ]
  },
  {
    "firstAuthor": "Ritze",
    "year": 2015,
    "title": {
      "text": "Matching HTML Tables to DBpedia",
      "link": ""
    },
    "added": "",
    "conferenceJournal": "WIMS",
    "nameOfApproach": "T2K Match",
    "mainMethod": {
      "type": "Unsupervised",
      "technique": "Iterative instance + schema matching (duplicate-based voting; Jaccard, Levenshtein, date & numeric similarities) with GA-tuned parameters"
    },
    "domain": {
      "domain": "Independent",
      "type": ""
    },
    "coreTasks": {
      "cta": true,
      "cpa": true,
      "cea": true,
      "cnea": false
    },
    "supportTasks": {
      "dataPreparation": {
        "description": "remove HTML artifacts, special characters and additional whitespaces. Further, value lists are split into individual values, all values are lower-cased and normalized. For the normalization, we use a set of handcrafted transformation rules to resolve abbreviations, e.g. \"co.\" is transformed into \"company\". Moreover, the header is detected",
        "spellChecker": "",
        "unitsOfMeasurements": "Further, we normalize units of measurements using around 200 manually generated conversion rules, e.g. 8mi2 is converted to 20.72 million m2."
      },
      "subjectDetection": "",
      "columnClassification": "We further perform a data type detection for each attribute which is important for choosing the similarity measure. The data type is detected using about 100 manually defined regular expressions. They are able to detect string, numeric value, timestamp and coordinate. The final data type decision for an attribute is based on majority vote.",
      "typeAnnotation": "we determine the distribution of DBpedia classes of the best candidate for each entity and choose the most frequent classes as candidates for schema matching.",
      "predicateAnnotation": "Each value of the top candidates votes for a correspondence between the attribute and its property. This vote is weighted by the value-based similarity of the two values and the similarity value from the candidate selection step. Votes from all values are summed up and the attribute property pair with the highest value is chosen. It follows the intuition that a similar attribute property pair has many similar values on similar entities/candidates. Our computation is purely duplicate-based and does not perform any label matching on the headers since headers in HTML tables do not often have meaningful names. The matching of attributes with properties is further aggregated by summing up all the scores of all property correspondences per class to refine the class ranking. At this point we choose the class with the highest score as final correspondence.",
      "datatypeAnnotation": "We further perform a data type detection for each attribute which is important for choosing the similarity measure. The data type is detected using about 100 manually defined regular expressions. They are able to detect string, numeric value, timestamp and coordinate. The final data type decision for an attribute is based on majority vote.",
      "entityLinking": {
        "description": "First, we search for the entity label in DBpedia. The found candidates are ranked according to a similarity function and the top k candidates are kept. Then, we determine the distribution of DBpedia classes of the best candidate for each entity and choose the most frequent classes as candidates for schema matching. In turn, this is used to refine the candidate resources: All candidates not belonging to a chosen class are removed, and for each entity we perform another search with the selected classes as additional constraint. We compute similarities between the values of HTML table entities and candidate resources by applying two blocking strategies: (1) the values of each entity are only compared to the values of its candidates and (2) only values with the same data type are compared. In case of multi-values, we calculate the similarity of all combinations and choose the maximum.",
        "candidateGeneration": "lookup, DBP LS",
        "entityDisambiguation": "features, contextual inf"
      },
      "nilAnnotation": "The article explicitly mentions that with the T2K approach one could fill the missing values to DBpedia and vice-versa (Web Tables). Howver, they do no provide any evidence on how they store or use new entities / properties / values in DBpedia. "
    },
    "revision": {
      "type": "None",
      "description": ""
    },
    "validation": "T2D gold-standard (1 748 tables / 26 124 row links)",
    "codeAvailability": "https://github.com/olehmberg/T2KMatch",
    "license": "Apache 2.0",
    "inputs": {
      "typeOfTable": "Web Table (HTML)",
      "kg": {
        "tripleStore": "DBpedia",
        "index": ""
      }
    },
    "output": "Correspondences: table→class, column→property, row→entity (links to DBpedia URIs)",
    "checkedByAuthor": true,
    "checkedByAi": true,
    "id": "ritze2015matching",
    "doi": "https://doi.org/10.1145/2797115.2797118",
    "authors": [
      "Dominique Ritze",
      "Oliver Lehmberg",
      "Christian Bizer"
    ],
    "citations": [
      { "ref": "bryl2014learning",         "title": "Learning conflict resolution strategies for cross-language Wikipedia data fusion" },
      { "ref": "cafarella2008webtables",   "title": "WebTables: Exploring the Power of Tables on the Web" },
      { "ref": "dassarma2012finding",      "title": "Finding Related Tables" },
      { "ref": "dong2014knowledge",        "title": "Knowledge Vault: A Web-scale Approach to Probabilistic Knowledge Fusion" },
      { "ref": "duan2012instance",        "title": "Instance-based matching of large ontologies using locality-sensitive hashing" },
      { "ref": "fan2014hybrid",           "title": "A Hybrid Machine-Crowdsourcing System for Matching Web Tables" },
      { "ref": "gupta2014biperpedia",      "title": "Biperpedia: An Ontology for Search Applications" },
      { "ref": "lehmann2014dbpedia",       "title": "Dbpedia - a large-scale, multilingual knowledge base extracted from Wikipedia" },
      { "ref": "limaye2010annotating",     "title": "Annotating and Searching Web Tables Using Entities, Types and Relationships" },
      { "ref": "mulwad2010using",          "title": "Using linked data to interpret tables" },
      { "ref": "rinser2013cross",          "title": "Cross-Lingual Entity Matching and Infobox Alignment in Wikipedia" },
      { "ref": "sekhavat2014knowledge",    "title": "Knowledge Base Augmentation using Tabular Data" },
      { "ref": "singhal2012introducing",   "title": "Introducing the knowledge graph: Things, not string" },
      { "ref": "suchanek2011paris",        "title": "Paris: Probabilistic alignment of Relations, Instances, and Schema" },
      { "ref": "suchanek2007yago",         "title": "Yago: A Core of Semantic Knowledge" },
      { "ref": "venetis2011recovering",    "title": "Recovering Semantics of Tables on the Web" },
      { "ref": "wang2012understanding",    "title": "Understanding Tables on the Web" },
      { "ref": "wang2002detecting",        "title": "Detecting Tables in HTML Documents" },
      { "ref": "weikum2010from",           "title": "From Information to Knowledge: Harvesting Entities and Relationships from Web Sources" },
      { "ref": "yakout2012infogather",     "title": "InfoGather: Entity Augmentation and Attribute Discovery by Holistic Matching with Web Tables" },
      { "ref": "zhang2014start",           "title": "Start small, build complete: Effective and efficient semantic table interpretation using tableminer" },
      { "ref": "zhang2014towards",         "title": "Towards efficient and effective semantic table interpretation" }
    ]
  },
  {
    "firstAuthor": "Ermilov",
    "year": 2016,
    "title": {
      "text": "TAIPAN: Automatic Property Mapping for Tabular Data",
      "link": ""
    },
    "added": "",
    "conferenceJournal": "EKAW",
    "nameOfApproach": "TAIPAN",
    "mainMethod": {
      "type": "Supervised",
      "technique": "Decision-tree (or SVM) classifier on support + connectivity features + probabilistic property ranking"
    },
    "domain": {
      "domain": "Independent",
      "type": ""
    },
    "coreTasks": {
      "cta": true,
      "cpa": true,
      "cea": false,
      "cnea": false
    },
    "supportTasks": {
      "dataPreparation": {
        "description": "",
        "spellChecker": "",
        "unitsOfMeasurements": ""
      },
      "subjectDetection": "After characterizing columns by means of their support and connectivity scores, we can use binary classifiers to classify columns of a table as being either subject columns or not. Best classifiers SVM, Decision Tree",
      "columnClassification": " ",
      "typeAnnotation": "Approach takes into account the relation between the S-column and the other NE columns. It uses a probabilistic model based on the most frequent types in the \\ac{kg} and majority voting to determine the column type annotation.",
      "predicateAnnotation": "relation probability: number of matching pairs / number of table rows",
      "datatypeAnnotation": "",
      "entityLinking": {
        "description": "",
        "candidateGeneration": "",
        "entityDisambiguation": ""
      },
      "nilAnnotation": ""
    },
    "revision": {
      "type": "None",
      "description": ""
    },
    "validation": "T2D* (manually curated) and DBpedia Table Dataset (DBD)",
    "codeAvailability": "https://github.com/dice-group/TAIPAN",
    "license": "GPL 3.0",
    "inputs": {
      "typeOfTable": "HTML Web tables (T2D*) and synthetic tables generated from DBpedia (DBD)",
      "kg": {
        "tripleStore": "DBpedia",
        "index": ""
      }
    },
    "output": "Mappings: subject-column, column→DBpedia property pairs (ready to emit RDF triples)",
    "checkedByAuthor": true,
    "checkedByAi": true,
    "id": "ermilov2016taipan",
    "doi": "https://doi.org/10.1007/978-3-319-49004-5_11",
    "authors": [
      "Ivan Ermilov",
      "Axel-Cyrille Ngonga Ngomo"
    ],
    "citations": [
      { "ref": "balakrishnan2016applying",  "title": "Applying WebTables in practice" },
      { "ref": "carmel2014erd",            "title": "ERD'14: Entity Recognition and Disambiguation Challenge" },
      { "ref": "ermilov2013csv2rdf",       "title": "CSV2RDF: User-driven CSV to RDF Mass Conversion Framework" },
      { "ref": "ermilov2013user",          "title": "User-driven Semantic Mapping of Tabular Data" },
      { "ref": "etzioni2005unsupervised",  "title": "Unsupervised Named-Entity Extraction from the Web: An Experimental Study" },
      { "ref": "gerber2012extracting",     "title": "Extracting Multilingual Natural-Language Patterns for RDF Predicates" },
      { "ref": "hripcsak2005agreement",    "title": "Agreement, the F-measure, and Reliability in Information Retrieval" },
      { "ref": "knoblock2012semi",         "title": "Semi-Automatically Mapping Structured Sources into the Semantic Web" },
      { "ref": "landis1977measurement",    "title": "The Measurement of Observer Agreement for Categorical Data" },
      { "ref": "lehmberg2015mannheim",     "title": "The Mannheim Search Join Engine" },
      { "ref": "limaye2010annotating",     "title": "Annotating and Searching Web Tables Using Entities, Types and Relationships" },
      { "ref": "mintz2009distant",         "title": "Distant Supervision for Relation Extraction without Labeled Data" },
      { "ref": "mulwad2010using",          "title": "Using Linked Data to Interpret Tables" },
      { "ref": "nadeau2007survey",         "title": "A Survey of Named Entity Recognition and Classification" },
      { "ref": "nakashole2012patty",       "title": "Patty: A Taxonomy of Relational Patterns with Semantic Types" },
      { "ref": "ritze2015matching",        "title": "Matching HTML Tables to DBpedia" },
      { "ref": "ritze2016profiling",       "title": "Profiling the Potential of Web Tables for Augmenting Cross-Domain Knowledge Bases" },
      { "ref": "snow2004learning",         "title": "Learning Syntactic Patterns for Automatic Hypernym Discovery" },
      { "ref": "speck2014ensemble",        "title": "Ensemble Learning for Named Entity Recognition" },
      { "ref": "suchanek2011paris",        "title": "PARIS: Probabilistic Alignment of Relations, Instances, and Schema" },
      { "ref": "usbeck2014agdistis",       "title": "AGDISTIS – Graph-Based Disambiguation of Named Entities Using Linked Data" },
      { "ref": "usbeck2015gerbil",         "title": "GERBIL – General Entity Annotator Benchmark Framework" },
      { "ref": "venetis2010table",         "title": "Table Search Using Recovered Semantics" },
      { "ref": "venetis2011recovering",    "title": "Recovering Semantics of Tables on the Web" },
      { "ref": "wang2015concept",          "title": "Concept Expansion Using Web Tables" },
      { "ref": "wang2012understanding",    "title": "Understanding Tables on the Web" },
      { "ref": "zhang2014towards",         "title": "Towards Efficient and Effective Semantic Table Interpretation" }
    ]
  },
  {
    "firstAuthor": "Neumaier",
    "year": 2016,
    "title": {
      "text": "Multi-level semantic labelling of numerical values",
      "link": ""
    },
    "added": "",
    "conferenceJournal": "ISWC",
    "nameOfApproach": "",
    "mainMethod": {
      "type": "Unsupervised",
      "technique": "Hierarchical clustering + k-nearest-neighbour (KS / Euclidean distance)"
    },
    "domain": {
      "domain": "Independent",
      "type": ""
    },
    "coreTasks": {
      "cta": true,
      "cpa": false,
      "cea": false,
      "cnea": false
    },
    "supportTasks": {
      "dataPreparation": {
        "description": "",
        "spellChecker": "",
        "unitsOfMeasurements": ""
      },
      "subjectDetection": "",
      "columnClassification": "k-NN ranking of property + context for each numerical column",
      "typeAnnotation": "",
      "predicateAnnotation": " ",
      "datatypeAnnotation": "Only numerical values.",
      "entityLinking": {
        "description": "",
        "candidateGeneration": "",
        "entityDisambiguation": ""
      },
      "nilAnnotation": ""
    },
    "revision": {
      "type": "None",
      "description": ""
    },
    "validation": "10-fold cross-validation on 50 numeric properties (33,657 test nodes) plus an experiment on 1,343 CSV files from Open Data portals.",
    "codeAvailability": "https://github.com/sebneu/number_labelling",
    "license": "Apache 2.0",
    "inputs": {
      "typeOfTable": "Numerical columns (bags of values) from DBpedia and Open-Data CSV tables",
      "kg": {
        "tripleStore": "DBpedia",
        "index": ""
      }
    },
    "output": "Ranked list of (property, context) candidates with distance scores",
    "checkedByAuthor": true,
    "checkedByAi": true,
    "id": "neumaier2016multilevel",
    "doi": "https://doi.org/10.1007/978-3-319-46523-4_26",
    "authors": [
      "Sebastian Neumaier",
      "Jürgen Umbrich",
      "Josiane Xavier Parreira",
      "Axel Polleres"
    ],
    "citations": [
      { "ref": "adelfio2013schema", "title": "Schema extraction for tabular data on the web" },
      { "ref": "arenas2012a", "title": "A Direct Mapping of Relational Data to RDF" },
      { "ref": "cruz2013semantic", "title": "Semantic extraction of geographic data from web tables for big data integration" },
      { "ref": "dassarma2012finding", "title": "Finding related tables" },
      { "ref": "ermilov2013user", "title": "User-driven semantic mapping of tabular data" },
      { "ref": "fleischhacker2014detecting", "title": "Detecting errors in numerical linked data using cross-checked outlier detection" },
      { "ref": "gal2016from", "title": "From diversity-based prediction to better ontology & schema matching" },
      { "ref": "halevy2016discovering", "title": "Discovering structure in the universe of attribute names" },
      { "ref": "lopez2012queriocity", "title": "Queriocity: A linked data platform for urban information management" },
      { "ref": "navigli2012babelnet", "title": "BabelNet: The automatic construction, evaluation and application of a wide-coverage multilingual semantic network" },
      { "ref": "ramnandan2015assigning", "title": "Assigning semantic labels to data sources" },
      { "ref": "rastan2013towards", "title": "Towards generic framework for tabular data extraction and management in documents" },
      { "ref": "ritze2015matching", "title": "Matching HTML tables to DBpedia" },
      { "ref": "ritze2016profiling", "title": "Profiling the potential of web tables for augmenting cross-domain knowledge bases" },
      { "ref": "rong2012amachine", "title": "A machine learning approach for instance matching based on similarity metrics" },
      { "ref": "syed2010exploiting", "title": "Exploiting a Web of Semantic Data for Interpreting Tables" },
      { "ref": "taheriyan2014ascalable", "title": "A Scalable Approach to Learn Semantic Models of Structured Sources" },
      { "ref": "tandy2015generating", "title": "Generating RDF from tabular data on the web" },
      { "ref": "umbrich2015quality", "title": "Quality assessment & evolution of open data portals" },
      { "ref": "venetis2011recovering", "title": "Recovering semantics of tables on the web" },
      { "ref": "wang2012understanding", "title": "Understanding tables on the web" },
      { "ref": "wienand2014detecting", "title": "Detecting incorrect numerical data in DBpedia" },
      { "ref": "zhang2013infogather+", "title": "Infogather+: Semantic matching and annotation of numeric and time-varying attributes in web tables" },
      { "ref": "zhang2014towards", "title": "Towards efficient and effective semantic table interpretation" }
    ]
  },
  {
    "firstAuthor": "Pham",
    "year": 2016,
    "title": {
      "text": "Semantic labeling: A domain-independent approach",
      "link": ""
    },
    "added": "",
    "conferenceJournal": "ISWC",
    "nameOfApproach": "DSL(Domain-independent SemanticLabeler)",
    "mainMethod": {
      "type": "Supervised",
      "technique": "Logistic Regression"
    },
    "domain": {
      "domain": "Independent",
      "type": "Musum, city, soccer, weather"
    },
    "coreTasks": {
      "cta": true,
      "cpa": false,
      "cea": false,
      "cnea": false
    },
    "supportTasks": {
      "dataPreparation": {
        "description": "",
        "spellChecker": "",
        "unitsOfMeasurements": ""
      },
      "subjectDetection": "",
      "columnClassification": "In our approach, we compute three different value similarity metrics: Jaccard similarity and TF-IDF cosine similarity for textual data, as well as a modified version of Jaccard similarity for numeric values. For numeric data, there are semantic types that we are unable to distinguish by using value similarity because they have the same range of values. Therefore, we analyze the distribution of numeric values contained in the attributes using statistical hypothesis testing as one of the similarity metrics. We use KolmogorovSmirnov test (KS test)[6] as our statistical hypothesis test based on evaluation of different statistical tests in Ramnandan et al.'s research ",
      "typeAnnotation": "",
      "predicateAnnotation": " ",
      "datatypeAnnotation": "In our approach, we compute three different value similarity metrics: Jaccard similarity and TF-IDF cosine similarity for textual data, as well as a modified version of Jaccard similarity for numeric values.",
      "entityLinking": {
        "description": "",
        "candidateGeneration": "",
        "entityDisambiguation": ""
      },
      "nilAnnotation": ""
    },
    "revision": {
      "type": "None",
      "description": ""
    },
    "validation": "Datasets: museum (29 sources), city (10), soccer (12), weather (4) + T2D Gold Standard",
    "codeAvailability": "https://github.com/minhptx/iswc-2016-semantic-labeling",
    "license": "Apache 2.0",
    "inputs": {
      "typeOfTable": "Structured sources (CSV files, relational tables, spreadsheets, web tables)",
      "kg": {
        "tripleStore": "",
        "index": ""
      }
    },
    "output": "The output is a set of top-k semantic types corresponding to the unlabeled attribute.",
    "checkedByAuthor": true,
    "checkedByAi": true,
    "id": "pham2016semantic",
    "doi": "https://doi.org/10.1007/978-3-319-46523-4_27",
    "authors": [
      "Minh Pham",
      "Suresh Alse",
      "Craig A. Knoblock",
      "Pedro Szekely"
    ],
    "citations": [
      { "ref": "ambite2009automatically", "title": "Automatically Constructing Semantic Web Services from Online Sources" },
      { "ref": "breiman2001random", "title": "Random Forests" },
      { "ref": "craswell2009mean", "title": "Mean reciprocal rank" },
      { "ref": "goel2012exploiting", "title": "Exploiting structure within data for accurate labeling using conditional random fields" },
      { "ref": "gunaratna2016gleaning", "title": "Gleaning Types for Literals in RDF Triples with Application to Entity Summarization" },
      { "ref": "lehmann2005testing", "title": "Testing Statistical Hypotheses" },
      { "ref": "limaye2010annotating", "title": "Annotating and Searching Web Tables Using Entities, Types and Relationships" },
      { "ref": "manning2008introduction", "title": "Introduction to Information Retrieval" },
      { "ref": "mulwad2013semantic", "title": "Semantic message passing for generating linked data from tables" },
      { "ref": "mulwad2015tabel", "title": "TABEL - A Domain Independent and Extensible Framework for Inferring the Semantics of Tables" },
      { "ref": "ramnandan2015assigning", "title": "Assigning Semantic Labels to Data Sources" },
      { "ref": "ritze2015matching", "title": "Matching HTML Tables to DBpedia" },
      { "ref": "syed2010exploiting", "title": "Exploiting a web of semantic data for interpreting tables" },
      { "ref": "taheriyan2016learning", "title": "Learning the semantics of structured data sources" },
      { "ref": "venetis2011recovering", "title": "Recovering semantics of tables on the web" }
    ]
  },
  {
    "firstAuthor": "Taheriyan",
    "year": 2016,
    "title": {
      "text": "Learning the semantics of structured data sources",
      "link": ""
    },
    "added": "",
    "conferenceJournal": "JOWS",
    "nameOfApproach": "Karma",
    "mainMethod": {
      "type": "Hybrid – supervised (semantic-labeling) + unsupervised/graph search (relation inference)",
      "technique": "TF-IDF cosine similarity & KS-test (labeling) + weighted-graph construction & top-k Steiner-tree search (BANKS algorithm)"
    },
    "domain": {
      "domain": "Dependent",
      "type": "museum"
    },
    "coreTasks": {
      "cta": true,
      "cpa": true,
      "cea": false,
      "cnea": false
    },
    "supportTasks": {
      "dataPreparation": {
        "description": "",
        "spellChecker": "",
        "unitsOfMeasurements": ""
      },
      "subjectDetection": "",
      "columnClassification": "syntactic information about data sources such as attribute names or attribute types (string, int, date, ...) may give the system some hints to discover semantic types. We employ the technique proposed by Ramnandan2015 to learn semantic types of source attributes. Their approach focuses on learning the semantic types from the data rather than the attribute names. It learns a semantic labeling function from a set of sources that have been manually labeled. ",
      "typeAnnotation": "For each class node v in sm(si), we search the graph to see if G includes a class node with the same label. It is possible that sm(si) contains multiple class nodes with the same label, for instance, a model including the link isFriendOf from one Person to another Person. In this case, we make sure that G also has at least the same number of class nodes with that label. Once we added the required class nodes to the graph, we map the class nodes in the model to the class nodes in the graph. If G has multiple class nodes with the same label, we select the one that is tagged by larger number of known semantic models. We add anentry to H with v as the key and the mapped node(v′) as the value.",
      "predicateAnnotation": "The goal is to connect class nodes of G using the direct paths or the. paths inferred through the subclass hierarchy in O. Once we apply this labeling method, it generates a set of candidate semantic types for each source attribute, each with a confidence value. Our algorithm then selects the top k semantic types for each attribute as an input to the next step of the process. 11 ,...,tp1k Thus, the output of the labeling step for s(a1,a2,...,am) is T = {(tp11 1k ),...,(tpm1 m1 ,...,tpmk mk )}, where in tpij ij , tij is the jth semantic type learned for the attribute ai and pij is the associated confidence value which is a decimal value between 0 and 1.",
      "datatypeAnnotation": "If the data values associated with a source attribute ai are textual data, the labeling algorithm uses the cosine similarity between TF/IDF vectors of the labeled documents and the input document to predict candidate semantic types. For attributes with numeric data, the algorithm uses statistical hypothesis testing [25] to analyze the distribution of numericvalues.",
      "entityLinking": {
        "description": "Therefore, we adopt a different strategy; if there is more than one node in the graph matching a node in the semantic model, we select the one having moretags.",
        "candidateGeneration": "",
        "entityDisambiguation": ""
      },
      "nilAnnotation": "Not only entities. When adding a new node or link, we tag it with a unique identifier (e.g., si, name of the source) indicating that the node/link exist in sm(si)."
    },
    "revision": {
      "type": "Semi automated",
      "description": "Users then interact with the system to adjust the automatically generated model. During this process, users can transform the data as needed to normalize data expressed in different formats and to restructure it."
    },
    "validation": "29 museum sources (CSV, XML, JSON); 10-fold cross-validation on datasets dsedm & dscrm. The link to the datasets https://github.com/taheriyan/jws-knowledge-graphs-2015",
    "codeAvailability": "https://github.com/usc-isi-i2/Web-Karma",
    "license": "Apache 2.0",
    "inputs": {
      "typeOfTable": "Relational DBs, spreadsheets, XML, JSON and Web-API outputs.",
      "kg": {
        "tripleStore": "",
        "index": "CIDOC-CRM, EDM"
      }
    },
    "output": "Semantic model (graph) + optional RDF/R2RML export",
    "checkedByAuthor": true,
    "checkedByAi": true,
    "id": "taheriyan2016learning",
    "doi": "https://doi.org/10.1016/j.websem.2015.12.003",
    "authors": [
      "Mohsen Taheriyan",
      "Craig A. Knoblock",
      "Pedro Szekely",
      "José Luis Ambite"
    ],
    "citations": [
      { "ref": "doan2012principles", "title": "Principles of Data Integration" },
      { "ref": "han2008rdf123", "title": "RDF123: From Spreadsheets to RDF" },
      { "ref": "sheth2008semantics", "title": "Semantics Enhanced Services: METEOR-S, SAWSDL and SA-REST" },
      { "ref": "langegger2009xlwrap", "title": "XLWrap — Querying and Integrating Arbitrary Spreadsheets with SPARQL" },
      { "ref": "sahoo2009survey", "title": "A Survey of Current Approaches for Mapping of Relational Databases to RDF" },
      { "ref": "polfliet2010automated", "title": "Automated Mapping Generation for Converting Databases into Linked Data" },
      { "ref": "limaye2010annotating", "title": "Annotating and Searching Web Tables Using Entities, Types and Relationships" },
      { "ref": "vavliakis2010rdote", "title": "RDOTE — Transforming Relational Databases into Semantic Web Data" },
      { "ref": "ding2010twcdatagov", "title": "TWC Data-gov Corpus: Incrementally Generating Linked Government Data from data.gov" },
      { "ref": "saquicela2011lightweight", "title": "Lightweight Semantic Annotation of Geospatial RESTful Services" },
      { "ref": "venetis2011recovering", "title": "Recovering Semantics of Tables on the Web" },
      { "ref": "wang2012understanding", "title": "Understanding Tables on the Web" },
      { "ref": "mulwad2013semantic", "title": "Semantic Message Passing for Generating Linked Data from Tables" },
      { "ref": "krishnamurthy2015assigning", "title": "Assigning Semantic Labels to Data Sources" },
      { "ref": "taheriyan2014scalable", "title": "A Scalable Approach to Learn Semantic Models of Structured Sources" },
      { "ref": "taheriyan2013graph", "title": "A Graph-based Approach to Learn Semantic Descriptions of Data Sources" },
      { "ref": "hennicke2011datamodel", "title": "A Data Model for Cross-domain Data Representation: The Europeana Data Model in the Case of Archival and Museum Data" },
      { "ref": "doerr2003cidoc", "title": "The CIDOC Conceptual Reference Module: An Ontological Approach to Semantic Interoperability of Metadata" },
      { "ref": "das2012r2rml", "title": "R2RML: RDB to RDF Mapping Language" },
      { "ref": "knoblock2012semiautomatically", "title": "Semi-automatically Mapping Structured Sources into the Semantic Web" },
      { "ref": "szekely2013connecting", "title": "Connecting the Smithsonian American Art Museum to the Linked Data Cloud" },
      { "ref": "szekely2011exploiting", "title": "Exploiting Semantics of Web Services for Geospatial Data Fusion" },
      { "ref": "taheriyan2012webapis", "title": "Semi-Automatically Modeling Web APIs to Create Linked APIs" },
      { "ref": "taheriyan2012rapidly", "title": "Rapidly Integrating Services into the Linked Data Cloud" },
      { "ref": "lehmann2005testing", "title": "Testing Statistical Hypotheses" },
      { "ref": "winter1987steiner", "title": "Steiner Problem in Networks — A Survey" },
      { "ref": "takahashi1980approximate", "title": "An Approximate Solution for the Steiner Problem in Graphs" },
      { "ref": "kou1981fast", "title": "A Fast Algorithm for Steiner Trees" },
      { "ref": "mehlhorn1988faster", "title": "A Faster Approximation Algorithm for the Steiner Problem in Graphs" },
      { "ref": "bhalotia2002keyword", "title": "Keyword Searching and Browsing in Databases Using BANKS" },
      { "ref": "craswell2009mean", "title": "Mean Reciprocal Rank" },
      { "ref": "arenas2010exchange", "title": "Relational and XML Data Exchange" },
      { "ref": "bellahsene2011schema", "title": "Schema Matching and Mapping" },
      { "ref": "rahm2001survey", "title": "A Survey of Approaches to Automatic Schema Matching" },
      { "ref": "dhamankar2004imap", "title": "iMAP: Discovering Complex Semantic Matches Between Database Schemas" },
      { "ref": "fagin2009schema", "title": "Schema mapping creation and data exchange" },
      { "ref": "fagin2005data", "title": "Data Exchange: Semantics and Query Answering" },
      { "ref": "marnette2011spicy", "title": "++Spicy: An Open-source Tool for Second-generation Schema Mapping and Data Exchange" },
      { "ref": "alexe2011designing", "title": "Designing and Refining Schema Mappings via Data Examples" },
      { "ref": "an2007semantic", "title": "A Semantic Approach to Discovering Schema Mapping Expressions" },
      { "ref": "bizer2003d2rmap", "title": "D2R MAP — A Database to RDF Mapping Language" },
      { "ref": "bizer2006d2rserver", "title": "D2R Server — Publishing Relational Databases on the Semantic Web" },
      { "ref": "bizer2004d2rq", "title": "D2RQ — Treating Non-RDF Databases as Virtual RDF Graphs" },
      { "ref": "munoz2013triplifying", "title": "Triplifying wikipedia’s tables" },   
      { "ref": "auer2007dbpedia", "title": "DBpedia: A nucleus for a web of open data" },      
      { "ref": "syed2011hybrid", "title": "Creating and Exploiting a Hybrid Knowledge Base for Linked Data" },
      { "ref": "bollacker2008freebase", "title": "Freebase: A Collaboratively Created Graph Database for Structuring Human Knowledge" },
      { "ref": "parundekar2012disco", "title": "Discovering Concept Coverings in Ontologies of Linked Data Sources" },
      { "ref": "carman2007learning", "title": "Learning Semantic Definitions of Online Information Sources" },
      { "ref": "kalfoglou2003ontology", "title": "Ontology Mapping: The State of the Art" },
      { "ref": "pavel2013ontology", "title": "Ontology Matching: State of the Art and Future Challenges" },
      { "ref": "taheriyan2015leveraging", "title": "Leveraging Linked Data to Infer Semantic Relations Within Structured Sources" }
    ]
  },
  {
    "firstAuthor": "Taheriyan",
    "year": 2016,
    "title": {
      "text": "Leveraging Linked Data to Discover Semantic Relations within Data Sources",
      "link": ""
    },
    "added": "",
    "conferenceJournal": "ISWC",
    "nameOfApproach": "Karma",
    "mainMethod": {
      "type": "Unsupervised",
      "technique": "Graph-pattern mining + BANKS top-k minimum-cost tree search"
    },
    "domain": {
      "domain": "Independent",
      "type": ""
    },
    "coreTasks": {
      "cta": false,
      "cpa": true,
      "cea": false,
      "cnea": false
    },
    "supportTasks": {
      "dataPreparation": {
        "description": "",
        "spellChecker": "",
        "unitsOfMeasurements": ""
      },
      "subjectDetection": "",
      "columnClassification": " ",
      "typeAnnotation": "",
      "predicateAnnotation": "Auhtors exploit the predicates used by LOD datasets, by extracting all predicates that connect two given classes in the LOD. BANKS algorithm computes the top k minimum cost trees that span a subset of the nodes in a graph (the nodes that the semantic types are mapped to).",
      "datatypeAnnotation": "",
      "entityLinking": {
        "description": "",
        "candidateGeneration": "",
        "entityDisambiguation": ""
      },
      "nilAnnotation": ""
    },
    "revision": {
      "type": "Fully automated",
      "description": "GUI usage"
    },
    "validation": "Four datasets (29 museum sources, Smithsonian LOD, same 29 sources with EDM, 15 weapon-ads sources)",
    "codeAvailability": "https://github.com/usc-isi-i2/Web-Karma",
    "license": "Apache 2.0",
    "inputs": {
      "typeOfTable": "Structured sources (CSV, XML, JSON, relational spreadsheets)",
      "kg": {
        "tripleStore": "Virtuoso repository (triples encoded with CIDOC-CRM)",
        "index": ""
      }
    },
    "output": "A semantic model expressing how the assigned labels are connected",
    "checkedByAuthor": true,
    "checkedByAi": true,
    "id": "taheriyan2016leveraging",
    "doi": "https://doi.org/10.1007/978-3-319-46523-4_33",
    "authors": [
      "Mohsen Taheriyan",
      "Craig A. Knoblock",
      "Pedro Szekely",
      "José Luis Ambite"
    ],
    "citations": [
      { "ref": "bhalotia2002keyword", "title": "Keyword Searching and Browsing in Databases Using BANKS" },
      { "ref": "carman2007learning", "title": "Learning Semantic Definitions of Online Information Sources" },
      { "ref": "ding2010twcdatagov", "title": "TWC Data-gov Corpus: Incrementally Generating Linked Government Data from data.gov" },
      { "ref": "han2008rdf123", "title": "RDF123: From Spreadsheets to RDF" },
      { "ref": "knoblock2012semiautomatically", "title": "Semi-Automatically Mapping Structured Sources into the Semantic Web" },
      { "ref": "krishnamurthy2015assigning", "title": "Assigning Semantic Labels to Data Sources" },
      { "ref": "limaye2010annotating", "title": "Annotating and Searching Web Tables Using Entities, Types and Relationships" },
      { "ref": "mulwad2013semantic", "title": "Semantic Message Passing for Generating Linked Data from Tables" },
      { "ref": "pham2016semantic", "title": "Semantic Labeling: A Domain-independent Approach" },
      { "ref": "polfliet2010automated", "title": "Automated Mapping Generation for Converting Databases into Linked Data" },
      { "ref": "sahoo2009survey", "title": "A Survey of Current Approaches for Mapping of Relational Databases to RDF" },
      { "ref": "saquicela2011lightweight", "title": "Lightweight Semantic Annotation of Geospatial RESTful Services" },
      { "ref": "schaible2016termpicker", "title": "TermPicker: Enabling the Reuse of Vocabulary Terms by Exploiting Data from the Linked Open Data Cloud" },
      { "ref": "syed2011creating", "title": "Creating and Exploiting a Hybrid Knowledge Base for Linked Data" },
      { "ref": "taheriyan2016learning", "title": "Learning the Semantics of Structured Data Sources" },
      { "ref": "taheriyan2015leveraging", "title": "Leveraging Linked Data to Infer Semantic Relations within Structured Sources" },
      { "ref": "venetis2011recovering", "title": "Recovering Semantics of Tables on the Web" },
      { "ref": "wang2012understanding", "title": "Understanding Tables on the Web" }
    ]
  },
  {
    "firstAuthor": "Efthymiou",
    "year": 2017,
    "title": {
      "text": "Matching Web Tables with Knowledge Base Entities: From Entity Lookups to Entity Embeddings",
      "link": ""
    },
    "added": "",
    "conferenceJournal": "ISWC",
    "nameOfApproach": "",
    "mainMethod": {
      "type": "Hybrid",
      "technique": "hybrid"
    },
    "domain": {
      "domain": "Independent",
      "type": ""
    },
    "coreTasks": {
      "cta": false,
      "cpa": true,
      "cea": true,
      "cnea": false
    },
    "supportTasks": {
      "dataPreparation": {
        "description": "stopword removal",
        "spellChecker": "",
        "unitsOfMeasurements": ""
      },
      "subjectDetection": "the label column (that I think refers to the subject column) is defined as the leftmost column with the maximum number of distinct (non-numeric) values",
      "columnClassification": "column sampling",
      "typeAnnotation": "",
      "predicateAnnotation": "associate each column with an object property having as domain the ontology class to which the subject column entity belongs",
      "datatypeAnnotation": "",
      "entityLinking": {
        "description": "(a) a lookup-based method which relies on the minimal entity context provided in Web tables to discover correspondences to the KB, (b) a semantic embeddings method that exploits a vectorial representation of the rich entity context in a KB to identify the most relevant subset of entities in the Web table, and (c) an ontology matching method, which exploits schematic and instance information of entities available both in a KB and a Web table.",
        "candidateGeneration": "lookup, custom index",
        "entityDisambiguation": "entity embedding, contextual inf"
      },
      "nilAnnotation": ""
    },
    "revision": {
      "type": "None",
      "description": ""
    },
    "validation": "TD2, Limaye, Wikipedia (a GS constructed by the authors created by extracting the hyperlinks of existing Wikipedia tables to Wikipedia pages, which we have replaced with annotations to the corresponding entities from the October 2015 version of DBpedia.) Since the header rows in Wikipedia tables are not linked to properties, our gold standard does not contain schema-level mappings.",
    "codeAvailability": "http://www.cs.toronto.edu/~oktie/webtables/",
    "license": "Not specified",
    "inputs": {
      "typeOfTable": "Web tables",
      "kg": {
        "tripleStore": "",
        "index": ""
      }
    },
    "output": "JSON",
    "checkedByAuthor": true,
    "authors": [],
    "checkedByAi": false
  },
  {
    "firstAuthor": "Ell",
    "year": 2017,
    "title": {
      "text": "Towards a Large Corpus of Richly Annotated Web Tables for Knowledge Base Population",
      "link": ""
    },
    "added": "",
    "conferenceJournal": "LD4IE",
    "nameOfApproach": "This paper is not about an apporach rather than on proposing techniques or hypothesis about the tables in order to improve STI approaches performance",
    "mainMethod": {
      "type": "Unsupervised",
      "technique": "lookup"
    },
    "domain": {
      "domain": "Independent",
      "type": ""
    },
    "coreTasks": {
      "cta": false,
      "cpa": false,
      "cea": true,
      "cnea": false
    },
    "supportTasks": {
      "dataPreparation": {
        "description": "Table Normalization Task (normalizing values found in cells); format of the dates; regular expersion to detect a certain language",
        "spellChecker": "",
        "unitsOfMeasurements": "Values, such as those representing weights, lengths, volumes, time etc. can have unit identifiers attached. For each string that appears to be a value followed by a unit identifier we create a hypothesis that contains both the value and the base unit identifier separately where the value is converted to the base unit"
      },
      "subjectDetection": "",
      "columnClassification": "",
      "typeAnnotation": "Given the value of plain hypotheses created by table normalization, we check the three indexes related to the language the hypothesis is based on for all resources this value could refer to and order the results by their frequency. For the top 10 entities, properties, and classes we create cell-based hypotheses.",
      "predicateAnnotation": "",
      "datatypeAnnotation": "This task makes use of an index for each language (containing language-tagged strings as well as datatyped-literals from the respective language version of DBpedia) to quickly retrieve a set of properties given an entity, a literal, and a datatype.",
      "entityLinking": {
        "description": "",
        "candidateGeneration": "lookup, custom index",
        "entityDisambiguation": "features"
      },
      "nilAnnotation": ""
    },
    "revision": {
      "type": "None",
      "description": ""
    },
    "validation": "WDC Web Table Corpus 2015",
    "codeAvailability": "",
    "license": "Apache 2.0",
    "inputs": {
      "typeOfTable": "Web Tables",
      "kg": {
        "tripleStore": "DBpedia",
        "index": "Labels + literals"
      }
    },
    "output": "",
    "checkedByAuthor": false,
    "authors": [],
    "checkedByAi": false
  },
  {
    "firstAuthor": "Zhang",
    "year": 2017,
    "title": {
      "text": "Effective and Efficient Semantic Table Interpretation using TableMiner+",
      "link": ""
    },
    "added": "",
    "conferenceJournal": "JOWS",
    "nameOfApproach": "TableMiner+",
    "mainMethod": {
      "type": "Unsupervised",
      "technique": "probabilistic features"
    },
    "domain": {
      "domain": "Independent",
      "type": ""
    },
    "coreTasks": {
      "cta": true,
      "cpa": true,
      "cea": true,
      "cnea": false
    },
    "supportTasks": {
      "dataPreparation": {
        "description": "BoW representation, stopword removal",
        "spellChecker": "",
        "unitsOfMeasurements": ""
      },
      "subjectDetection": "Subject column detection is done by using simple regular expressions that examine the syntactic features of cell text, such as number of words, capitalization, mentions of months or days in a week ('empty', 'named entity', 'number', 'date expression', 'long text' (e.g., sentence, or paragraph), and 'other'). Next, if a candidate NE-columnhasacolumnheader that is a preposition word, it is discarded.",
      "columnClassification": "generates candidate concepts for an NEcolumn and computes confidence scores for each candidate. Intuitively, if we already know the entity annotation for each cell, we can define candidate concepts as the set of concepts associated with the entity from each cell. Specifically, in each iteration, a cell taken from the column is disambiguated by comparing the feature representation of each candidate entity against the feature representation of that cell. Then the concepts associated with the highest scoring (i.e., the winning) entity7 are gathered to create a set of candidate concepts for the column.",
      "typeAnnotation": "it performs NE annotation by coupling column classification with entity disambiguation in an incremental, mutually recursive, bootstrapping approach. The NE annotation starts with a LEARNING phase that is able to interpret independently an NE column to create preliminary concept annotation for an NE-column and entity annotation for the cells of the column. The cells with the same content are treated as a singleton in order to build a shared and combined context in-table. The number of features in the representation of each cell is used as a preference score. Such is followed by the update phase, which revises the annotations iteratively by enforcing interdependence between columns.",
      "predicateAnnotation": "Relation enumeration firstly begins by interpreting relations between the subject column and any other columns on each row independently. Then a confidence score is computed for each candidate relation. the subset of triples containing as predicate are selected. Then the object of each triple in this set is matched against the content in the table using the frequency weighted dice function and the highest score is assigned to be the confidence score for the candidate relation. The dice function computes an overlap score between the bag-of-words representations of the cell and the object of a triple that contains. The confidence score is comuted and it is composed of a relation instance score re and a relation context score.",
      "datatypeAnnotation": "Literal-columns are expected to contain attribute data of entities in the subject column. This work also assigns a column annotation that best describes the attribute data in literal-columns. Given a literal-column Tj that forms a binary relation rj,jwith the subject column Tj, the annotation for this column is simply l(rj,j), since rj,jtypically describes a property of the subject column concept in such cases.",
      "entityLinking": {
        "description": "entity linking and the NE column identification and annotattion occure in the same time",
        "candidateGeneration": "lookup",
        "entityDisambiguation": "features, contextual inf"
      },
      "nilAnnotation": ""
    },
    "revision": {
      "type": "None",
      "description": ""
    },
    "validation": "For evaluation, we compiled and annotated four datasets using Freebase: Limaye200, LimayeAll, IMDB and MusicBrainz.",
    "codeAvailability": "https://github.com/ziqizhang/sti",
    "license": "Apache 2.0",
    "inputs": {
      "typeOfTable": "Web tables",
      "kg": {
        "tripleStore": "Freebase",
        "index": "rdf graph"
      }
    },
    "output": "",
    "checkedByAuthor": false,
    "authors": [],
    "checkedByAi": false
  },
  {
    "firstAuthor": "Kacprzak",
    "year": 2018,
    "title": {
      "text": "Making Sense of Numerical Data - Semantic Labelling of Web Tables",
      "link": ""
    },
    "added": "",
    "conferenceJournal": "EKAW",
    "nameOfApproach": "NUMER",
    "mainMethod": {
      "type": "Unsupervised",
      "technique": "features"
    },
    "domain": {
      "domain": "Independent",
      "type": ""
    },
    "coreTasks": {
      "cta": true,
      "cpa": false,
      "cea": false,
      "cnea": false
    },
    "supportTasks": {
      "dataPreparation": {
        "description": "strip non numerical chars from numeric columns",
        "spellChecker": "",
        "unitsOfMeasurements": ""
      },
      "subjectDetection": "In this work we focus on labelling columns with numerical data, assuming a subject column has been previously identified.",
      "columnClassification": "considers as numeric the columns with at least 50% of numerical values, else the columns are classified as textual.",
      "typeAnnotation": "",
      "predicateAnnotation": "",
      "datatypeAnnotation": "Compare the distribution of values in numerical columns with bags of values from the target KB. They consider only columns that have a semantic relation with the types of the entities in the subject column. For each retrieved type from the KG, a list of all instances in the target KB is generated. For each entity they select properties of rdf:type owl:DatatypeProperty associated to it.",
      "entityLinking": {
        "description": "",
        "candidateGeneration": "",
        "entityDisambiguation": ""
      },
      "nilAnnotation": ""
    },
    "revision": {
      "type": "None",
      "description": ""
    },
    "validation": "MLL",
    "codeAvailability": "https://github.com/chabrowa/semantification",
    "license": "MIT",
    "inputs": {
      "typeOfTable": "",
      "kg": {
        "tripleStore": "DBpedia",
        "index": ""
      }
    },
    "output": "",
    "checkedByAuthor": false,
    "authors": [],
    "checkedByAi": false
  },
  {
    "firstAuthor": "Luo",
    "year": 2018,
    "title": {
      "text": "Cross-Lingual Entity Linking for Web Tables",
      "link": ""
    },
    "added": "",
    "conferenceJournal": "AAAI",
    "nameOfApproach": "",
    "mainMethod": {
      "type": "Supervised",
      "technique": "Neural Network"
    },
    "domain": {
      "domain": "Independent",
      "type": ""
    },
    "coreTasks": {
      "cta": false,
      "cpa": false,
      "cea": false,
      "cnea": false
    },
    "supportTasks": {
      "dataPreparation": {
        "description": "",
        "spellChecker": "",
        "unitsOfMeasurements": ""
      },
      "subjectDetection": "",
      "columnClassification": "",
      "typeAnnotation": "",
      "predicateAnnotation": "",
      "datatypeAnnotation": "",
      "entityLinking": {
        "description": "we first generate candidate entities of each single mention, then we learn two different features: the mention feature and context feature derived from the mention-entity embedding pairs of the table. To make different representations from two language spaces compatible. Meanwhile, we learn a third feature called coherence feature only from the candidate entity table. We train word embeddings and entity embeddings on two corpus of different languages separately. The vector spaces of embeddings in different languages are naturally incompatible, and it's hard for us to directly compare or calculate them. To tackle this problem, we employ a bilingual translation layer to map embeddings from one language space to another.",
        "candidateGeneration": "",
        "entityDisambiguation": ""
      },
      "nilAnnotation": "we attempt to solve the cross-lingual table linking problem without using any non-English knowledge bases. The paper presents a joint statistical model to simultaneously link all mentions that appear in one table. The framework is based on neural networks, aiming to bridge the language gap by vector space transformation and a coherence feature that captures the correlations between entities in one table. Experimental results report that our approach improves the accuracy of cross-lingual table linking by a relative gain of 12.1%. Detailed analysis of our approach also shows a positive and important gain brought by the joint framework and coherence feature."
    },
    "revision": {
      "type": "None",
      "description": ""
    },
    "validation": "",
    "codeAvailability": "",
    "license": "Not specified",
    "inputs": {
      "typeOfTable": "Tables",
      "kg": {
        "tripleStore": "Wikipedia",
        "index": ""
      }
    },
    "output": "",
    "checkedByAuthor": false,
    "authors": [],
    "checkedByAi": false
  },
  {
    "firstAuthor": "Zhang",
    "year": 2018,
    "title": {
      "text": "Ad Hoc Table Retrieval using Semantic Similarity",
      "link": ""
    },
    "added": "",
    "conferenceJournal": "WWW",
    "nameOfApproach": "STR",
    "mainMethod": {
      "type": "Unsupervised",
      "technique": "Neural Network"
    },
    "domain": {
      "domain": "Independent",
      "type": ""
    },
    "coreTasks": {
      "cta": false,
      "cpa": false,
      "cea": true,
      "cnea": false
    },
    "supportTasks": {
      "dataPreparation": {
        "description": "Bag of entities",
        "spellChecker": "",
        "unitsOfMeasurements": ""
      },
      "subjectDetection": "Core = Subject. We introduce a simple and effective core column detection method. It is based on the notion of column entity rate, which is defined as the ratio of cells in a column that contain an entity. ",
      "columnClassification": "",
      "typeAnnotation": "",
      "predicateAnnotation": "",
      "datatypeAnnotation": "",
      "entityLinking": {
        "description": "We employ a fielded entity representation with five fields (names, categories, attributes, similar entity names, and related entity names) and rank entities using the Mixture of Language Models approach. The field weights are set uniformly. This corresponds to the MLM-all model in and is shown to be a solid baseline.We return the top-k entities, where k is set to 10.",
        "candidateGeneration": "lookup, SPARQL",
        "entityDisambiguation": "entity embedding"
      },
      "nilAnnotation": "a method for performing semantic matching between queries and tables. The \"raw\" content of a query/table is represented as a set of terms, where terms can be eitherwords or entities. Each of the raw terms is mapped to a semantic vector representation"
    },
    "revision": {
      "type": "None",
      "description": ""
    },
    "validation": "TabEL",
    "codeAvailability": "https://github.com/iai-group/www2018-table",
    "license": "Not specified",
    "inputs": {
      "typeOfTable": "",
      "kg": {
        "tripleStore": "",
        "index": ""
      }
    },
    "output": "",
    "checkedByAuthor": false,
    "authors": [],
    "checkedByAi": false
  },
  {
    "firstAuthor": "Chabot",
    "year": 2019,
    "title": {
      "text": "DAGOBAH: An End-to-End Context-Free Tabular Data Semantic Annotation System",
      "link": ""
    },
    "added": "",
    "conferenceJournal": "SemTab",
    "nameOfApproach": "DAGOBAH",
    "mainMethod": {
      "type": "Hybrid",
      "technique": "rule base, embeddings"
    },
    "domain": {
      "domain": "Independent",
      "type": ""
    },
    "coreTasks": {
      "cta": true,
      "cpa": true,
      "cea": true,
      "cnea": false
    },
    "supportTasks": {
      "dataPreparation": {
        "description": "DAGOBAH conducts a preliminary cleaning process is first applied in order to have a macroscopic transformation process covering the most known artefacts: encoding homogenization and special characters deletion (parenthesis, square bracket and non alphanumeric characters) optimize the lookups. The intent is not to correct every string issues, but to",
        "spellChecker": "",
        "unitsOfMeasurements": ""
      },
      "subjectDetection": "The key column is an Object column containing a large number of unique values and located on the left side of the table.",
      "columnClassification": "Discriminate Columns with String, DateTime, Numerical",
      "typeAnnotation": "A basic type coverage of the cells criteria is not relevant as right types might be more specific but not frequent enough to be consider as the target ones. To solve this issue, a threshold based on relative scores is used. To each type t in {ti} (list of all types in a given column), a score St is first associated, from which a relative score Rt is computed. Only types with Rt > 0.7 (configurable threshold) are considered in the next steps. In order to select the target type from the short-listed ones, a TF-IDF-like method is used to compute the specificity.",
      "predicateAnnotation": "Concerning the CPA, a simple lookup technique on the header was used during round 1 explaining the low accuracy.",
      "datatypeAnnotation": "",
      "entityLinking": {
        "description": "In order to enhance the CEA results, the previous ordered types are used to disambiguate the candidates entities. If the first candidate of the lookup has the target type, it is selected as the target entity; if not, we select the entity associated to this type in the lookup list (if the list is empty, no annotation is produced). Both regex and Levenshtein distance strategies have been implemented.",
        "candidateGeneration": "lookup, WKD API, Wikidata Cirrus Engine, DBP LS, Wikipedia API, custom index",
        "entityDisambiguation": "features, entity embedding"
      },
      "nilAnnotation": "Challenges: a high dependency on lookup services (over which DAGOBAH has little control) and difficulties in correctly setting up algorithms (in particular finding the right compromise between specificity and representativeness of types in the case of CTA). Concerning the CPA, a simple lookup technique on the header was used during round 1 explaining the low accuracy."
    },
    "revision": {
      "type": "None",
      "description": ""
    },
    "validation": "SemTab 2019",
    "codeAvailability": "",
    "license": "Orange",
    "inputs": {
      "typeOfTable": "Tables",
      "kg": {
        "tripleStore": "DBpedia",
        "index": ""
      }
    },
    "output": "RDF",
    "checkedByAuthor": true,
    "authors": [],
    "checkedByAi": false
  },
  {
    "firstAuthor": "Chen",
    "year": 2019,
    "title": {
      "text": "ColNet: Embedding the Semantics of Web Tables for Column Type Prediction",
      "link": ""
    },
    "added": "",
    "conferenceJournal": "AAAI",
    "nameOfApproach": "ColNet",
    "mainMethod": {
      "type": "Hybrid",
      "technique": "CNN"
    },
    "domain": {
      "domain": "Independent",
      "type": ""
    },
    "coreTasks": {
      "cta": true,
      "cpa": false,
      "cea": true,
      "cnea": false
    },
    "supportTasks": {
      "dataPreparation": {
        "description": "",
        "spellChecker": "",
        "unitsOfMeasurements": ""
      },
      "subjectDetection": "",
      "columnClassification": "",
      "typeAnnotation": "1. lookup. Given an entity column, it retrieves column cells' corresponding entities in the KB and adopts the classes of the matched entities as a set of candidate classes for annotation. 2. prediction. For each candidate class, a customized binary CNN classifier which is able to learn both inter-cell and intra-cell locality features is trained and applied to predict whether cells of a column are of this class. 3. ensemble. Cell to entity matching and voting with majority can contribute to a highly confident prediction, while prediction with CNNs, which considers the contextual semantics of words can deal with type disambiguation and recall cells missed by lookup.",
      "predicateAnnotation": "",
      "datatypeAnnotation": "",
      "entityLinking": {
        "description": "In sampling, we first retrieve a set of entities from the KB, by matching all the column cells with KB entities according to the entity label and entity anchor text using a lexical index. Those matched entities are called particular entities. The classes and super classes of each particular entity are inferred (via KB reasoning) and they are used as candidate classes for annotation, denoted as C. The reason of selecting candidate classes instead of using all the KB classes is to avoid additional noise, thus reducing false positive predictions and computation. For each candidate class, we further infer all of its KB entities that are not matched. They are defined as general entities. The second round uses each column's candidate classes from the first round to constrain the cell to entity. matching, thus refining the entity suggestions. This step filters out some particular entities and candidate classes with limited matching confidence",
        "candidateGeneration": "lookup",
        "entityDisambiguation": "features, contextual inf"
      },
      "nilAnnotation": "ColNet is a framework that utilizes a KB, word representations and machine learning to automatically train prediction models for annotating types of entity columns that are assumed to have no metadata.. It first embeds the overall semantics of columns into vector space and then predicts their types with a set of candidate KB classes, using machine learning techniques like Convolutional Neural Networks (CNNs) and an ensemble of results from lookup. To automatically train robust prediction models, we use the cells to retrieve the candidate KB classes, infer their entities to construct training samples, and deal with the challenge of sample shortage using transfer learning. In summary, this study contributes a more accurate column type annotation framework by combining knowledge lookup and machine learning with the knowledge gap considered. As the framework does not assume any table metadata or table structure, it can be applied to not only Web tables but also general tabular data. The study also provides a general approach that embeds the overall semantics of a column where the correlation between cells is incorporated."
    },
    "revision": {
      "type": "None",
      "description": ""
    },
    "validation": "The method is evaluated with DBpedia and two different Web table datasets, T2Dv2 from the general Web and Limaye from Wikipedia pages",
    "codeAvailability": "https://github.com/alan-turing-institute/SemAIDA",
    "license": "Apache 2.0",
    "inputs": {
      "typeOfTable": "Tables",
      "kg": {
        "tripleStore": "DBpedia",
        "index": ""
      }
    },
    "output": "NE and entity linking",
    "checkedByAuthor": true,
    "authors": [],
    "checkedByAi": false
  },
  {
    "firstAuthor": "Chen",
    "year": 2019,
    "title": {
      "text": "Learning Semantic Annotations for Tabular Data",
      "link": ""
    },
    "added": "",
    "conferenceJournal": "IJCAI",
    "nameOfApproach": "ColNet",
    "mainMethod": {
      "type": "Unsupervised",
      "technique": "CNN"
    },
    "domain": {
      "domain": "Independent",
      "type": ""
    },
    "coreTasks": {
      "cta": true,
      "cpa": true,
      "cea": false,
      "cnea": false
    },
    "supportTasks": {
      "dataPreparation": {
        "description": "",
        "spellChecker": "",
        "unitsOfMeasurements": ""
      },
      "subjectDetection": "",
      "columnClassification": "",
      "typeAnnotation": "focuses on annotating columns that consist of phrases. For instance, a column containing \"Google, Amazon and Apple Inc.\" can be annotated by the class Company. To achieve this, they propose a method called HNN that captures the contextual semantics of a column.",
      "predicateAnnotation": "Property features are used to represent the potential relations between the target column and its surrounding columns. Property Vector algorithm is proposed for property annotation.",
      "datatypeAnnotation": "",
      "entityLinking": {
        "description": "",
        "candidateGeneration": "",
        "entityDisambiguation": ""
      },
      "nilAnnotation": ""
    },
    "revision": {
      "type": "None",
      "description": ""
    },
    "validation": "T2D, Limaye, Efthymiou",
    "codeAvailability": "https://github.com/alan-turing-institute/SemAIDA ",
    "license": "Apache 2.0",
    "inputs": {
      "typeOfTable": "Tables",
      "kg": {
        "tripleStore": "DBpedia",
        "index": ""
      }
    },
    "output": "",
    "checkedByAuthor": true,
    "authors": [],
    "checkedByAi": false
  },
  {
    "firstAuthor": "Cremaschi",
    "year": 2019,
    "title": {
      "text": "MantisTable: an Automatic Approach for the Semantic Table Interpretation",
      "link": ""
    },
    "added": "",
    "conferenceJournal": "SemTab",
    "nameOfApproach": "MantisTable",
    "mainMethod": {
      "type": "Unsupervised",
      "technique": "features"
    },
    "domain": {
      "domain": "Independent",
      "type": ""
    },
    "coreTasks": {
      "cta": true,
      "cpa": true,
      "cea": true,
      "cnea": false
    },
    "supportTasks": {
      "dataPreparation": {
        "description": "aims to clean and uniform data inside the table. Transformations applied to tables are as follows: deletion of HTML tags and some characters (i.e.), transformation of text into lowercase, deletion of text in brackets, resolution of acronyms and abbreviations, and normalisation of units of measurement.",
        "spellChecker": "To decipher acronyms and abbreviations, the Oxford English Dictionary3 is used.",
        "unitsOfMeasurements": "The normalisation of units of measurement is performed by applying regular expressions. MantisTable extends the original set of regular expressions to cover a complete set of units, which includes. area, currency, density, electric current, energy, flow rate, force, frequency, fuel efficiency, information unit, length, linear mass density, mass, numbers, population density, power, pressure, speed, temperature, time, torque, voltage and volume."
      },
      "subjectDetection": "subject column detection that takes into account the identified NE-columns. We can define the S-column as the main column of the table based on different statistic features, like Average Number of Words (aw) in each cell, Fraction of Empty Cells (emc) in the column, Fraction of Cells with Unique content (uc) and Distance from the First NE-column (df). The column with the highest score will be selected as the S-column for the considered table.",
      "columnClassification": "whose tasks are the semantic classification that assigns types to columns that are named entity (NE-column) or literal column (Lcolumn), and the detection of the subject column (S-column). The first step of the Column Analysis phase is to identify good L-column candidates",
      "typeAnnotation": "For each winning entity (Eij) we pick the associated concepts (rdf:type), then for each column we build a dictionary Cj where each rdf:type have associated the number of rows of the table containing that concept divided by the total number of entities found for that column. We use a threshold set at 40% of the maximum score, the concepts with a score lower then this threshold are discarded. Table 4 show an example of this scoring. With the concept list obtained in this way, we build a concept graph representing the hierarchy between them. in order to complete the column annotation task we pick the path of the winning connected component which maximizes the score.",
      "predicateAnnotation": "Predicate Annotation, whose task is to find relations in the form of predicates, between the Subject column and the other columns, to set the overall meaning of the table. MantisTable approach considers these to fpredicates found in the Entity Linking phase and takes the predicate with maximum frequency ",
      "datatypeAnnotation": "To accomplish this task, we consider 16 regular expressions that identify several Regextypes (e.g. numbers, geo coordinate, address, hex color code, URL). If the number of occurrences of the most frequent Regextype in a column exceeds a given threshold, that column is annotated as L-column, otherwise, it is annotated as NE-column. To distinguish between three main datatypes: dates, numbers and strings. While dates and strings are matched exactly, numeric matching is done using anapproximated matching algorithm: a pair of numbers makes a match if the distance (the absolute difference) between the two is less than a threshold.",
      "entityLinking": {
        "description": "To discover the mappings for each cell in a row we take a set of eligible entities from the KG. entities are considered eligible if label contains the cell's content or contains the cell's tokens. By converting this information to a graph representation we find all the paths that, starting from a eligible entity of the cell's subject, enter into a eligible entity of the cell's object of the row. To increase the accuracy we also try to match the literal cells with the literals in the subject cell's candidate entities: that is, we seek for a match between literals in the table and eligible entities by using a simple matching algorithm.",
        "candidateGeneration": "lookup, SPARQL",
        "entityDisambiguation": "features"
      },
      "nilAnnotation": ""
    },
    "revision": {
      "type": "Fully automated",
      "description": ""
    },
    "validation": "Challenge rounds",
    "codeAvailability": "https://bitbucket.org/disco_unimib/mantistable-tool.py/src/master/",
    "license": "Apache 2.0",
    "inputs": {
      "typeOfTable": "",
      "kg": {
        "tripleStore": "",
        "index": ""
      }
    },
    "output": "",
    "checkedByAuthor": true,
    "authors": [],
    "checkedByAi": false
  },
  {
    "firstAuthor": "Hulsebos",
    "year": 2019,
    "title": {
      "text": "Sherlock: A Deep Learning Approach to Semantic Data Type Detection",
      "link": ""
    },
    "added": "",
    "conferenceJournal": "SIGKDD",
    "nameOfApproach": "Sherlock",
    "mainMethod": {
      "type": "Supervised",
      "technique": "Neural Network"
    },
    "domain": {
      "domain": "Independent",
      "type": ""
    },
    "coreTasks": {
      "cta": true,
      "cpa": false,
      "cea": false,
      "cnea": false
    },
    "supportTasks": {
      "dataPreparation": {
        "description": "computation of statistic features",
        "spellChecker": "",
        "unitsOfMeasurements": ""
      },
      "subjectDetection": "",
      "columnClassification": "",
      "typeAnnotation": "multi-input deep neural network",
      "predicateAnnotation": "",
      "datatypeAnnotation": "multi-input deep neural network",
      "entityLinking": {
        "description": "",
        "candidateGeneration": "",
        "entityDisambiguation": ""
      },
      "nilAnnotation": ""
    },
    "revision": {
      "type": "None",
      "description": ""
    },
    "validation": "T2D",
    "codeAvailability": "https://github.com/mitmedialab/sherlock-project ",
    "license": "MIT",
    "inputs": {
      "typeOfTable": "CSV",
      "kg": {
        "tripleStore": "DBpedia",
        "index": ""
      }
    },
    "output": "",
    "checkedByAuthor": true,
    "authors": [],
    "checkedByAi": false
  },
  {
    "firstAuthor": "Kruit",
    "year": 2019,
    "title": {
      "text": "Extracting Novel Facts from Tables for Knowledge Graph Completion",
      "link": ""
    },
    "added": "",
    "conferenceJournal": "ISWC",
    "nameOfApproach": "TAKCO",
    "mainMethod": {
      "type": "Hybrid",
      "technique": "PGM, features"
    },
    "domain": {
      "domain": "Independent",
      "type": ""
    },
    "coreTasks": {
      "cta": true,
      "cpa": true,
      "cea": true,
      "cnea": true
    },
    "supportTasks": {
      "dataPreparation": {
        "description": "",
        "spellChecker": "",
        "unitsOfMeasurements": ""
      },
      "subjectDetection": "selecting the column with most unique non-numeric values breaking ties by choosing the leftmost one. For every cell in the key column, we then select a set of entity candidates.",
      "columnClassification": "",
      "typeAnnotation": "",
      "predicateAnnotation": "We can now compute likelihood scores for mapping cells to relations (Eq.4), and for mapping columns to relations",
      "datatypeAnnotation": "",
      "entityLinking": {
        "description": "compute a score of the row-entity assignments by comparing all cell values in the row with all the labels of entities that are connected to the candidate entities. Authors use jaccard to compute the highest attainable string similarity between the cell at column c and row ρ and the values of the r-links from e. Then the row-entity assignments which maximise the coherence in the table, i.e., maximise the similarity between the entities are calculated. These assignments are determined using Loopy Belief Propagation (LBP).",
        "candidateGeneration": "lookup, custom index",
        "entityDisambiguation": "features, similarity"
      },
      "nilAnnotation": "Our method does not prune out row-entity assignments, but performs the interpretation by performing inference over all possible assignments. The PGM uses label similarities as priors, and then updates its likelihood scoring to maximise the coherence of entity assignments across the rows using Loopy Belief Propagation (LBP). Coherence is not computed using a predefined metric but is automatically selected as a combination of properties that are shared by the entities in the table. This is a novel feature of our method which makes it capable of working with KGs with different topologies and/or relations. We also propose an approach to perform slot-filling by disambiguating attribute cells in a novel link-prediction framework. Our approach makes use of embeddings of KG entities and relations to improve the quality of the disambiguation whenever label matching is not sufficient. This furthers our aim to find novel facts for KG completion."
    },
    "revision": {
      "type": "None",
      "description": ""
    },
    "validation": "T2Dv2, Webaroo",
    "codeAvailability": "https://github.com/karmaresearch/takco",
    "license": "MIT",
    "inputs": {
      "typeOfTable": "Tables",
      "kg": {
        "tripleStore": "DBpedia, Wikidata",
        "index": ""
      }
    },
    "output": "New facts to complete KGs",
    "checkedByAuthor": true,
    "authors": [],
    "checkedByAi": false
  },
  {
    "firstAuthor": "Morikawa",
    "year": 2019,
    "title": {
      "text": "Semantic Table Interpretation using LOD4ALL",
      "link": ""
    },
    "added": "",
    "conferenceJournal": "SemTab",
    "nameOfApproach": "LOD4ALL",
    "mainMethod": {
      "type": "Unsupervised",
      "technique": "features"
    },
    "domain": {
      "domain": "Independent",
      "type": ""
    },
    "coreTasks": {
      "cta": true,
      "cpa": true,
      "cea": true,
      "cnea": false
    },
    "supportTasks": {
      "dataPreparation": {
        "description": "",
        "spellChecker": "",
        "unitsOfMeasurements": ""
      },
      "subjectDetection": "",
      "columnClassification": "",
      "typeAnnotation": "In this step, estimating a column type (CTA result) using candidate entities extracted. This step consists of the three following steps: 1- Calculate a cover ratio; 2-Search a class score from the score DB; 3-Calculate a predict score using both a score ratio and a class-score",
      "predicateAnnotation": "In this step, we first collect candidate predicates using entities determined in Step 4 by executing SPARQL (Listing 1.1) to RDF store. %URI1% and %URI2% in SPARQL are replaced entities determined in Step 4. Next, by calculating a frequency, we obtain the predicate of the greatest frequency. The output of this step is the result of the CPA task.",
      "datatypeAnnotation": "",
      "entityLinking": {
        "description": "The original literal search function of LOD4ALL uses Elastic- search that returns a subject (a candidate entity) corresponding to an object that matches a cell value. This function can obtain candidate entities in the following steps: Direct search: First, by combining http://DBpedia.org/resource/ with the cell value, we create a candidate entity. Next, we execute ASK query to RDF store. Keyword search: We have enhanced the literal search function of LOD4ALL that can retrieve subjects that have rdfs:label, foaf:name, foaf:surname and foaf:givenName in the triple. We have adopted SimString[8] for the similar string search. We have set 100.0 for the score of an entity found by Direct search, and set a value multiplying the Elasticsearch's score and the SimString's score for the score of an entity that have found by Keyword search.",
        "candidateGeneration": "lookup, SPARQL, custom index",
        "entityDisambiguation": "features, contextual inf"
      },
      "nilAnnotation": ""
    },
    "revision": {
      "type": "None",
      "description": ""
    },
    "validation": "SemTab 2019",
    "codeAvailability": "",
    "license": "Not specified",
    "inputs": {
      "typeOfTable": "Tables",
      "kg": {
        "tripleStore": "DBpedia",
        "index": "ElasticSearch"
      }
    },
    "output": "CEA,CTA,CPA",
    "checkedByAuthor": true,
    "authors": [],
    "checkedByAi": false
  },
  {
    "firstAuthor": "Nguyen",
    "year": 2019,
    "title": {
      "text": "MTab: Matching Tabular Data to Knowledge Graph using Probability Models",
      "link": ""
    },
    "added": "",
    "conferenceJournal": "SemTab",
    "nameOfApproach": "MTab",
    "mainMethod": {
      "type": "Unsupervised",
      "technique": "features"
    },
    "domain": {
      "domain": "Independent",
      "type": ""
    },
    "coreTasks": {
      "cta": true,
      "cpa": true,
      "cea": true,
      "cnea": false
    },
    "supportTasks": {
      "dataPreparation": {
        "description": "use of ftfy tool for text Decoding; use of fasttext models for Language Prediction: Data Type Prediction-13 predefined data types of duckling (numerical tags, email, URL, or phone number. If there is no tag assigned, we assign this cell type as a text tag): pre-trained SpaCy models for Entity Type Prediction to predict 18 entity types; If there is no tag assigned, this cell type is assigned to a text tag; Entity Lookup on DBpedia spotlight / endpoint for relevant entities with English URL.",
        "spellChecker": "",
        "unitsOfMeasurements": ""
      },
      "subjectDetection": "",
      "columnClassification": "we categorize table columns to entity columns and literal columns. We aggregate the data type (Duckling Tags and SpaCy Tags) from each cell in a column using majority voting. If the majority tag is text or entityrelated, the columns is an entity column, else a numerical column. Regarding numerical columns, we perform semantic labeling with EmbNum method [5] to annotate relations (DBpedia properties) for numerical columns 9. Then, we infer types (DBpedia classes) from those relations.",
      "typeAnnotation": "Given a set of entity columns in table S is Ment, we consider these signals (i) from the probabilities of type potential from numerical columns; (ii) the probabilities of type potential aggregated from the types of entity lookup for the all cells in column mj; (iii) the probabilities of type potential aggregated from SpaCy entity type prediction for the all cell in column mj. We used majority voting and normalized these voting value to [0,1]. Then, we associate those normalized voting value type potential probabilities; and (iv) the probabilities of type potential given header value of the column mj. We associate the normalized Levenshtein distance as potential probability that a type (DBpedia class) correspond with a header value.",
      "predicateAnnotation": "Given two columns mj1 and mj2 , we estimate the probabilities of relation potential. We consider two type of relation between two columns: Entity column to Entity column and Entity column to non-Entity column.",
      "datatypeAnnotation": "The set of numerical columns in table S is Mnum. Given a numerical column mj, we use re-trained EmbNum model on DBpedia [5] to derive embedding vector for the list of all numerical values of the column and then search the corresponding relations from the database of labeled attributes 10. The result qmj is a ranking of relevance numerical attributes in terms of distribution similarity. We also use α as the limit for ranking result. For textual values: We use the normalized Levenshtein distance while For numerical values: the relevance ratio.",
      "entityLinking": {
        "description": "Given a cell value ci,j, we have a set of ranking result lists from lookup services. In MTab, we adopted the four services as DBpedia lookup, DBpedia Endpoint, Wikidata lookup, and Wikipedia lookup. However, we can use any services as long as their output is a ranking list of relevance entities.",
        "candidateGeneration": "lookup, DBP LS, DBP endpoint, Wikipedia API, WKD API",
        "entityDisambiguation": "features, similarity"
      },
      "nilAnnotation": ""
    },
    "revision": {
      "type": "None",
      "description": ""
    },
    "validation": "SemTab 2019",
    "codeAvailability": "",
    "license": "Not specified",
    "inputs": {
      "typeOfTable": "vertical relational table.",
      "kg": {
        "tripleStore": "DBpedia",
        "index": ""
      }
    },
    "output": "CEA,CTA,CPA",
    "checkedByAuthor": true,
    "authors": [],
    "checkedByAi": false
  },
  {
    "firstAuthor": "Oliveira",
    "year": 2019,
    "title": {
      "text": "ADOG - Annotating Data with Ontologies and Graphs",
      "link": ""
    },
    "added": "",
    "conferenceJournal": "SemTab",
    "nameOfApproach": "ADOG",
    "mainMethod": {
      "type": "Unsupervised",
      "technique": "features"
    },
    "domain": {
      "domain": "Independent",
      "type": ""
    },
    "coreTasks": {
      "cta": true,
      "cpa": true,
      "cea": true,
      "cnea": false
    },
    "supportTasks": {
      "dataPreparation": {
        "description": "",
        "spellChecker": "",
        "unitsOfMeasurements": ""
      },
      "subjectDetection": "",
      "columnClassification": "",
      "typeAnnotation": "Not detailed",
      "predicateAnnotation": "Not detailed",
      "datatypeAnnotation": "",
      "entityLinking": {
        "description": "string similarity",
        "candidateGeneration": "lookup, custom index",
        "entityDisambiguation": "Levenshtein distance"
      },
      "nilAnnotation": "the matching process can start by matching the data against the ElasticSearch index. When several matches are returned from the matching process, additional measures are employed to score the relevance of each match to the query, considering the context of the data to annotate. The three main steps are calculating the similarity and frequency of properties measures, and final score weighting. This measure finds the string similarity between query words and the matched terms. Both strings are normalised, punctuation is removed, and word inside brackets are ignored. The similarity measure uses Levenshtein Distance (LD). If any extra properties, besides the labels, were indexed from the source KG, this step calculates and normalises their frequencies for each match. For example, in DBpedia, these properties can be the categories, types or even other entities linked to the matched entity via an object property. The final score of each candidate will be weighted considering the previous steps, plus the normalised ElasticSearch score for each search performed. These weights are variable and can be adjusted to fit any model, giving more or less weight to similarity, search scores, or property frequencies."
    },
    "revision": {
      "type": "None",
      "description": ""
    },
    "validation": "",
    "codeAvailability": "https://github.com/danielapoliveira/iswc-annotation-challenge.",
    "license": "Not specified",
    "inputs": {
      "typeOfTable": "ontology, KG and Table",
      "kg": {
        "tripleStore": "DBpedia",
        "index": "ArangoDB + ElasticSearch"
      }
    },
    "output": "CEA,CTA,CPA",
    "checkedByAuthor": true,
    "authors": [],
    "checkedByAi": false
  },
  {
    "firstAuthor": "Steenwinckel",
    "year": 2019,
    "title": {
      "text": "CSV2KG: Transforming Tabular Data into Semantic Knowledge",
      "link": ""
    },
    "added": "",
    "conferenceJournal": "SemTab",
    "nameOfApproach": "CSV2KG",
    "mainMethod": {
      "type": "Unsupervised",
      "technique": "lookup"
    },
    "domain": {
      "domain": "Independent",
      "type": ""
    },
    "coreTasks": {
      "cta": true,
      "cpa": true,
      "cea": true,
      "cnea": false
    },
    "supportTasks": {
      "dataPreparation": {
        "description": "For each of the cell values, we first clean them by retaining only the part that comes before a \"(\" or \"[\" and by removing all \"%\", \"\"\", and \"\\\" characters",
        "spellChecker": "",
        "unitsOfMeasurements": ""
      },
      "subjectDetection": "",
      "columnClassification": "",
      "typeAnnotation": "Most specific class that matches the entities in the cell of a column. Since the classes of the DBpedia ontology form a hierarchy, they can be represented in a tree. We can now traverse this tree and apply majority voting (i.e. taking the child with the highest count) on each level of this tree. We continue recursively until the entropy of the two highest counts of its children is lower than a specified threshold.",
      "predicateAnnotation": "The cell annotations are used to annotate the properties or relations between pairs of columns. To do this, we iterate over cell pairs from two target columns between which we want to infer the relation. Then, for each of these cell pairs (s, o), we query for all predicates p from the DBpedia ontology that exists between these two entities: {p | (s,p,o) ∈ DBpedia}. Finally, the predicate that can be found the most between the cell pairs is chosen. In case of relationships with equal highest counts, we check the range and domain using the column types. When the range and domain of multiple relationships are valid possibilities, we take the relationships with the most specific range and domain column type (using depth(domain) + depth(range)).",
      "datatypeAnnotation": "",
      "entityLinking": {
        "description": "Then, we check whether http://DBpedia.org/resource/<X> exists where <X> is simply the cleaned cell value with spaces replaced by underscores (try url). Parallel with this, the cell value is provided to the DBpedia lookup API to generate more candidates (DBpedia lookup). As no column type annotations are available yet during this initial phase, we do not provide this additional information. If both the DBpedia lookup and the try url step did not result in any candidates, the DBpedia Spotlight API is applied. In the end, a large pool of possible candidates remain. On this pool, we apply disambiguation by selecting the candidate of which its rdf:label has the lowest Levenshtein distance to the actual cell value.",
        "candidateGeneration": "lookup, DBP LS, DBP urls, DBP Spotlight",
        "entityDisambiguation": "features, similarity"
      },
      "nilAnnotation": "First, crude annotations are made for each cell in the table by generating multiple candidates and disambiguating them by using string similarities on the cell values and the rdf:label of each candidate. Afterwards, the column types and properties between columns are inferred using these cell annotations. In a fourth step, the inferred column types and properties are used to create more accurate head cell annotations (the cells in the first column of a table). Phase five uses the new head cells to correct the other cells in the table, using the property annotations. Finally, in phase six, new column types were inferred using all the available corrected cells."
    },
    "revision": {
      "type": "None",
      "description": ""
    },
    "validation": "SemTab 2019",
    "codeAvailability": "https://github.com/IBCNServices/CSV2KG",
    "license": "Not specified",
    "inputs": {
      "typeOfTable": "CSV",
      "kg": {
        "tripleStore": "DBpedia",
        "index": ""
      }
    },
    "output": "CEA,CTA,CPA",
    "checkedByAuthor": true,
    "authors": [],
    "checkedByAi": false
  },
  {
    "firstAuthor": "Takeoka",
    "year": 2019,
    "title": {
      "text": "Meimei: An Efficient Probabilistic Approach for Semantically Annotating Tables",
      "link": ""
    },
    "added": "",
    "conferenceJournal": "AAAI",
    "nameOfApproach": "meimei",
    "mainMethod": {
      "type": "Supervised",
      "technique": "Markov Network"
    },
    "domain": {
      "domain": "Independent",
      "type": ""
    },
    "coreTasks": {
      "cta": true,
      "cpa": false,
      "cea": false,
      "cnea": false
    },
    "supportTasks": {
      "dataPreparation": {
        "description": "",
        "spellChecker": "",
        "unitsOfMeasurements": ""
      },
      "subjectDetection": "",
      "columnClassification": "For literal-columns, we compute several numerical statistics of the column cells",
      "typeAnnotation": "It is natural that we use the mean (and standard deviation) of embedding vectors as the feature vector of a column given the analogy that the mean of word embedding vectors is often used as the feature vector of a sentence or documents (Arora, Liang, and Ma 2017). The mean of word embedding vectors is often used as the feature vector of a sentence even if embedding approaches based on long shortterm memory appeared. Since the characteristics of columns are similar to those of bag-of-words, we use the mean of embedding vectors as a feature vector.",
      "predicateAnnotation": "",
      "datatypeAnnotation": "Since literal-columns may also have textual information such as measurement units (e.g., \"20 s\"), we also use several textual features such as the frequency of each letter and the length of each string. Our feature extraction for literalcolumns comprises three steps: 1. Calculate numerical statistics: we extract numerical values from cells xc and calculate several statistics vnum from the values. 2. Calculate textual features: we calculate several textural features vtxt such as the frequency of each letter. 3. Concatenate features: we concatenate numerical statistics vnum with textual features vtxt",
      "entityLinking": {
        "description": "",
        "candidateGeneration": "",
        "entityDisambiguation": ""
      },
      "nilAnnotation": "This paper presents a novel approach for table data annotation that combines a latent probabilistic model with multilabel classifiers. It features three advantages over previous approaches due to using highly predictive multi-label classifiers in the probabilistic computation of semantic annotation. (1) It is more versatile due to using multi-label classifiers in the probabilistic model, which enables various types of data such as numerical values to be supported. (2) It is more accurate due to the multi-label classifiers and probabilistic model working together to improve predictive performance. (3) It is more efficient due to potential functions based on multi-label classifiers reducing the computational cost for annotation. Extensive experiments demonstrated the superiority of the proposed approach over state-of-the-art approaches for semantic annotation of real data (183 human-annotated tables obtained from the UCI Machine Learning Repository)."
    },
    "revision": {
      "type": "None",
      "description": ""
    },
    "validation": "Private company dataset",
    "codeAvailability": "",
    "license": "Not specified",
    "inputs": {
      "typeOfTable": "CSV",
      "kg": {
        "tripleStore": "WordNet",
        "index": ""
      }
    },
    "output": "",
    "checkedByAuthor": true,
    "authors": [],
    "checkedByAi": false
  },
  {
    "firstAuthor": "Thawani",
    "year": 2019,
    "title": {
      "text": "Entity Linking to Knowledge Graphs to Infer Column Types and Properties",
      "link": ""
    },
    "added": "",
    "conferenceJournal": "SemTab",
    "nameOfApproach": "",
    "mainMethod": {
      "type": "Unsupervised",
      "technique": "features"
    },
    "domain": {
      "domain": "Independent",
      "type": ""
    },
    "coreTasks": {
      "cta": true,
      "cpa": true,
      "cea": true,
      "cnea": false
    },
    "supportTasks": {
      "dataPreparation": {
        "description": "We use candidates for all cells in a column to compile a set of all the classes and properties used to describe them, and for each candidate, we define a uniform-length binary sparse feature vector to record the classes and properties used to describe it. These features are not equally informative. We seek to maximize coverage and selectivity. Intuitively, a feature has good coverage if for every cell there is a candidate for which this feature has value 1. TF-IDF is used",
        "spellChecker": "",
        "unitsOfMeasurements": ""
      },
      "subjectDetection": "",
      "columnClassification": "",
      "typeAnnotation": "For each column C our algorithm starts from dbo:Thing on level 0 of semantic class tree and calculates the percentages of cells in C that belong to classes on certain level of the DBpedia class tree. The algorithm then picks most common class with the highest percentage above a given threshold.",
      "predicateAnnotation": "In the CPA task, the goal is to find the DBpedia ontology property that best matches the relation between a primary column and other secondary columns. As input, we have the ranked candidates from CEA and sample size N, which is the top N of the candidates we want to consider, to limit the size of our query search space. For each row, we query DBpedia for the properties between all pairs of candidates in the primary and secondary columns.",
      "datatypeAnnotation": "For secondary columns consisting of literals, we transform the value to address potential differences between the cell value and the values in the KG. Currently we address cases of string, date, and numerical literals.",
      "entityLinking": {
        "description": "",
        "candidateGeneration": "External lookup (Wikidata API), custom index",
        "entityDisambiguation": "Levenshtein distance, contextual inf, NN"
      },
      "nilAnnotation": "work we investigated a feature engineering approach. Lexical features capture the lexical similarity between the contents of a cell and entity labels, and semantic features capture semantic coherence among cells in a column."
    },
    "revision": {
      "type": "None",
      "description": ""
    },
    "validation": "SemTab 2019",
    "codeAvailability": "https://github.com/usc-isi-i2/wikidata-wikifier/blob/master/wikifier/wikifier.py",
    "license": "MIT",
    "inputs": {
      "typeOfTable": "CSV",
      "kg": {
        "tripleStore": "",
        "index": "ElasticSearch"
      }
    },
    "output": "",
    "checkedByAuthor": true,
    "authors": [],
    "checkedByAi": false
  },
  {
    "firstAuthor": "Zhang",
    "year": 2019,
    "title": {
      "text": "Sato: Contextual Semantic Type Detection in Tables",
      "link": ""
    },
    "added": "",
    "conferenceJournal": "VLDB",
    "nameOfApproach": "Sato",
    "mainMethod": {
      "type": "Supervised",
      "technique": "multi-layer nn, lda topic modeling"
    },
    "domain": {
      "domain": "Independent",
      "type": ""
    },
    "coreTasks": {
      "cta": true,
      "cpa": false,
      "cea": false,
      "cnea": false
    },
    "supportTasks": {
      "dataPreparation": {
        "description": "Remove content in parentheses, convert strings to lowercase, capitalize words except for the first and concatenate results into a single string.",
        "spellChecker": "",
        "unitsOfMeasurements": ""
      },
      "subjectDetection": "",
      "columnClassification": "",
      "typeAnnotation": "Combines topic modeling and structure learning with a single-column type prediction based on the Sherlock model. Two types of context are used:\n- Global, the set of all cell values in the table;\n- Local, the set of independently predicted semantic types of the neighboring columns in the same table. The type annotation is achieved using column-wise features including character embeddings, word embeddings, paragraph embeddings as well as column statistics.",
      "predicateAnnotation": "",
      "datatypeAnnotation": "",
      "entityLinking": {
        "description": "",
        "candidateGeneration": "",
        "entityDisambiguation": ""
      },
      "nilAnnotation": ""
    },
    "revision": {
      "type": "None",
      "description": ""
    },
    "validation": "T2Dv2",
    "codeAvailability": "https://github.com/megagonlabs/sato",
    "license": "Apache 2.0",
    "inputs": {
      "typeOfTable": "DBpedia",
      "kg": {
        "tripleStore": "",
        "index": ""
      }
    },
    "output": "",
    "checkedByAuthor": true,
    "authors": [],
    "checkedByAi": false
  },
  {
    "firstAuthor": "Abdelmageed",
    "year": 2020,
    "title": {
      "text": "JenTab: Matching Tabular Data to Knowledge Graphs",
      "link": ""
    },
    "added": "",
    "conferenceJournal": "SemTab",
    "nameOfApproach": "JenTab",
    "mainMethod": {
      "type": "Unsupervised",
      "technique": "features"
    },
    "domain": {
      "domain": "Independent",
      "type": ""
    },
    "coreTasks": {
      "cta": true,
      "cpa": true,
      "cea": true,
      "cnea": false
    },
    "supportTasks": {
      "dataPreparation": {
        "description": "we use a regular expression to split up terms that are missing spaces like in \"1stGlobal Opinion Leader's Summit\". Similarly, we remove certain special characters like parentheses. The result of these steps are stored as a cell's \"clean value\"",
        "spellChecker": "YES (autocorrect.py), Fix incorrect encoding (ftfy), split terms with missing spaces, remove special chars. Finally, we also apply an off-the-shelf spell checker, autocorrect to fix typos resulting in an \"autocorrected value\" per cell",
        "unitsOfMeasurements": ""
      },
      "subjectDetection": "The first column is the Subject (assumption)",
      "columnClassification": "Datatypes (object, date, string, and number). NON SPIEGA COME",
      "typeAnnotation": "Candidate generation: \n- Retrieve the candidate concepts of the entities found in the CEA considering also the instanceOf and subclassOf relationships Disambiguation:\n- Least Common subsummer: check the concept hierarchy\n- Direct Parents: majority vote\n- Popularity: select the concept by populrity",
      "predicateAnnotation": "Retrieve candidate predicates by considering relationships between cells (from subject colum). It considers both object properties and literal properties. For literals, different heuristics are considered for different datatypes. Disambiguation:\n- Majority Vote",
      "datatypeAnnotation": "",
      "entityLinking": {
        "description": "Different strategies for obtaining candidates:\n- Generic: cell value and WD labels\n- Full Cell: lookup cell value\n- All Token: lookup tokens w/o stopword\n- Selective: remove () and then lookup\n- Token: lookup token in isolation\n- Autocorrection: lookup corrected val \n- Context\nDifferent strategies for selecting candidates:\n- String similarity: Levenshtein distance and popularity of entities\n- By column: check the presence of the same value in a column",
        "candidateGeneration": "lookup, WKD API",
        "entityDisambiguation": "features, contextual inf"
      },
      "nilAnnotation": ""
    },
    "revision": {
      "type": "None",
      "description": ""
    },
    "validation": "SemTab 2020",
    "codeAvailability": "https://github.com/fusion-jena/JenTab ",
    "license": "MIT",
    "inputs": {
      "typeOfTable": "CSV",
      "kg": {
        "tripleStore": "Wikidata",
        "index": ""
      }
    },
    "output": "CEA,CTA,CPA",
    "checkedByAuthor": true,
    "authors": [],
    "checkedByAi": false
  },
  {
    "firstAuthor": "Azzi",
    "year": 2020,
    "title": {
      "text": "AMALGAM: making tabular dataset explicit with knowledge graph",
      "link": ""
    },
    "added": "",
    "conferenceJournal": "SemTab",
    "nameOfApproach": "AMALGAM",
    "mainMethod": {
      "type": "Unsupervised",
      "technique": "features"
    },
    "domain": {
      "domain": "Independent",
      "type": ""
    },
    "coreTasks": {
      "cta": true,
      "cpa": false,
      "cea": true,
      "cnea": false
    },
    "supportTasks": {
      "dataPreparation": {
        "description": "Fix incorrect encoding (Pandas)",
        "spellChecker": "YES (Gurundi.py)",
        "unitsOfMeasurements": ""
      },
      "subjectDetection": "",
      "columnClassification": "",
      "typeAnnotation": "After the prelinking using Wikidata API, they count the concept occurrences",
      "predicateAnnotation": "",
      "datatypeAnnotation": "",
      "entityLinking": {
        "description": "Lookup using Wikidata API. They consider the context (row) and the concept of the column",
        "candidateGeneration": "lookup, WKD API",
        "entityDisambiguation": "features, contextual inf"
      },
      "nilAnnotation": ""
    },
    "revision": {
      "type": "None",
      "description": ""
    },
    "validation": "SemtTab 2020",
    "license": "Not specified",
    "inputs": {
      "typeOfTable": "CSV",
      "kg": {
        "tripleStore": "Wikidata",
        "index": ""
      }
    },
    "output": "CEA,CTA",
    "checkedByAuthor": false,
    "authors": [],
    "checkedByAi": false
  },
  {
    "firstAuthor": "Baazouzi",
    "year": 2020,
    "title": {
      "text": "Kepler-aSI : Kepler as A Semantic Interpreter",
      "link": ""
    },
    "added": "",
    "conferenceJournal": "SemTab",
    "nameOfApproach": "KEPLER-ASI",
    "mainMethod": {
      "type": "Unsupervised",
      "technique": "features"
    },
    "domain": {
      "domain": "Independent",
      "type": ""
    },
    "coreTasks": {
      "cta": true,
      "cpa": false,
      "cea": false,
      "cnea": false
    },
    "supportTasks": {
      "dataPreparation": {
        "description": "- deletion of some chars\n- trasformation into lowercase\n- delete text in brackets\n- normalisation of units",
        "spellChecker": "",
        "unitsOfMeasurements": "Yes (regex)"
      },
      "subjectDetection": "- aw: the average number of words in each cell\n- emc: the fraction of empty cells in the column\n- uc: the fraction of cells with unique content\n- df: the distance of the first NE-column",
      "columnClassification": "Regex, eg, numbers, geographic coordinates, address, hexadecimal color code, URL",
      "typeAnnotation": "The content of a column is fetched in query to Wikidata. If multiple entities were returned for a cell, the one with the number of occurrences was taken.",
      "predicateAnnotation": "",
      "datatypeAnnotation": "",
      "entityLinking": {
        "description": "",
        "candidateGeneration": "",
        "entityDisambiguation": ""
      },
      "nilAnnotation": ""
    },
    "revision": {
      "type": "None",
      "description": ""
    },
    "validation": "SemTab 2020",
    "codeAvailability": "",
    "license": "Not specified",
    "inputs": {
      "typeOfTable": "CSV",
      "kg": {
        "tripleStore": "Wikidata",
        "index": ""
      }
    },
    "output": "CTA",
    "checkedByAuthor": false,
    "authors": [],
    "checkedByAi": false
  },
  {
    "firstAuthor": "Chen",
    "year": 2020,
    "title": {
      "text": "LinkingPark: An Integrated Approach for Semantic Table Interpretation",
      "link": ""
    },
    "added": "",
    "conferenceJournal": "SemTab",
    "nameOfApproach": "LinkingPark",
    "mainMethod": {
      "type": "Unsupervised",
      "technique": "features"
    },
    "domain": {
      "domain": "Independent",
      "type": ""
    },
    "coreTasks": {
      "cta": true,
      "cpa": true,
      "cea": true,
      "cnea": false
    },
    "supportTasks": {
      "dataPreparation": {
        "description": "",
        "spellChecker": "Yes (tailor made, the corrector checks all strings within one edit distance to the original mention string)",
        "unitsOfMeasurements": ""
      },
      "subjectDetection": "",
      "columnClassification": "",
      "typeAnnotation": "Most common types shared by most of the entities. In case of the same count, prioritise the most specific one.",
      "predicateAnnotation": "start from the strings in the cells (in the same row) and generate candidates considering numerical properties and entity properties.",
      "datatypeAnnotation": "set of statistics per numeric datatypes (range, mean, stdev)",
      "entityLinking": {
        "description": "Candidate Generation: Lookup usign Wikidata API and fine-grained Elastic Search index (word-based, trigram-based) Entity Disambiguation: Type consistency along each column of entities and property relatedness within each row of attribute values TF-IDF weighing",
        "candidateGeneration": "lookup, Mediawiki API, custom index",
        "entityDisambiguation": "features, contextual inf"
      },
      "nilAnnotation": ""
    },
    "revision": {
      "type": "None",
      "description": ""
    },
    "validation": "SemTab 2020",
    "codeAvailability": "",
    "license": "Not specified",
    "inputs": {
      "typeOfTable": "CSV",
      "kg": {
        "tripleStore": "Wikidata",
        "index": "ElasticSearch"
      }
    },
    "output": "CEA,CTA,CPA",
    "checkedByAuthor": false,
    "authors": [],
    "checkedByAi": false
  },
  {
    "firstAuthor": "Cremaschi",
    "year": 2020,
    "title": {
      "text": "A fully automated approach to a complete Semantic Table Interpretation",
      "link": ""
    },
    "added": "",
    "conferenceJournal": "FGCS",
    "nameOfApproach": "MantisTable",
    "mainMethod": {
      "type": "Unsupervised",
      "technique": "features"
    },
    "domain": {
      "domain": "Independent",
      "type": ""
    },
    "coreTasks": {
      "cta": true,
      "cpa": true,
      "cea": true,
      "cnea": false
    },
    "supportTasks": {
      "dataPreparation": {
        "description": "Deletion of HTML tags and some characters, transformation of text into lowercase, deletion of text in brackets, explanation of acronyms and abbreviations, and normalisation of units of measurement.",
        "spellChecker": "",
        "unitsOfMeasurements": ""
      },
      "subjectDetection": "The following list of features is considered:\n- Fraction of empty cells;\n- Distance from the first NE-column;\n- Average number of words.\nThen, each column is assigned a score and the highest scoring is the S-column",
      "columnClassification": "Semantic classification into either Literal columns (L-column) via regex or NE-column",
      "typeAnnotation": "For each winning entity, all the rdf:type values are extracted from DBpedia. Then, for each extracted type, the frequency (considering also different ontologies) and the number of cells in which the type appears are calculated. The set of type candidates is defined according to two conditions: (i) fall within the range defined by the maximum global frequency as upper bound and δ as lower bound; (ii) if the type belongs to a number of cells greater than a threshold β. The most specific concept from the two branches of the hierarchy is used to annotate the column.",
      "predicateAnnotation": "The winning concept of the S-column is the subject of relationships among columns, and annotations of the other columns are objects. To identify candidate predicates, they exploit two techniques based on exploratory queries and summary profiles. The former searches the KG for the subject and the object with two distinct methods for NE-columns and L-columns, while the latter uses a distributed tool that integrates profiles for RDF data",
      "datatypeAnnotation": "Datatype annotation relies on the results of the Column Type Analysis that delivered an association between every L-column and a specific Regextype. A mapping between Regextypes and Datatypes is performed. In the case of one-to-one relation, the corresponding datatype is used to annotate the L-column, otherwise a further analysis step is required to identify the correct datatype,",
      "entityLinking": {
        "description": "When the query returns more than one entity, the edit distance (i.e. Levenshtein distance) is computed between the normalised table cell content and the normalised  candidate entity label. Only the entity with the smallest edit distance is considered for the annotation.",
        "candidateGeneration": "lookup",
        "entityDisambiguation": "features, similarity"
      },
      "nilAnnotation": ""
    },
    "revision": {
      "type": "Fully automated",
      "description": ""
    },
    "validation": "SemTab 2019, T2D, Limaye",
    "codeAvailability": "https://bitbucket.org/disco_unimib/mantistable-tool/",
    "license": "Apache 2.0",
    "inputs": {
      "typeOfTable": "CSV",
      "kg": {
        "tripleStore": "DBpedia",
        "index": ""
      }
    },
    "output": "CEA,CTA,CPA",
    "checkedByAuthor": true,
    "authors": [],
    "checkedByAi": false
  },
  {
    "firstAuthor": "Cremaschi",
    "year": 2020,
    "title": {
      "text": "MantisTable SE: an Efficient Approach for the Semantic Table Interpretation",
      "link": ""
    },
    "added": "",
    "conferenceJournal": "SemTab",
    "nameOfApproach": "MantisTable SE",
    "mainMethod": {
      "type": "Unsupervised",
      "technique": "features"
    },
    "domain": {
      "domain": "Independent",
      "type": ""
    },
    "coreTasks": {
      "cta": true,
      "cpa": true,
      "cea": true,
      "cnea": false
    },
    "supportTasks": {
      "dataPreparation": {
        "description": "All the cells of all the tables are analysed using a tokeniser managing special characters and removing parenthesis and the text block inside them.",
        "spellChecker": "",
        "unitsOfMeasurements": ""
      },
      "subjectDetection": "The subject column (S-column) can be identified between NE-column thanks to content-based scores",
      "columnClassification": "Semantic classification into either Literal columns (L-column) via regex or NE-column",
      "typeAnnotation": "Every entity is reconsidered wrt the CPA reordering. Only considering WIkidata, the concepts are retrieved that correspond to every candidate entity from LamAPI. For every column, an in-memory structure storing frequencies (by-max normalization) of the most common datatypes is used. The winning concept is chosen as follows:\n- concepts with a frequency lower than 0.95 are discarded\n- considering every possible column pair, count inbound and outbound edges; the final concept selected is the one having the highest number of connections in the Wikidata graph.",
      "predicateAnnotation": "All the predicates are retrieved for every possible candidate couple with confidence greater than 0 and they are sorted by their relative frequency to the entire column. The predicate with the greatest frequency will be ranked first.",
      "datatypeAnnotation": "Literal columns are identified through regex while all the otherr columns are considered to be NE columns",
      "entityLinking": {
        "description": "For each cell of the S-column and NE-columns a confidence score is calculated by computing the edit distance (Levenshtein) between the labels in different languages of candidate eneity and the content of the cell. L-columns obtain a confidence score that is computed differently for numeric, string and date datatypes.",
        "candidateGeneration": "lookup, custom index",
        "entityDisambiguation": "features, contextual inf"
      },
      "nilAnnotation": ""
    },
    "revision": {
      "type": "None",
      "description": ""
    },
    "validation": "SemTab 2020",
    "codeAvailability": "https://bitbucket.org/disco_unimib/mantistable-4 ",
    "license": "Apache 2.0",
    "inputs": {
      "typeOfTable": "CSV",
      "kg": {
        "tripleStore": "DBpedia, Wikidata",
        "index": "LamAPI"
      }
    },
    "output": "CEA,CTA,CPA",
    "checkedByAuthor": true,
    "authors": [],
    "checkedByAi": false
  },
  {
    "firstAuthor": "Eslahi",
    "year": 2020,
    "title": {
      "text": "Annotating Web Tables through Knowledge Bases: A Context-Based Approach",
      "link": ""
    },
    "added": "",
    "conferenceJournal": "SDS",
    "nameOfApproach": "",
    "mainMethod": {
      "type": "Hybrid",
      "technique": "features, embeddings"
    },
    "domain": {
      "domain": "Independent",
      "type": ""
    },
    "coreTasks": {
      "cta": true,
      "cpa": false,
      "cea": true,
      "cnea": false
    },
    "supportTasks": {
      "dataPreparation": {
        "description": "",
        "spellChecker": "",
        "unitsOfMeasurements": ""
      },
      "subjectDetection": "",
      "columnClassification": "",
      "typeAnnotation": "the three most frequent types obtained from an Entity Linking phase serve as a filter to enhance the results. Among these three types, the most frequent type in the column is determined using majority voting as the selection criterion.",
      "predicateAnnotation": "",
      "datatypeAnnotation": "",
      "entityLinking": {
        "description": "Candidate Generation Lookup: create list of candate and majority vote on type on whole column Looping Method: cosine similarity between their vector representations (embedding) then build a graph with all unambiguous candates from the table.",
        "candidateGeneration": "lookup",
        "entityDisambiguation": "features, entity embedding"
      },
      "nilAnnotation": ""
    },
    "revision": {
      "type": "",
      "description": ""
    },
    "validation": "Limaye, T2D",
    "codeAvailability": "https://github.com/eXascaleInfolab/sds2020_web_table_annotation",
    "license": "Not specified",
    "inputs": {
      "typeOfTable": "Web table",
      "kg": {
        "tripleStore": "Wikidata",
        "index": ""
      }
    },
    "output": "",
    "checkedByAuthor": true,
    "authors": [],
    "checkedByAi": false
  },
  {
    "firstAuthor": "Guo",
    "year": 2020,
    "title": {
      "text": "Web Table Column Type Detection Using Deep Learning and Probability Graph Model",
      "link": ""
    },
    "added": "",
    "conferenceJournal": "WISA",
    "nameOfApproach": "",
    "mainMethod": {
      "type": "Supervised",
      "technique": "Neural Network, CRF"
    },
    "domain": {
      "domain": "Independent",
      "type": ""
    },
    "coreTasks": {
      "cta": true,
      "cpa": false,
      "cea": false,
      "cnea": false
    },
    "supportTasks": {
      "dataPreparation": {
        "description": "",
        "spellChecker": "",
        "unitsOfMeasurements": ""
      },
      "subjectDetection": "",
      "columnClassification": "character or numeric",
      "typeAnnotation": "For single column type annotation, it detects the semantic type based on the content of cells contained in the target column. For character columns uses a vector that combines character embedding and word embedding as input to the subsequent neural network model. (BiGRU-Attention hybrid NN model). \n For multi-column type detection, a linear-CRF model is used to improve the results of single-column classification by leveraging the relationships with other columns. ",
      "predicateAnnotation": " ",
      "datatypeAnnotation": "An analysis is conducted to distinguish character columns from numerical columns, which can also include characters, by using a classification method based on statistical features. ",
      "entityLinking": {
        "description": "",
        "candidateGeneration": "",
        "entityDisambiguation": ""
      },
      "nilAnnotation": ""
    },
    "revision": {
      "type": "None",
      "description": ""
    },
    "validation": "T2D, Limaye",
    "codeAvailability": "",
    "license": "Not specified",
    "inputs": {
      "typeOfTable": "",
      "kg": {
        "tripleStore": "",
        "index": ""
      }
    },
    "output": "",
    "authors": [],
    "checkedByAi": false
  },
  {
    "firstAuthor": "Huynh",
    "year": 2020,
    "title": {
      "text": "DAGOBAH: Enhanced Scoring Algorithms for Scalable Annotations of Tabular Data",
      "link": ""
    },
    "added": "",
    "conferenceJournal": "SemTab",
    "nameOfApproach": "DAGOBAH SL 2020",
    "mainMethod": {
      "type": "Hybrid",
      "technique": "features, embeddings, matching"
    },
    "domain": {
      "domain": "Independent",
      "type": ""
    },
    "coreTasks": {
      "cta": true,
      "cpa": true,
      "cea": true,
      "cnea": false
    },
    "supportTasks": {
      "dataPreparation": {
        "description": "Same as previous year (with improvements)",
        "spellChecker": "",
        "unitsOfMeasurements": ""
      },
      "subjectDetection": "",
      "columnClassification": "Discriminate Columns with String, DateTime, Numerical with Unit, Numerical w/o Unit",
      "typeAnnotation": "Same as previous year (with improvements)",
      "predicateAnnotation": "CPA is calculated from CEA by applying a majority voting technique (the most occurring relation between two cell annotations in two columns)",
      "datatypeAnnotation": "The method uses the column type information (string or number) during the CPA step, but specific information of how they are obtained is not provided",
      "entityLinking": {
        "description": "Iterative {CEA, CTA, CPA} disambiguation",
        "candidateGeneration": "lookup, custom index",
        "entityDisambiguation": "features, similarity, contextual inf"
      },
      "nilAnnotation": ""
    },
    "revision": {
      "type": "None",
      "description": ""
    },
    "validation": "SemTab 2020",
    "codeAvailability": "",
    "license": "Not specified",
    "inputs": {
      "typeOfTable": "CSV",
      "kg": {
        "tripleStore": "Wikidata",
        "index": "Spark dataframes"
      }
    },
    "output": "",
    "checkedByAuthor": true,
    "authors": [],
    "checkedByAi": false
  },
  {
    "firstAuthor": "Khurana",
    "year": 2020,
    "title": {
      "text": "Semantic Annotation for Tabular Data",
      "link": ""
    },
    "added": "",
    "conferenceJournal": "CIKM",
    "nameOfApproach": "C²",
    "mainMethod": {
      "type": "Supervised",
      "technique": "maximum likelihood estimation (mle) through ensembles"
    },
    "domain": {
      "domain": "Independent",
      "type": ""
    },
    "coreTasks": {
      "cta": true,
      "cpa": false,
      "cea": false,
      "cnea": false
    },
    "supportTasks": {
      "dataPreparation": {
        "description": "Inverted Entity Concept Count Index: This key-value inverted index lists the number of times a categorical entity has been mentioned under respective column names. \n Numerical interval tree: interval of numerical data are defined so that it is possible to exclude certain data types (when numerical values range from 10 to 140 it is unlikely that the column represents age). \n Composite Pattern Tree Index: This index deals with data that is neither categorical/string type nor the numeric type. Regex are employed in this case",
        "spellChecker": "",
        "unitsOfMeasurements": ""
      },
      "subjectDetection": "",
      "columnClassification": " ",
      "typeAnnotation": "The likelihood of all entities of a column belonging to concept is the joint probability of all its entities belonging to the concept at the same time. Also, the type of a column is the one that most likely explains all of its components. The type is determined by: \n- Using multiple data sources; \n - Smoothing \n - Analysing concept co-occurrence in the table; \n - Tuple validation and belief sharing wrt other data sources.",
      "predicateAnnotation": " ",
      "datatypeAnnotation": "Datatype annotation is performed as a data preparation step",
      "entityLinking": {
        "description": "",
        "candidateGeneration": "",
        "entityDisambiguation": ""
      },
      "nilAnnotation": ""
    },
    "revision": {
      "type": "None",
      "description": ""
    },
    "validation": "Limaye, Semantification, SemTab rounds from 1 to 4, T2Dv2, ISWC17",
    "codeAvailability": "",
    "license": "Not specified",
    "inputs": {
      "typeOfTable": "",
      "kg": {
        "tripleStore": "",
        "index": ""
      }
    },
    "output": "",
    "checkedByAuthor": true,
    "authors": [],
    "checkedByAi": false
  },
  {
    "firstAuthor": "Kim",
    "year": 2020,
    "title": {
      "text": "Generating Conceptual Subgraph from Tabular Data for Knowledge Graph Matching",
      "link": ""
    },
    "added": "",
    "conferenceJournal": "SemTab",
    "nameOfApproach": "SSL",
    "mainMethod": {
      "type": "Unsupervised",
      "technique": "features"
    },
    "domain": {
      "domain": "Independent",
      "type": ""
    },
    "coreTasks": {
      "cta": true,
      "cpa": true,
      "cea": true,
      "cnea": false
    },
    "supportTasks": {
      "dataPreparation": {
        "description": "",
        "spellChecker": "Fix typos using Google Search Engine",
        "unitsOfMeasurements": ""
      },
      "subjectDetection": "The first column is the Subject (assumption)",
      "columnClassification": "Determine data type (text, number, date)",
      "typeAnnotation": "Using 'instance of (P31)'",
      "predicateAnnotation": "Check predicates between cells",
      "datatypeAnnotation": "",
      "entityLinking": {
        "description": "Candidate Generation \n Lookup: SPARQL query to identify SPO considering data type of the columns. \n Remove candidates considering the content unrelated to the annotation",
        "candidateGeneration": "lookup, SPARQL",
        "entityDisambiguation": "features"
      },
      "nilAnnotation": ""
    },
    "revision": {
      "type": "None",
      "description": ""
    },
    "validation": "SemTab 2020",
    "codeAvailability": "",
    "license": "Not specified",
    "inputs": {
      "typeOfTable": "CSV",
      "kg": {
        "tripleStore": "Wikidata",
        "index": ""
      }
    },
    "output": "CEA,CTA,CPA",
    "checkedByAuthor": false,
    "authors": [],
    "checkedByAi": false
  },
  {
    "firstAuthor": "Li",
    "year": 2020,
    "title": {
      "text": "Deep Entity Matching with Pre-Trained Language Models",
      "link": ""
    },
    "added": "",
    "conferenceJournal": "VLDB",
    "nameOfApproach": "Ditto",
    "mainMethod": {
      "type": "Supervised",
      "technique": "BERT, DistilBERT, RoBERTa, XLNet"
    },
    "domain": {
      "domain": "Independent",
      "type": ""
    },
    "coreTasks": {
      "cta": false,
      "cpa": false,
      "cea": true,
      "cnea": false
    },
    "supportTasks": {
      "dataPreparation": {
        "description": "",
        "spellChecker": "",
        "unitsOfMeasurements": ""
      },
      "subjectDetection": "",
      "columnClassification": " ",
      "typeAnnotation": "",
      "predicateAnnotation": " ",
      "datatypeAnnotation": "",
      "entityLinking": {
        "description": "",
        "candidateGeneration": "",
        "entityDisambiguation": "features, LM"
      },
      "nilAnnotation": ""
    },
    "revision": {
      "type": "None",
      "description": ""
    },
    "validation": "Entity Resolution benchmark, the Magellan dataset, WDC product matching dataset",
    "codeAvailability": "https://github.com/megagonlabs/ditto ",
    "license": "Apache 2.0",
    "inputs": {
      "typeOfTable": "",
      "kg": {
        "tripleStore": "",
        "index": ""
      }
    },
    "output": "",
    "checkedByAuthor": false,
    "authors": [],
    "checkedByAi": false
  },
  {
    "firstAuthor": "Nguyen",
    "year": 2020,
    "title": {
      "text": "MTab4Wikidata at SemTab 2020: Tabular Data Annotation with Wikidata",
      "link": ""
    },
    "added": "",
    "conferenceJournal": "SemTab",
    "nameOfApproach": "Mtab4Wikidata",
    "mainMethod": {
      "type": "Unsupervised",
      "technique": "features"
    },
    "domain": {
      "domain": "Independent",
      "type": ""
    },
    "coreTasks": {
      "cta": true,
      "cpa": true,
      "cea": true,
      "cnea": false
    },
    "supportTasks": {
      "dataPreparation": {
        "description": "",
        "spellChecker": "",
        "unitsOfMeasurements": ""
      },
      "subjectDetection": "",
      "columnClassification": " ",
      "typeAnnotation": "majority types",
      "predicateAnnotation": "aggregate alla properties of statment candidates in the same row, then majority voting",
      "datatypeAnnotation": "",
      "entityLinking": {
        "description": "Candidate Generation \n - fuzzy entity search and two cells in conjunction using fuzzy statement search  \n Disambiguation \n - compute context similarity taking the average of all statement similarities in the same row",
        "candidateGeneration": "lookup, custom index",
        "entityDisambiguation": "features, contextual inf"
      },
      "nilAnnotation": ""
    },
    "revision": {
      "type": "None",
      "description": ""
    },
    "validation": "SemTab 2020",
    "codeAvailability": "",
    "license": "Not specified",
    "inputs": {
      "typeOfTable": "CSV",
      "kg": {
        "tripleStore": "Wikidata",
        "index": "HashTable + Sparse Matrix"
      }
    },
    "output": "CEA,CTA,CPA",
    "checkedByAuthor": true,
    "authors": [],
    "checkedByAi": false
  },
  {
    "firstAuthor": "Shigapov",
    "year": 2020,
    "title": {
      "text": "bbw: Matching CSV to Wikidata via Meta-lookup",
      "link": ""
    },
    "added": "",
    "conferenceJournal": "SemTab",
    "nameOfApproach": "bbw (boosted by wiki)",
    "mainMethod": {
      "type": "Unsupervised",
      "technique": "features"
    },
    "domain": {
      "domain": "Independent",
      "type": ""
    },
    "coreTasks": {
      "cta": true,
      "cpa": true,
      "cea": true,
      "cnea": false
    },
    "supportTasks": {
      "dataPreparation": {
        "description": "Fix econding problems with ftfy",
        "spellChecker": "",
        "unitsOfMeasurements": ""
      },
      "subjectDetection": "",
      "columnClassification": "Regex to predict number, time, name and string datatypes",
      "typeAnnotation": "Find the most common class usign a special blazegraph query",
      "predicateAnnotation": "Most frequenty property",
      "datatypeAnnotation": "",
      "entityLinking": {
        "description": "Candidate Generation \n - meta-look with SearX and then edit distance and then SPARQL query and then edit distance. Query using all the elements in a row or their types. \n Disambiguation \n Most frequenty entity",
        "candidateGeneration": "lookup, SearX, SPARQL",
        "entityDisambiguation": "features"
      },
      "nilAnnotation": ""
    },
    "revision": {
      "type": "None",
      "description": ""
    },
    "validation": "SemTab 2020",
    "codeAvailability": "https://github.com/UB-Mannheim/bbw",
    "license": "MIT",
    "inputs": {
      "typeOfTable": "CSV",
      "kg": {
        "tripleStore": "Wikidata",
        "index": "SeerX metasearch API"
      }
    },
    "output": "CEA,CTA,CPA",
    "checkedByAuthor": true,
    "authors": [],
    "checkedByAi": false
  },
  {
    "firstAuthor": "Tyagi",
    "year": 2020,
    "title": {
      "text": "LexMa: Tabular Data to Knowledge Graph Matching using Lexical Techniques",
      "link": ""
    },
    "added": "",
    "conferenceJournal": "SemTab",
    "nameOfApproach": "LexMa",
    "mainMethod": {
      "type": "Unsupervised",
      "technique": "lookup"
    },
    "domain": {
      "domain": "Independent",
      "type": ""
    },
    "coreTasks": {
      "cta": true,
      "cpa": false,
      "cea": true,
      "cnea": false
    },
    "supportTasks": {
      "dataPreparation": {
        "description": "trimming and uppercase",
        "spellChecker": "",
        "unitsOfMeasurements": ""
      },
      "subjectDetection": "",
      "columnClassification": " ",
      "typeAnnotation": "majority types",
      "predicateAnnotation": " ",
      "datatypeAnnotation": "",
      "entityLinking": {
        "description": "Candate Generation \n - Wikidata lookup service \n Disambiguation \n - cosine similarity \nMissing value are searched in DBpedia and then converted into a Wikipedia entity",
        "candidateGeneration": "lookup, WKD API",
        "entityDisambiguation": "features, similarity"
      },
      "nilAnnotation": ""
    },
    "revision": {
      "type": "None",
      "description": ""
    },
    "validation": "SemTab 2020",
    "codeAvailability": "https://github.com/shaliniktyagi/TabularData_to_Knowledge_graph",
    "license": "Not specified",
    "inputs": {
      "typeOfTable": "CSV",
      "kg": {
        "tripleStore": "Wikidata",
        "index": ""
      }
    },
    "output": "CTA,CPA",
    "checkedByAuthor": true,
    "authors": [],
    "checkedByAi": false
  },
  {
    "firstAuthor": "Yumusak",
    "year": 2020,
    "title": {
      "text": "Knowledge graph matching with inter-service information transfer",
      "link": ""
    },
    "added": "",
    "conferenceJournal": "SemTab",
    "nameOfApproach": "TeamTR",
    "mainMethod": {
      "type": "Unsupervised",
      "technique": "features"
    },
    "domain": {
      "domain": "Independent",
      "type": ""
    },
    "coreTasks": {
      "cta": true,
      "cpa": true,
      "cea": false,
      "cnea": false
    },
    "supportTasks": {
      "dataPreparation": {
        "description": "",
        "spellChecker": "Usign search enigines",
        "unitsOfMeasurements": ""
      },
      "subjectDetection": "",
      "columnClassification": " ",
      "typeAnnotation": "Not enough information",
      "predicateAnnotation": "Simple sparql Query, eventually adding date datatype or threshold fot numeric values",
      "datatypeAnnotation": "",
      "entityLinking": {
        "description": "",
        "candidateGeneration": "",
        "entityDisambiguation": ""
      },
      "nilAnnotation": ""
    },
    "revision": {
      "type": "None",
      "description": ""
    },
    "validation": "SemTab 2020",
    "codeAvailability": "https://github.com/semihyumusak/semtab_teamtr_2020",
    "license": "Not specified",
    "inputs": {
      "typeOfTable": "CSV",
      "kg": {
        "tripleStore": "Wikidata",
        "index": ""
      }
    },
    "output": "CTA,CPA",
    "checkedByAuthor": true,
    "authors": [],
    "checkedByAi": false
  },
  {
    "firstAuthor": "Zhang",
    "year": 2020,
    "title": {
      "text": "Novel Entity Discovery from Web Tables",
      "link": ""
    },
    "added": "",
    "conferenceJournal": "WWW",
    "nameOfApproach": "",
    "mainMethod": {
      "type": "Supervised",
      "technique": "lexical, semantic features"
    },
    "domain": {
      "domain": "Independent",
      "type": ""
    },
    "coreTasks": {
      "cta": false,
      "cpa": true,
      "cea": true,
      "cnea": true
    },
    "supportTasks": {
      "dataPreparation": {
        "description": "",
        "spellChecker": "",
        "unitsOfMeasurements": ""
      },
      "subjectDetection": "table is said to be linkable if the KB has a match- ing entity for any of the mentions in its core column, i.e., the subject column that contains most entity-based mentions [16, 34]",
      "columnClassification": "Uses column header for a classification model trained on T2D",
      "typeAnnotation": "Label similarity + values similarity",
      "predicateAnnotation": " ",
      "datatypeAnnotation": "The KB values and tabular values in the column are classified as time, numerical, string, or other data types. We type ambiguous values, such as \"1836\", as both \"numerical\" and \"time\". We assign a type to column data type by majority voting",
      "entityLinking": {
        "description": "Candidate Generatiom\n- Wikipedia search API \nCandate Classification \n- lexical simlarity (Levenshtein, Jaccard, Letter Distance, Substring Indicator) \n- sematic similarity ? \nEntity Disambiguation \n- filter on type",
        "candidateGeneration": "lookup, Wikipedia API",
        "entityDisambiguation": "features, ML"
      },
      "nilAnnotation": "collects all tables with unlinked mentions and consider i) the number of linked mentions and ii) the linking rate. use linked entities and related information to search Wikipedia. Select the entities among the top k through a similarity measure. \n Natural Embedding \n Topical Space \n Lexical Space"
    },
    "revision": {
      "type": "None",
      "description": ""
    },
    "validation": "T2D, W2D, T2Dv2",
    "codeAvailability": "https://zenodo.org/record/3627274",
    "license": "CCA 4.0",
    "inputs": {
      "typeOfTable": "CSV",
      "kg": {
        "tripleStore": "DBpedia",
        "index": ""
      }
    },
    "output": "",
    "checkedByAuthor": true,
    "authors": [],
    "checkedByAi": false
  },
  {
    "firstAuthor": "Abdelmageed",
    "year": 2021,
    "title": {
      "text": "JenTab Meets SemTab 2021's New Challenges",
      "link": ""
    },
    "added": "",
    "conferenceJournal": "SemTab",
    "nameOfApproach": "JenTab",
    "mainMethod": {
      "type": "Unsupervised",
      "technique": "features"
    },
    "domain": {
      "domain": "Independent",
      "type": ""
    },
    "coreTasks": {
      "cta": true,
      "cpa": true,
      "cea": true,
      "cnea": false
    },
    "supportTasks": {
      "dataPreparation": {
        "description": "datatype detection",
        "spellChecker": "",
        "unitsOfMeasurements": ""
      },
      "subjectDetection": "column position",
      "columnClassification": "Datatypes (object, date, string, and number)",
      "typeAnnotation": "See Abdelmageed2020",
      "predicateAnnotation": "See Abdelmageed2020",
      "datatypeAnnotation": "See Abdelmageed2020",
      "entityLinking": {
        "description": "See Abdelmageed2020",
        "candidateGeneration": "lookup, SPARQL",
        "entityDisambiguation": "features, similarity"
      },
      "nilAnnotation": ""
    },
    "revision": {
      "type": "None",
      "description": ""
    },
    "validation": "SemTab 2021",
    "codeAvailability": "https://github.com/fusion-jena/JenTab",
    "license": "Apache 2.0",
    "inputs": {
      "typeOfTable": "CSV",
      "kg": {
        "tripleStore": "DBpedia, Wikidata",
        "index": ""
      }
    },
    "output": "CEA,CTA,CPA",
    "checkedByAuthor": true,
    "authors": [],
    "checkedByAi": false
  },
  {
    "firstAuthor": "Abdelmageed",
    "year": 2021,
    "title": {
      "text": "JenTab: A Toolkit for Semantic Table Annotations",
      "link": ""
    },
    "added": "",
    "conferenceJournal": "KGC",
    "nameOfApproach": "JenTab",
    "mainMethod": {
      "type": "Unsupervised",
      "technique": "features"
    },
    "domain": {
      "domain": "Independent",
      "type": ""
    },
    "coreTasks": {
      "cta": true,
      "cpa": true,
      "cea": true,
      "cnea": false
    },
    "supportTasks": {
      "dataPreparation": {
        "description": "datatype detection",
        "spellChecker": "",
        "unitsOfMeasurements": ""
      },
      "subjectDetection": "column position",
      "columnClassification": "Datatypes (object, date, string, and number)",
      "typeAnnotation": "See Abdelmageed2020",
      "predicateAnnotation": "See Abdelmageed2020",
      "datatypeAnnotation": "See Abdelmageed2020",
      "entityLinking": {
        "description": "See Abdelmageed2020",
        "candidateGeneration": "lookup, SPARQL",
        "entityDisambiguation": "features, similarity"
      },
      "nilAnnotation": ""
    },
    "revision": {
      "type": "None",
      "description": ""
    },
    "validation": "SemTab 2020",
    "codeAvailability": "https://github.com/fusion-jena/JenTab",
    "license": "Apache 2.0",
    "inputs": {
      "typeOfTable": "CSV",
      "kg": {
        "tripleStore": "DBpedia, Wikidata",
        "index": ""
      }
    },
    "output": "CEA,CTA,CPA",
    "checkedByAuthor": true,
    "authors": [],
    "checkedByAi": false
  },
  {
    "firstAuthor": "Avogadro",
    "year": 2021,
    "title": {
      "text": "MantisTable V: a novel and efficient approach to Semantic Table Interpretation",
      "link": ""
    },
    "added": "",
    "conferenceJournal": "SemTab",
    "nameOfApproach": "MantisTable V",
    "mainMethod": {
      "type": "Unsupervised",
      "technique": "features"
    },
    "domain": {
      "domain": "Independent",
      "type": ""
    },
    "coreTasks": {
      "cta": true,
      "cpa": true,
      "cea": true,
      "cnea": false
    },
    "supportTasks": {
      "dataPreparation": {
        "description": "During this phase, all tables' cells are analysed using a tokeniser managing special characters and additional spaces",
        "spellChecker": "",
        "unitsOfMeasurements": ""
      },
      "subjectDetection": "Identified within the NE columns using content based scores",
      "columnClassification": "Identification of literal (L-) columns using a set of Regextypes",
      "typeAnnotation": "",
      "predicateAnnotation": "All the predicates previously identified via LamAPI for each column are sorted by their relative frequency to the entire column. The predicate with the greatest frequency will be ranked first.",
      "datatypeAnnotation": "Identification of literal (L-) columns using a set of Regextypes",
      "entityLinking": {
        "description": "Entity-linking on NE-columns by searching the LamAPI, using the Lookup service",
        "candidateGeneration": "lookup, custom index",
        "entityDisambiguation": "features"
      },
      "nilAnnotation": ""
    },
    "revision": {
      "type": "None",
      "description": ""
    },
    "validation": "SemTab 2021",
    "codeAvailability": "https://bitbucket.org/disco_unimib/mantistable-v ",
    "license": "Apache 2.0",
    "inputs": {
      "typeOfTable": "",
      "kg": {
        "tripleStore": "DBpedia, Wikidata",
        "index": "LamAPI"
      }
    },
    "output": "CEA,CTA,CPA",
    "checkedByAuthor": true,
    "authors": [],
    "checkedByAi": false
  },
  {
    "firstAuthor": "Baazouzi",
    "year": 2021,
    "title": {
      "text": "Kepler-aSI at SemTab 2021",
      "link": ""
    },
    "added": "",
    "conferenceJournal": "SemTab",
    "nameOfApproach": "KEPLER-ASI",
    "mainMethod": {
      "type": "Unsupervised",
      "technique": "features"
    },
    "domain": {
      "domain": "Independent",
      "type": ""
    },
    "coreTasks": {
      "cta": true,
      "cpa": true,
      "cea": true,
      "cnea": false
    },
    "supportTasks": {
      "dataPreparation": {
        "description": "stop word elimination",
        "spellChecker": "pyspellchecker",
        "unitsOfMeasurements": "pandas"
      },
      "subjectDetection": "",
      "columnClassification": "Aimed at explicitly extracting the candidates for the annotation process. The priming is carried out by an analysis of the processing columns, which aims to understand and delimit the set of regular expressions which contains a set of units. This step allows to identify multiple Regextypes using regular expressions. Also language detection is performed. ",
      "typeAnnotation": "After a set of information is collected for each entity (instanceOf, partOf, subclassOf), the column type is identified using a SPARQL query. If more than one type is returned by the query, no annotation is made. ",
      "predicateAnnotation": "After having annotated the cell values as well as the different types of each of the considered entities, they identify the relationships between two cells appearing on the same row via a property using a SPARQL query,",
      "datatypeAnnotation": "Datatype is detected in the preprocessing phase by using regex",
      "entityLinking": {
        "description": "The approach reuses the results of the CTA task process by introducing the necessary modifications on the SPARQL query. If the operation returns more than one annotation, they run a process based on examining the context of the considered column, relative to what was obtained with the CTA task, to overcome the ambiguity problem.",
        "candidateGeneration": "lookup, SPARQL",
        "entityDisambiguation": "contextual inf"
      },
      "nilAnnotation": ""
    },
    "revision": {
      "type": "None",
      "description": ""
    },
    "validation": "SemTab 2021",
    "codeAvailability": "",
    "license": "Not specified",
    "inputs": {
      "typeOfTable": "CSV",
      "kg": {
        "tripleStore": "Wikidata",
        "index": ""
      }
    },
    "output": "CEA,CTA,CPA",
    "checkedByAuthor": true,
    "authors": [],
    "checkedByAi": false
  },
  {
    "firstAuthor": "Heist",
    "year": 2021,
    "title": {
      "text": "Information Extraction From Co-Occurring Similar Entities",
      "link": ""
    },
    "added": "",
    "conferenceJournal": "WWW",
    "nameOfApproach": "CaLiGraph extraction framework",
    "mainMethod": {
      "type": "Hybrid",
      "technique": "Distant Supervision, Rule Mining"
    },
    "domain": {
      "domain": "Independent",
      "type": ""
    },
    "coreTasks": {
      "cta": false,
      "cpa": false,
      "cea": false,
      "cnea": false
    },
    "supportTasks": {
      "dataPreparation": {
        "description": "",
        "spellChecker": "",
        "unitsOfMeasurements": ""
      },
      "subjectDetection": "implicitly identify the subject column of the table by identifying the subject entities of the table (see section 4.3 Subject Entity Discovery)",
      "columnClassification": " ",
      "typeAnnotation": "type frequency and domain of predicate statistics from the kg",
      "predicateAnnotation": "most frequent",
      "datatypeAnnotation": "",
      "entityLinking": {
        "description": "",
        "candidateGeneration": "",
        "entityDisambiguation": ""
      },
      "nilAnnotation": ""
    },
    "revision": {
      "type": "None",
      "description": ""
    },
    "validation": "",
    "codeAvailability": "https://github.com/nheist/CaLiGraph ",
    "license": "GPL 3.0",
    "inputs": {
      "typeOfTable": "Web tables",
      "kg": {
        "tripleStore": "CaliGraph,DBpedia,Yago",
        "index": ""
      }
    },
    "output": "RDF assertions",
    "checkedByAuthor": true,
    "authors": [],
    "checkedByAi": false
  },
  {
    "firstAuthor": "Huynh",
    "year": 2021,
    "title": {
      "text": "DAGOBAH: Table and Graph Contexts for Eﬀicient Semantic Annotation of Tabular Data",
      "link": ""
    },
    "added": "",
    "conferenceJournal": "SemTab",
    "nameOfApproach": "DAGOBAH SL 2021",
    "mainMethod": {
      "type": "Hybrid",
      "technique": "features, embeddings, matching"
    },
    "domain": {
      "domain": "Independent",
      "type": ""
    },
    "coreTasks": {
      "cta": true,
      "cpa": true,
      "cea": true,
      "cnea": false
    },
    "supportTasks": {
      "dataPreparation": {
        "description": "Same as previous year",
        "spellChecker": "",
        "unitsOfMeasurements": ""
      },
      "subjectDetection": "Same as previous year",
      "columnClassification": "Discriminate Columns with String, DateTime, Numerical with Unit, Numerical w/o Unit",
      "typeAnnotation": "Same as previous year",
      "predicateAnnotation": "CPA is calculated from CEA (the most occuring relation between two cell annotations in two columns)",
      "datatypeAnnotation": "VRAI (named entity, literals with unit, miscellaneous literals (e.g., Email, URL, IP Address)",
      "entityLinking": {
        "description": "Iterative {CEA, CTA, CPA} disambiguation",
        "candidateGeneration": "lookup, custom index",
        "entityDisambiguation": "features, similarity, contextual inf"
      },
      "nilAnnotation": ""
    },
    "revision": {
      "type": "Fully automated",
      "description": ""
    },
    "validation": "SemTab 2021",
    "codeAvailability": "",
    "license": "Orange",
    "inputs": {
      "typeOfTable": "CSV, TXT, XLSX",
      "kg": {
        "tripleStore": "DBpedia, Wikidata",
        "index": "ElasticSearch"
      }
    },
    "output": "JSON",
    "checkedByAuthor": true,
    "authors": [],
    "checkedByAi": false
  },
  {
    "firstAuthor": "Nguyen",
    "year": 2021,
    "title": {
      "text": "SemTab 2021: Tabular Data Annotation with MTab Tool",
      "link": ""
    },
    "added": "",
    "conferenceJournal": "SemTab",
    "nameOfApproach": "MTab",
    "mainMethod": {
      "type": "Unsupervised",
      "technique": "features"
    },
    "domain": {
      "domain": "Independent",
      "type": ""
    },
    "coreTasks": {
      "cta": true,
      "cpa": true,
      "cea": true,
      "cnea": false
    },
    "supportTasks": {
      "dataPreparation": {
        "description": "remove HTML tags, non-cell-values and use ftfy tool to fix noisy cells",
        "spellChecker": "",
        "unitsOfMeasurements": ""
      },
      "subjectDetection": "A column is a subject column when its datatype is NE, it is determined based on the uniqueness score as an increased score for columns with many uniqeu values and reduces the score for columns with missing values. The subject column is the one with the highest unique score. If the same score is shared, the leftmost column is chosen. ",
      "columnClassification": "Column analysis is conducted by classifying the datatype of a cell and detecting the subject column. ",
      "typeAnnotation": "The column datatype is the most common type within its cells",
      "predicateAnnotation": "Predicates between the subject column and all the other columns are identified",
      "datatypeAnnotation": "First a table cell's datatype into non-cell (empty), literal or NE using SpaCy pretrained models. NE, date-time and numeric entities are identified this way. A table column's data type into either a non-match column (empty column), a literal, or a named-entity column. The column data type is derived from the majority voting of all cell data types in this column.",
      "entityLinking": {
        "description": "Entity candidate generation is performed for each table cell with the entity search modules. MTab tool provides the three entity search modules, i.e., keyword search, fuzzy search, and aggregation search",
        "candidateGeneration": "lookup, custom index",
        "entityDisambiguation": "features, contextual inf"
      },
      "nilAnnotation": ""
    },
    "revision": {
      "type": "Fully automated",
      "description": ""
    },
    "validation": "SemTab 2021",
    "codeAvailability": "https://github.com/phucty/mtab_tool (API DOCS FOR ONLINE TOOL)",
    "license": "MIT",
    "inputs": {
      "typeOfTable": "CSV",
      "kg": {
        "tripleStore": "DBpedia, Wikidata",
        "index": "Custom BM25"
      }
    },
    "output": "CEA,CTA,CPA",
    "checkedByAuthor": true,
    "authors": [],
    "checkedByAi": false
  },
  {
    "firstAuthor": "Steenwinckel",
    "year": 2021,
    "title": {
      "text": "MAGIC: Mining an Augmented Graph using INK, starting from a CSV",
      "link": ""
    },
    "added": "",
    "conferenceJournal": "SemTab",
    "nameOfApproach": "MAGIC",
    "mainMethod": {
      "type": "Hybrid",
      "technique": "INK, lookup"
    },
    "domain": {
      "domain": "Independent",
      "type": ""
    },
    "coreTasks": {
      "cta": true,
      "cpa": true,
      "cea": true,
      "cnea": false
    },
    "supportTasks": {
      "dataPreparation": {
        "description": "future work",
        "spellChecker": "",
        "unitsOfMeasurements": ""
      },
      "subjectDetection": "",
      "columnClassification": " ",
      "typeAnnotation": "The column type can be derived from all cells containing annotated values. For all cells, an INK embedding of depth 1 is generated and the rdf:type for DBpedia and Wikidata P31 relationships are kept to determine the column type annotations. Again, the annotation with the highest count value is kept",
      "predicateAnnotation": "The INK embedding also provides the information going from the major column cell to the neighbouring cells within the same row. This information is directly derived from the provided embedding by selecting the object or data property relationships from the INK embedding. The combination of a relationship between two cells is kept within a dictionary. After the procedure to provide annotations for all cells is finished, the relationships between all those two cells are counted and the relationship with the maximal count is returned",
      "datatypeAnnotation": "",
      "entityLinking": {
        "description": "DBpedia Spotlight is used to collect candidates from a cell description; candidates are filteres according to predefined characteristics. For the selected candidate annotations an INK embedding of depth 2 is generated. Within these embeddings, a next function will search for matching information residing in the other cells on the same row from which the candidate embeddings were generated.",
        "candidateGeneration": "lookup, DBP Spotlight, WKD API",
        "entityDisambiguation": "features, entity embedding"
      },
      "nilAnnotation": ""
    },
    "revision": {
      "type": "None",
      "description": ""
    },
    "validation": "SemTab 2021",
    "codeAvailability": "https://github.com/IBCNServices/Magic",
    "license": "imec",
    "inputs": {
      "typeOfTable": "CSV",
      "kg": {
        "tripleStore": "Wikidata",
        "index": "CEA,CTA,CPA"
      }
    },
    "output": "",
    "checkedByAuthor": true,
    "authors": [],
    "checkedByAi": false
  },
  {
    "firstAuthor": "Wang",
    "year": 2021,
    "title": {
      "text": "TCN: Table Convolutional Network for Web Table Interpretation",
      "link": ""
    },
    "added": "",
    "conferenceJournal": "WWW",
    "nameOfApproach": "TCN",
    "mainMethod": {
      "type": "Supervised",
      "technique": "Transformer"
    },
    "domain": {
      "domain": "Independent",
      "type": ""
    },
    "coreTasks": {
      "cta": true,
      "cpa": true,
      "cea": false,
      "cnea": false
    },
    "supportTasks": {
      "dataPreparation": {
        "description": "we apply minimal preprocessing on cell values by lowering all cases and removing redundant spaces.",
        "spellChecker": "",
        "unitsOfMeasurements": ""
      },
      "subjectDetection": "",
      "columnClassification": " ",
      "typeAnnotation": "A representation learning framework (Table Convolution Networks) is employed which uses intra and intert table context available from a collection of tables instead limiting itself to the table under analysis",
      "predicateAnnotation": "Pairwise column relation is obtained through TCN",
      "datatypeAnnotation": "A music ontology is used for type detection; non identified types are set to XMLSchema#String",
      "entityLinking": {
        "description": "",
        "candidateGeneration": "",
        "entityDisambiguation": ""
      },
      "nilAnnotation": ""
    },
    "revision": {
      "type": "None",
      "description": ""
    },
    "validation": "custom dataset music domain",
    "codeAvailability": "",
    "license": "Not specified",
    "inputs": {
      "typeOfTable": "",
      "kg": {
        "tripleStore": "",
        "index": ""
      }
    },
    "output": "",
    "checkedByAuthor": false,
    "authors": [],
    "checkedByAi": false
  },
  {
    "firstAuthor": "Yang",
    "year": 2021,
    "title": {
      "text": "GBMTab: A Graph-Based Method for Interpreting Noisy Semantic Table to Knowledge Graph",
      "link": ""
    },
    "added": "",
    "conferenceJournal": "SemTab",
    "nameOfApproach": "GBMTab",
    "mainMethod": {
      "type": "Supervised",
      "technique": "PGM"
    },
    "domain": {
      "domain": "Independent",
      "type": ""
    },
    "coreTasks": {
      "cta": true,
      "cpa": false,
      "cea": true,
      "cnea": false
    },
    "supportTasks": {
      "dataPreparation": {
        "description": "",
        "spellChecker": "",
        "unitsOfMeasurements": ""
      },
      "subjectDetection": "",
      "columnClassification": " ",
      "typeAnnotation": "majority voting",
      "predicateAnnotation": "NO CPA",
      "datatypeAnnotation": "",
      "entityLinking": {
        "description": "A noise mention repair mechanism is adopted; EL is divided into candidate generation and entity disambiguation. EL is achieved through string similarity comparison and noise mention repair. ",
        "candidateGeneration": "lookup, custom index, Mediawiki API",
        "entityDisambiguation": "features, probabilistic"
      },
      "nilAnnotation": ""
    },
    "revision": {
      "type": "None",
      "description": ""
    },
    "validation": "SemTab 2021",
    "codeAvailability": "",
    "license": "Not specified",
    "inputs": {
      "typeOfTable": "CSV",
      "kg": {
        "tripleStore": "Wikidata",
        "index": ""
      }
    },
    "output": "CEA,CTA",
    "checkedByAuthor": false,
    "authors": [],
    "checkedByAi": false
  },
  {
    "firstAuthor": "Zhou",
    "year": 2021,
    "title": {
      "text": "Tabular Data Concept Type Detection Using Star-Transformers",
      "link": ""
    },
    "added": "",
    "conferenceJournal": "CIKM",
    "nameOfApproach": "",
    "mainMethod": {
      "type": "Supervised",
      "technique": "Star-Transformers"
    },
    "domain": {
      "domain": "Independent",
      "type": ""
    },
    "coreTasks": {
      "cta": true,
      "cpa": false,
      "cea": false,
      "cnea": false
    },
    "supportTasks": {
      "dataPreparation": {
        "description": "feature extraction",
        "spellChecker": "",
        "unitsOfMeasurements": ""
      },
      "subjectDetection": "",
      "columnClassification": " ",
      "typeAnnotation": "The frequency of the msot common level 2 (eg children) and most common level 3 (eg grandchildren) DBpedia classes is calculated and the most frequent one is chosen.",
      "predicateAnnotation": " ",
      "datatypeAnnotation": "",
      "entityLinking": {
        "description": "",
        "candidateGeneration": "",
        "entityDisambiguation": ""
      },
      "nilAnnotation": ""
    },
    "revision": {
      "type": "None",
      "description": ""
    },
    "validation": "custom dataset",
    "codeAvailability": "",
    "license": "Not specified",
    "inputs": {
      "typeOfTable": "",
      "kg": {
        "tripleStore": "",
        "index": ""
      }
    },
    "output": "",
    "checkedByAuthor": true,
    "authors": [],
    "checkedByAi": false
  },
  {
    "firstAuthor": "Abdelmageed",
    "year": 2022,
    "title": {
      "text": "JenTab: Do CTA solutions affect the entire scores?",
      "link": ""
    },
    "added": "",
    "conferenceJournal": "KGC",
    "nameOfApproach": "JenTab",
    "mainMethod": {
      "type": "Unsupervised",
      "technique": "features"
    },
    "domain": {
      "domain": "Independent",
      "type": ""
    },
    "coreTasks": {
      "cta": true,
      "cpa": true,
      "cea": true,
      "cnea": false
    },
    "supportTasks": {
      "dataPreparation": {
        "description": "datatype detection",
        "spellChecker": "",
        "unitsOfMeasurements": ""
      },
      "subjectDetection": "column position",
      "columnClassification": "Datatypes (object, date, string, and number)",
      "typeAnnotation": "See Abdelmageed2020",
      "predicateAnnotation": "See Abdelmageed2020",
      "datatypeAnnotation": "See Abdelmageed2020",
      "entityLinking": {
        "description": "See Abdelmageed2020",
        "candidateGeneration": "lookup, SPARQL",
        "entityDisambiguation": "features, similarity"
      },
      "nilAnnotation": ""
    },
    "revision": {
      "type": "None",
      "description": ""
    },
    "validation": "SemTab 2020",
    "codeAvailability": "https://github.com/fusion-jena/JenTab",
    "license": "Apache 2.0",
    "inputs": {
      "typeOfTable": "CSV",
      "kg": {
        "tripleStore": "DBpedia, Wikidata",
        "index": ""
      }
    },
    "output": "CEA,CTA,CPA",
    "checkedByAuthor": true,
    "authors": [],
    "checkedByAi": false
  },
  {
    "firstAuthor": "Chen",
    "year": 2022,
    "title": {
      "text": "LinkingPark: An automatic semantic table interpretation system",
      "link": ""
    },
    "added": "",
    "conferenceJournal": "JOWS",
    "nameOfApproach": "LinkingPark",
    "mainMethod": {
      "type": "Unsupervised",
      "technique": "features"
    },
    "domain": {
      "domain": "Independent",
      "type": ""
    },
    "coreTasks": {
      "cta": true,
      "cpa": true,
      "cea": true,
      "cnea": false
    },
    "supportTasks": {
      "dataPreparation": {
        "description": "future work",
        "spellChecker": "",
        "unitsOfMeasurements": ""
      },
      "subjectDetection": "The subject column is heuristically considered to be the leftmost column that contains cells of the string datatype",
      "columnClassification": "Column analysis is conducted by classifying the datatype of a cell and detecting the subject column. ",
      "typeAnnotation": "Type inference algorithm is a heuristic voting method, dependent on EL resutls.",
      "predicateAnnotation": "The property can be classified into two categories: entity property and literal property, according to the subject/object column types. For each non-subject column, the algorithm computes its entity property distribution and literal property distribution. The definitive property is the highest probability within those computed.",
      "datatypeAnnotation": "int, float, datetime and strings are the datatype considered. A cell content is classified into such types if it can be converted into that type using standard type conversion functions, otherwise it is considered to be a string. ",
      "entityLinking": {
        "description": "A set of candidate entities through a candidate generation sub-module which uses a dictionary search (alias mapping is conducted and then a dictionary lookup is performed) and a fuzzy search (mostly for strings with multiple spelling errors)",
        "candidateGeneration": "lookup, custom index",
        "entityDisambiguation": "features, similarity, contextual inf"
      },
      "nilAnnotation": ""
    },
    "revision": {
      "type": "None",
      "description": ""
    },
    "validation": "SemTab 2021",
    "codeAvailability": "https://github.com/microsoft/vert-papers/tree/master/papers/LinkingPark",
    "license": "MIT",
    "inputs": {
      "typeOfTable": "CSV",
      "kg": {
        "tripleStore": "DBpedia, Wikidata",
        "index": "ElasticSearch"
      }
    },
    "output": "CEA,CTA,CPA",
    "checkedByAuthor": true,
    "authors": [],
    "checkedByAi": false
  },
  {
    "firstAuthor": "Cremaschi",
    "year": 2022,
    "title": {
      "text": "s-elBat: a Semantic Interpretation Approach for Messy taBle-s",
      "link": ""
    },
    "added": "",
    "conferenceJournal": "SemTab",
    "nameOfApproach": "s-Elbat",
    "mainMethod": {
      "type": "Unsupervised",
      "technique": "features"
    },
    "domain": {
      "domain": "Independent",
      "type": ""
    },
    "coreTasks": {
      "cta": true,
      "cpa": true,
      "cea": true,
      "cnea": false
    },
    "supportTasks": {
      "dataPreparation": {
        "description": "Convertion to lowercase, column classification by associating L-column and NE-column labels to column containing strings and NE mentions respectively. Subject column identification.",
        "spellChecker": "",
        "unitsOfMeasurements": ""
      },
      "subjectDetection": "The S-column is identified in a non deterministic way for the final annotation, but it can positively influence the execution time. ",
      "columnClassification": "Columns are classified as either subject (S-), named entity (NE-) or literal (LIT-) column in a preprocessing step. Cells from NE-columns are extracted to generate a set of potential candidates for the entity retrieval step.",
      "typeAnnotation": "CTA performed by iterating the cell annotation over all the cells in the given column. A dictionary with the frequency of all the classes of the winning entities obtained in the previous step is created; the type with the maximum frequency will be selected as an annotation for the column under analysis.",
      "predicateAnnotation": "Most information for CPA is collected during the CEA phase through LamAPI. A dictionary for every column containing all the winning properties and related frequencies is created and then the most frequent property is selected for CPA.",
      "datatypeAnnotation": "Datatypes are attributed during the preprocessing step for LIT columns",
      "entityLinking": {
        "description": "EL, thus entity retrieval and disambiguation, is performed with LamAPI.",
        "candidateGeneration": "lookup, custom index",
        "entityDisambiguation": "features, similarity, contextual information"
      },
      "nilAnnotation": ""
    },
    "revision": {
      "type": "None",
      "description": ""
    },
    "validation": "SemTab 2022",
    "codeAvailability": "https://bitbucket.org/disco_unimib/selbat/ ",
    "license": "Apache 2.0",
    "inputs": {
      "typeOfTable": "CSV,JSON",
      "kg": {
        "tripleStore": "DBpedia, Wikidata",
        "index": "LamAPI"
      }
    },
    "output": "CEA,CTA,CPA",
    "checkedByAuthor": true,
    "authors": [],
    "checkedByAi": false
  },
  {
    "firstAuthor": "Deng",
    "year": 2022,
    "title": {
      "text": "TURL: Table Understanding through Representation Learning",
      "link": ""
    },
    "added": "",
    "conferenceJournal": "SIGMOD",
    "nameOfApproach": "TURL",
    "mainMethod": {
      "type": "Supervised",
      "technique": "BERT"
    },
    "domain": {
      "domain": "Independent",
      "type": ""
    },
    "coreTasks": {
      "cta": true,
      "cpa": true,
      "cea": true,
      "cnea": false
    },
    "supportTasks": {
      "dataPreparation": {
        "description": "",
        "spellChecker": "",
        "unitsOfMeasurements": ""
      },
      "subjectDetection": " We employ a simple heuristic for subject column detection: the subject column must be located in the first two columns of the table and contain unique entities.",
      "columnClassification": "use an additional type embedding vector t e to differentiate three types of entity cells (i.e., subject/object/topic).",
      "typeAnnotation": "Use the available information in each cell of a given table directly for column type annotation without performing entity linking first. The representations of tokens in the column header and representations of entity cells in the column are leveraged to calculate the probability of predicting the column type. ",
      "predicateAnnotation": "aggregated column representations like in CTA optimized with binary cross-entropy loss",
      "datatypeAnnotation": "",
      "entityLinking": {
        "description": " For entity linking, we first generate candidate entities using the Wikidata Lookup service. We then rank them by their matching scores with the target cell. We obtain a contextualized representation for each cell with its cell text and table metadata. To represent each candidate entity, we utilize the name, description and type information from a KB. ",
        "candidateGeneration": "lookup, WKD API",
        "entityDisambiguation": "features, LM"
      },
      "nilAnnotation": "Here we aim to conduct relation extraction without explicitly linking table cells to entities. This is important as it allows the extraction of new knowledge from Web tables for tasks like knowledge base population."
    },
    "revision": {
      "type": "None",
      "description": ""
    },
    "validation": "T2D, WikiGS",
    "codeAvailability": "https://github.com/sunlab-osu/TURL",
    "license": "Apache 2.0",
    "inputs": {
      "typeOfTable": "Web tables",
      "kg": {
        "tripleStore": "Freebase, Wikidata, DBpedia",
        "index": ""
      }
    },
    "output": "CTA,CPA,CEA",
    "checkedByAuthor": true,
    "authors": [],
    "checkedByAi": false
  },
  {
    "firstAuthor": "Gottschalk",
    "year": 2022,
    "title": {
      "text": "Tab2KG: Semantic table interpretation with lightweight semantic profiles",
      "link": ""
    },
    "added": "",
    "conferenceJournal": "SWJ",
    "nameOfApproach": "Tab2KG",
    "mainMethod": {
      "type": "Supervised",
      "technique": "Siamese Network"
    },
    "domain": {
      "domain": "Independent",
      "type": ""
    },
    "coreTasks": {
      "cta": true,
      "cpa": true,
      "cea": false,
      "cnea": true
    },
    "supportTasks": {
      "dataPreparation": {
        "description": "data transformed in RML format",
        "spellChecker": "",
        "unitsOfMeasurements": ""
      },
      "subjectDetection": "Subject column detection Several approaches [11,52] for semantic table interpretation assume the existence of a subject column, i.e., the main column of the data table where every other column is directly connected to. The subject column detection is typically identified through a set of statistic features. Approaches relying on a subject column do not consider the involvement of any classes which are not directly represented in the data table (for example, consider Fig. 1, but without the first column). Tab2KG utilizes a graph-based approach where such class relations can be found",
      "columnClassification": "dateparser library for classification into numeric, spatial, boolean or text categories. Later the columns are further classified into more categories using regex + Alobaid et al (\"Typology-based semantic labeling of numeric tabular data\") method ",
      "typeAnnotation": "domain profile + table profile",
      "predicateAnnotation": " ",
      "datatypeAnnotation": "Data type identification: For each table column, we identify its data type(s) by trying to parse more than 90% of the values as numeric, Boolean, spatial (Well-Known Text or Well-Known Binary format [25]) or temporal (using the dateparser library). If that is not possible, the column is assigned the text data type.",
      "entityLinking": {
        "description": "",
        "candidateGeneration": "",
        "entityDisambiguation": ""
      },
      "nilAnnotation": ""
    },
    "revision": {
      "type": "None",
      "description": ""
    },
    "validation": "Datasets on github, subsets of DBpedia and schema.org",
    "codeAvailability": "https://github.com/sgottsch/Tab2KG",
    "license": "MIT",
    "inputs": {
      "typeOfTable": "CSV",
      "kg": {
        "tripleStore": "DBpedia, Schema.org",
        "index": ""
      }
    },
    "output": "Data graph which represents the content of the table (TURTLE)",
    "checkedByAuthor": true,
    "authors": [],
    "checkedByAi": false
  },
  {
    "firstAuthor": "Huynh",
    "year": 2022,
    "title": {
      "text": "From Heuristics to Language Models: A Journey Through the Universe of Semantic Table Interpretation with DAGOBAH",
      "link": ""
    },
    "added": "",
    "conferenceJournal": "SemTab",
    "nameOfApproach": "DAGOBAH SL2022",
    "mainMethod": {
      "type": "Hybrid",
      "technique": "Heuristics, transformer-based embeddings"
    },
    "domain": {
      "domain": "Independent",
      "type": ""
    },
    "coreTasks": {
      "cta": true,
      "cpa": true,
      "cea": true,
      "cnea": false
    },
    "supportTasks": {
      "dataPreparation": {
        "description": "",
        "spellChecker": "",
        "unitsOfMeasurements": ""
      },
      "subjectDetection": "",
      "columnClassification": "A pre-processing step is also applied to each column to find a primitive type such as ORG (organization), LOC (location), MONEY (currency), etc. which is typical for the Named Entity Recognition task in NLP",
      "typeAnnotation": "Same as previous year",
      "predicateAnnotation": "CPA is calculated from CEA (the most occuring relation between two cell annotations in two columns)",
      "datatypeAnnotation": "A pre-processing step is also applied to each column to find a primitive type such as ORG (organization), LOC (location), MONEY (currency), etc. which is typical for the Named Entity Recognition task in NLP",
      "entityLinking": {
        "description": "Two stage approach consisting of: lookup step ad entity scoring step (DAGOBAH 2021 improved). The algorithm employs also the Entity Disambiguation by Reading Entity Descriptions",
        "candidateGeneration": "Elasticsearch ",
        "entityDisambiguation": "BERT (the system uses entities description and table headers)"
      },
      "nilAnnotation": ""
    },
    "revision": {
      "type": "Fully automated",
      "description": "DAGOBAH UI enables users to validate DAGOBAH's results."
    },
    "validation": "semtab 2022",
    "codeAvailability": "",
    "license": "Orange",
    "inputs": {
      "typeOfTable": "CSV",
      "kg": {
        "tripleStore": "DBpedia, Wikidata, Schema.org",
        "index": "ElasticSearch"
      }
    },
    "output": "CTA,CPA,CEA",
    "checkedByAuthor": true,
    "authors": [],
    "checkedByAi": false
  },
  {
    "firstAuthor": "Liu",
    "year": 2022,
    "title": {
      "text": "Radar Station: Using KG Embeddings for Semantic Table Interpretation and Entity Disambiguation",
      "link": ""
    },
    "added": "",
    "conferenceJournal": "ISWC",
    "nameOfApproach": "Radar Station",
    "mainMethod": {
      "type": "Hybrid",
      "technique": "Heuristics, KG embedding"
    },
    "domain": {
      "domain": "Independent",
      "type": ""
    },
    "coreTasks": {
      "cta": false,
      "cpa": false,
      "cea": true,
      "cnea": false
    },
    "supportTasks": {
      "dataPreparation": {
        "description": "",
        "spellChecker": "",
        "unitsOfMeasurements": ""
      },
      "subjectDetection": "",
      "columnClassification": " ",
      "typeAnnotation": "",
      "predicateAnnotation": " ",
      "datatypeAnnotation": "",
      "entityLinking": {
        "description": "CEA disambiguation with KG embedding.",
        "candidateGeneration": "lookup",
        "entityDisambiguation": "contextual inf"
      },
      "nilAnnotation": ""
    },
    "revision": {
      "type": "None",
      "description": ""
    },
    "validation": "T2D, Limaye, Tough Tables, ShortTables",
    "codeAvailability": "https://github.com/Orange-OpenSource/radar-station",
    "license": "Orange",
    "inputs": {
      "typeOfTable": "CSV, TXT, XLSX",
      "kg": {
        "tripleStore": "Wikidata",
        "index": ""
      }
    },
    "output": "",
    "checkedByAuthor": true,
    "authors": [],
    "checkedByAi": false
  },
  {
    "firstAuthor": "Suhara",
    "year": 2022,
    "title": {
      "text": "Annotating Columns with Pre-trained Language Models",
      "link": ""
    },
    "added": "",
    "conferenceJournal": "SIGMOD",
    "nameOfApproach": "Doduo",
    "mainMethod": {
      "type": "Supervised",
      "technique": "BERT"
    },
    "domain": {
      "domain": "Independent",
      "type": ""
    },
    "coreTasks": {
      "cta": true,
      "cpa": true,
      "cea": false,
      "cnea": false
    },
    "supportTasks": {
      "dataPreparation": {
        "description": "",
        "spellChecker": "",
        "unitsOfMeasurements": ""
      },
      "subjectDetection": "",
      "columnClassification": " ",
      "typeAnnotation": "",
      "predicateAnnotation": " ",
      "datatypeAnnotation": "",
      "entityLinking": {
        "description": "",
        "candidateGeneration": "",
        "entityDisambiguation": ""
      },
      "nilAnnotation": ""
    },
    "revision": {
      "type": "None",
      "description": ""
    },
    "validation": "WikiTable, VizNet",
    "codeAvailability": "https://github.com/megagonlabs/doduo",
    "license": "Apache 2.0",
    "inputs": {
      "typeOfTable": "",
      "kg": {
        "tripleStore": "Freebase,DBpedia",
        "index": ""
      }
    },
    "output": "",
    "checkedByAuthor": false,
    "authors": [],
    "checkedByAi": false
  },
  {
    "firstAuthor": "Zhang",
    "year": 2023,
    "title": {
      "text": "TableLlama: Towards Open Large Generalist Models for Tables",
      "link": ""
    },
    "added": "",
    "conferenceJournal": "arXiv",
    "nameOfApproach": "TableLlama",
    "mainMethod": {
      "type": "Supervised",
      "technique": "Llama 2"
    },
    "domain": {
      "domain": "Independent",
      "type": ""
    },
    "coreTasks": {
      "cta": true,
      "cpa": true,
      "cea": true,
      "cnea": false
    },
    "supportTasks": {
      "dataPreparation": {
        "description": "",
        "spellChecker": "",
        "unitsOfMeasurements": ""
      },
      "subjectDetection": "",
      "columnClassification": "",
      "typeAnnotation": " ",
      "predicateAnnotation": " ",
      "datatypeAnnotation": "",
      "entityLinking": {
        "description": "",
        "candidateGeneration": "",
        "entityDisambiguation": " "
      },
      "nilAnnotation": ""
    },
    "revision": {
      "type": "None",
      "description": ""
    },
    "validation": "TURL Dataset",
    "codeAvailability": "https://github.com/OSU-NLP-Group/TableLlama",
    "license": "MIT",
    "inputs": {
      "typeOfTable": "",
      "kg": {
        "tripleStore": "Wikidata",
        "index": ""
      }
    },
    "output": "",
    "checkedByAuthor": false,
    "authors": [],
    "checkedByAi": false
  },
  {
    "firstAuthor": "Li",
    "year": 2023,
    "title": {
      "text": "Table-GPT: Table-tuned GPT for Diverse Table Tasks",
      "link": ""
    },
    "added": "",
    "conferenceJournal": "arXiv",
    "nameOfApproach": "Table-GPT",
    "mainMethod": {
      "type": "Supervised",
      "technique": "GPT-3.5"
    },
    "domain": {
      "domain": "Independent",
      "type": ""
    },
    "coreTasks": {
      "cta": true,
      "cpa": false,
      "cea": false,
      "cnea": false
    },
    "supportTasks": {
      "dataPreparation": {
        "description": "",
        "spellChecker": "",
        "unitsOfMeasurements": ""
      },
      "subjectDetection": "",
      "columnClassification": "",
      "typeAnnotation": " ",
      "predicateAnnotation": "",
      "datatypeAnnotation": "",
      "entityLinking": {
        "description": "",
        "candidateGeneration": "",
        "entityDisambiguation": ""
      },
      "nilAnnotation": ""
    },
    "revision": {
      "type": "None",
      "description": ""
    },
    "validation": "TURL Dataset",
    "codeAvailability": "https://github.com/OSU-NLP-Group/TableLlama",
    "license": "Not specified",
    "inputs": {
      "typeOfTable": "Efthymiou, Limaye, Sherlock, T2D",
      "kg": {
        "tripleStore": "",
        "index": ""
      }
    },
    "output": "",
    "checkedByAuthor": false,
    "authors": [],
    "checkedByAi": false
  },
  {
    "firstAuthor": "Cremaschi",
    "authors": [
      "Marco Cremaschi",
      "Fabio D’Adda",
      "Andrea Maurino"
    ],
    "year": 2025,
    "title": {
      "text": "stEELlm: An LLM for Generating Semantic Annotations of Tabular Data",
      "link": "https://doi.org/10.1145/3719206"
    },
    "added": "2025-07-10",
    "conferenceJournal": "TIST",
    "nameOfApproach": "stEELlm",
    "mainMethod": {
      "type": "Supervised",
      "technique": "Fine-tuned Mixtral 8×7B LLM with LoRA adapters"
    },
    "domain": {
      "domain": "Independent",
      "type": ""
    },
    "coreTasks": {
      "cta": false,
      "cpa": false,
      "cea": true,
      "cnea": false
    },
    "supportTasks": {
      "dataPreparation": {
        "description": "CSV tables from WikidataTables 2023, HardTables 2022 and SemTab 2020 (140 800 in total) are cleaned (URL prefixes, Unicode chars, case normalisation) and enriched with candidate entities retrieved through LamAPI.",
        "spellChecker": "",
        "unitsOfMeasurements": ""
      },
      "subjectDetection": "Not addressed.",
      "columnClassification": "A heuristic column-classification step labels columns as Named-Entity (NE) or Literal (LIT) to steer the downstream linking.",
      "typeAnnotation": "",
      "predicateAnnotation": "",
      "datatypeAnnotation": "",
      "entityLinking": {
        "description": "Candidate generation via LamAPI lookup on Wikidata followed by disambiguation performed by the fine-tuned Mixtral 8×7B model that outputs the best QID for each cell.",
        "candidateGeneration": "LamAPI entity lookup",
        "entityDisambiguation": "Fine-tuned Mixtral 8×7B"
      },
      "nilAnnotation": ""
    },
    "revision": {
      "type": "None",
      "description": ""
    },
    "validation": "WikidataTables 2023, HardTables 2022, SemTab 2020",
    "codeAvailability": "https://github.com/unimib-datAI/steellm",
    "license": "GNU Affero General Public License v3",
    "inputs": {
      "typeOfTable": "CSV relational tables",
      "kg": {
        "tripleStore": "Wikidata",
        "index": "LamAPI"
      }
    },
    "output": "CSV list of (row,column)=QID annotations",
    "checkedByAuthor": true,
    "checkedByAi": true,
    "doi": "https://doi.org/10.1145/3719206"
  }
]