[
    {
        "id": "2007_hignette_an",
        "added": "",
        "year": 2007,
        "firstAuthor": "Hignette",
        "authors": [
            "Gaëlle Hignette",
            "Patrice Buche",
            "Juliette Dibie-Barthélemy",
            "Ollivier Haemmerlé"
        ],
        "title": "An Ontology-Driven Annotation of Data Tables",
        "venue": {
            "type": "workshop",
            "acronym": "WISE"
        },
        "nameOfApproach": "",
        "techniqueTags": [
            "rule-based",
            "ontology-driven"
        ],
        "coreTasks": {
            "cta": true,
            "cpa": true,
            "cea": false,
            "cnea": false
        },
        "supportTasks": {
            "dataPreparation": {
                "description": "Uses a domain ontology with stopwords, units, value ranges and a list of 'no-result' indicators to normalise and interpret table content.",
                "spellChecker": "",
                "unitsOfMeasurements": "Ontology units for numeric types (e.g., °C, °F)."
            },
            "columnClassification": "Rule-based detection of numeric vs symbolic columns using numbers, units and 'no-result' indicators.",
            "subjectDetection": "",
            "datatypeAnnotation": "",
            "typeAnnotation": "Assigns numeric/symbolic ontology types to columns by combining title similarity with units/ranges (numeric) and taxonomy term similarity (symbolic).",
            "predicateAnnotation": "Identifies n-ary relations from the ontology by combining table title similarity with recognised column types.",
            "nilAnnotation": "",
            "entityLinking": {
                "description": "",
                "candidateGeneration": "",
                "entityDisambiguation": ""
            }
        },
        "mainMethod": {
            "type": "unsupervised",
            "technique": "rule-based"
        },
        "revision": {
            "type": "fully automated",
            "description": "Fully automatic scoring with thresholds for column typing and relation selection; no manual post-editing is required."
        },
        "domain": {
            "domain": "dependent",
            "type": "food microbiology"
        },
        "validation": {
            "goldStandard": "60 tables (349 columns) from scientific publications in food microbiology; 16 relations annotated.",
            "metrics": [
                "Precision",
                "Recall",
                "F1"
            ]
        },
        "code": "",
        "license": "Not Specified",
        "inputs": {
            "typeOfTable": "Web tables",
            "tableSources": [
                "web",
                "scientific"
            ]
        },
        "kg": {
            "tripleStore": "Domain ontology for food microbiology (numeric/symbolic types and relations)",
            "index": ""
        },
        "output": "XML",
        "applicationPurpose": "Ontology-driven annotation of scientific web tables to integrate and query data in an XML warehouse.",
        "userInterfaceTool": "",
        "checkedByAuthor": false,
        "checkedByAi": true,
        "doi": "https://doi.org/10.1007/978-3-540-77010-7_4",
        "citations": [
            {
                "ref": "2005_buche_fuzzy",
                "title": "Fuzzy querying of incomplete, imprecise, and heterogeneously structured data in the relational model using ontologies and rules"
            },
            {
                "ref": "2004_zanibbi_a",
                "title": "A survey of table recognition: Models, observations, transformations, and inferences"
            },
            {
                "ref": "2004_pivk_from",
                "title": "From tables to frames"
            },
            {
                "ref": "2006_tenier_instantiation",
                "title": "Instantiation of relations for semantic annotation"
            },
            {
                "ref": "2002_embley_automatically",
                "title": "Automatically extracting ontologically specified data from html tables of unknown structure"
            },
            {
                "ref": "2000_freitag_boosted",
                "title": "Boosted wrapper induction"
            },
            {
                "ref": "2001_baumgartner_visual",
                "title": "Visual web information extraction with Lixto"
            },
            {
                "ref": "2005_gagliardi_an",
                "title": "An automatic ontology-based approach to enrich tables semantically"
            },
            {
                "ref": "1998_lin_an",
                "title": "An information-theoretic definition of similarity"
            },
            {
                "ref": "2006_hignette_fuzzy",
                "title": "Fuzzy semantic approach for data integration applied to risk in food: an example about the cold chain"
            },
            {
                "ref": "1979_vanrijsbergen_information",
                "title": "Information Retrieval, 2nd edition"
            },
            {
                "ref": "2002_yangarber_unsupervised",
                "title": "Unsupervised learning of generalized names"
            },
            {
                "ref": "1999_platt_fast",
                "title": "Fast training of support vector machines using sequential minimal optimization"
            },
            {
                "ref": "1965_zadeh_fuzzy",
                "title": "Fuzzy sets"
            }
        ],
        "uncertainFields": [
            {
                "field": "doi",
                "reason": "DOI is not stated in the paper text; external lookup would be required. "
            },
            {
                "field": "venue.acronym",
                "reason": "The publication appears in 'WISE 2007 Workshops (LNCS 4832)'; using 'WISE' may conflate workshop vs conference branding. "
            },
            {
                "field": "output",
                "reason": "XML is inferred from the stated goal of building an XML data warehouse; the annotation export format is not formally specified. "
            },
            {
                "field": "kg.tripleStore",
                "reason": "A domain ontology is used but no specific KG/triplestore name is given; represented generically. "
            }
        ]
    },
    {
        "id": "2009_cafarella_data",
        "added": "",
        "year": 2009,
        "firstAuthor": "Cafarella",
        "authors": [
            "Michael J. Cafarella",
            "Alon Halevy",
            "Nodira Khoussainova"
        ],
        "title": "Data Integration for the Relational Web",
        "venue": {
            "type": "conference",
            "acronym": "VLDB"
        },
        "nameOfApproach": "Octopus",
        "techniqueTags": [
            "clustering"
        ],
        "coreTasks": {
            "cta": false,
            "cpa": false,
            "cea": false,
            "cnea": false
        },
        "supportTasks": {
            "dataPreparation": {
                "description": "",
                "spellChecker": "",
                "unitsOfMeasurements": ""
            },
            "columnClassification": "",
            "subjectDetection": "",
            "datatypeAnnotation": "",
            "typeAnnotation": "",
            "predicateAnnotation": "",
            "nilAnnotation": "",
            "entityLinking": {
                "description": "",
                "candidateGeneration": "",
                "entityDisambiguation": ""
            }
        },
        "mainMethod": {
            "type": "unsupervised",
            "technique": "clustering"
        },
        "revision": {
            "type": "semi automated",
            "description": "System executes best-effort operators and lets the user review, correct errors, and adjust tables (e.g., select/union/split/rename) during integration."
        },
        "domain": {
            "domain": "independent",
            "type": "generic web data"
        },
        "validation": {
            "goldStandard": "52-query workload gathered via Amazon Mechanical Turk; relevance judged by two independent annotators",
            "metrics": [
                "Hits@k",
                "Top-k Accuracy"
            ]
        },
        "code": "",
        "license": "Not Specified",
        "inputs": {
            "typeOfTable": "HTML tables and HTML lists",
            "tableSources": [
                "web"
            ]
        },
        "kg": {
            "tripleStore": "",
            "index": ""
        },
        "output": "",
        "applicationPurpose": "Interactive creation and integration of structured Web data sources into new datasets.",
        "userInterfaceTool": "Web UI",
        "checkedByAuthor": false,
        "checkedByAi": true,
        "doi": "https://doi.org/10.14778/1687627.1687750",
        "citations": [
            {
                "ref": "2003_bernstein_applying",
                "title": "Applying Model Management to Classical Meta Data Problems"
            },
            {
                "ref": "1970_bloom_spacetime",
                "title": "Space/Time Trade-offs in Hash Coding with Allowable Errors"
            },
            {
                "ref": "2008_cafarella_uncovering",
                "title": "Uncovering the Relational Web"
            },
            {
                "ref": "2008_cafarella_webtables",
                "title": "WebTables: Exploring the Power of Tables on the Web"
            },
            {
                "ref": "1999_dasilva_a",
                "title": "A Local Maxima Method and a Fair Dispersion Normalization for Extracting Multi-Word Units from Corpora"
            },
            {
                "ref": "2007_derose_building",
                "title": "Building Structured Web Community Portals: A Top-Down, Compositional, and Incremental Approach"
            },
            {
                "ref": "2001_doan_reconciling",
                "title": "Reconciling Schemas of Disparate Data Sources: A Machine-Learning Approach"
            },
            {
                "ref": "2005_dong_reference",
                "title": "Reference Reconciliation in Complex Information Spaces"
            },
            {
                "ref": "2009_elmeleegy_harvesting",
                "title": "Harvesting Relational Tables from Lists on the Web"
            },
            {
                "ref": "2004_etzioni_web",
                "title": "Web-scale Information Extraction in KnowItAll: (Preliminary Results)"
            },
            {
                "ref": "1999_friedman_navigational",
                "title": "Navigational Plans for Data Integration"
            },
            {
                "ref": "2001_galhardas_declarative",
                "title": "Declarative Data Cleaning: Language, Model, and Algorithms"
            },
            {
                "ref": "2008_kok_extracting",
                "title": "Extracting Semantic Networks from Text Via Relational Clustering"
            },
            {
                "ref": "",
                "title": "Microsoft Popfly"
            },
            {
                "ref": "2001_rahm_a",
                "title": "A Survey of Approaches to Automatic Schema Matching"
            },
            {
                "ref": "2001_raman_potters",
                "title": "Potter’s Wheel: An Interactive Data Cleaning System"
            },
            {
                "ref": "2004_sarawagi_semi",
                "title": "Semi-Markov Conditional Random Fields for Information Extraction"
            },
            {
                "ref": "2007_tuchinda_building",
                "title": "Building Data Integration Queries by Demonstration"
            },
            {
                "ref": "2002_turney_mining",
                "title": "Mining the Web for Synonyms: PMI-IR versus LSA on TOEFL"
            },
            {
                "ref": "2007_wong_making",
                "title": "Making Mashups with Marmite: Towards End-User Programming for the Web"
            },
            {
                "ref": "",
                "title": "Yahoo Pipes"
            }
        ],
        "uncertainFields": [
            {
                "field": "doi",
                "reason": "A DOI is not visible in the provided PDF; one may exist in digital libraries."
            },
            {
                "field": "kg.tripleStore",
                "reason": "The system does not rely on a knowledge graph; no triple store is mentioned."
            },
            {
                "field": "output",
                "reason": "The paper does not specify a serialisation format for outputs (e.g., CSV, RDF)."
            },
            {
                "field": "validation.metrics",
                "reason": "Reported results are percentages of relevant tables in top-k; mapped to Hits@k/Top-k Accuracy."
            },
            {
                "field": "userInterfaceTool",
                "reason": "Screenshots suggest an interactive interface; the exact tool type/name is not formally specified."
            }
        ]
    },
    {
        "id": "2009_hignette_fuzzy",
        "added": "",
        "year": 2009,
        "firstAuthor": "Hignette",
        "authors": [
            "Gaëlle Hignette",
            "Patrice Buche",
            "Juliette Dibie-Barthélemy",
            "Ollivier Haemmerlé"
        ],
        "title": "Fuzzy Annotation of Web Data Tables Driven by a Domain Ontology",
        "venue": {
            "type": "conference",
            "acronym": "ESWC"
        },
        "nameOfApproach": "@Web",
        "techniqueTags": [
            "rule-based",
            "ontology-driven"
        ],
        "coreTasks": {
            "cta": true,
            "cpa": true,
            "cea": true,
            "cnea": false
        },
        "supportTasks": {
            "dataPreparation": {
                "description": "Tables are extracted from the Web, stored in a common XML model, and lemmatised/normalised; numeric vs symbolic columns are segregated and units detected before annotation.",
                "spellChecker": "",
                "unitsOfMeasurements": "Ontology defines allowed units and numeric ranges (e.g., °C/°F for Temperature) used to filter and score numeric columns."
            },
            "columnClassification": "Distinguishes numeric vs symbolic columns using ontology units; classifies symbolic columns to ontology symbolic types via cosine similarity over titles and cell contents.",
            "subjectDetection": "",
            "datatypeAnnotation": "Assigns numeric columns to ontology numeric types using units and value-range constraints; builds fuzzy sets (e.g., intervals, mean±SE).",
            "typeAnnotation": "Assigns symbolic columns to ontology symbolic types by combining title/content similarity and taxonomy matches.",
            "predicateAnnotation": "Recognises relations by comparing the table's typed-column signature to n-ary relation signatures in the ontology and combining with title similarity.",
            "nilAnnotation": "",
            "entityLinking": {
                "description": "Links cells to ontology taxonomy terms using cosine similarity and proportional-advantage thresholds; keeps fuzzy membership over multiple candidates.",
                "candidateGeneration": "Lookup against all terms in the relevant type's taxonomy derived from the ontology.",
                "entityDisambiguation": "Selects best type per cell if advantage over second-best exceeds a threshold; retains a fuzzy set of candidates with membership scores."
            }
        },
        "mainMethod": {
            "type": "unsupervised",
            "technique": "rule-based"
        },
        "revision": {
            "type": "fully automated",
            "description": "Annotation pipeline runs automatically; fuzzy memberships enable optional later human validation without changing the core outputs."
        },
        "domain": {
            "domain": "dependent",
            "type": "food microbiology; chemical risk in food; aeronautics"
        },
        "validation": {
            "goldStandard": "Manually annotated scientific tables (e.g., 60 tables with 123 relations; additional corpora and column-level evaluations).",
            "metrics": [
                "Precision",
                "Recall"
            ]
        },
        "code": "",
        "license": "Not Specified",
        "inputs": {
            "typeOfTable": "Web tables",
            "tableSources": [
                "web",
                "pdf",
                "scientific"
            ]
        },
        "kg": {
            "tripleStore": "",
            "index": ""
        },
        "output": "RDF",
        "applicationPurpose": "Data enrichment and integration into the MIEL querying ecosystem.",
        "userInterfaceTool": "@Web",
        "checkedByAuthor": false,
        "checkedByAi": true,
        "doi": "https://doi.org/10.1007/978-3-642-02121-3_47",
        "citations": [
            {
                "ref": "2001_rahm_a",
                "title": "A survey of approaches to automatic schema matching"
            },
            {
                "ref": "2008_buche_flexible",
                "title": "Flexible querying of fuzzy rdf annotations using fuzzy conceptual graphs"
            },
            {
                "ref": "2003_doan_learning",
                "title": "Learning to match the schemas of data sources: A multistrategy approach"
            },
            {
                "ref": "2007_liu_tableseer",
                "title": "Tableseer: automatic table metadata extraction and searching in digital libraries"
            },
            {
                "ref": "2008_cafarella_uncovering",
                "title": "Uncovering the relational web"
            },
            {
                "ref": "2008_cafarella_webtables",
                "title": "Webtables: exploring the power of tables on the web"
            },
            {
                "ref": "2004_pivk_from",
                "title": "From tables to frames"
            },
            {
                "ref": "2006_tenier_instantiation",
                "title": "Instantiation of relations for semantic annotation"
            },
            {
                "ref": "2002_embley_automatically",
                "title": "Automatically extracting ontologically specified data from HTML tables of unknown structure"
            },
            {
                "ref": "2006_noy_defining",
                "title": "Defining n-ary relations on the semantic web"
            },
            {
                "ref": "2007_hignette_an",
                "title": "An ontology-driven annotation of data tables"
            },
            {
                "ref": "1979_vanrijsbergen_information",
                "title": "Information Retrieval (2nd ed.)"
            },
            {
                "ref": "1999_platt_fast",
                "title": "Fast training of support vector machines using sequential minimal optimization"
            },
            {
                "ref": "2005_gagliardi_an",
                "title": "An automatic ontology-based approach to enrich tables semantically"
            },
            {
                "ref": "1965_zadeh_fuzzy",
                "title": "Fuzzy sets"
            },
            {
                "ref": "1978_zadeh_fuzzy",
                "title": "Fuzzy sets as a basis for a theory of possibility"
            },
            {
                "ref": "1997_dubois_the",
                "title": "The three semantics of fuzzy sets"
            },
            {
                "ref": "2004_cliver_foodborne",
                "title": "Foodborne infections and intoxications"
            }
        ],
        "uncertainFields": [
            {
                "field": "nameOfApproach",
                "reason": "The annotation component is implemented within the @Web software, while MIEL is the querying system; the paper does not brand the annotator separately."
            },
            {
                "field": "coreTasks.cea",
                "reason": "Cell-level linking is to ontology taxonomy terms rather than to a public KG; mapping to CEA is inferred from description rather than explicit task naming."
            },
            {
                "field": "inputs.tableSources[1]",
                "reason": "Tables are said to come from publications and the Web; PDFs are likely but not always explicitly stated for every corpus."
            },
            {
                "field": "kg.tripleStore",
                "reason": "An OWL domain ontology is used, but no specific triple store or public KG (e.g., DBpedia) is named."
            },
            {
                "field": "userInterfaceTool",
                "reason": "@Web is a software platform; the existence of a dedicated end-user GUI for annotation is implied but not detailed."
            },
            {
                "field": "doi",
                "reason": "The DOI is not provided in the paper text available; leaving it empty to avoid inventing information."
            }
        ]
    },
    {
        "id": "2009_tao_automatic",
        "added": "",
        "year": 2009,
        "firstAuthor": "Tao",
        "authors": [
            "Cui Tao",
            "David W. Embley"
        ],
        "title": "Automatic hidden-web table interpretation, conceptualization, and semantic annotation",
        "venue": {
            "type": "journal",
            "acronym": "DKE"
        },
        "nameOfApproach": "TISP++ (built on TISP)",
        "techniqueTags": [
            "rule-based",
            "ontology-driven"
        ],
        "coreTasks": {
            "cta": false,
            "cpa": false,
            "cea": false,
            "cnea": false
        },
        "supportTasks": {
            "dataPreparation": {
                "description": "Parses HTML, unnests nested tables, filters layout tables, and derives structure patterns via sibling-page comparison. ",
                "spellChecker": "",
                "unitsOfMeasurements": ""
            },
            "columnClassification": "",
            "subjectDetection": "",
            "datatypeAnnotation": "Generates OWL datatype properties for labels and records and annotates values accordingly. ",
            "typeAnnotation": "",
            "predicateAnnotation": "",
            "nilAnnotation": "",
            "entityLinking": {
                "description": "",
                "candidateGeneration": "",
                "entityDisambiguation": ""
            }
        },
        "mainMethod": {
            "type": "unsupervised",
            "technique": "rule-based"
        },
        "revision": {
            "type": "fully automated",
            "description": "Fully automatic pipeline with dynamic pattern adjustment when encountering structural variations; no user-in-the-loop. "
        },
        "domain": {
            "domain": "independent",
            "type": "generic"
        },
        "validation": {
            "goldStandard": "Evaluated on >2000 tables from 275 sibling pages across 35 websites (car ads, molecular biology, geopolitical); overall F-measure for interpretation 94.5%. ",
            "metrics": [
                "Precision",
                "Recall",
                "F1"
            ]
        },
        "code": "",
        "license": "Not Specified",
        "inputs": {
            "typeOfTable": "HTML tables",
            "tableSources": [
                "web",
                "scientific",
                "gov-open-data"
            ]
        },
        "kg": {
            "tripleStore": "Generated OWL ontology queried via a SPARQL-capable store (implemented with Jena). ",
            "index": ""
        },
        "output": "RDF",
        "applicationPurpose": "Make hidden-web table data interpretable, semantically annotated, and queriable via standard SPARQL engines. ",
        "userInterfaceTool": "SPARQL query interface with source-page value highlighting",
        "checkedByAuthor": false,
        "checkedByAi": true,
        "doi": "https://doi.org/10.1016/j.datak.2009.02.010",
        "citations": [
            {
                "ref": "2003_arasu_extracting",
                "title": "Extracting structured data from web pages"
            },
            {
                "ref": "crescenz i2001roadrunner",
                "title": "RoadRunner: towards automatic data extraction from large web sites"
            },
            {
                "ref": "2005_zhai_web",
                "title": "Web data extraction based on partial tree alignment"
            },
            {
                "ref": "1979_tai_the",
                "title": "The tree-to-tree correction problem"
            },
            {
                "ref": "1991_yang_identifying",
                "title": "Identifying syntactic differences between two programs"
            },
            {
                "ref": "1996_wang_tabular",
                "title": "Tabular Abstraction, Editing, and Formatting"
            },
            {
                "ref": "2007_gatterbauer_towards",
                "title": "Towards domain-independent information extraction from web tables"
            },
            {
                "ref": "2002_cohen_a",
                "title": "A flexible learning system for wrapping tables and lists in HTML documents"
            },
            {
                "ref": "2004_lerman_using",
                "title": "Using the structure of web sites for automatic segmentation of tables"
            },
            {
                "ref": "2004_tengli_learning",
                "title": "Learning table extraction from examples"
            },
            {
                "ref": "2004_pivk_from",
                "title": "From tables to frames"
            },
            {
                "ref": "2006_embley_table",
                "title": "Table processing paradigms: a research survey"
            },
            {
                "ref": "2002_embley_automatically",
                "title": "Automatically extracting ontologically specified data from HTML tables with unknown structure"
            },
            {
                "ref": "2005_embley_automating",
                "title": "Automating the extraction of data from HTML tables with unknown structure"
            },
            {
                "ref": "2000_chen_mining",
                "title": "Mining tables from large scale HTML texts"
            },
            {
                "ref": "2006_gatterbauer_table",
                "title": "Table extraction using spatial reasoning on the CSS2 visual box model"
            }
        ],
        "uncertainFields": [
            {
                "field": "nameOfApproach",
                "reason": "Paper introduces both TISP and its extension TISP++; opted to name TISP++ as the approach encompassing ontology and annotation."
            },
            {
                "field": "techniqueTags",
                "reason": "No ML models (SVM/CRF/transformer) are used; classification as rule-based/ontology-driven inferred from pattern rules and OWL generation."
            },
            {
                "field": "coreTasks.cta",
                "reason": "CTA as later formalised is not explicitly targeted; interpretation/annotation are ontology-specific rather than KG class prediction."
            },
            {
                "field": "coreTasks.cpa",
                "reason": "Relationships are represented in the generated ontology but not framed as CPA over an external KG."
            },
            {
                "field": "coreTasks.cea",
                "reason": "Annotations link to a generated ontology rather than disambiguating against a public KG; mapping to CEA is unclear."
            },
            {
                "field": "kg.tripleStore",
                "reason": "They use Jena to output OWL and query via SPARQL, but no specific triple store (e.g., Virtuoso) is named."
            },
            {
                "field": "userInterfaceTool",
                "reason": "A query UI with highlighting is described but not formally named."
            },
            {
                "field": "inputs.tableSources[1]",
                "reason": "‘scientific’ added based on WormBase/NCBI examples; not enumerated explicitly as a source type by the authors."
            },
            {
                "field": "inputs.tableSources[2]",
                "reason": "‘gov-open-data’ added based on CIA Factbook/USGS examples; inferred rather than explicitly categorised."
            },
            {
                "field": "venue.acronym",
                "reason": "Acronym ‘DKE’ assumed for Data & Knowledge Engineering; not explicitly printed as an acronym in the paper."
            }
        ]
    },
    {
        "id": "2010_limaye_annotating",
        "added": "",
        "year": 2010,
        "firstAuthor": "Limaye",
        "authors": [
            "Girija Limaye",
            "Sunita Sarawagi",
            "Soumen Chakrabarti"
        ],
        "title": "Annotating and Searching Web Tables Using Entities, Types and Relationships",
        "venue": {
            "type": "journal",
            "acronym": "PVLDB"
        },
        "nameOfApproach": "",
        "techniqueTags": [
            "SVM",
            "ontology-driven"
        ],
        "coreTasks": {
            "cta": true,
            "cpa": true,
            "cea": true,
            "cnea": false
        },
        "supportTasks": {
            "dataPreparation": {
                "description": "Screen out formatting tables, capture table context and headers, and build text/lemma indices to propose candidates.",
                "spellChecker": "",
                "unitsOfMeasurements": ""
            },
            "columnClassification": "",
            "subjectDetection": "",
            "datatypeAnnotation": "",
            "typeAnnotation": "Assign KG types to columns using features over headers and collective signals.",
            "predicateAnnotation": "Assign KG relations to column pairs using compatibility between types and entity pairs.",
            "nilAnnotation": "",
            "entityLinking": {
                "description": "Link cells to KG entities using candidate lookup and collective disambiguation.",
                "candidateGeneration": "Retrieve candidates via text similarity between cell strings and entity lemmas using a text index.",
                "entityDisambiguation": "Joint probabilistic graphical model with message passing over entities, types, and relations."
            }
        },
        "mainMethod": {
            "type": "supervised",
            "technique": "SVM",
            "supervision": {
                "type": "supervised"
            }
        },
        "revision": {
            "type": "fully automated",
            "description": "Annotations are produced automatically by the trained model without manual post-editing."
        },
        "domain": {
            "domain": "independent",
            "type": "generic"
        },
        "validation": {
            "goldStandard": "Manual labels for Wiki Manual (36 tables), Web Manual (371 tables) and Web Relations; Wiki Link with 131k linked cells; catalog-derived ground truth from YAGO/DBpedia.",
            "metrics": [
                "Accuracy",
                "F1",
                "MAP"
            ]
        },
        "code": "",
        "license": "Not Specified",
        "inputs": {
            "typeOfTable": "Web tables",
            "tableSources": [
                "web",
                "wiki"
            ]
        },
        "kg": {
            "tripleStore": "YAGO; DBpedia",
            "index": "Lemma/text index (Lucene) for candidate retrieval"
        },
        "output": "",
        "applicationPurpose": "Relational Web search over annotated tables (select-project/join queries).",
        "userInterfaceTool": "Prototype relational Web search tool",
        "checkedByAuthor": false,
        "checkedByAi": true,
        "doi": "https://doi.org/10.14778/1920841.1921005",
        "citations": [
            {
                "ref": "2008_cafarella_webtables",
                "title": "WebTables: exploring the power of tables on the Web"
            },
            {
                "ref": "2008_cafarella_uncovering",
                "title": "Uncovering the relational Web"
            },
            {
                "ref": "2007_suchanek_yago",
                "title": "YAGO: A core of semantic knowledge unifying WordNet and Wikipedia"
            },
            {
                "ref": "2007_cucerzan_large",
                "title": "Large-scale named entity disambiguation based on Wikipedia data"
            },
            {
                "ref": "2008_milne_learning",
                "title": "Learning to link with Wikipedia"
            },
            {
                "ref": "2009_kulkarni_collective",
                "title": "Collective annotation of Wikipedia entities in Web text"
            },
            {
                "ref": "2009_gupta_answering",
                "title": "Answering table augmentation queries from unstructured lists on the Web"
            },
            {
                "ref": "2009_singh_curating",
                "title": "Curating and searching the annotated web"
            },
            {
                "ref": "2009_koller_probabilistic",
                "title": "Probabilistic Graphical Models: Principles and Techniques"
            },
            {
                "ref": "1983_salton_introduction",
                "title": "Introduction to Modern Information Retrieval"
            },
            {
                "ref": "2008_sarawagi_information",
                "title": "Information extraction"
            },
            {
                "ref": "2005_tsochantaridis_large",
                "title": "Large margin methods for structured and interdependent output variables"
            },
            {
                "ref": "2003_dill_semtag",
                "title": "SemTag and Seeker: Bootstrapping the semantic Web via automated semantic annotation"
            }
        ],
        "uncertainFields": [
            {
                "field": "venue.type",
                "reason": "The article appears in PVLDB (a journal) but is also presented at VLDB 2010; some bibliographies list it as a conference paper."
            },
            {
                "field": "venue.acronym",
                "reason": "Could be recorded as VLDB(conference) or PVLDB (journal); chosen PVLDB."
            },
            {
                "field": "kg.tripleStore",
                "reason": "Paper uses YAGO as the main catalog and also leverages DBpedia/Wikipedia; field expects a single store name."
            },
            {
                "field": "userInterfaceTool",
                "reason": "A prototype relational Web search tool is described but not formally named."
            },
            {
                "field": "output",
                "reason": "No explicit export format (e.g., RDF/CSV) is specified; outputs are annotations used for search."
            },
            {
                "field": "techniqueTags[1]",
                "reason": "Marked as ontology-driven because it leverages a catalog (YAGO/DBpedia); the paper does not explicitly use this label."
            },
            {
                "field": "inputs.tableSources[1]",
                "reason": "Wikipedia tables are used for training/evaluation; treating this as a separate source (wiki) may be seen as a subset of web."
            },
            {
                "field": "applicationPurpose",
                "reason": "Summarised from the search application section; phrasing may vary."
            }
        ]
    },
    {
        "id": "2010_mulwad_t2ld",
        "added": "",
        "year": 2010,
        "firstAuthor": "Mulwad",
        "authors": [
            "Varish Mulwad",
            "Tim Finin",
            "Zareen Syed",
            "Anupam Joshi"
        ],
        "title": "T2LD: Interpreting and Representing Tables as Linked Data?",
        "venue": {
            "type": "conference",
            "acronym": "ISWC"
        },
        "nameOfApproach": "T2LD",
        "techniqueTags": [
            "SVM",
            "ontology-driven"
        ],
        "coreTasks": {
            "cta": true,
            "cpa": true,
            "cea": true,
            "cnea": true
        },
        "supportTasks": {
            "dataPreparation": {
                "description": "Queries KBs with headers and cell strings and computes ranking features (e.g., PageRank, page length, and string similarities). Basic normalisation of strings is implied by lookup and feature computation.",
                "spellChecker": "",
                "unitsOfMeasurements": ""
            },
            "columnClassification": "Assigns a KG class label to each column via KB queries and scoring.",
            "subjectDetection": "",
            "datatypeAnnotation": "",
            "typeAnnotation": "Predicts KG class labels for columns (CTA) using DBpedia/Freebase/WordNet/YAGO evidence.",
            "predicateAnnotation": "Selects relations between column pairs from KB-derived candidates using a scoring procedure.",
            "nilAnnotation": "Flags cells as NIL/new entities when confidence is low, enabling discovery of entities absent from the KG.",
            "entityLinking": {
                "description": "Links cell strings to KG entities using a two-stage SVM pipeline.",
                "candidateGeneration": "Retrieves top-N entity candidates from KB lookups using header/context-enhanced queries.",
                "entityDisambiguation": "Ranks candidates with SVM-Rank using KB score, page length, PageRank, Levenshtein and Dice; a second SVM accepts/rejects based on rank score and margin."
            }
        },
        "mainMethod": {
            "type": "supervised",
            "technique": "SVM",
            "supervision": {
                "type": "supervised"
            }
        },
        "revision": {
            "type": "fully automated",
            "description": "Annotations are produced automatically; human judgements are used only for offline evaluation."
        },
        "domain": {
            "domain": "independent",
            "type": "generic"
        },
        "validation": {
            "goldStandard": "15 tables (52 columns, 611 entities) from Google Squared, Wikipedia and the Web; 23 columns used for relation evaluation.",
            "metrics": [
                "MAP",
                "Recall",
                "Accuracy"
            ]
        },
        "code": "",
        "license": "Not Specified",
        "inputs": {
            "typeOfTable": "HTML tables",
            "tableSources": [
                "web",
                "wiki"
            ]
        },
        "kg": {
            "tripleStore": "DBpedia",
            "index": ""
        },
        "output": "RDF (N3)",
        "applicationPurpose": "Generate linked data from tables and enrich/extend KGs.",
        "userInterfaceTool": "",
        "checkedByAuthor": false,
        "checkedByAi": true,
        "doi": "",
        "citations": [
            {
                "ref": "2010_finin_creating",
                "title": "Creating and Exploiting a Web of Semantic Data"
            },
            {
                "ref": "2008_cafarella_webtables",
                "title": "Webtables: exploring the power of tables on the web"
            },
            {
                "ref": "2010_mulwad_t2ld",
                "title": "T2LD - An automatic framework for extracting, interpreting and representing tables as Linked Data"
            },
            {
                "ref": "2009_sahoo_a",
                "title": "A survey of current approaches for mapping of relational databases to rdf"
            },
            {
                "ref": "2008_han_rdf123",
                "title": "RDF123: from Spreadsheets to RDF"
            },
            {
                "ref": "2010_syed_exploiting",
                "title": "Exploiting a Web of Semantic Data for Interpreting Tables"
            },
            {
                "ref": "2010_mulwad_using",
                "title": "Using linked data to interpret tables"
            }
        ],
        "uncertainFields": [
            {
                "field": "venue.acronym",
                "reason": "The paper appears in the ISWC 2010 Posters/Demos track; using 'ISWC' may omit the track specificity."
            },
            {
                "field": "doi",
                "reason": "No DOI is visible; CEUR-WS poster/demo papers often lack DOIs."
            },
            {
                "field": "kg.tripleStore",
                "reason": "DBpedia is used, but additional KBs (e.g., Wikitology, Freebase, YAGO) support typing; the primary store is not explicitly singled out."
            },
            {
                "field": "inputs.typeOfTable",
                "reason": "Evaluation uses web/Wikipedia tables; broader claims reference spreadsheets and databases, which may not be in-scope for the prototype."
            },
            {
                "field": "supportTasks.columnClassification",
                "reason": "The method assigns KG class labels to columns; it is unclear whether it also performs NE vs literal column detection as a separate step."
            },
            {
                "field": "userInterfaceTool",
                "reason": "A prototype is mentioned but no explicit UI or CLI is described."
            },
            {
                "field": "validation.goldStandard",
                "reason": "The evaluation uses a small curated set of tables rather than a named public gold standard."
            }
        ]
    },
    {
        "id": "2010_syed_exploiting",
        "added": "",
        "year": 2010,
        "firstAuthor": "Syed",
        "authors": [
            "Zareen Syed",
            "Tim Finin",
            "Varish Mulwad",
            "Anupam Joshi"
        ],
        "title": "Exploiting a Web of Semantic Data for Interpreting Tables",
        "venue": {
            "type": "conference",
            "acronym": "WebSci"
        },
        "nameOfApproach": "Wikitology",
        "techniqueTags": [
            "ontology-driven"
        ],
        "coreTasks": {
            "cta": true,
            "cpa": true,
            "cea": true,
            "cnea": false
        },
        "supportTasks": {
            "dataPreparation": {
                "description": "",
                "spellChecker": "",
                "unitsOfMeasurements": ""
            },
            "columnClassification": "",
            "subjectDetection": "",
            "datatypeAnnotation": "",
            "typeAnnotation": "Predicts column classes by voting over types returned from Wikitology/DBpedia using headers and cell values.",
            "predicateAnnotation": "Enumerates DBpedia relations between linked entity pairs across columns and selects the most frequent relation.",
            "nilAnnotation": "",
            "entityLinking": {
                "description": "Generates top-N candidates from Wikitology for each cell and re-ranks using predicted types.",
                "candidateGeneration": "Queries Wikitology IR index fields (title, redirects, firstSentence, linkedConcepts, propertiesValues) to retrieve candidates.",
                "entityDisambiguation": "Constrains candidates by predicted types and selects the highest-scoring match."
            }
        },
        "mainMethod": {
            "type": "unsupervised",
            "technique": "ontology-driven"
        },
        "revision": {
            "type": "fully automated",
            "description": "Prototype runs automatically without human-in-the-loop validation."
        },
        "domain": {
            "domain": "independent",
            "type": ""
        },
        "validation": {
            "goldStandard": "5 tables from Google Squared",
            "metrics": [
                "Accuracy"
            ]
        },
        "code": "",
        "license": "Not Specified",
        "inputs": {
            "typeOfTable": "Web tables",
            "tableSources": [
                "web"
            ]
        },
        "kg": {
            "tripleStore": "DBpedia; Wikitology",
            "index": "Wikitology IR index over Wikipedia/DBpedia (title, redirects, firstSentence, types, linkedConcepts, propertiesValues)"
        },
        "output": "RDF",
        "applicationPurpose": "Interpret web tables and export them as linked data.",
        "userInterfaceTool": "",
        "checkedByAuthor": false,
        "checkedByAi": true,
        "doi": "https://doi.org/10.1145/1935826.1935904",
        "citations": [],
        "uncertainFields": [
            {
                "field": "venue.acronym",
                "reason": "Acronym is not explicitly printed in the PDF; assumed to be WebSci for the Web Science Conference."
            },
            {
                "field": "doi",
                "reason": "No DOI is shown in the paper; left empty as it may not exist for this venue/year."
            },
            {
                "field": "kg.tripleStore",
                "reason": "Paper uses Wikitology (hybrid KB) and queries DBpedia relations; listing both may conflate KB and triple store."
            },
            {
                "field": "supportTasks.typeAnnotation",
                "reason": "They predict classes for columns, which aligns with CTA; exact procedure naming may differ from later STI task taxonomies."
            },
            {
                "field": "supportTasks.predicateAnnotation",
                "reason": "Relation selection is described heuristically; mapping it directly to CPA may oversimplify their approach."
            },
            {
                "field": "revision.type",
                "reason": "No explicit statement about user-in-the-loop post-processing; assumed fully automated based on prototype description."
            }
        ]
    },
    {
        "id": "2011_crestan_web-scale",
        "added": "",
        "year": 2011,
        "firstAuthor": "Crestan",
        "authors": [
            "Eric Crestan",
            "Patrick Pantel"
        ],
        "title": "Web-Scale Table Census and Classification",
        "venue": {
            "type": "conference",
            "acronym": "WSDM"
        },
        "nameOfApproach": "TabEx",
        "techniqueTags": [],
        "coreTasks": {
            "cta": false,
            "cpa": false,
            "cea": false,
            "cnea": false
        },
        "supportTasks": {
            "dataPreparation": {
                "description": "",
                "spellChecker": "",
                "unitsOfMeasurements": ""
            },
            "columnClassification": "",
            "subjectDetection": "",
            "datatypeAnnotation": "",
            "typeAnnotation": "",
            "predicateAnnotation": "",
            "nilAnnotation": "",
            "entityLinking": {
                "description": "",
                "candidateGeneration": "",
                "entityDisambiguation": ""
            }
        },
        "mainMethod": {
            "type": "supervised",
            "technique": "Gradient Boosted Decision Trees (GBDT)",
            "supervision": {
                "type": "supervised"
            }
        },
        "revision": {
            "type": "fully automated",
            "description": "Classification is fully automatic with evaluation on manually annotated samples; no user post-editing described."
        },
        "domain": {
            "domain": "independent",
            "type": ""
        },
        "validation": {
            "goldStandard": "Manually annotated random samples of web tables (e.g., 5,000 tables) used as gold data.",
            "metrics": [
                "Accuracy",
                "Precision",
                "Recall",
                "F1"
            ]
        },
        "code": "",
        "license": "Not Specified",
        "inputs": {
            "typeOfTable": "HTML tables",
            "tableSources": [
                "web"
            ]
        },
        "output": "",
        "applicationPurpose": "Classify HTML tables by type to support knowledge extraction.",
        "userInterfaceTool": "",
        "checkedByAuthor": false,
        "checkedByAi": true,
        "doi": "",
        "citations": [
            {
                "ref": "2008_cafarella_webtables",
                "title": "WebTables: Exploring the Power of Tables on the Web"
            },
            {
                "ref": "2008_cafarella_uncovering",
                "title": "Uncovering the Relational Web"
            },
            {
                "ref": "2009_chang_towards",
                "title": "Towards intent-driven bidterm suggestion"
            },
            {
                "ref": "2000_chen_mining",
                "title": "Mining Tables from Large-Scale HTML Texts"
            },
            {
                "ref": "2009_elmeleegy_harvesting",
                "title": "Harvesting Relational Tables from Lists on the Web"
            },
            {
                "ref": "2006_gazen_overview",
                "title": "Overview of Autofeed: An Unsupervised Learning System for Generating Webfeeds"
            },
            {
                "ref": "2008_huanhuan_context",
                "title": "Context-aware query suggestion by mining click-through and session data"
            },
            {
                "ref": "2001_friedman_greedy",
                "title": "Greedy function approximation: A gradient boosting machine"
            },
            {
                "ref": "2006_friedman_recent",
                "title": "Recent advances in predictive (machine) learning"
            },
            {
                "ref": "2007_gatterbauer_towards",
                "title": "Towards Domain-Independent Information Extraction from Web Tables"
            },
            {
                "ref": "2003_lin_identifying",
                "title": "Identifying Synonyms among Distributionally Similar Words"
            },
            {
                "ref": "2001_penn_flexible",
                "title": "Flexible Web Document Analysis for Delivery to Narrow-Bandwidth Devices"
            },
            {
                "ref": "2002_wang_a",
                "title": "A Machine Learning Based Approach for Table Detection on the Web"
            },
            {
                "ref": "2001_yoshida_a",
                "title": "A Method to Integrate Tables of the World Wide Web"
            }
        ],
        "uncertainFields": [
            {
                "field": "techniqueTags",
                "reason": "The approach uses GBDT, which is not among the allowed tags; therefore the list is left empty."
            },
            {
                "field": "output",
                "reason": "The paper does not specify any output serialisation format for results."
            },
            {
                "field": "userInterfaceTool",
                "reason": "No user interface or tool is described."
            },
            {
                "field": "code",
                "reason": "No code repository or download link is provided."
            },
            {
                "field": "domain.type",
                "reason": "The method is domain-independent; per schema this may be empty."
            },
            {
                "field": "validation.goldStandard",
                "reason": "They use manually annotated samples but no named gold standard; the description summarises this."
            },
            {
                "field": "doi",
                "reason": "The DOI is not stated in the provided text; left empty to avoid invention."
            },
            {
                "field": "citations[6].ref",
                "reason": "First author appears as \"Huanhuan, J. H.\" in the reference text, which may reflect formatting/ordering issues."
            }
        ]
    },
    {
        "id": "2011_mulwad_automatically",
        "added": "",
        "year": 2011,
        "firstAuthor": "Mulwad",
        "authors": [
            "Varish Mulwad",
            "Tim Finin",
            "Anupam Joshi"
        ],
        "title": "Automatically Generating Government Linked Data from Tables",
        "venue": {
            "type": "conference",
            "acronym": "AAAI"
        },
        "nameOfApproach": "",
        "techniqueTags": [
            "SVM",
            "ontology-driven"
        ],
        "coreTasks": {
            "cta": true,
            "cpa": true,
            "cea": true,
            "cnea": true
        },
        "supportTasks": {
            "dataPreparation": {
                "description": "Discusses using captions/surrounding text and handling literals as additional evidence; details are limited.",
                "spellChecker": "",
                "unitsOfMeasurements": "Mentions extracting/using units information from captions or surrounding text."
            },
            "columnClassification": "",
            "subjectDetection": "",
            "datatypeAnnotation": "Maps literal columns (e.g., FIPS codes) to properties associated with related entities.",
            "typeAnnotation": "Maps column headers to ontology classes (e.g., DBpedia/Freebase/WordNet/YAGO).",
            "predicateAnnotation": "Discovers relations between columns via majority voting over relations observed in DBpedia.",
            "nilAnnotation": "Identifies cells that refer to entities not in the KB (NIL/new entities).",
            "entityLinking": {
                "description": "Two-stage linking: candidate retrieval from Wikitology, then SVM-based ranking and decision to link or mark as new.",
                "candidateGeneration": "Wikitology queries return top-N candidate entities per cell.",
                "entityDisambiguation": "SVM-Rank with features (KB score, page length, PageRank, Levenshtein, Dice), followed by an SVM classifier to accept/reject the top candidate."
            }
        },
        "mainMethod": {
            "type": "supervised",
            "technique": "SVM",
            "supervision": {
                "type": "supervised"
            }
        },
        "revision": {
            "type": "fully automated",
            "description": "Automatic pipeline; a human-in-the-loop is proposed as a potential enhancement but not required."
        },
        "domain": {
            "domain": "dependent",
            "type": "open government data"
        },
        "validation": {
            "goldStandard": "15 tables from Google Squared, Wikipedia and the Web; examples from data.gov dataset 1425",
            "metrics": [
                "MAP",
                "Recall",
                "Accuracy"
            ]
        },
        "code": "",
        "license": "Not Specified",
        "inputs": {
            "typeOfTable": "Web tables",
            "tableSources": [
                "gov-open-data",
                "web",
                "wiki"
            ]
        },
        "kg": {
            "tripleStore": "DBpedia",
            "index": "Wikitology"
        },
        "output": "RDF",
        "applicationPurpose": "Generate high-quality Linked Data from tabular open government datasets.",
        "userInterfaceTool": "",
        "checkedByAuthor": false,
        "checkedByAi": true,
        "doi": "",
        "citations": [
            {
                "ref": "2009_bizer_dbpedia",
                "title": "Dbpedia - a crystallization point for the web of data"
            },
            {
                "ref": "2009_bizer_the",
                "title": "The emerging web of linked data"
            },
            {
                "ref": "2004_brickley_rdf",
                "title": "RDF Vocabulary Description Language 1.0: RDF Schema"
            },
            {
                "ref": "2008_cafarella_webtables",
                "title": "WebTables: exploring the power of tables on the web"
            },
            {
                "ref": "",
                "title": "Dataset 1425 - Census of Agriculture Race, Ethnicity and Gender Profile Data"
            },
            {
                "ref": "2010_ding_twc",
                "title": "TWC Data-Gov Corpus: incrementally generating linked government data from data.gov"
            },
            {
                "ref": "2008_han_rdf123",
                "title": "RDF123: from Spreadsheets to RDF"
            },
            {
                "ref": "2009_koller_probabilistic",
                "title": "Probabilistic Graphical Models: Principles and Techniques"
            },
            {
                "ref": "2009_langegger_xlwrap",
                "title": "XLWrap - querying and integrating arbitrary spreadsheets with SPARQL"
            },
            {
                "ref": "2010_limaye_annotating",
                "title": "Annotating and searching web tables using entities, types and relationships"
            },
            {
                "ref": "2010_mulwad_t2ld",
                "title": "T2LD: Interpreting and Representing Tables as Linked Data"
            },
            {
                "ref": "2010_mulwad_using",
                "title": "Using linked data to interpret tables"
            },
            {
                "ref": "1996_sackett_evidence",
                "title": "Evidence based medicine: what it is and what it isn't"
            },
            {
                "ref": "2009_sahoo_a",
                "title": "A survey of current approaches for mapping of relational databases to RDF"
            },
            {
                "ref": "2011_syed_creating",
                "title": "Creating and Exploiting a Hybrid Knowledge Base for Linked Data"
            },
            {
                "ref": "2010_syed_exploiting",
                "title": "Exploiting a Web of Semantic Data for Interpreting Tables"
            },
            {
                "ref": "2011_venetis_recovering",
                "title": "Recovering semantics of tables on the web"
            },
            {
                "ref": "2011_wang_understanding",
                "title": "Understanding tables on the web"
            },
            {
                "ref": "2011_wu_towards",
                "title": "Towards a probabilistic taxonomy of many concepts"
            }
        ],
        "uncertainFields": [
            {
                "field": "venue.acronym",
                "reason": "PDF credits AAAI but does not state a specific venue edition; 'AAAI' acronym assumed."
            },
            {
                "field": "domain.domain",
                "reason": "Work is motivated by open government data but also evaluated on generic Web/Wikipedia tables; could be independent."
            },
            {
                "field": "supportTasks.datatypeAnnotation",
                "reason": "Paper maps literal columns to properties; explicit datatype typing (e.g., XSD) is not fully specified."
            },
            {
                "field": "inputs.tableSources",
                "reason": "Sources selected from examples in the text; exact evaluation mix may vary."
            },
            {
                "field": "nameOfApproach",
                "reason": "Related work references T2LD, but this paper does not clearly name the presented system."
            },
            {
                "field": "kg.index",
                "reason": "Wikitology is used for candidate generation; treated here as the indexing layer."
            },
            {
                "field": "validation.goldStandard",
                "reason": "Evaluation uses a small custom set of tables rather than a named gold standard."
            },
            {
                "field": "doi",
                "reason": "No DOI is provided in the paper/PDF."
            }
        ]
    },
    {
        "id": "2011_venetis_recovering",
        "added": "",
        "year": 2011,
        "firstAuthor": "Venetis",
        "authors": [
            "Petros Venetis",
            "Alon Halevy",
            "Jayant Madhavan",
            "Marius Paşca",
            "Warren Shen",
            "Fei Wu",
            "Gengxin Miao",
            "Chung Wu"
        ],
        "title": "Recovering Semantics of Tables on the Web",
        "venue": {
            "type": "journal",
            "acronym": "PVLDB"
        },
        "nameOfApproach": "",
        "techniqueTags": [
            "rule-based",
            "SVM",
            "CRF"
        ],
        "coreTasks": {
            "cta": true,
            "cpa": true,
            "cea": false,
            "cnea": false
        },
        "supportTasks": {
            "dataPreparation": {
                "description": "Extract and filter HTML tables from the Web; identify subject columns before annotation.",
                "spellChecker": "",
                "unitsOfMeasurements": ""
            },
            "columnClassification": "",
            "subjectDetection": "Subject column identified via a left-to-right heuristic and an SVM classifier.",
            "datatypeAnnotation": "",
            "typeAnnotation": "Assign class labels to columns using a Web-extracted isA database and a likelihood model.",
            "predicateAnnotation": "Assign relation labels between column pairs using Open Information Extraction over Web text.",
            "nilAnnotation": "",
            "entityLinking": {
                "description": "",
                "candidateGeneration": "",
                "entityDisambiguation": ""
            }
        },
        "mainMethod": {
            "type": "hybrid",
            "technique": "rule-based + CRF + SVM"
        },
        "revision": {
            "type": "fully automated",
            "description": "Automatic labelling based on probabilistic evidence thresholds; no human-in-the-loop correction."
        },
        "domain": {
            "domain": "independent",
            "type": "general"
        },
        "validation": {
            "goldStandard": "Manual gold standard of 168 tables; large-scale corpus of ~12.3M HTML tables and a user study on 100 class–property queries.",
            "metrics": [
                "Precision",
                "Recall"
            ]
        },
        "code": "",
        "license": "Not Specified",
        "inputs": {
            "typeOfTable": "HTML tables",
            "tableSources": [
                "web"
            ]
        },
        "output": "",
        "applicationPurpose": "Improve table search and find related tables by recovering column types and inter-column relations.",
        "userInterfaceTool": "",
        "checkedByAuthor": false,
        "checkedByAi": true,
        "doi": "https://doi.org/10.14778/2002938.2002939",
        "citations": [
            {
                "ref": "2007_banko_open",
                "title": "Open Information Extraction from the Web"
            },
            {
                "ref": "2008_banko_the",
                "title": "The Tradeoffs Between Open and Traditional Relation Extraction"
            },
            {
                "ref": "2008_cafarella_webtables",
                "title": "WebTables: Exploring the Power of Tables on the Web"
            },
            {
                "ref": "2008_cafarella_uncovering",
                "title": "Uncovering the Relational Web"
            },
            {
                "ref": "2005_downey_a",
                "title": "A Probabilistic Model of Redundancy in Information Extraction"
            },
            {
                "ref": "2009_elmeleegy_harvesting",
                "title": "Harvesting Relational Tables from Lists on the Web"
            },
            {
                "ref": "2009_gupta_answering",
                "title": "Answering Table Augmentation Queries from Unstructured Lists on the Web"
            },
            {
                "ref": "2010_limaye_annotating",
                "title": "Annotating and Searching Web Tables Using Entities, Types and Relationships"
            },
            {
                "ref": "2008_pasca_weakly",
                "title": "Weakly-Supervised Acquisition of Open-Domain Classes and Class Attributes from Web Documents and Query Logs"
            },
            {
                "ref": "2007_suchanek_yago",
                "title": "YAGO: a Core of Semantic Knowledge Unifying WordNet and Wikipedia"
            }
        ],
        "uncertainFields": [
            {
                "field": "doi",
                "reason": "DOI not stated in the provided text; PVLDB papers often use 10.14778/... identifiers but none is specified."
            },
            {
                "field": "nameOfApproach",
                "reason": "No formal system name given; 'TABLE' is mentioned only as an internal name for the experimental search engine."
            },
            {
                "field": "output",
                "reason": "No explicit serialisation format (e.g., RDF/JSON-LD) is described."
            },
            {
                "field": "userInterfaceTool",
                "reason": "The paper does not specify a UI or tool modality."
            },
            {
                "field": "supportTasks.columnClassification",
                "reason": "Numeric/date features are used in heuristics, but no explicit NE vs LIT classifier is reported."
            },
            {
                "field": "supportTasks.datatypeAnnotation",
                "reason": "No KG datatype annotation is described."
            },
            {
                "field": "citations",
                "reason": "List may be incomplete; only key references were extracted."
            }
        ]
    },
    {
        "id": "2012_goel_exploiting",
        "added": "",
        "year": 2012,
        "firstAuthor": "Goel",
        "authors": [
            "Aman Goel",
            "Craig A. Knoblock",
            "Kristina Lerman"
        ],
        "title": "Exploiting Structure within Data for Accurate Labeling using Conditional Random Fields",
        "venue": {
            "type": "conference",
            "acronym": "ICAI"
        },
        "nameOfApproach": "",
        "techniqueTags": [
            "CRF"
        ],
        "coreTasks": {
            "cta": false,
            "cpa": false,
            "cea": false,
            "cnea": false
        },
        "supportTasks": {
            "dataPreparation": {
                "description": "Custom lexical analysis to tokenise fields and extract generic alphabetic, numeric and symbol features.",
                "spellChecker": "",
                "unitsOfMeasurements": ""
            },
            "columnClassification": "",
            "subjectDetection": "",
            "datatypeAnnotation": "",
            "typeAnnotation": "",
            "predicateAnnotation": "",
            "nilAnnotation": "",
            "entityLinking": {
                "description": "",
                "candidateGeneration": "",
                "entityDisambiguation": ""
            }
        },
        "mainMethod": {
            "type": "supervised",
            "technique": "CRF",
            "supervision": {
                "type": "supervised"
            }
        },
        "revision": {
            "type": "fully automated",
            "description": "After training, labels are produced automatically by CRF inference with no manual post-editing described."
        },
        "domain": {
            "domain": "independent",
            "type": "generic"
        },
        "validation": {
            "goldStandard": "400 tuples per domain from four web sources (weather, flight status, geocoding) with manual labels for fields and tokens.",
            "metrics": [
                "Accuracy"
            ]
        },
        "code": "",
        "license": "Not Specified",
        "inputs": {
            "typeOfTable": "Structured fields/tuples from web pages and databases",
            "tableSources": [
                "web",
                "relational"
            ]
        },
        "output": "",
        "applicationPurpose": "Semantic labelling of structured data fields to support data integration.",
        "userInterfaceTool": "",
        "checkedByAuthor": false,
        "checkedByAi": true,
        "doi": "",
        "citations": [
            {
                "ref": "2001_borkar_automatic",
                "title": "Automatic segmentation of text into structured records"
            },
            {
                "ref": "2000_doan_learning",
                "title": "Learning source descriptions for data integration"
            },
            {
                "ref": "2001_kschischang_factor",
                "title": "Factor graphs and the sum-product algorithm"
            },
            {
                "ref": "2001_lafferty_conditional",
                "title": "Conditional random fields: Probabilistic models for segmenting and labeling sequence data"
            },
            {
                "ref": "1988_lauritzen_local",
                "title": "Local computations with probabilities on graphical structures and their application to expert systems"
            },
            {
                "ref": "2004_lerman_using",
                "title": "Using the structure of web sites for automatic segmentation of tables"
            },
            {
                "ref": "2006_lerman_semantic",
                "title": "Semantic labeling of online information sources"
            },
            {
                "ref": "1989_liu_on",
                "title": "On the limited memory method for large scale optimization"
            },
            {
                "ref": "2007_nadeau_a",
                "title": "A survey of named entity recognition and classification"
            },
            {
                "ref": "1988_pearl_probabilistic",
                "title": "Probabilistic Reasoning in Intelligent Systems"
            },
            {
                "ref": "2003_pinto_table",
                "title": "Table extraction using conditional random fields"
            },
            {
                "ref": "1989_rabiner_a",
                "title": "A tutorial on hidden markov models and selected applications in speech recognition"
            },
            {
                "ref": "2003_sha_shallow",
                "title": "Shallow parsing with conditional random fields"
            },
            {
                "ref": "2007_sutton_dynamic",
                "title": "Dynamic conditional random fields: Factorized probabilistic models for labeling and segmenting sequence data"
            },
            {
                "ref": "2006_tang_tree",
                "title": "Tree-structured conditional random fields for semantic annotation"
            },
            {
                "ref": "1967_viterbi_error",
                "title": "Error bounds for convolutional codes and an asymptotically optimum decoding algorithm"
            },
            {
                "ref": "2005_zhu_2d",
                "title": "2d conditional random fields for web information extraction"
            }
        ],
        "uncertainFields": [
            {
                "field": "venue.acronym",
                "reason": "Derived from the file name; the PDF text shown does not explicitly state the venue."
            },
            {
                "field": "doi",
                "reason": "No DOI is indicated in the available copy; the venue may not assign one."
            },
            {
                "field": "inputs.typeOfTable",
                "reason": "The method labels structured tuples rather than explicit tables; exact input format may vary."
            },
            {
                "field": "output",
                "reason": "No serialisation format (e.g., RDF/JSON-LD) is specified; outputs are label assignments."
            },
            {
                "field": "domain.type",
                "reason": "We marked it as generic, but the evaluation spans specific domains (weather, flights, geocoding)."
            },
            {
                "field": "code",
                "reason": "No code repository or download link is provided in the text."
            },
            {
                "field": "validation.goldStandard",
                "reason": "Datasets are scraped and manually labelled; not a named public GS."
            }
        ]
    },
    {
        "id": "2012_goel_exploiting",
        "added": "",
        "year": 2012,
        "firstAuthor": "Goel",
        "authors": [
            "Aman Goel",
            "Craig A. Knoblock",
            "Kristina Lerman"
        ],
        "title": "Exploiting Structure within Data for Accurate Labeling using Conditional Random Fields",
        "venue": {
            "type": "conference",
            "acronym": "ICAI"
        },
        "nameOfApproach": "",
        "techniqueTags": [
            "CRF"
        ],
        "coreTasks": {
            "cta": false,
            "cpa": false,
            "cea": false,
            "cnea": false
        },
        "supportTasks": {
            "dataPreparation": {
                "description": "Lexical tokenisation and feature extraction into alphabetic, numeric, and symbol features; either aggregates token features at field level or models token nodes explicitly in CRF graphs. ",
                "spellChecker": "",
                "unitsOfMeasurements": "Handles unit/symbol tokens such as DegreeSymbol (◦), PercentSymbol (%), mph, and km during tokenisation. "
            },
            "columnClassification": "",
            "subjectDetection": "",
            "datatypeAnnotation": "",
            "typeAnnotation": "",
            "predicateAnnotation": "",
            "nilAnnotation": "",
            "entityLinking": {
                "description": "",
                "candidateGeneration": "",
                "entityDisambiguation": ""
            }
        },
        "mainMethod": {
            "type": "supervised",
            "technique": "CRF",
            "supervision": {
                "type": "supervised"
            }
        },
        "revision": {
            "type": "fully automated",
            "description": "Outputs are produced automatically by CRF-based inference; no post-hoc human correction stage is described. "
        },
        "domain": {
            "domain": "independent",
            "type": "Generic structured data across multiple domains (weather, flight status, geocoding)."
        },
        "validation": {
            "goldStandard": "Manually labelled datasets built by scraping 100 pages from each of 4 sources per domain (≈400 tuples/domain), with field and token labels. ",
            "metrics": [
                "Accuracy"
            ]
        },
        "code": "",
        "license": "Not Specified",
        "inputs": {
            "typeOfTable": "Structured web page fields",
            "tableSources": [
                "web"
            ]
        },
        "kg": {
            "tripleStore": "",
            "index": ""
        },
        "output": "Field and token labels",
        "applicationPurpose": "Semantic annotation (labelling) of structured data fields via CRFs; studies how exploiting latent structure improves labelling accuracy. ",
        "userInterfaceTool": "",
        "usesLLM": {},
        "checkedByAuthor": false,
        "checkedByAi": true,
        "doi": "",
        "citations": [
            {
                "ref": "2001_lafferty_conditional",
                "title": "Conditional random fields: Probabilistic models for segmenting and labeling sequence data."
            },
            {
                "ref": "2001_kschischang_factor",
                "title": "Factor graphs and the sum-product algorithm."
            },
            {
                "ref": "1988_lauritzen_local",
                "title": "Local computations with probabilities on graphical structures and their application to expert systems."
            },
            {
                "ref": "2003_pinto_table",
                "title": "Table extraction using conditional random fields."
            },
            {
                "ref": "2003_sha_shallow",
                "title": "Shallow parsing with conditional random fields."
            },
            {
                "ref": "2007_sutton_dynamic",
                "title": "Dynamic conditional random fields: Factorized probabilistic models for labeling and segmenting sequence data."
            },
            {
                "ref": "2006_tang_tree",
                "title": "Tree-structured conditional random fields for semantic annotation."
            },
            {
                "ref": "2005_zhu_2d",
                "title": "2d conditional random fields for web information extraction."
            },
            {
                "ref": "2006_lerman_semantic",
                "title": "Semantic labeling of online information sources."
            },
            {
                "ref": "2004_lerman_using",
                "title": "Using the structure of web sites for automatic segmentation of tables."
            },
            {
                "ref": "2001_borkar_automatic",
                "title": "Automatic segmentation of text into structured records."
            },
            {
                "ref": "1989_rabiner_a",
                "title": "A tutorial on hidden markov models and selected applications in speech recognition."
            },
            {
                "ref": "1988_pearl_probabilistic",
                "title": "Probabilistic Reasoning in Intelligent Systems."
            },
            {
                "ref": "2007_nadeau_a",
                "title": "A survey of named entity recognition and classification."
            },
            {
                "ref": "2000_doan_learning",
                "title": "Learning source descriptions for data integration."
            },
            {
                "ref": "1989_liu_on",
                "title": "On the limited memory method for large scale optimization."
            },
            {
                "ref": "1967_viterbi_error",
                "title": "Error bounds for convolutional codes and an asymptotically optimum decoding algorithm."
            }
        ],
        "uncertainFields": [
            {
                "field": "doi",
                "reason": "No DOI indicated in the PDF; left empty."
            },
            {
                "field": "venue.acronym",
                "reason": "Acronym inferred from the filename; not explicitly stated in the text."
            },
            {
                "field": "venue.type",
                "reason": "Assumed 'conference' from the ICAI filename; proceedings details are not visible in the provided pages."
            },
            {
                "field": "output",
                "reason": "The paper reports accuracy but does not specify a serialised output format (e.g., RDF/CSV)."
            },
            {
                "field": "kg.tripleStore",
                "reason": "No knowledge graph is used in this work; field intentionally left empty."
            },
            {
                "field": "inputs.typeOfTable",
                "reason": "The approach operates on structured web fields rather than tables; label chosen to reflect this."
            }
        ]
    },
    {
        "id": "2012_knoblock_semi-automatically",
        "added": "",
        "year": 2012,
        "firstAuthor": "Knoblock",
        "authors": [
            "Craig A. Knoblock",
            "Pedro A. Szekely",
            "José Luis Ambite",
            "Aman Goel",
            "Shubham Gupta",
            "Kristina Lerman",
            "Maria Muslea",
            "Mohsen Taheriyan",
            "Parag Mallick"
        ],
        "title": "Semi-automatically Mapping Structured Sources into the Semantic Web",
        "venue": {
            "type": "conference",
            "acronym": "ESWC"
        },
        "nameOfApproach": "Karma",
        "techniqueTags": [
            "CRF",
            "ontology-driven"
        ],
        "coreTasks": {
            "cta": true,
            "cpa": true,
            "cea": false,
            "cnea": false
        },
        "supportTasks": {
            "dataPreparation": {
                "description": "Cleaning and transformation operations may be needed during mapping; planned UI support is mentioned.",
                "spellChecker": "",
                "unitsOfMeasurements": ""
            },
            "columnClassification": "",
            "subjectDetection": "",
            "datatypeAnnotation": "Literal columns can be mapped to datatype properties in the ontology.",
            "typeAnnotation": "Semantic types for columns are inferred with a CRF and refined by the user.",
            "predicateAnnotation": "Relationships between columns are computed via ontology paths/Steiner tree and can be adjusted by the user.",
            "nilAnnotation": "",
            "entityLinking": {
                "description": "",
                "candidateGeneration": "",
                "entityDisambiguation": ""
            }
        },
        "mainMethod": {
            "type": "hybrid",
            "technique": "CRF-based semantic typing combined with ontology-driven graph construction (Steiner tree) and interactive constraints"
        },
        "revision": {
            "type": "semi automated",
            "description": "A GUI lets users correct semantic types, force relationships, and split class instances after the automatic proposal."
        },
        "domain": {
            "domain": "independent",
            "type": ""
        },
        "validation": {
            "goldStandard": "Equivalence to published SMW-LDE R2R mappings (41 rules) and modelling of an ACE OWL events database",
            "metrics": []
        },
        "code": "https://github.com/InformationIntegrationGroup/Web-Karma-Public",
        "license": "Not Specified",
        "inputs": {
            "typeOfTable": "Structured sources (databases, spreadsheets, CSV, XML)",
            "tableSources": [
                "relational",
                "spreadsheet"
            ]
        },
        "kg": {
            "tripleStore": "",
            "index": ""
        },
        "output": "RDF",
        "applicationPurpose": "Build source models to generate RDF against a given ontology and expose SPARQL over sources.",
        "userInterfaceTool": "Web UI (Karma)",
        "checkedByAuthor": false,
        "checkedByAi": true,
        "doi": "https://doi.org/10.14778/2336664.2336665",
        "citations": [
            {
                "ref": "2010_bizer_the",
                "title": "The R2R Framework: Publishing and Discovering Mappings on the Web"
            },
            {
                "ref": "2006_bizer_d2r",
                "title": "D2R Server – Publishing Relational Databases on the Semantic Web"
            },
            {
                "ref": "2011_das_r2rml",
                "title": "R2RML: RDB to RDF Mapping Language"
            },
            {
                "ref": "2001_lafferty_conditional",
                "title": "Conditional Random Fields: Probabilistic Models for Segmenting and Labeling Sequence Data"
            },
            {
                "ref": "1981_kou_a",
                "title": "A fast algorithm for Steiner trees"
            },
            {
                "ref": "2010_becker_extending",
                "title": "Extending SMW+ with a Linked Data Integration Framework"
            }
        ],
        "uncertainFields": [
            {
                "field": "coreTasks.cea",
                "reason": "The system generates URIs and RDF from identifiers but does not explicitly describe entity linking/disambiguation at cell level."
            },
            {
                "field": "inputs.tableSources[0]",
                "reason": "Relational databases are clearly supported; inclusion of other sources is broad, but only relational and spreadsheet are selected to stay conservative."
            },
            {
                "field": "kg.tripleStore",
                "reason": "No specific triple store is stated; the paper focuses on producing RDF and GLAV mappings rather than querying a particular KG backend."
            },
            {
                "field": "validation.goldStandard",
                "reason": "Described as reproducing SMW-LDE R2R mappings and an ACE OWL database mapping rather than a formal GS with standard metrics. "
            },
            {
                "field": "code",
                "reason": "The URL appears as a footnote in the paper; repository status or licence is not detailed in the text. "
            },
            {
                "field": "supportTasks.datatypeAnnotation",
                "reason": "Datatype property mapping is implied by examples of data properties but not exhaustively specified."
            }
        ]
    },
    {
        "id": "2012_pimplikar_answering",
        "added": "",
        "year": 2012,
        "firstAuthor": "Pimplikar",
        "authors": [
            "Rakesh Pimplikar",
            "Sunita Sarawagi"
        ],
        "title": "Answering Table Queries on the Web using Column Keywords",
        "venue": {
            "type": "journal",
            "acronym": "PVLDB"
        },
        "nameOfApproach": "WWT",
        "techniqueTags": [],
        "coreTasks": {
            "cta": false,
            "cpa": false,
            "cea": false,
            "cnea": false
        },
        "supportTasks": {
            "dataPreparation": {
                "description": "Heuristic extraction of headers and context from HTML tables; Lucene indexing; filtering of non-data tables.",
                "spellChecker": "",
                "unitsOfMeasurements": ""
            },
            "columnClassification": "",
            "subjectDetection": "",
            "datatypeAnnotation": "",
            "typeAnnotation": "",
            "predicateAnnotation": "",
            "nilAnnotation": "",
            "entityLinking": {
                "description": "",
                "candidateGeneration": "",
                "entityDisambiguation": ""
            }
        },
        "mainMethod": {
            "type": "supervised",
            "technique": "Graphical model with bipartite matching and constrained graph cuts",
            "supervision": {
                "type": "supervised"
            }
        },
        "revision": {
            "type": "fully automated",
            "description": "Automated column mapping and consolidation; no manual post-editing described."
        },
        "domain": {
            "domain": "independent",
            "type": ""
        },
        "validation": {
            "goldStandard": "Manual ground truth labels for 1,906 tables over 59 queries",
            "metrics": [
                "F1"
            ]
        },
        "code": "",
        "license": "Not Specified",
        "inputs": {
            "typeOfTable": "HTML tables",
            "tableSources": [
                "web"
            ]
        },
        "output": "HTML table",
        "applicationPurpose": "Structured web table search and consolidation",
        "userInterfaceTool": "",
        "checkedByAuthor": false,
        "checkedByAi": true,
        "doi": "https://doi.org/10.1007/978-3-642-34002-4_11",
        "citations": [
            {
                "ref": "2009_cafarella_data",
                "title": "Data integration for the relational web"
            },
            {
                "ref": "2008_cafarella_webtables",
                "title": "Webtables: exploring the power of tables on the web"
            },
            {
                "ref": "2009_gupta_answering",
                "title": "Answering table augmentation queries from unstructured lists on the web"
            },
            {
                "ref": "2001_boykov_fast",
                "title": "Fast approximate energy minimization via graph cuts"
            },
            {
                "ref": "2006_kolmogorov_convergent",
                "title": "Convergent tree-reweighted message passing for energy minimization"
            },
            {
                "ref": "2009_koller_probabilistic",
                "title": "Probabilistic graphical models: principles and techniques"
            },
            {
                "ref": "2003_pinto_table",
                "title": "Table extraction using conditional random fields"
            },
            {
                "ref": "2011_crestan_web",
                "title": "Web-scale table census and classification"
            }
        ],
        "uncertainFields": [
            {
                "field": "venue.type",
                "reason": "PVLDB is a journal tightly linked to the VLDB conference; some sources cite it as a conference proceeding."
            },
            {
                "field": "output",
                "reason": "The system returns a consolidated table but no explicit export format is specified."
            },
            {
                "field": "userInterfaceTool",
                "reason": "A structured search engine is presented, but a specific UI is not described."
            },
            {
                "field": "applicationPurpose",
                "reason": "Summarised from the abstract rather than given as an explicit section."
            },
            {
                "field": "nameOfApproach",
                "reason": "The system is referred to as WWT; exact stylisation is not formalised."
            },
            {
                "field": "validation.goldStandard",
                "reason": "They report manually labelled mappings for 1,906 tables (59 queries) but do not name a specific dataset."
            },
            {
                "field": "mainMethod.supervision.type",
                "reason": "Weights are tuned on labelled data, treated as supervised although training details are brief."
            },
            {
                "field": "inputs.tableSources",
                "reason": "Tables are harvested from arbitrary HTML pages; other sources like Wikipedia may be implicitly included."
            },
            {
                "field": "techniqueTags",
                "reason": "No listed tag (SVM/CRF/clustering/transformer/etc.) directly applies; left empty."
            }
        ]
    },
    {
        "id": "2012_wang_understanding",
        "added": "",
        "year": 2012,
        "firstAuthor": "Wang",
        "authors": [
            "Jingjing Wang",
            "Haixun Wang",
            "Zhongyuan Wang",
            "Kenny Q. Zhu"
        ],
        "title": "Understanding Tables on the Web",
        "venue": {
            "type": "conference",
            "acronym": "ER"
        },
        "nameOfApproach": "",
        "techniqueTags": [
            "rule-based",
            "ontology-driven"
        ],
        "coreTasks": {
            "cta": true,
            "cpa": false,
            "cea": false,
            "cnea": false
        },
        "supportTasks": {
            "dataPreparation": {
                "description": "Rules filter raw HTML tables, detect or generate headers, and identify the entity column using Probase-based scores. ",
                "spellChecker": "",
                "unitsOfMeasurements": ""
            },
            "columnClassification": "Detects entity (NE) vs attribute (literal) columns via κE/κA evidence from Probase. ",
            "subjectDetection": "Selects the entity column by maximising agreement between entity and attribute concepts. ",
            "datatypeAnnotation": "",
            "typeAnnotation": "Associates the entity column with a Probase concept (conceptualisation). ",
            "predicateAnnotation": "",
            "nilAnnotation": "",
            "entityLinking": {
                "description": "",
                "candidateGeneration": "",
                "entityDisambiguation": ""
            }
        },
        "mainMethod": {
            "type": "unsupervised",
            "technique": "rule-based"
        },
        "revision": {
            "type": "fully automated",
            "description": "Outputs are produced automatically without user curation; results are used for semantic search and to expand Probase. "
        },
        "domain": {
            "domain": "independent",
            "type": ""
        },
        "validation": {
            "goldStandard": "Manual evaluation of 200 filtered web tables, 200 Wikipedia tables, and 30 high-frequency concepts (reporting header detection and entity-column precision). SpringerLink",
            "metrics": [
                "Precision",
                "Accuracy"
            ]
        },
        "code": "",
        "license": "Not Specified",
        "inputs": {
            "typeOfTable": "HTML tables",
            "tableSources": [
                "web",
                "wiki"
            ]
        },
        "kg": {
            "tripleStore": "Probase",
            "index": "Knowledge APIs κA and κE with plausibility/ambiguity scoring; seed-attribute ranking and DBpedia lookups for attributes. "
        },
        "output": "table statements",
        "applicationPurpose": "Semantic table understanding for web-scale tables; semantic search; Probase taxonomy expansion. ",
        "userInterfaceTool": "Web UI (semantic table search prototype)",
        "checkedByAuthor": false,
        "checkedByAi": true,
        "doi": "https://doi.org/10.1007/978-3-642-34002-4_11",
        "citations": [
            {
                "ref": "2012_wu_probase",
                "title": "Probase: A probabilistic taxonomy for text understanding"
            },
            {
                "ref": "2008_cafarella_webtables",
                "title": "WebTables: Exploring the power of tables on the web"
            },
            {
                "ref": "2011_venetis_recovering",
                "title": "Recovering semantics of tables on the web"
            },
            {
                "ref": "1992_hearst_automatic",
                "title": "Automatic acquisition of hyponyms from large text corpora"
            },
            {
                "ref": "2007_auer_dbpedia",
                "title": "DBpedia: A Nucleus for a Web of Open Data"
            }
        ],
        "uncertainFields": [
            {
                "field": "venue.acronym",
                "reason": "Conference is ER 2012 (LNCS 7532); acronym normalised to 'ER' without year."
            },
            {
                "field": "kg.tripleStore",
                "reason": "Method centres on Probase but also consults DBpedia for attributes; we list Probase as the primary KG. "
            },
            {
                "field": "output",
                "reason": "The system returns ranked table statements/tables for queries but does not define a formal export format."
            },
            {
                "field": "userInterfaceTool",
                "reason": "A prototype search engine is described but not formally named; 'Web UI' is inferred. "
            },
            {
                "field": "validation.metrics",
                "reason": "Paper reports correctness rates and average scores; mapped to 'Precision' and 'Accuracy' as closest allowed metrics. "
            },
            {
                "field": "inputs.tableSources[1]",
                "reason": "Wikipedia tables were used for parts of the evaluation; broader web tables were also used."
            }
        ]
    },
    {
        "id": "2013_adelfio_schema",
        "added": "",
        "year": 2013,
        "firstAuthor": "Adelfio",
        "authors": [
            "Marco D. Adelfio",
            "Hanan Samet"
        ],
        "title": "Schema Extraction for Tabular Data on the Web",
        "venue": {
            "type": "journal",
            "acronym": "PVLDB"
        },
        "nameOfApproach": "",
        "techniqueTags": [
            "CRF"
        ],
        "coreTasks": {
            "cta": false,
            "cpa": false,
            "cea": false,
            "cnea": false
        },
        "supportTasks": {
            "dataPreparation": {
                "description": "",
                "spellChecker": "",
                "unitsOfMeasurements": ""
            },
            "columnClassification": "",
            "subjectDetection": "",
            "datatypeAnnotation": "",
            "typeAnnotation": "",
            "predicateAnnotation": "",
            "nilAnnotation": "",
            "entityLinking": {
                "description": "",
                "candidateGeneration": "",
                "entityDisambiguation": ""
            }
        },
        "mainMethod": {
            "type": "supervised",
            "technique": "CRF",
            "supervision": {
                "type": "supervised"
            }
        },
        "revision": {
            "type": "fully automated",
            "description": "Outputs are produced automatically by a trained CRF-based classifier without user post-editing."
        },
        "domain": {
            "domain": "independent",
            "type": ""
        },
        "validation": {
            "goldStandard": "10-fold cross-validation on a collected corpus of relational HTML tables and spreadsheets; comparisons with WebTables features.",
            "metrics": [
                "Precision",
                "Recall",
                "Accuracy"
            ]
        },
        "code": "",
        "license": "Not Specified",
        "inputs": {
            "typeOfTable": "HTML tables and spreadsheets",
            "tableSources": [
                "web",
                "spreadsheet"
            ]
        },
        "output": "",
        "applicationPurpose": "Schema extraction of web and spreadsheet tables",
        "userInterfaceTool": "",
        "checkedByAuthor": false,
        "checkedByAi": true,
        "doi": "https://doi.org/10.14778/2536336.2536343",
        "citations": [
            {
                "ref": "2011_venetis_recovering",
                "title": "Recovering semantics of tables on the web"
            },
            {
                "ref": "2003_sha_shallow",
                "title": "Shallow parsing with conditional random fields"
            },
            {
                "ref": "2012_yakout_infogather",
                "title": "InfoGather: entity augmentation and attribute discovery by holistic matching with web tables"
            },
            {
                "ref": "2002_wang_a",
                "title": "A machine learning based approach for table detection on the web"
            },
            {
                "ref": "2004_zanibbi_a",
                "title": "A survey of table recognition: Models, observations, transformations, and inferences"
            }
        ],
        "uncertainFields": [
            {
                "field": "venue.type",
                "reason": "Published in PVLDB (journal) and also presented at VLDB 2013; categorisation could be seen as conference-related."
            },
            {
                "field": "output",
                "reason": "The paper does not specify an exported output format such as RDF/CSV."
            },
            {
                "field": "applicationPurpose",
                "reason": "Purpose summarised broadly from context; not explicitly framed as an application section."
            },
            {
                "field": "validation.goldStandard",
                "reason": "Uses an internal collected corpus rather than a named public gold standard."
            },
            {
                "field": "userInterfaceTool",
                "reason": "No UI or tool is described; assumed absent."
            },
            {
                "field": "code",
                "reason": "No code repository or release is mentioned."
            }
        ]
    },
    {
        "id": "2013_buche_fuzzy",
        "added": "",
        "year": 2013,
        "firstAuthor": "Buche",
        "authors": [
            "Patrice Buche",
            "Juliette Dibie-Barthelemy",
            "Liliana Ibanescu",
            "Lydie Soler"
        ],
        "title": "Fuzzy Web Data Tables Integration Guided by an Ontological and Terminological Resource",
        "venue": {
            "type": "journal",
            "acronym": "TKDE"
        },
        "nameOfApproach": "ONDINE",
        "techniqueTags": [
            "rule-based",
            "ontology-driven"
        ],
        "coreTasks": {
            "cta": true,
            "cpa": true,
            "cea": false,
            "cnea": false
        },
        "supportTasks": {
            "dataPreparation": {
                "description": "Tables are standardised and structured; symbolic vs numerical columns are identified with the aid of the OTR.",
                "spellChecker": "",
                "unitsOfMeasurements": "Units are modelled in the OTR using an SI-based unit hierarchy."
            },
            "columnClassification": "Distinguishes symbolic and numerical columns using OTR knowledge about terms and units.",
            "subjectDetection": "",
            "datatypeAnnotation": "Maps numerical columns to quantities and associated units defined in the OTR.",
            "typeAnnotation": "Annotates columns with symbolic concepts (classes) from the OTR.",
            "predicateAnnotation": "Identifies n-ary relations represented by the table by matching column concepts to OTR relation signatures.",
            "nilAnnotation": "",
            "entityLinking": {
                "description": "",
                "candidateGeneration": "",
                "entityDisambiguation": ""
            }
        },
        "mainMethod": {
            "type": "unsupervised",
            "technique": "rule-based"
        },
        "revision": {
            "type": "semi automated",
            "description": "Human experts review and validate fuzzy RDF annotations before loading into the XML/RDF warehouse."
        },
        "domain": {
            "domain": "dependent",
            "type": "food safety (microbial risk)"
        },
        "validation": {
            "goldStandard": "",
            "metrics": [
                "Precision",
                "Recall"
            ]
        },
        "code": "",
        "license": "Not Specified",
        "inputs": {
            "typeOfTable": "Web tables (extracted from Web documents; represented as XML)",
            "tableSources": [
                "web",
                "scientific"
            ]
        },
        "kg": {
            "tripleStore": "XML/RDF data warehouse (OTR-based)",
            "index": ""
        },
        "output": "RDF",
        "applicationPurpose": "Supplement local data sources with annotated Web tables and enable flexible, preference-aware querying.",
        "userInterfaceTool": "Web UI (MIEL++ GUI; @Web)",
        "checkedByAuthor": false,
        "checkedByAi": true,
        "doi": "https://doi.org/10.1109/TKDE.2011.245",
        "citations": [
            {
                "ref": "2007_liu_tableseer",
                "title": "TableSeer: Automatic Table Metadata Extraction and Searching in Digital Libraries"
            },
            {
                "ref": "2008_cafarella_webtables",
                "title": "WebTables: Exploring the Power of Tables on the Web"
            },
            {
                "ref": "2008_pan_scalable",
                "title": "Scalable Querying Services over Fuzzy Ontologies"
            },
            {
                "ref": "2006_baziz_a",
                "title": "A Fuzzy Logic Approach to Information Retrieval Using a Ontology-Based Representation of Documents"
            }
        ],
        "uncertainFields": [
            {
                "field": "coreTasks.cpa",
                "reason": "The system recognises and instantiates n-ary relations from the OTR; mapping to CPA (pairwise KG properties) is analogous but not explicit."
            },
            {
                "field": "inputs.tableSources",
                "reason": "Sources are described as Web and digital library scientific documents; specific file formats are not exhaustively listed."
            },
            {
                "field": "kg.tripleStore",
                "reason": "They query an XML/RDF data warehouse with SPARQL rather than a named public KG; phrasing may vary."
            },
            {
                "field": "userInterfaceTool",
                "reason": "The paper mentions a GUI for MIEL++ and the @Web software; exact tool names/packaging may differ from the implementation."
            },
            {
                "field": "techniqueTags[0]",
                "reason": "The approach is algorithmic and OTR-guided with thresholds; categorising it as rule-based is reasonable but not explicitly named as such."
            }
        ]
    },
    {
        "id": "2013_cruz_giva",
        "added": "",
        "year": 2013,
        "firstAuthor": "Cruz",
        "authors": [
            "Isabel F. Cruz",
            "Venkat R. Ganesh",
            "Claudio Caletti",
            "Pavan Reddy"
        ],
        "title": "GIVA: A Semantic Framework for Geospatial and Temporal Data Integration, Visualization, and Analytics",
        "venue": {
            "type": "conference",
            "acronym": "SIGSPATIAL"
        },
        "nameOfApproach": "GIVA",
        "techniqueTags": [
            "ontology-driven"
        ],
        "coreTasks": {
            "cta": false,
            "cpa": false,
            "cea": false,
            "cnea": false
        },
        "supportTasks": {
            "dataPreparation": {
                "description": "Extraction of feature-rich tables from web tables and semantic processing to identify spatial coordinates/time stamps; translation into a common spatial format.",
                "spellChecker": "",
                "unitsOfMeasurements": ""
            },
            "columnClassification": "",
            "subjectDetection": "",
            "datatypeAnnotation": "",
            "typeAnnotation": "",
            "predicateAnnotation": "",
            "nilAnnotation": "",
            "entityLinking": {
                "description": "",
                "candidateGeneration": "",
                "entityDisambiguation": ""
            }
        },
        "mainMethod": {
            "type": "hybrid",
            "technique": "ontology-driven"
        },
        "revision": {
            "type": "semi automated",
            "description": "Users can optionally review the extracted ontology; other components (matching, translation, storage) run automatically."
        },
        "domain": {
            "domain": "dependent",
            "type": "geospatial/environmental"
        },
        "validation": {
            "goldStandard": "",
            "metrics": []
        },
        "code": "",
        "license": "Not Specified",
        "inputs": {
            "typeOfTable": "HTML tables and GIS formats (CSV, GML, KML, SHP)",
            "tableSources": [
                "web",
                "spreadsheet"
            ]
        },
        "kg": {
            "tripleStore": "OWLIM",
            "index": ""
        },
        "output": "RDF",
        "applicationPurpose": "Geospatial/temporal data integration, visualisation and analytics for domain experts.",
        "userInterfaceTool": "Web UI",
        "checkedByAuthor": false,
        "checkedByAi": true,
        "doi": "https://doi.org/10.1145/2525314.2525324",
        "citations": [
            {
                "ref": "1999_abiteboul_tools",
                "title": "Tools for Data Translation and Integration"
            },
            {
                "ref": "2009_cruz_agreementmaker",
                "title": "AgreementMaker: Efficient Matching for Large Real-World Schemas and Ontologies"
            },
            {
                "ref": "2012_cruz_automatic",
                "title": "Automatic Configuration Selection Using Ontology Matching Task Profiling"
            },
            {
                "ref": "2008_cruz_structural",
                "title": "Structural Alignment Methods with Applications to Geospatial Ontologies"
            },
            {
                "ref": "2009_cruz_ontology",
                "title": "Ontology Driven Data Integration in Heterogeneous Networks"
            },
            {
                "ref": "2005_kiryakov_owlima",
                "title": "OWLIM–A Pragmatic Semantic Repository for OWL"
            },
            {
                "ref": "2009_hall_the",
                "title": "The WEKA Data Mining Software: An Update"
            },
            {
                "ref": "2011_rishe_geospatial",
                "title": "Geospatial Data Management with TerraFly"
            },
            {
                "ref": "2001_mccurley_geospatial",
                "title": "Geospatial Mapping and Navigation of the Web"
            },
            {
                "ref": "2007_middel_a",
                "title": "A Framework for Visualizing Multivariate Geodata"
            }
        ],
        "uncertainFields": [
            {
                "field": "venue.acronym",
                "reason": "Paper mentions \"Proceedings of ACMGIS\" and SIGSPATIAL’13; using SIGSPATIAL as the venue acronym may be ambiguous."
            },
            {
                "field": "techniqueTags[0]",
                "reason": "Framework combines ontology matching with ML (decision tree) for table extraction; only \"ontology-driven\" fits allowed tags."
            },
            {
                "field": "mainMethod.technique",
                "reason": "Technique is a mix of ontology matching and ML; summarised as ontology-driven."
            },
            {
                "field": "revision.type",
                "reason": "Authors note optional user review of extracted ontology; extent of human-in-the-loop across components is not fully specified."
            },
            {
                "field": "domain.type",
                "reason": "Targets geospatial data with environmental/public administration examples; domain label consolidated as geospatial/environmental."
            },
            {
                "field": "validation.goldStandard",
                "reason": "Demo paper does not report a named gold standard; only mentions training on 100 web tables."
            },
            {
                "field": "output",
                "reason": "RDF triples are generated, but the application also exposes a WFS; RDF chosen as primary output."
            },
            {
                "field": "kg.tripleStore",
                "reason": "OWLIM is the RDF store; the system also consults DBpedia for ontology construction, which could be interpreted as the KG."
            },
            {
                "field": "inputs.tableSources",
                "reason": "Sources include web tables and CSV; spreadsheet chosen to represent CSV though the exact origin of CSV files is not fully detailed."
            },
            {
                "field": "userInterfaceTool",
                "reason": "Only described generically as a web interface (AJAX/jQuery, D3.js); no specific tool name provided."
            },
            {
                "field": "code",
                "reason": "No repository or download link is referenced."
            },
            {
                "field": "license",
                "reason": "No licensing information is provided in the paper."
            },
            {
                "field": "applicationPurpose",
                "reason": "Summarised from the abstract; phrasing may vary."
            },
            {
                "field": "coreTasks.cta",
                "reason": "Paper is not focused on STI tasks (CTA/CPA/CEA/CNEA); set to false conservatively."
            },
            {
                "field": "supportTasks.dataPreparation.description",
                "reason": "Description generalised from multiple sections; exact scope may differ."
            }
        ]
    },
    {
        "id": "2013_deng_scalable",
        "added": "",
        "year": 2013,
        "firstAuthor": "Deng",
        "authors": [
            "Dong Deng",
            "Yu Jiang",
            "Guoliang Li",
            "Jian Li",
            "Cong Yu"
        ],
        "title": "Scalable Column Concept Determination for Web Tables Using Large Knowledge Bases",
        "venue": {
            "type": "journal",
            "acronym": "PVLDB"
        },
        "nameOfApproach": "",
        "techniqueTags": [
            "rule-based",
            "ontology-driven"
        ],
        "coreTasks": {
            "cta": true,
            "cpa": false,
            "cea": false,
            "cnea": false
        },
        "supportTasks": {
            "dataPreparation": {
                "description": "Generates string signatures (e.g., q-grams) to enable fuzzy matching and uses MapReduce-based similarity joins for scalability.",
                "spellChecker": "",
                "unitsOfMeasurements": ""
            },
            "columnClassification": "",
            "subjectDetection": "",
            "datatypeAnnotation": "",
            "typeAnnotation": "Selects top-k KG types per column by aggregating fuzzy matches between cell values and KG entities and ranking via set-similarity functions.",
            "predicateAnnotation": "",
            "nilAnnotation": "",
            "entityLinking": {
                "description": "",
                "candidateGeneration": "",
                "entityDisambiguation": ""
            }
        },
        "mainMethod": {
            "type": "unsupervised",
            "technique": "rule-based"
        },
        "revision": {
            "type": "fully automated",
            "description": "Batch, MapReduce-based pipeline; no human-in-the-loop post-editing is described."
        },
        "domain": {
            "domain": "independent",
            "type": ""
        },
        "validation": {
            "goldStandard": "WWT (Wikipedia Web Tables) and WEX (Wikipedia Extraction) datasets with manual ground truth for evaluation; KG sources Freebase and YAGO.",
            "metrics": [
                "Precision",
                "Recall",
                "F1"
            ]
        },
        "code": "",
        "license": "Not Specified",
        "inputs": {
            "typeOfTable": "HTML tables",
            "tableSources": [
                "web",
                "wiki"
            ]
        },
        "kg": {
            "tripleStore": "Freebase; Yago",
            "index": "Signature-based indexing with bloom filter hierarchy for partition identification"
        },
        "output": "Top-k KG types per column",
        "applicationPurpose": "Web-scale table understanding to support search and integration.",
        "userInterfaceTool": "",
        "checkedByAuthor": false,
        "checkedByAi": true,
        "doi": "https://doi.org/10.14778/2536258.2536271",
        "citations": [
            {
                "ref": "2010_limaye_annotating",
                "title": "Annotating and searching web tables using entities, types and relationships"
            },
            {
                "ref": "2011_venetis_recovering",
                "title": "Recovering semantics of tables on the web"
            },
            {
                "ref": "2008_cafarella_webtables",
                "title": "WebTables: exploring the power of tables on the Web"
            },
            {
                "ref": "2007_auer_dbpedia",
                "title": "DBpedia: A nucleus for a web of open data"
            },
            {
                "ref": "2007_suchanek_yago",
                "title": "YAGO: a core of semantic knowledge"
            }
        ],
        "uncertainFields": [
            {
                "field": "inputs.typeOfTable",
                "reason": "The paper processes Web/Wikipedia tables rendered in HTML; the exact label expected by the schema could also be 'Web tables'."
            },
            {
                "field": "kg.index",
                "reason": "The description summarises mechanisms (signatures, bloom filter hierarchy) used in the pipeline rather than a conventional KG index component."
            },
            {
                "field": "output",
                "reason": "No explicit serialisation format is provided; the outcome is a ranked list of concepts per column."
            },
            {
                "field": "mainMethod.technique",
                "reason": "The method is algorithmic (similarity-join with heuristics) and not a classic 'rule-based' system; 'rule-based' is used as the closest allowed label."
            },
            {
                "field": "validation.goldStandard",
                "reason": "Named datasets WWT and WEX are used; the schema requests a GS name but the paper mixes manual ground truth and extracted tables."
            }
        ]
    },
    {
        "id": "2013_ermilov_user-driven",
        "added": "",
        "year": 2013,
        "firstAuthor": "Ermilov",
        "authors": [
            "Ivan Ermilov",
            "Sören Auer",
            "Claus Stadler"
        ],
        "title": "User-driven semantic mapping of tabular data",
        "venue": {
            "type": "conference",
            "acronym": "I-SEMANTICS"
        },
        "nameOfApproach": "CSV2RDF",
        "techniqueTags": [
            "rule-based"
        ],
        "coreTasks": {
            "cta": false,
            "cpa": false,
            "cea": false,
            "cnea": false
        },
        "supportTasks": {
            "dataPreparation": {
                "description": "Resources are crawled and cleaned; headers are extracted; default mappings are auto-generated for CSV files.",
                "spellChecker": "",
                "unitsOfMeasurements": ""
            },
            "columnClassification": "",
            "subjectDetection": "",
            "datatypeAnnotation": "",
            "typeAnnotation": "",
            "predicateAnnotation": "",
            "nilAnnotation": "",
            "entityLinking": {
                "description": "",
                "candidateGeneration": "",
                "entityDisambiguation": ""
            }
        },
        "mainMethod": {
            "type": "unsupervised",
            "technique": "rule-based"
        },
        "revision": {
            "type": "semi automated",
            "description": "Default mappings are created automatically and can be revised by users via a Semantic MediaWiki; data can be re-transformed after edits."
        },
        "domain": {
            "domain": "independent",
            "type": ""
        },
        "validation": {
            "goldStandard": "",
            "metrics": []
        },
        "code": "",
        "license": "Not Specified",
        "inputs": {
            "typeOfTable": "CSV",
            "tableSources": [
                "gov-open-data",
                "web"
            ]
        },
        "kg": {
            "tripleStore": "",
            "index": ""
        },
        "output": "RDF",
        "applicationPurpose": "Crowd-sourced mapping and mass conversion of tabular data from open data portals into RDF.",
        "userInterfaceTool": "Web UI (Semantic MediaWiki), CLI (Sparqlify-CSV)",
        "checkedByAuthor": false,
        "checkedByAi": true,
        "doi": "https://doi.org/10.1145/2506182.2506196",
        "citations": [
            {
                "ref": "2009_auer_triplify",
                "title": "Triplify: Light-weight linked data publication from relational databases"
            },
            {
                "ref": "berners-lee1998relational",
                "title": "Relational databases on the semantic web"
            },
            {
                "ref": "2009_ding_the",
                "title": "The data-gov wiki: A semantic web portal for linked government data"
            },
            {
                "ref": "2010_lebo_converting",
                "title": "Converting governmental datasets into linked data"
            },
            {
                "ref": "2007_pivk_transforming",
                "title": "Transforming arbitrary tables into logical form with TARTAR"
            }
        ],
        "uncertainFields": [
            {
                "field": "venue.acronym",
                "reason": "Proceedings refer to I-SEMANTICS '13; acronym formatting varies between sources."
            },
            {
                "field": "kg.tripleStore",
                "reason": "The approach focuses on CSV-to-RDF conversion without specifying a target KG or triple store."
            },
            {
                "field": "license",
                "reason": "No explicit licence for the system or code is stated in the paper."
            },
            {
                "field": "userInterfaceTool",
                "reason": "Described as a Semantic MediaWiki-based mapping wiki plus Sparqlify-CSV CLI; exact tool naming is not standardised."
            },
            {
                "field": "applicationPurpose",
                "reason": "Purpose summarised from the abstract rather than an explicit 'Application/Purpose' section."
            },
            {
                "field": "inputs.tableSources",
                "reason": "Derived from the use of PublicData.eu and web data portals; not listed as a controlled set by the authors."
            },
            {
                "field": "nameOfApproach",
                "reason": "Preprint emphasises 'CSV2RDF' while ACM record lists the generic paper title; using CSV2RDF as the system name."
            }
        ]
    },
    {
        "id": "2013_mulwad_semantic",
        "added": "",
        "year": 2013,
        "firstAuthor": "Mulwad",
        "authors": [
            "Varish Mulwad",
            "Tim Finin",
            "Anupam Joshi"
        ],
        "title": "Semantic Message Passing for Generating Linked Data from Tables",
        "venue": {
            "type": "conference",
            "acronym": "ISWC"
        },
        "nameOfApproach": "Semantic Message Passing",
        "techniqueTags": [
            "ontology-driven",
            "rule-based"
        ],
        "coreTasks": {
            "cta": true,
            "cpa": true,
            "cea": true,
            "cnea": true
        },
        "supportTasks": {
            "dataPreparation": {
                "description": "Preprocessing includes row sampling, acronym expansion and recognising stylised literals (e.g., phone numbers); literals are detected via regular expressions.",
                "spellChecker": "",
                "unitsOfMeasurements": ""
            },
            "columnClassification": "Detect columns with only literal values and map them to no-annotation.",
            "subjectDetection": "",
            "datatypeAnnotation": "",
            "typeAnnotation": "Assign DBpedia/Yago classes to column headers via majority voting over cell-entity classes and a granularity tie-break.",
            "predicateAnnotation": "Generate candidate relations between column pairs from DBpedia/Yago links and select via majority voting with thresholds.",
            "nilAnnotation": "Cells with absent/low-confidence candidates are assigned no-annotation (NIL).",
            "entityLinking": {
                "description": "Link cell strings to entities using candidates from Wikitology/LOD with contextual cues and an entity ranker.",
                "candidateGeneration": "Query Wikitology using the cell string plus header and row context; aggregate candidates' classes from DBpedia and Yago.",
                "entityDisambiguation": "Re-rank candidates using similarity/popularity features (Naive Bayes classifier) and joint inference constraints."
            }
        },
        "mainMethod": {
            "type": "hybrid",
            "technique": "Probabilistic graphical model with semantic message passing combined with knowledge-driven heuristics"
        },
        "revision": {
            "type": "fully automated",
            "description": "Joint inference runs automatically; future user-in-the-loop feedback is suggested but not part of the implementation."
        },
        "domain": {
            "domain": "independent",
            "type": ""
        },
        "validation": {
            "goldStandard": "Tables from Web/Wikipedia (Web Manual, Wiki Manual, Web Relation, Wiki Links), with additional manual GS for CTA/CPA.",
            "metrics": [
                "Precision",
                "Recall",
                "F1",
                "Accuracy"
            ]
        },
        "code": "",
        "license": "Not Specified",
        "inputs": {
            "typeOfTable": "HTML tables",
            "tableSources": [
                "web",
                "wiki"
            ]
        },
        "kg": {
            "tripleStore": "DBpedia; Yago; Wikitology",
            "index": "Wikitology and class/property alignments (e.g., PARIS)"
        },
        "output": "RDF",
        "applicationPurpose": "Convert tables into linked data to improve search, interoperability and integration.",
        "userInterfaceTool": "",
        "checkedByAuthor": false,
        "checkedByAi": true,
        "doi": "https://doi.org/10.1007/978-3-642-41335-3_23",
        "citations": [
            {
                "ref": "2009_bizer_dbpedia",
                "title": "DBpedia - A Crystallization Point for the Web of Data"
            },
            {
                "ref": "2008_cafarella_webtables",
                "title": "WebTables: Exploring the Power of Tables on the Web"
            },
            {
                "ref": "2010_limaye_annotating",
                "title": "Annotating and Searching Web Tables Using Entities, Types and Relationships"
            },
            {
                "ref": "2011_venetis_recovering",
                "title": "Recovering Semantics of Tables on the Web"
            },
            {
                "ref": "2011_suchanek_paris",
                "title": "PARIS: Probabilistic Alignment of Relations, Instances, and Schema"
            },
            {
                "ref": "2010_mulwad_using",
                "title": "Using Linked Data to Interpret Tables"
            },
            {
                "ref": "2008_han_rdf123",
                "title": "RDF123: From Spreadsheets to RDF"
            },
            {
                "ref": "2011_syed_creating",
                "title": "Creating and Exploiting a Hybrid Knowledge Base for Linked Data"
            }
        ],
        "uncertainFields": [
            {
                "field": "kg.tripleStore",
                "reason": "The system simultaneously uses multiple LOD sources; the field expects a single value."
            },
            {
                "field": "kg.index",
                "reason": "Wikitology functions as a hybrid KB/index; precise indexing infrastructure is not fully specified."
            },
            {
                "field": "inputs.typeOfTable",
                "reason": "Evaluation mentions Web and Wikipedia tables; \"HTML tables\" vs \"Web tables\" terminology varies."
            },
            {
                "field": "userInterfaceTool",
                "reason": "No UI/tool is described; future user feedback is only proposed."
            },
            {
                "field": "license",
                "reason": "The paper does not specify a software licence; assumed as not specified."
            },
            {
                "field": "supportTasks.subjectDetection",
                "reason": "Primary/subject column identification is discussed conceptually but not clearly implemented."
            },
            {
                "field": "supportTasks.datatypeAnnotation",
                "reason": "Literal columns are detected, but explicit mapping to KG datatypes is not described."
            }
        ]
    },
    {
        "id": "2013_munoz_triplifying",
        "added": "",
        "year": 2013,
        "firstAuthor": "Muñoz",
        "authors": [
            "Emir Muñoz",
            "Aidan Hogan",
            "Alessandra Mileo"
        ],
        "title": "Triplifying Wikipedia's Tables",
        "venue": {
            "type": "workshop",
            "acronym": "LD4IE"
        },
        "nameOfApproach": "",
        "techniqueTags": [
            "rule-based",
            "ontology-driven"
        ],
        "coreTasks": {
            "cta": false,
            "cpa": true,
            "cea": true,
            "cnea": false
        },
        "supportTasks": {
            "dataPreparation": {
                "description": "Normalises Wikitables into matrices, handling headers, colspans/rowspans, and HTML cleaning; filters links and repairs jagged tables.",
                "spellChecker": "",
                "unitsOfMeasurements": ""
            },
            "columnClassification": "",
            "subjectDetection": "",
            "datatypeAnnotation": "",
            "typeAnnotation": "",
            "predicateAnnotation": "Discovers DBpedia predicates between entities within rows and between row entities and the article protagonist.",
            "nilAnnotation": "",
            "entityLinking": {
                "description": "Maps internal Wikipedia links in cells to DBpedia entities after filtering and redirect resolution.",
                "candidateGeneration": "Uses internal wiki-links present in cells as candidates.",
                "entityDisambiguation": "Follows redirects and filters categories/list pages to resolve entities."
            }
        },
        "mainMethod": {
            "type": "unsupervised",
            "technique": "rule-based"
        },
        "revision": {
            "type": "fully automated",
            "description": "Extraction runs automatically without user-in-the-loop; manual labelling was used only for evaluation."
        },
        "domain": {
            "domain": "independent",
            "type": "Wikipedia tables"
        },
        "validation": {
            "goldStandard": "Random sample of 250 extracted triples manually judged by three annotators; moderate agreement and ~52% correct triples.",
            "metrics": [
                "Precision"
            ]
        },
        "code": "",
        "license": "Not Specified",
        "inputs": {
            "typeOfTable": "HTML tables",
            "tableSources": [
                "wiki",
                "web"
            ]
        },
        "kg": {
            "tripleStore": "DBpedia",
            "index": "Local DBpedia on-disk indexes with caching for lookups."
        },
        "output": "RDF",
        "applicationPurpose": "KG extension and enrichment from Wikipedia tables.",
        "userInterfaceTool": "",
        "checkedByAuthor": false,
        "checkedByAi": true,
        "doi": "",
        "citations": [
            {
                "ref": "2009_bizer_dbpedia",
                "title": "DBpedia – a crystallization point for the Web of Data"
            },
            {
                "ref": "2013_hoffart_yago2",
                "title": "YAGO2: A spatially and temporally enhanced knowledge base from Wikipedia"
            },
            {
                "ref": "2008_cafarella_webtables",
                "title": "WebTables: exploring the power of tables on the Web"
            },
            {
                "ref": "2011_venetis_recovering",
                "title": "Recovering semantics of tables on the Web"
            },
            {
                "ref": "2010_limaye_annotating",
                "title": "Annotating and searching web tables using entities, types and relationships"
            },
            {
                "ref": "2007_pivk_transforming",
                "title": "Transforming arbitrary tables into logical form with TARTAR"
            },
            {
                "ref": "2011_crestan_web",
                "title": "Web-scale table census and classification"
            },
            {
                "ref": "2010_syed_exploiting",
                "title": "Exploiting a Web of Semantic Data for Interpreting Tables"
            }
        ],
        "uncertainFields": [
            {
                "field": "venue.acronym",
                "reason": "Assumed from file name; the PDF excerpt did not explicitly show the venue acronym."
            },
            {
                "field": "doi",
                "reason": "No DOI was visible; CEUR-WS workshop papers often lack DOIs."
            },
            {
                "field": "coreTasks.cea",
                "reason": "Entity linking relies on existing wiki-links; inclusion as CEA assumes mapping links to KG entities counts as CEA."
            },
            {
                "field": "validation.metrics[0]",
                "reason": "They report an estimated ~52% correctness; treated as Precision though the paper does not present full metric details."
            },
            {
                "field": "domain.type",
                "reason": "Marked independent but restricted to Wikipedia tables; classification could be interpreted differently."
            },
            {
                "field": "supportTasks.predicateAnnotation",
                "reason": "Predicate discovery is approximate and partly illustrative; extent of implementation may be limited."
            }
        ]
    },
    {
        "id": "2013_munoz_triplifying",
        "added": "",
        "year": 2013,
        "firstAuthor": "Muñoz",
        "authors": [
            "Emir Muñoz",
            "Aidan Hogan",
            "Alessandra Mileo"
        ],
        "title": "Triplifying Wikipedia's Tables",
        "venue": {
            "type": "workshop",
            "acronym": "LD4IE"
        },
        "nameOfApproach": "",
        "techniqueTags": [
            "ontology-driven"
        ],
        "coreTasks": {
            "cta": false,
            "cpa": false,
            "cea": false,
            "cnea": false
        },
        "supportTasks": {
            "dataPreparation": {
                "description": "Normalises Wikitables into matrices by handling headers, captions, row/col spans, and repairs jagged tables after HTML parsing and cleaning. Extracts internal wiki-links and maps them to DBpedia entities.",
                "spellChecker": "",
                "unitsOfMeasurements": ""
            },
            "columnClassification": "",
            "subjectDetection": "",
            "datatypeAnnotation": "",
            "typeAnnotation": "",
            "predicateAnnotation": "",
            "nilAnnotation": "",
            "entityLinking": {
                "description": "",
                "candidateGeneration": "",
                "entityDisambiguation": ""
            }
        },
        "mainMethod": {
            "type": "unsupervised",
            "technique": "ontology-driven"
        },
        "revision": {
            "type": "fully automated",
            "description": "Extraction of candidate triples is automatic; authors discuss future ML-based post-filtering to improve precision."
        },
        "domain": {
            "domain": "independent",
            "type": ""
        },
        "validation": {
            "goldStandard": "250 randomly selected triples manually labelled by three judges (moderate agreement; ≈52% correct).",
            "metrics": [
                "Precision"
            ]
        },
        "code": "",
        "license": "Not Specified",
        "inputs": {
            "typeOfTable": "HTML tables",
            "tableSources": [
                "wiki"
            ]
        },
        "kg": {
            "tripleStore": "DBpedia",
            "index": "Local indexes/SPARQL lookups over DBpedia; two on-disk lookups per entity pair with LRU caching."
        },
        "output": "RDF",
        "applicationPurpose": "Extract RDF triples from Wikipedia tables to enrich knowledge bases and the Web of Data.",
        "userInterfaceTool": "",
        "checkedByAuthor": "",
        "checkedByAi": true,
        "doi": "",
        "citations": [
            {
                "ref": "2009_bizer_dbpedia",
                "title": "DBpedia – a crystallization point for the Web of Data"
            },
            {
                "ref": "2008_cafarella_webtables",
                "title": "WebTables: exploring the power of tables on the Web"
            },
            {
                "ref": "2013_hoffart_yago2",
                "title": "YAGO2: A spatially and temporally enhanced knowledge base from Wikipedia"
            },
            {
                "ref": "2010_limaye_annotating",
                "title": "Annotating and searching web tables using entities, types and relationships"
            },
            {
                "ref": "2012_das_r2rml",
                "title": "R2RML: RDB to RDF Mapping Language"
            },
            {
                "ref": "2011_mendes_dbpedia",
                "title": "DBpedia Spotlight: shedding light on the web of documents"
            },
            {
                "ref": "2011_venetis_recovering",
                "title": "Recovering semantics of tables on the Web"
            },
            {
                "ref": "2011_crestan_web",
                "title": "Web-scale table census and classification"
            }
        ],
        "uncertainFields": [
            {
                "field": "venue.acronym",
                "reason": "Inferred as LD4IE from workshop context; acronym not explicitly printed in the provided excerpt."
            },
            {
                "field": "techniqueTags[0]",
                "reason": "Classified as ontology-driven since DBpedia guides extraction; alternative labels like rule-based could also apply."
            },
            {
                "field": "mainMethod.technique",
                "reason": "Described generally; no single named algorithm beyond KB lookups."
            },
            {
                "field": "validation.goldStandard",
                "reason": "Summary phrasing condensed; exact wording and scope of the gold standard may vary in the full text."
            },
            {
                "field": "coreTasks.cea",
                "reason": "Entities are mapped via wiki-links, but the paper does not explicitly frame this as the CEA task."
            },
            {
                "field": "coreTasks.cpa",
                "reason": "Relations are mined between table entities, but the paper does not explicitly define this as CPA."
            },
            {
                "field": "doi",
                "reason": "Workshop/CEUR papers often lack a DOI; none was stated in the provided material."
            }
        ]
    },
    {
        "id": "2013_quercini_entity",
        "added": "",
        "year": 2013,
        "firstAuthor": "Quercini",
        "authors": [
            "Gianluca Quercini",
            "Chantal Reynaud"
        ],
        "title": "Entity Discovery and Annotation in Tables",
        "venue": {
            "type": "conference",
            "acronym": "EDBT"
        },
        "nameOfApproach": "",
        "techniqueTags": [
            "SVM",
            "rule-based",
            "ontology-driven"
        ],
        "coreTasks": {
            "cta": false,
            "cpa": false,
            "cea": false,
            "cnea": false
        },
        "supportTasks": {
            "dataPreparation": {
                "description": "Filters cells via regex/patterns and column types; augments queries with spatial clues and geocoding to reduce ambiguity.",
                "spellChecker": "",
                "unitsOfMeasurements": ""
            },
            "columnClassification": "Applies a column-coherence scoring to identify the column most likely to contain entity names of the target type.",
            "subjectDetection": "",
            "datatypeAnnotation": "",
            "typeAnnotation": "",
            "predicateAnnotation": "",
            "nilAnnotation": "",
            "entityLinking": {
                "description": "",
                "candidateGeneration": "",
                "entityDisambiguation": ""
            }
        },
        "mainMethod": {
            "type": "supervised",
            "technique": "SVM",
            "supervision": {
                "type": "supervised"
            }
        },
        "revision": {
            "type": "fully automated",
            "description": "Post-processing removes spurious annotations using column-coherence scores; no human-in-the-loop validation is required."
        },
        "domain": {
            "domain": "independent",
            "type": ""
        },
        "validation": {
            "goldStandard": "Manually annotated 40 GFT tables; Wiki Manual dataset (36 tables).",
            "metrics": [
                "Precision",
                "Recall",
                "F1"
            ]
        },
        "code": "",
        "license": "Not Specified",
        "inputs": {
            "typeOfTable": "Web tables (Google Fusion Tables)",
            "tableSources": [
                "web"
            ]
        },
        "kg": {
            "tripleStore": "DBpedia",
            "index": ""
        },
        "output": "",
        "applicationPurpose": "Discover and annotate previously unseen entities in tables (e.g., POIs) to support data extraction and enrichment for faceted browsing.",
        "userInterfaceTool": "",
        "checkedByAuthor": false,
        "checkedByAi": true,
        "doi": "https://doi.org/10.1145/2452376.2452457",
        "citations": [
            {
                "ref": "2009_bizer_dbpedia",
                "title": "DBpedia - A Crystallization Point for the Web of Data."
            },
            {
                "ref": "2008_cafarella_webtables",
                "title": "WebTables: Exploring the Power of Tables on the Web."
            },
            {
                "ref": "2010_limaye_annotating",
                "title": "Annotating and Searching Web Tables Using Entities, Types and Relationships."
            },
            {
                "ref": "2011_venetis_recovering",
                "title": "Recovering Semantics of Tables on the Web."
            },
            {
                "ref": "2007_suchanek_yago",
                "title": "Yago: a Core of Semantic Knowledge."
            },
            {
                "ref": "2012_wu_probase",
                "title": "Probase: a Probabilistic Taxonomy for Text Understanding."
            },
            {
                "ref": "2010_gonzalez_google",
                "title": "Google Fusion Tables: Web-centered Data Management and Collaboration."
            },
            {
                "ref": "2009_hignette_fuzzy",
                "title": "Fuzzy Annotation of Web Data Tables Driven by a Domain Ontology."
            },
            {
                "ref": "2008_han_rdf123",
                "title": "RDF123: From Spreadsheets to RDF."
            }
        ],
        "uncertainFields": [
            {
                "field": "venue.acronym",
                "reason": "The event is jointly branded EDBT/ICDT; the appropriate acronym could be either \"EDBT\" or \"EDBT/ICDT\"."
            },
            {
                "field": "coreTasks.cea",
                "reason": "The work detects cells that are entity names and types but does not explicitly link them to KG identifiers as required by CEA."
            },
            {
                "field": "kg.tripleStore",
                "reason": "DBpedia is used to build training data rather than as a target KG for output annotations."
            },
            {
                "field": "applicationPurpose",
                "reason": "The algorithm was implemented within a faceted browser project for digital cities, but its primary stated purpose is general entity discovery in tables."
            }
        ]
    },
    {
        "id": "2013_quercini_entity",
        "added": "",
        "year": 2013,
        "firstAuthor": "Quercini",
        "authors": [
            "Gianluca Quercini",
            "Chantal Reynaud"
        ],
        "title": "Entity Discovery and Annotation in Tables",
        "venue": {
            "type": "conference",
            "acronym": "EDBT"
        },
        "nameOfApproach": "",
        "techniqueTags": [
            "SVM",
            "ontology-driven",
            "rule-based"
        ],
        "coreTasks": {
            "cta": false,
            "cpa": false,
            "cea": false,
            "cnea": false
        },
        "supportTasks": {
            "dataPreparation": {
                "description": "Pre-processing filters out non-entity cells using regex patterns and GFT column types; post-processing enforces column coherence.",
                "spellChecker": "",
                "unitsOfMeasurements": ""
            },
            "columnClassification": "Not explicitly formalised; leverages GFT column types and column-level scoring to isolate the entity-name column.",
            "subjectDetection": "Identifies rows containing entities of target types and pinpoints the entity-name column via aggregated cell scores.",
            "datatypeAnnotation": "",
            "typeAnnotation": "",
            "predicateAnnotation": "",
            "nilAnnotation": "",
            "entityLinking": {
                "description": "",
                "candidateGeneration": "",
                "entityDisambiguation": ""
            }
        },
        "mainMethod": {
            "type": "supervised",
            "technique": "SVM",
            "supervision": {
                "type": "supervised"
            }
        },
        "revision": {
            "type": "fully automated",
            "description": "No user-in-the-loop; post-processing removes spurious annotations based on column coherence."
        },
        "domain": {
            "domain": "independent",
            "type": ""
        },
        "validation": {
            "goldStandard": "40 GFT tables (manual GS) and the Wiki Manual dataset (36 Wikipedia tables).",
            "metrics": [
                "Precision",
                "Recall",
                "F1"
            ]
        },
        "code": "",
        "license": "Not Specified",
        "inputs": {
            "typeOfTable": "Web tables",
            "tableSources": [
                "web",
                "wiki"
            ]
        },
        "kg": {
            "tripleStore": "DBpedia",
            "index": ""
        },
        "output": "",
        "applicationPurpose": "KG extension and data enrichment for points of interest; supports faceted browsing.",
        "userInterfaceTool": "Web UI (faceted browser)",
        "checkedByAuthor": false,
        "checkedByAi": true,
        "doi": "",
        "citations": [
            {
                "ref": "2009_bizer_dbpedia",
                "title": "DBpedia - A Crystallization Point for the Web of Data"
            },
            {
                "ref": "2008_cafarella_webtables",
                "title": "WebTables: Exploring the Power of Tables on the Web"
            },
            {
                "ref": "2011_venetis_recovering",
                "title": "Recovering Semantics of Tables on the Web"
            },
            {
                "ref": "2010_limaye_annotating",
                "title": "Annotating and Searching Web Tables Using Entities, Types and Relationships"
            }
        ],
        "uncertainFields": [
            {
                "field": "doi",
                "reason": "The DOI is not visible in the provided text."
            },
            {
                "field": "output",
                "reason": "The paper does not specify a serialisation format for the annotations."
            },
            {
                "field": "venue.acronym",
                "reason": "The proceedings are branded EDBT/ICDT; we used 'EDBT' but the joint acronym could also be considered."
            },
            {
                "field": "domain.domain",
                "reason": "Method is applied to POIs but claimed general; classified as independent with some ambiguity."
            },
            {
                "field": "userInterfaceTool",
                "reason": "The faceted browser is part of a broader application; unsure if it is packaged as a tool for this approach."
            },
            {
                "field": "techniqueTags",
                "reason": "Included 'rule-based' for pre/post-processing heuristics; the main contribution is SVM-based supervision."
            },
            {
                "field": "inputs.tableSources",
                "reason": "Included 'wiki' due to evaluation on Wikipedia tables; primary source is GFT on the web."
            }
        ]
    },
    {
        "id": "2013_zhang_infogather",
        "added": "",
        "year": 2013,
        "firstAuthor": "Zhang",
        "authors": [
            "Meihui Zhang",
            "Kaushik Chakrabarti"
        ],
        "title": "InfoGather+: Semantic Matching and Annotation of Numeric and Time-Varying Attributes in Web Tables",
        "venue": {
            "type": "conference",
            "acronym": "SIGMOD"
        },
        "nameOfApproach": "InfoGather+",
        "techniqueTags": [
            "rule-based"
        ],
        "coreTasks": {
            "cta": false,
            "cpa": false,
            "cea": false,
            "cnea": false
        },
        "supportTasks": {
            "dataPreparation": {
                "description": "Extract relational HTML tables from web crawl, split to entity–attribute binaries, and build indexes for entities, labels, and graph edges. Hard-coded unit/scale conversion rules and year tokens support matching and conversions. ",
                "spellChecker": "",
                "unitsOfMeasurements": "Pre-defined conversion rules (e.g., USD↔Euro; bil↔mil) and synonyms for units/scales. "
            },
            "columnClassification": "",
            "subjectDetection": "",
            "datatypeAnnotation": "",
            "typeAnnotation": "",
            "predicateAnnotation": "",
            "nilAnnotation": "",
            "entityLinking": {
                "description": "",
                "candidateGeneration": "",
                "entityDisambiguation": ""
            }
        },
        "mainMethod": {
            "type": "unsupervised",
            "technique": "Probabilistic graphical model (Markov random field) with label propagation and rule-based conversions"
        },
        "revision": {
            "type": "fully automated",
            "description": "Joint inference over labels and edges produces results automatically; no user-in-the-loop editing is described. "
        },
        "domain": {
            "domain": "independent",
            "type": ""
        },
        "validation": {
            "goldStandard": "Forbes Global 2000 (2011), Wikipedia list of countries by area, Tax Foundation corporate tax rates, City Mayors 2011 cities. ",
            "metrics": [
                "Precision",
                "Recall",
                "Accuracy"
            ]
        },
        "code": "",
        "license": "Not Specified",
        "inputs": {
            "typeOfTable": "HTML tables",
            "tableSources": [
                "web"
            ]
        },
        "output": "",
        "applicationPurpose": "Entity augmentation for numeric and time-varying attributes using a semantic graph.",
        "userInterfaceTool": "",
        "checkedByAuthor": false,
        "checkedByAi": true,
        "doi": "https://doi.org/10.1145/2463676.2465276",
        "citations": [
            {
                "ref": "2012_yakout_infogather",
                "title": "InfoGather: entity augmentation and attribute discovery by holistic matching with web tables"
            },
            {
                "ref": "2010_limaye_annotating",
                "title": "Annotating and searching web tables using entities, types and relationships"
            },
            {
                "ref": "2012_pimplikar_answering",
                "title": "Answering table queries on the web using column keywords"
            },
            {
                "ref": "2008_cafarella_webtables",
                "title": "WebTables: exploring the power of tables on the web"
            },
            {
                "ref": "2009_cafarella_data",
                "title": "Data integration for the relational web"
            },
            {
                "ref": "2011_venetis_recovering",
                "title": "Recovering semantics of tables on the web"
            }
        ],
        "uncertainFields": [
            {
                "field": "output",
                "reason": "The paper reports augmented table results but does not specify an export format (e.g., CSV/RDF). "
            },
            {
                "field": "userInterfaceTool",
                "reason": "An API is described conceptually, but no concrete UI/tool name is provided. "
            },
            {
                "field": "code",
                "reason": "No repository or downloadable implementation is referenced."
            },
            {
                "field": "mainMethod.type",
                "reason": "Treated as unsupervised since no labelled training data are used; if heuristics are considered supervision, one might argue 'hybrid'. "
            },
            {
                "field": "inputs.typeOfTable",
                "reason": "They refer to 'web/HTML tables'; we selected 'HTML tables' to match the schema wording. "
            },
            {
                "field": "validation.metrics",
                "reason": "Paper explicitly discusses precision/recall and accuracy for components; other metrics like F1 are not clearly reported. "
            },
            {
                "field": "doi",
                "reason": "DOI confirmed via ACM Digital Library."
            }
        ]
    },
    {
        "id": "2014_sekhavat_knowledge",
        "added": "",
        "year": 2014,
        "firstAuthor": "Sekhavat",
        "authors": [
            "Yoones A. Sekhavat",
            "Francesco di Paolo",
            "Denilson Barbosa",
            "Paolo Merialdo"
        ],
        "title": "Knowledge Base Augmentation using Tabular Data",
        "venue": {
            "type": "workshop",
            "acronym": "LDOW"
        },
        "nameOfApproach": "",
        "techniqueTags": [
            "rule-based",
            "ontology-driven"
        ],
        "coreTasks": {
            "cta": false,
            "cpa": true,
            "cea": false,
            "cnea": false
        },
        "supportTasks": {
            "dataPreparation": {
                "description": "Link table entities to a text corpus via exact string matching, then extract and match inter-entity text spans to known relational patterns; patterns are indexed for efficiency.",
                "spellChecker": "",
                "unitsOfMeasurements": ""
            },
            "columnClassification": "",
            "subjectDetection": "",
            "datatypeAnnotation": "",
            "typeAnnotation": "",
            "predicateAnnotation": "Assign a KB relation to the pair of columns using a probabilistic model over textual patterns (rank aggregation vs global ranking) and apply a confidence threshold.",
            "nilAnnotation": "",
            "entityLinking": {
                "description": "",
                "candidateGeneration": "",
                "entityDisambiguation": ""
            }
        },
        "mainMethod": {
            "type": "unsupervised",
            "technique": "rule-based"
        },
        "revision": {
            "type": "fully automated",
            "description": "Pipeline computes posterior probabilities for relations from observed patterns and selects the most probable relation without manual review."
        },
        "domain": {
            "domain": "independent",
            "type": ""
        },
        "validation": {
            "goldStandard": "Ground truth built from YAGO facts matched in the NELL corpus; 25 entity pairs per relation over 23–24 relations; evaluation reports the rank position of the correct relation.",
            "metrics": []
        },
        "code": "",
        "license": "Not Specified",
        "inputs": {
            "typeOfTable": "HTML tables and spreadsheets",
            "tableSources": [
                "web",
                "spreadsheet",
                "wiki"
            ]
        },
        "kg": {
            "tripleStore": "YAGO",
            "index": "Patterns indexed with an in-memory suffix tree; uses the intersection of PATTY patterns and NELL triples (4,357 patterns; 108,699,400 triples)."
        },
        "output": "triples",
        "applicationPurpose": "Augment an existing knowledge base with new facts inferred from tabular data.",
        "userInterfaceTool": "",
        "checkedByAuthor": "",
        "checkedByAi": true,
        "doi": "",
        "citations": [
            {
                "ref": "2008_cafarella_webtables",
                "title": "WebTables: Exploring the power of tables on the web"
            },
            {
                "ref": "2010_limaye_annotating",
                "title": "Annotating and searching web tables using entities, types and relationships"
            },
            {
                "ref": "2011_venetis_recovering",
                "title": "Recovering semantics of tables on the web"
            },
            {
                "ref": "2012_nakashole_patty",
                "title": "Patty: A taxonomy of relational patterns with semantic types"
            },
            {
                "ref": "2007_suchanek_yago",
                "title": "YAGO: A core of semantic knowledge"
            },
            {
                "ref": "2009_mintz_distant",
                "title": "Distant supervision for relation extraction without labeled data"
            },
            {
                "ref": "2013_mulwad_semantic",
                "title": "Semantic Message Passing for Generating Linked Data from Tables"
            },
            {
                "ref": "2013_munoz_triplifying",
                "title": "Triplifying Wikipedia's tables"
            },
            {
                "ref": "2011_yosef_aida",
                "title": "AIDA: An online tool for accurate disambiguation of named entities in text and tables"
            }
        ],
        "uncertainFields": [
            {
                "field": "output",
                "reason": "The paper extracts relational triples but does not specify an output serialisation such as RDF."
            },
            {
                "field": "doi",
                "reason": "A DOI is not provided in the paper; LDOW workshop papers often lack DOIs."
            },
            {
                "field": "code",
                "reason": "A link to data is provided, but no code repository is mentioned."
            },
            {
                "field": "techniqueTags[1]",
                "reason": "Tagged as ontology-driven because relations come from YAGO; this could be debated as the core method is pattern-based."
            }
        ]
    },
    {
        "id": "2014_taheriyan_a",
        "added": "",
        "year": 2014,
        "firstAuthor": "Taheriyan",
        "authors": [
            "Mohsen Taheriyan",
            "Craig A. Knoblock",
            "Pedro Szekely",
            "Jose Luis Ambite"
        ],
        "title": "A Scalable Approach to Learn Semantic Models of Structured Sources",
        "venue": {
            "type": "conference",
            "acronym": "ICSC"
        },
        "nameOfApproach": "",
        "techniqueTags": [
            "CRF",
            "ontology-driven"
        ],
        "coreTasks": {
            "cta": true,
            "cpa": true,
            "cea": false,
            "cnea": false
        },
        "supportTasks": {
            "dataPreparation": {
                "description": "",
                "spellChecker": "",
                "unitsOfMeasurements": ""
            },
            "columnClassification": "",
            "subjectDetection": "",
            "datatypeAnnotation": "Literal attributes are mapped to ontology data properties during semantic typing.",
            "typeAnnotation": "Semantic types for attributes are learned with a CRF over attribute names and sample values.",
            "predicateAnnotation": "Relationships are inferred by building a weighted graph from known models and ontologies and extracting a minimal Steiner tree.",
            "nilAnnotation": "",
            "entityLinking": {
                "description": "",
                "candidateGeneration": "",
                "entityDisambiguation": ""
            }
        },
        "mainMethod": {
            "type": "hybrid",
            "technique": "CRF for semantic typing + Steiner-tree-based graph search using domain ontologies and known models"
        },
        "revision": {
            "type": "semi automated",
            "description": "Produces ranked candidate semantic models automatically; minimal user input may select or correct the final model."
        },
        "domain": {
            "domain": "dependent",
            "type": "cultural heritage / museums"
        },
        "validation": {
            "goldStandard": "Manually created semantic models for 29 museum sources",
            "metrics": [
                "Precision",
                "Recall"
            ]
        },
        "code": "",
        "license": "Not Specified",
        "inputs": {
            "typeOfTable": "Relational databases, spreadsheets, XML/JSON sources and Web APIs",
            "tableSources": [
                "relational",
                "spreadsheet",
                "web"
            ]
        },
        "kg": {
            "tripleStore": "EDM, AAC, SKOS, Dublin Core, FOAF, ORE, ElementsGr2 (domain ontologies)",
            "index": ""
        },
        "output": "RDF",
        "applicationPurpose": "Learn semantic source models for data integration and RDF publishing.",
        "userInterfaceTool": "",
        "checkedByAuthor": "",
        "checkedByAi": true,
        "doi": "https://doi.org/10.1109/ICSC.2014.13",
        "citations": [
            {
                "ref": "2012_doan_principles",
                "title": "Principles of Data Integration"
            },
            {
                "ref": "2011_venetis_recovering",
                "title": "Recovering Semantics of Tables on the Web"
            },
            {
                "ref": "2010_limaye_annotating",
                "title": "Annotating and Searching Web Tables Using Entities, Types and Relationships"
            },
            {
                "ref": "2013_szekely_connecting",
                "title": "Connecting the Smithsonian American Art Museum to the Linked Data Cloud"
            },
            {
                "ref": "2001_lafferty_conditional",
                "title": "Conditional Random Fields: Probabilistic Models for Segmenting and Labeling Sequence Data"
            },
            {
                "ref": "1981_kou_a",
                "title": "A Fast Algorithm for Steiner Trees"
            },
            {
                "ref": "1987_winter_steiner",
                "title": "Steiner Problem in Networks - A survey"
            },
            {
                "ref": "2013_taheriyan_a",
                "title": "A Graph-based Approach to Learn Semantic Descriptions of Data Sources"
            },
            {
                "ref": "2012_knoblock_semi",
                "title": "Semi-Automatically Mapping Structured Sources into the Semantic Web"
            },
            {
                "ref": "2007_carman_learning",
                "title": "Learning Semantic Definitions of Online Information Sources"
            },
            {
                "ref": "2004_dhamankar_imap",
                "title": "iMAP: Discovering Complex Semantic Matches between Database Schemas"
            }
        ],
        "uncertainFields": [
            {
                "field": "nameOfApproach",
                "reason": "The paper presents an approach but does not introduce a specific system name."
            },
            {
                "field": "userInterfaceTool",
                "reason": "No concrete UI/tool is presented for this method; Karma is cited only in related work."
            },
            {
                "field": "kg.tripleStore",
                "reason": "They use several domain ontologies rather than a single public KG or triplestore."
            },
            {
                "field": "inputs.typeOfTable",
                "reason": "Covers heterogeneous structured sources beyond classic tabular formats; phrasing may be broader than typical table labels."
            },
            {
                "field": "code",
                "reason": "No repository link is provided in the paper; related software may exist elsewhere."
            },
            {
                "field": "validation.goldStandard",
                "reason": "Described as manual models by experts; no specific GS name is given."
            },
            {
                "field": "revision.type",
                "reason": "The text mentions minimal user input but does not formalise an interaction protocol."
            }
        ]
    },
    {
        "id": "2014_taheriyan_a",
        "added": "",
        "year": 2014,
        "firstAuthor": "Taheriyan",
        "authors": [
            "Mohsen Taheriyan",
            "Craig A. Knoblock",
            "Pedro Szekely",
            "José Luis Ambite"
        ],
        "title": "A Scalable Approach to Learn Semantic Models of Structured Sources",
        "venue": {
            "type": "conference",
            "acronym": "ICSC"
        },
        "nameOfApproach": "",
        "techniqueTags": [
            "CRF",
            "ontology-driven"
        ],
        "coreTasks": {
            "cta": true,
            "cpa": true,
            "cea": false,
            "cnea": false
        },
        "supportTasks": {
            "dataPreparation": {
                "description": "",
                "spellChecker": "",
                "unitsOfMeasurements": ""
            },
            "columnClassification": "",
            "subjectDetection": "",
            "datatypeAnnotation": "",
            "typeAnnotation": "Assigns semantic types to source attributes using a CRF-based classifier with features from attribute names and sample data.",
            "predicateAnnotation": "Infers relationships between typed attributes by building a weighted graph from known models and ontologies and extracting minimal connecting trees (Steiner tree).",
            "nilAnnotation": "",
            "entityLinking": {
                "description": "",
                "candidateGeneration": "",
                "entityDisambiguation": ""
            }
        },
        "mainMethod": {
            "type": "hybrid",
            "technique": "CRF for semantic typing combined with ontology-driven graph search and Steiner tree approximation"
        },
        "revision": {
            "type": "fully automated",
            "description": "Generates and ranks candidate semantic models automatically; minimal user input is implied but not required by the core method."
        },
        "domain": {
            "domain": "dependent",
            "type": "cultural heritage / museums"
        },
        "validation": {
            "goldStandard": "Manually created semantic models for 29 museum data sources using EDM, AAC, SKOS, Dublin Core, FOAF, ORE, and ElementsGr2 ontologies",
            "metrics": [
                "Precision",
                "Recall"
            ]
        },
        "code": "",
        "license": "Not Specified",
        "inputs": {
            "typeOfTable": "Structured sources (relational databases, spreadsheets, XML, JSON, Web APIs)",
            "tableSources": [
                "relational",
                "spreadsheet",
                "web"
            ]
        },
        "kg": {
            "tripleStore": "EDM, AAC, SKOS, Dublin Core, FOAF, ORE, ElementsGr2",
            "index": ""
        },
        "output": "RDF",
        "applicationPurpose": "Learning semantic source models to support integration and RDF publishing",
        "userInterfaceTool": "",
        "checkedByAuthor": "",
        "checkedByAi": true,
        "doi": "https://doi.org/10.1109/ICSC.2014.13",
        "citations": [
            {
                "ref": "2012_doan_principles",
                "title": "Principles of Data Integration"
            },
            {
                "ref": "2001_lafferty_conditional",
                "title": "Conditional Random Fields: Probabilistic Models for Segmenting and Labeling Sequence Data"
            },
            {
                "ref": "1981_kou_a",
                "title": "A Fast Algorithm for Steiner Trees"
            },
            {
                "ref": "2012_goel_exploiting",
                "title": "Exploiting Structure within Data for Accurate Labeling Using Conditional Random Fields"
            },
            {
                "ref": "2013_taheriyan_a",
                "title": "A Graph-based Approach to Learn Semantic Descriptions of Data Sources"
            },
            {
                "ref": "2013_szekely_connecting",
                "title": "Connecting the Smithsonian American Art Museum to the Linked Data Cloud"
            },
            {
                "ref": "2012_knoblock_semi",
                "title": "Semi-Automatically Mapping Structured Sources into the Semantic Web"
            },
            {
                "ref": "2011_venetis_recovering",
                "title": "Recovering Semantics of Tables on the Web"
            },
            {
                "ref": "2010_limaye_annotating",
                "title": "Annotating and Searching Web Tables Using Entities, Types and Relationships"
            }
        ],
        "uncertainFields": [
            {
                "field": "nameOfApproach",
                "reason": "The paper does not present a specific proper name for the proposed method beyond describing it as a scalable approach."
            },
            {
                "field": "revision.type",
                "reason": "The text emphasises automation with minimal user input, but does not explicitly specify a post-processing review step."
            },
            {
                "field": "userInterfaceTool",
                "reason": "No dedicated UI/tool is introduced for this paper; prior work references Karma, but its direct use here is not stated."
            },
            {
                "field": "kg.tripleStore",
                "reason": "The work uses multiple domain ontologies rather than a single concrete KG instance like DBpedia or Wikidata."
            },
            {
                "field": "inputs.tableSources",
                "reason": "‘Web’ is included to reflect Web APIs mentioned generally; exact source mix for the evaluated dataset is not exhaustively enumerated."
            },
            {
                "field": "applicationPurpose",
                "reason": "Purpose is inferred from the introduction and example (integration and RDF publishing) rather than stated as a formal application label."
            }
        ]
    },
    {
        "id": "2015_bhagavatula_tabel",
        "added": "",
        "year": 2015,
        "firstAuthor": "Bhagavatula",
        "authors": [
            "Chandra Sekhar Bhagavatula",
            "Thanapon Noraset",
            "Doug Downey"
        ],
        "title": "TabEL: Entity Linking in Web Tables",
        "venue": {
            "type": "conference",
            "acronym": "ISWC"
        },
        "nameOfApproach": "TabEL",
        "techniqueTags": [],
        "coreTasks": {
            "cta": false,
            "cpa": false,
            "cea": true,
            "cnea": false
        },
        "supportTasks": {
            "dataPreparation": {
                "description": "Wikipedia and Web tables are normalised to r×c matrices; mentions are identified and priors P(e|s) are estimated from hyperlinks to build features.",
                "spellChecker": "",
                "unitsOfMeasurements": ""
            },
            "columnClassification": "",
            "subjectDetection": "",
            "datatypeAnnotation": "",
            "typeAnnotation": "",
            "predicateAnnotation": "",
            "nilAnnotation": "",
            "entityLinking": {
                "description": "Entity linking over table cells using collective coherence across rows and columns.",
                "candidateGeneration": "For each surface s, candidates are all KB entities with non-zero P(e|s) estimated from Web and Wikipedia hyperlinks.",
                "entityDisambiguation": "Graphical model over row/column cliques with Iterative Classification Algorithm (ICA); a trained logistic-regression ranker selects entities using prior, semantic relatedness and context features."
            }
        },
        "mainMethod": {
            "type": "supervised",
            "technique": "Logistic regression ranking with collective inference (ICA)",
            "supervision": {
                "type": "supervised"
            }
        },
        "revision": {
            "type": "fully automated",
            "description": "Disambiguation is performed automatically without human validation in the loop."
        },
        "domain": {
            "domain": "independent",
            "type": "generic"
        },
        "validation": {
            "goldStandard": "WEB MANUAL, WEB MANUAL-FIXED, WIKI LINKS, WIKI LINKS-RANDOM, TABEL 35K",
            "metrics": [
                "Accuracy",
                "Macro-Precision",
                "Macro-Recall",
                "Macro-F1"
            ]
        },
        "code": "",
        "license": "Not Specified",
        "inputs": {
            "typeOfTable": "Web tables",
            "tableSources": [
                "web",
                "wiki"
            ]
        },
        "kg": {
            "tripleStore": "YAGO",
            "index": ""
        },
        "output": "",
        "applicationPurpose": "Entity linking in Web tables to support semantic table interpretation and downstream KG augmentation.",
        "userInterfaceTool": "",
        "checkedByAuthor": "",
        "checkedByAi": true,
        "doi": "",
        "citations": [
            {
                "ref": "2008_cafarella_webtables",
                "title": "WebTables: Exploring the Power of Tables on the Web"
            },
            {
                "ref": "2010_limaye_annotating",
                "title": "Annotating and Searching Web Tables Using Entities, Types and Relationships"
            },
            {
                "ref": "2013_mulwad_semantic",
                "title": "Semantic Message Passing for Generating Linked Data from Tables"
            },
            {
                "ref": "2007_suchanek_yago",
                "title": "YAGO: A Core of Semantic Knowledge"
            },
            {
                "ref": "2012_hecht_explanatory",
                "title": "Explanatory semantic relatedness and explicit spatialization for exploratory search"
            },
            {
                "ref": "2008_witten_an",
                "title": "An effective, low-cost measure of semantic relatedness obtained from Wikipedia links"
            }
        ],
        "uncertainFields": [
            {
                "field": "doi",
                "reason": "The DOI is not stated in the text available."
            },
            {
                "field": "code",
                "reason": "Authors mention releasing resources, but no code URL is provided."
            },
            {
                "field": "output",
                "reason": "The paper reports entity annotations but no explicit output serialisation format."
            },
            {
                "field": "kg.index",
                "reason": "No specific indexing structure for the KB is described."
            },
            {
                "field": "userInterfaceTool",
                "reason": "No UI or tool front-end is mentioned."
            },
            {
                "field": "inputs.typeOfTable",
                "reason": "They target both Wikipedia and general Web (HTML) tables; 'Web tables' is used generically."
            },
            {
                "field": "techniqueTags",
                "reason": "The approach uses logistic regression and collective inference, which do not map to the allowed tags."
            }
        ]
    },
    {
        "id": "2015_ramnandan_assigning",
        "added": "",
        "year": 2015,
        "firstAuthor": "Ramnandan",
        "authors": [
            "S.K. Ramnandan",
            "Amol Mittal",
            "Craig A. Knoblock",
            "Pedro Szekely"
        ],
        "title": "Assigning Semantic Labels to Data Sources",
        "venue": {
            "type": "conference",
            "acronym": "ESWC"
        },
        "nameOfApproach": "SemanticTyper",
        "techniqueTags": [],
        "coreTasks": {
            "cta": true,
            "cpa": false,
            "cea": false,
            "cnea": false
        },
        "supportTasks": {
            "dataPreparation": {
                "description": "Tokenisation and normalisation of values; stemming and stop-word removal for text; handling of numeric/text mixtures.",
                "spellChecker": "",
                "unitsOfMeasurements": ""
            },
            "columnClassification": "Heuristic detection of numeric vs textual columns based on fraction of numeric values.",
            "subjectDetection": "",
            "datatypeAnnotation": "",
            "typeAnnotation": "Assigns class/property labels using TF-IDF cosine similarity for text and KS test for numeric columns.",
            "predicateAnnotation": "",
            "nilAnnotation": "",
            "entityLinking": {
                "description": "",
                "candidateGeneration": "",
                "entityDisambiguation": ""
            }
        },
        "mainMethod": {
            "type": "supervised",
            "technique": "TF-IDF cosine similarity for textual columns combined with Kolmogorov–Smirnov two-sample test for numeric columns",
            "supervision": {
                "type": "supervised"
            }
        },
        "revision": {
            "type": "fully automated",
            "description": "Produces top-k candidate labels with confidence scores; no user validation stage described."
        },
        "domain": {
            "domain": "independent",
            "type": "generic"
        },
        "validation": {
            "goldStandard": "Europeana Data Model (museum), DBpedia City properties, and weather/phone/flight datasets",
            "metrics": [
                "MRR"
            ]
        },
        "code": "https://github.com/usc-isi-i2/eswc-2015-semantic-typing",
        "license": "Not Specified",
        "inputs": {
            "typeOfTable": "Web tables and heterogeneous sources (tables, XML, JSON)",
            "tableSources": [
                "web",
                "wiki"
            ]
        },
        "kg": {
            "tripleStore": "DBpedia; Europeana Data Model",
            "index": "Apache Lucene used to index textual label documents"
        },
        "output": "",
        "applicationPurpose": "Automated semantic labelling of data source attributes to support data integration.",
        "userInterfaceTool": "",
        "checkedByAuthor": "",
        "checkedByAi": true,
        "doi": "https://doi.org/10.1007/978-3-319-18818-8_25",
        "citations": [
            {
                "ref": "2012_goel_exploiting",
                "title": "Exploiting structure within data for accurate labeling using conditional random fields"
            },
            {
                "ref": "2010_limaye_annotating",
                "title": "Annotating and searching web tables using entities, types and relationships"
            },
            {
                "ref": "2011_venetis_recovering",
                "title": "Recovering semantics of tables on the web"
            },
            {
                "ref": "2013_stonebraker_data",
                "title": "Data curation at scale: the Data Tamer system"
            },
            {
                "ref": "2009_ambite_automatically",
                "title": "Automatically Constructing Semantic Web Services from Online Sources"
            }
        ],
        "uncertainFields": [
            {
                "field": "techniqueTags",
                "reason": "The paper does not use any of the allowed tag categories (e.g., SVM/CRF/transformer/rule-based) as core techniques."
            },
            {
                "field": "output",
                "reason": "No serialisation format (e.g., RDF/JSON-LD) is specified; the system outputs label predictions only."
            },
            {
                "field": "kg.tripleStore",
                "reason": "DBpedia is used; Europeana Data Model is an ontology rather than a triple store, but both are cited as resources."
            },
            {
                "field": "kg.index",
                "reason": "Lucene indexes training ‘documents’ of label values, not a KG index; mapping this to the KG 'index' field may be approximate."
            },
            {
                "field": "inputs.typeOfTable",
                "reason": "They consider generic data sources (tables, XML, JSON); phrasing may not match a single specific table type."
            },
            {
                "field": "license",
                "reason": "The paper shares a GitHub repo but the licence is not specified in the paper text."
            },
            {
                "field": "applicationPurpose",
                "reason": "Purpose is inferred from motivation; no explicit application label is given."
            }
        ]
    },
    {
        "id": "2015_ritze_matching",
        "added": "",
        "year": 2015,
        "firstAuthor": "Ritze",
        "authors": [
            "Dominique Ritze",
            "Oliver Lehmberg",
            "Christian Bizer"
        ],
        "title": "Matching HTML Tables to DBpedia",
        "venue": {
            "type": "conference",
            "acronym": "WIMS"
        },
        "nameOfApproach": "T2K Match",
        "techniqueTags": [
            "ontology-driven",
            "rule-based"
        ],
        "coreTasks": {
            "cta": true,
            "cpa": true,
            "cea": true,
            "cnea": false
        },
        "supportTasks": {
            "dataPreparation": {
                "description": "Clean HTML, split value lists, lower-case and normalise values; detect headers, entity-label column, and data types.",
                "spellChecker": "",
                "unitsOfMeasurements": "Normalisation of units via ~200 handcrafted conversion rules (e.g., 8mi2 → 20.72 million m2)."
            },
            "columnClassification": "",
            "subjectDetection": "Heuristic to detect the entity-label attribute: string column with most unique values (tie → left-most).",
            "datatypeAnnotation": "Detect column data types (string, numeric, timestamp, coordinate) using ~100 regexes to select similarity measures.",
            "typeAnnotation": "Aggregate property scores to select table-to-class correspondences.",
            "predicateAnnotation": "Duplicate-based schema matching aggregates value similarities to map attributes to DBpedia properties.",
            "nilAnnotation": "",
            "entityLinking": {
                "description": "Iterative instance–schema matching to select a DBpedia resource per row with thresholding.",
                "candidateGeneration": "Search DBpedia labels (Lucene), keep top-k, refine with class constraints; handle surface forms and redirects.",
                "entityDisambiguation": "Iteratively weight value similarities with property/class scores and pick the top candidate."
            }
        },
        "mainMethod": {
            "type": "unsupervised",
            "technique": "rule-based iterative schema/instance matching"
        },
        "revision": {
            "type": "fully automated",
            "description": "Outputs are produced automatically without user interaction; evaluation is performed against a gold standard."
        },
        "domain": {
            "domain": "independent",
            "type": "cross-domain web tables"
        },
        "validation": {
            "goldStandard": "T2D Gold Standard (1,748 tables schema-level; 233 tables entity-level; 26,124 row-to-entity; 7,983 column-to-property).",
            "metrics": [
                "Precision",
                "Recall",
                "F1"
            ]
        },
        "code": "http://dws.informatik.uni-mannheim.de/en/research/T2K",
        "license": "Not Specified",
        "inputs": {
            "typeOfTable": "HTML tables",
            "tableSources": [
                "web"
            ]
        },
        "kg": {
            "tripleStore": "DBpedia",
            "index": "Lucene"
        },
        "output": "",
        "applicationPurpose": "Knowledge base extension (slot filling).",
        "userInterfaceTool": "",
        "checkedByAuthor": "",
        "checkedByAi": true,
        "doi": "https://doi.org/10.1145/2797115.2797118",
        "citations": [
            {
                "ref": "2008_cafarella_webtables",
                "title": "WebTables: Exploring the Power of Tables on the Web"
            },
            {
                "ref": "2010_limaye_annotating",
                "title": "Annotating and Searching Web Tables Using Entities, Types and Relationships"
            },
            {
                "ref": "2011_venetis_recovering",
                "title": "Recovering Semantics of Tables on the Web"
            },
            {
                "ref": "2014_dong_knowledge",
                "title": "Knowledge Vault: A Web-scale Approach to Probabilistic Knowledge Fusion"
            },
            {
                "ref": "2011_suchanek_paris",
                "title": "Paris: Probabilistic alignment of Relations, Instances, and Schema"
            },
            {
                "ref": "2012_wang_understanding",
                "title": "Understanding Tables on the Web"
            },
            {
                "ref": "2014_zhang_towards",
                "title": "Towards efficient and effective semantic table interpretation"
            },
            {
                "ref": "2014_gupta_biperpedia",
                "title": "Biperpedia: An Ontology for Search Applications"
            },
            {
                "ref": "2012_yakout_infogather",
                "title": "InfoGather: Entity Augmentation and Attribute Discovery by Holistic Matching with Web Tables"
            }
        ],
        "uncertainFields": [
            {
                "field": "code",
                "reason": "The paper references a project page with downloads; explicit source code availability is not clearly stated."
            },
            {
                "field": "output",
                "reason": "The output format of correspondences is not specified (e.g., RDF/CSV), only that correspondences are produced."
            },
            {
                "field": "userInterfaceTool",
                "reason": "No UI or tool front-end is described; likely a research prototype without a public UI."
            },
            {
                "field": "coreTasks.cnea",
                "reason": "The gold standard marks some rows as not matchable, but the approach does not explicitly perform NIL prediction."
            },
            {
                "field": "techniqueTags",
                "reason": "Classed as ontology-driven and rule-based based on KB-driven, heuristic matching; no explicit ML model is reported."
            }
        ]
    },
    {
        "id": "2016_ermilov_taipan",
        "added": "",
        "year": 2016,
        "firstAuthor": "Ermilov",
        "authors": [
            "Ivan Ermilov",
            "Axel-Cyrille Ngonga Ngomo"
        ],
        "title": "TAIPAN: Automatic Property Mapping for Tabular Data",
        "venue": {
            "type": "conference",
            "acronym": "EKAW"
        },
        "nameOfApproach": "Taipan",
        "techniqueTags": [
            "rule-based",
            "SVM",
            "ontology-driven"
        ],
        "coreTasks": {
            "cta": false,
            "cpa": true,
            "cea": false,
            "cnea": false
        },
        "supportTasks": {
            "dataPreparation": {
                "description": "",
                "spellChecker": "",
                "unitsOfMeasurements": ""
            },
            "columnClassification": "",
            "subjectDetection": "Identifies the subject column using support (entity disambiguation via AGDISTIS) and connectivity features, then classifies columns with learned models. ",
            "datatypeAnnotation": "",
            "typeAnnotation": "",
            "predicateAnnotation": "Maps binary relations from the subject column to DBpedia predicates using triple-pattern queries and LOV-derived seed properties with probabilistic ranking. ",
            "nilAnnotation": "",
            "entityLinking": {
                "description": "",
                "candidateGeneration": "",
                "entityDisambiguation": ""
            }
        },
        "mainMethod": {
            "type": "hybrid",
            "technique": "SVM + rule-based"
        },
        "revision": {
            "type": "fully automated",
            "description": "Automatic scoring and selection of subject columns and properties; no interactive correction is required. "
        },
        "domain": {
            "domain": "independent",
            "type": "cross-domain"
        },
        "validation": {
            "goldStandard": "T2D* (manually curated from T2D) and DBD (DBpedia Table Dataset). ",
            "metrics": [
                "Precision",
                "Recall",
                "F1"
            ]
        },
        "code": "https://github.com/aksw/taipan",
        "license": "Not Specified",
        "inputs": {
            "typeOfTable": "Web tables",
            "tableSources": [
                "web",
                "wiki"
            ]
        },
        "kg": {
            "tripleStore": "DBpedia",
            "index": "LOV reverse index over rdfs:label and rdfs:comment with score threshold. "
        },
        "output": "RDF",
        "applicationPurpose": "Table expansion and knowledge base augmentation. ",
        "userInterfaceTool": "",
        "checkedByAuthor": "",
        "checkedByAi": true,
        "doi": "https://doi.org/10.1007/978-3-319-49004-5_11",
        "citations": [
            {
                "ref": "2015_ritze_matching",
                "title": "Matching HTML tables to DBpedia"
            },
            {
                "ref": "2011_venetis_recovering",
                "title": "Recovering semantics of tables on the web"
            },
            {
                "ref": "2014_usbeck_agdistis",
                "title": "AGDISTIS - graph-based disambiguation of named entities using linked data"
            },
            {
                "ref": "2010_limaye_annotating",
                "title": "Annotating and searching web tables using entities, types and relationships"
            }
        ],
        "uncertainFields": [
            {
                "field": "mainMethod.technique",
                "reason": "The paper evaluates several classifiers (e.g., SVM, decision tree) for subject detection and uses rule-based scoring for property mapping; summarised here as 'SVM + rule-based'. "
            },
            {
                "field": "inputs.tableSources",
                "reason": "Includes 'wiki' because one evaluation dataset is generated from DBpedia; the main corpus is web tables. "
            },
            {
                "field": "kg.index",
                "reason": "Described as LOV reverse index with a score threshold; exact indexing details are brief. "
            },
            {
                "field": "license",
                "reason": "License is not stated in the paper; repository license not verified in the text. "
            },
            {
                "field": "userInterfaceTool",
                "reason": "No UI for Taipan is mentioned; only annotation interfaces for gold-standard curation are referenced. "
            },
            {
                "field": "output",
                "reason": "Approach outputs RDF triples conceptually, but no explicit serialisation format is specified. "
            }
        ]
    },
    {
        "id": "2016_neumaier_multi-level",
        "added": "",
        "year": 2016,
        "firstAuthor": "Neumaier",
        "authors": [
            "Sebastian Neumaier",
            "Jürgen Umbrich",
            "Josiane Xavier Parreira",
            "Axel Polleres"
        ],
        "title": "Multi-level semantic labelling of numerical values",
        "venue": {
            "type": "conference",
            "acronym": "ISWC"
        },
        "nameOfApproach": "",
        "techniqueTags": [
            "clustering",
            "ontology-driven"
        ],
        "coreTasks": {
            "cta": false,
            "cpa": false,
            "cea": false,
            "cnea": false
        },
        "supportTasks": {
            "dataPreparation": {
                "description": "Constructs a background knowledge graph from DBpedia, grouping numerical properties by subjects and contexts, and computes descriptive statistics/KS distances.",
                "spellChecker": "",
                "unitsOfMeasurements": ""
            },
            "columnClassification": "",
            "subjectDetection": "",
            "datatypeAnnotation": "",
            "typeAnnotation": "",
            "predicateAnnotation": "",
            "nilAnnotation": "",
            "entityLinking": {
                "description": "",
                "candidateGeneration": "",
                "entityDisambiguation": ""
            }
        },
        "mainMethod": {
            "type": "unsupervised",
            "technique": "k-nearest neighbours over a hierarchically clustered background graph using Kolmogorov–Smirnov distance and descriptive statistics"
        },
        "revision": {
            "type": "fully automated",
            "description": "Predictions are produced automatically by nearest neighbour ranking without user intervention."
        },
        "domain": {
            "domain": "independent",
            "type": ""
        },
        "validation": {
            "goldStandard": "DBpedia 3.9 dump with 50 frequent numerical properties; large-scale test nodes derived from held-out subjects",
            "metrics": [
                "Accuracy",
                "Top-1 Accuracy",
                "Top-k Accuracy"
            ]
        },
        "code": "",
        "license": "Not Specified",
        "inputs": {
            "typeOfTable": "CSV tables",
            "tableSources": [
                "wiki",
                "gov-open-data"
            ]
        },
        "kg": {
            "tripleStore": "DBpedia",
            "index": ""
        },
        "output": "",
        "applicationPurpose": "Semantic labelling of numerical columns and their contexts in tabular data",
        "userInterfaceTool": "",
        "checkedByAuthor": "",
        "checkedByAi": true,
        "doi": "",
        "citations": [
            {
                "ref": "2013_adelfio_schema",
                "title": "Schema extraction for tabular data on the web"
            },
            {
                "ref": "2015_ramnandan_assigning",
                "title": "Assigning semantic labels to data sources"
            },
            {
                "ref": "2015_tandy_generating",
                "title": "Generating RDF from tabular data on the web"
            },
            {
                "ref": "2014_fleischhacker_detecting",
                "title": "Detecting errors in numerical linked data using cross-checked outlier detection"
            },
            {
                "ref": "2014_wienand_detecting",
                "title": "Detecting incorrect numerical data in DBpedia"
            },
            {
                "ref": "2014_zhang_towards",
                "title": "Towards efficient and effective semantic table interpretation"
            }
        ],
        "uncertainFields": [
            {
                "field": "doi",
                "reason": "The DOI is not stated in the available text."
            },
            {
                "field": "output",
                "reason": "No explicit output serialisation or format is described."
            },
            {
                "field": "coreTasks.cta",
                "reason": "The paper labels numeric columns with properties and contexts but does not explicitly frame this as CTA."
            },
            {
                "field": "coreTasks.cpa",
                "reason": "Although properties are predicted, the paper does not present this as CPA in the STI sense."
            },
            {
                "field": "inputs.typeOfTable",
                "reason": "The approach is demonstrated on CSV-like Open Data and DBpedia-derived values; exact table type wording is inferred."
            },
            {
                "field": "userInterfaceTool",
                "reason": "A prototype is mentioned but no UI/tool is specified."
            },
            {
                "field": "kg.index",
                "reason": "Indexing details are not provided."
            },
            {
                "field": "license",
                "reason": "No license information is specified."
            },
            {
                "field": "validation.goldStandard",
                "reason": "Summarised from the description; no formal GS name is given."
            },
            {
                "field": "mainMethod.technique",
                "reason": "Technique phrasing paraphrases the described method."
            }
        ]
    },
    {
        "id": "2016_pham_semantic",
        "added": "",
        "year": 2016,
        "firstAuthor": "Pham",
        "authors": [
            "Minh Pham",
            "Suresh Alse",
            "Craig A. Knoblock",
            "Pedro Szekely"
        ],
        "title": "Semantic labeling: A domain-independent approach",
        "venue": {
            "type": "conference",
            "acronym": "ISWC"
        },
        "nameOfApproach": "DSL (Domain-independent Semantic Labeler) ",
        "techniqueTags": [],
        "coreTasks": {
            "cta": true,
            "cpa": true,
            "cea": false,
            "cnea": false
        },
        "supportTasks": {
            "dataPreparation": {
                "description": "Computes similarity features over attribute names and values (e.g., Jaccard, TF-IDF cosine, numeric Jaccard, KS test, Mann–Whitney histogram) with adjustments for text/number mixes. ",
                "spellChecker": "",
                "unitsOfMeasurements": ""
            },
            "columnClassification": "",
            "subjectDetection": "",
            "datatypeAnnotation": "",
            "typeAnnotation": "Assigns each column a KG class as part of a <class, property> semantic type. ",
            "predicateAnnotation": "Matches columns to KG properties (property matching) using learned similarity-based ranking. ",
            "nilAnnotation": "",
            "entityLinking": {
                "description": "",
                "candidateGeneration": "",
                "entityDisambiguation": ""
            }
        },
        "mainMethod": {
            "type": "supervised",
            "technique": "Logistic Regression over similarity metrics",
            "supervision": {
                "type": "supervised"
            }
        },
        "revision": {
            "type": "fully automated",
            "description": "Fully automatic ranking of top-k semantic types using classifier probabilities; no user-in-the-loop editing. "
        },
        "domain": {
            "domain": "independent",
            "type": "generic"
        },
        "validation": {
            "goldStandard": "Evaluated on city, museum, soccer, and weather datasets; additionally on the T2D Gold Standard for property matching. ",
            "metrics": [
                "MRR",
                "F1"
            ]
        },
        "code": "https://github.com/minhptx/iswc-2016-semantic-labeling.git",
        "license": "Not Specified",
        "inputs": {
            "typeOfTable": "Web tables, spreadsheets, and relational tables",
            "tableSources": [
                "web",
                "spreadsheet",
                "relational"
            ]
        },
        "kg": {
            "tripleStore": "DBpedia",
            "index": ""
        },
        "output": "",
        "applicationPurpose": "Automatic semantic labelling of table attributes for heterogeneous data integration. ",
        "userInterfaceTool": "",
        "checkedByAuthor": "",
        "checkedByAi": true,
        "doi": "https://doi.org/10.1007/978-3-319-46523-4_27",
        "citations": [
            {
                "ref": "2015_ramnandan_assigning",
                "title": "Assigning Semantic Labels to Data Sources"
            },
            {
                "ref": "2015_ritze_matching",
                "title": "Matching HTML Tables to DBpedia"
            },
            {
                "ref": "2010_limaye_annotating",
                "title": "Annotating and Searching Web Tables Using Entities, Types and Relationships"
            },
            {
                "ref": "2013_mulwad_semantic",
                "title": "Semantic message passing for generating linked data from tables"
            },
            {
                "ref": "2009_craswell_mean",
                "title": "Mean reciprocal rank"
            },
            {
                "ref": "2001_breiman_random",
                "title": "Random Forests"
            }
        ],
        "uncertainFields": [
            {
                "field": "coreTasks.cpa",
                "reason": "The paper performs property matching for columns but does not explicitly model inter-column relations as in some CPA definitions; marked true due to property matching focus. "
            },
            {
                "field": "output",
                "reason": "No explicit serialisation format (e.g., RDF/CSV) is specified for outputs; system reports ranked labels. "
            },
            {
                "field": "license",
                "reason": "The paper does not state a licence; the repository’s licence was not confirmed here. "
            },
            {
                "field": "inputs.typeOfTable",
                "reason": "Examples include relational databases, web tables and spreadsheets; exact supported formats may extend beyond those explicitly described. "
            },
            {
                "field": "kg.index",
                "reason": "Indexing mechanism is not specified; only the use of DBpedia is clearly mentioned. "
            }
        ]
    },
    {
        "id": "2016_taheriyan_leveraging",
        "added": "",
        "year": 2016,
        "firstAuthor": "Taheriyan",
        "authors": [
            "Mohsen Taheriyan",
            "Craig A. Knoblock",
            "Pedro Szekely",
            "José Luis Ambite"
        ],
        "title": "Leveraging Linked Data to Discover Semantic Relations Within Data Sources",
        "venue": {
            "type": "conference",
            "acronym": "ISWC"
        },
        "nameOfApproach": "Karma",
        "techniqueTags": [
            "ontology-driven"
        ],
        "coreTasks": {
            "cta": false,
            "cpa": true,
            "cea": false,
            "cnea": false
        },
        "supportTasks": {
            "dataPreparation": {
                "description": "Assumes columns are already assigned semantic labels; no specific preprocessing described.",
                "spellChecker": "",
                "unitsOfMeasurements": ""
            },
            "columnClassification": "",
            "subjectDetection": "",
            "datatypeAnnotation": "",
            "typeAnnotation": "",
            "predicateAnnotation": "Infers relations between columns using LOD graph-pattern mining combined with ontology paths.",
            "nilAnnotation": "",
            "entityLinking": {
                "description": "",
                "candidateGeneration": "",
                "entityDisambiguation": ""
            }
        },
        "mainMethod": {
            "type": "unsupervised",
            "technique": "Ontology-driven graph pattern mining over Linked Open Data"
        },
        "revision": {
            "type": "fully automated",
            "description": "Automatically generates and ranks candidate semantic models; can be refined by users in Karma if desired."
        },
        "domain": {
            "domain": "dependent",
            "type": "Cultural heritage (CIDOC-CRM/EDM) and schema.org extension (weapons ads)"
        },
        "validation": {
            "goldStandard": "Gold-standard semantic models for 29 museum sources (CIDOC-CRM/EDM) and 15 weapons-ad tables; leave-one-out evaluation; datasets on GitHub.",
            "metrics": [
                "Precision",
                "Recall"
            ]
        },
        "code": "https://github.com/usc-isi-i2/Web-Karma",
        "license": "Apache 2.0",
        "inputs": {
            "typeOfTable": "CSV, XML, JSON",
            "tableSources": [
                "web"
            ]
        },
        "kg": {
            "tripleStore": "CIDOC-CRM; EDM; schema.org",
            "index": "Patterns mined from Linked Open Data stored in Virtuoso; ontology paths used for graph expansion."
        },
        "output": "RDF",
        "applicationPurpose": "Automatically infer relations between columns to build complete semantic models.",
        "userInterfaceTool": "Karma (Web UI)",
        "checkedByAuthor": "",
        "checkedByAi": true,
        "doi": "https://doi.org/10.1007/978-3-319-46523-4_33",
        "citations": [
            {
                "ref": "2016_schaible_termpicker",
                "title": "TermPicker: Enabling the Reuse of Vocabulary Terms by Exploiting Data from the Linked Open Data Cloud"
            },
            {
                "ref": "2013_mulwad_semantic",
                "title": "Semantic Message Passing for Generating Linked Data from Tables"
            },
            {
                "ref": "2010_limaye_annotating",
                "title": "Annotating and Searching Web Tables Using Entities, Types and Relationships"
            },
            {
                "ref": "2011_venetis_recovering",
                "title": "Recovering Semantics of Tables on the Web"
            },
            {
                "ref": "2016_pham_semantic",
                "title": "Semantic Labeling: A Domain-independent Approach"
            },
            {
                "ref": "2012_knoblock_semi",
                "title": "Semi-Automatically Mapping Structured Sources into the Semantic Web"
            },
            {
                "ref": "2015_taheriyan_leveraging",
                "title": "Leveraging Linked Data to Infer Semantic Relations within Structured Sources"
            },
            {
                "ref": "2016_taheriyan_learning",
                "title": "Learning the Semantics of Structured Data Sources"
            }
        ],
        "uncertainFields": [
            {
                "field": "nameOfApproach",
                "reason": "The paper presents a method integrated into the Karma system but does not brand the method with a unique name; using the tool name may be debatable."
            },
            {
                "field": "inputs.tableSources",
                "reason": "Sources are described as CSV/XML/JSON from museums; assumed to be web-hosted, but exact provenance is not exhaustively specified."
            },
            {
                "field": "kg.tripleStore",
                "reason": "They rely on domain ontologies (CIDOC-CRM/EDM) and a schema.org extension plus Smithsonian LOD; representing these as a single 'tripleStore' is approximate."
            },
            {
                "field": "output",
                "reason": "The method outputs semantic models; RDF is typical via Karma but not stated as a direct serialized output of the algorithm."
            },
            {
                "field": "userInterfaceTool",
                "reason": "The algorithm is implemented within Karma; whether a specific UI was used for this paper's experiments is implied rather than explicitly detailed."
            }
        ]
    },
    {
        "id": "2016_taheriyan_learning",
        "added": "",
        "year": 2016,
        "firstAuthor": "Taheriyan",
        "authors": [
            "Mohsen Taheriyan",
            "Craig A. Knoblock",
            "Pedro Szekely",
            "José Luis Ambite"
        ],
        "title": "Learning the semantics of structured data sources",
        "venue": {
            "type": "journal",
            "acronym": "Web Semantics"
        },
        "nameOfApproach": "Karma",
        "techniqueTags": [
            "ontology-driven"
        ],
        "coreTasks": {
            "cta": true,
            "cpa": true,
            "cea": false,
            "cnea": false
        },
        "supportTasks": {
            "dataPreparation": {
                "description": "Uses sample data from the new source and merges known semantic models and ontology paths; no specific normalisation steps are detailed.",
                "spellChecker": "",
                "unitsOfMeasurements": ""
            },
            "columnClassification": "",
            "subjectDetection": "",
            "datatypeAnnotation": "Attributes with literal values are typed using pairs ⟨class, data property⟩ inferred during semantic labelling.",
            "typeAnnotation": "Semantic labelling assigns candidate semantic types (classes or class/property pairs) to source attributes.",
            "predicateAnnotation": "Relationships between attributes are inferred via a weighted graph built from known models and ontology paths, selecting minimum-cost (Steiner) trees.",
            "nilAnnotation": "",
            "entityLinking": {
                "description": "",
                "candidateGeneration": "",
                "entityDisambiguation": ""
            }
        },
        "mainMethod": {
            "type": "hybrid",
            "technique": "Semantic labelling (supervised) + ontology-driven graph search with top-k Steiner trees"
        },
        "revision": {
            "type": "semi automated",
            "description": "System suggests ranked semantic models; users can refine/correct them in the Karma UI to improve future predictions."
        },
        "domain": {
            "domain": "dependent",
            "type": "cultural heritage / museum"
        },
        "validation": {
            "goldStandard": "29 museum sources with expert-crafted gold-standard models using EDM and CIDOC-CRM",
            "metrics": [
                "Precision",
                "Recall",
                "MRR"
            ]
        },
        "code": "https://github.com/usc-isi-i2/Web-Karma",
        "license": "Not Specified",
        "inputs": {
            "typeOfTable": "CSV, XML, JSON, relational tables",
            "tableSources": [
                "web",
                "spreadsheet",
                "relational"
            ]
        },
        "kg": {
            "tripleStore": "EDM; CIDOC-CRM; FOAF; DBpedia; SKOS; DCMI Terms; FRBR; ORE; ElementsGr2",
            "index": ""
        },
        "output": "RDF",
        "applicationPurpose": "Automatic publication of structured sources as RDF into knowledge graphs; supports source discovery, information integration, and service composition.",
        "userInterfaceTool": "Karma (Web UI)",
        "checkedByAuthor": "",
        "checkedByAi": true,
        "doi": "https://doi.org/10.1016/j.websem.2015.12.003",
        "citations": [
            {
                "ref": "2015_krishnamurthy_assigning",
                "title": "Assigning semantic labels to data sources"
            },
            {
                "ref": "2012_das_r2rml",
                "title": "R2RML: RDB to RDF Mapping Language"
            },
            {
                "ref": "2013_szekely_connecting",
                "title": "Connecting the Smithsonian American art museum to the linked data cloud"
            }
        ],
        "uncertainFields": [
            {
                "field": "venue.acronym",
                "reason": "The journal’s full name is given as “Web Semantics: Science, Services and Agents on the World Wide Web”; the common short form/acronym isn’t explicitly stated, so “Web Semantics” is used. "
            },
            {
                "field": "coreTasks.cta",
                "reason": "The paper does not use the CTA label; we mapped their ‘semantic labelling’ of attributes to CTA by analogy. "
            },
            {
                "field": "coreTasks.cpa",
                "reason": "They infer relationships between attributes via ontology paths and Steiner trees, which aligns with CPA though the term isn’t used. "
            },
            {
                "field": "kg.tripleStore",
                "reason": "They model against multiple domain ontologies (EDM, CIDOC-CRM, SKOS, DCMI Terms, FOAF, FRBR, ORE, ElementsGr2) and show an example with DBpedia/FOAF; no single KG/triple store is prescribed. "
            },
            {
                "field": "inputs.tableSources",
                "reason": "Sources include relational databases, spreadsheets, XML/JSON and Web APIs; we mapped these to the closest allowed categories (web, spreadsheet, relational). "
            },
            {
                "field": "nameOfApproach",
                "reason": "The approach is implemented within the Karma framework; no separate unique method name is introduced, so we used “Karma”. "
            },
            {
                "field": "license",
                "reason": "No explicit software licence name is stated in the paper; thus set to “Not Specified”. "
            },
            {
                "field": "code",
                "reason": "The paper states the approach is integrated into the open-source Karma project; the linked repository is assumed to host the relevant code. "
            }
        ]
    },
    {
        "id": "2017_efthymiou_matching",
        "added": "",
        "year": 2017,
        "firstAuthor": "Efthymiou",
        "authors": [
            "Vasilis Efthymiou",
            "Oktie Hassanzadeh",
            "Mariano Rodriguez-Muro",
            "Vassilis Christophides"
        ],
        "title": "Matching Web Tables with Knowledge Base Entities: From Entity Lookups to Entity Embeddings",
        "venue": {
            "type": "conference",
            "acronym": "ISWC"
        },
        "nameOfApproach": "FactBase lookup",
        "techniqueTags": [
            "rule-based",
            "embeddings",
            "ontology-driven"
        ],
        "coreTasks": {
            "cta": false,
            "cpa": false,
            "cea": true,
            "cnea": false
        },
        "supportTasks": {
            "dataPreparation": {
                "description": "Heuristic label/column detection and refined/loose lookups with edit-distance tolerance and frequent description tokens.",
                "spellChecker": "",
                "unitsOfMeasurements": ""
            },
            "columnClassification": "Detect label and reference columns heuristically; mark potential reference (entity) columns via sampling lookups.",
            "subjectDetection": "Identify the label column as the leftmost column with maximum distinct non-numeric values.",
            "datatypeAnnotation": "",
            "typeAnnotation": "",
            "predicateAnnotation": "",
            "nilAnnotation": "",
            "entityLinking": {
                "description": "Unsupervised entity linking via lookup refinement, relation-aware constraints, and global disambiguation with entity embeddings.",
                "candidateGeneration": "DBpedia Lookup and a generic KB index (FactBase) over Wikidata labels/descriptions.",
                "entityDisambiguation": "Weighted PageRank over embedding-similarity graphs; relation-constrained refined lookups when applicable."
            }
        },
        "mainMethod": {
            "type": "hybrid",
            "technique": "rule-based + embeddings"
        },
        "revision": {
            "type": "fully automated",
            "description": "No human-in-the-loop; methods run end-to-end (MapReduce-based experiments and automatic evaluation). "
        },
        "domain": {
            "domain": "independent",
            "type": "general web tables"
        },
        "validation": {
            "goldStandard": "Evaluated on T2D, Limaye, and a new large Wikipedia tables gold standard; metrics reported as micro-averaged. ",
            "metrics": [
                "Precision",
                "Recall",
                "F1"
            ]
        },
        "code": "http://ibm.biz/webtables",
        "license": "Not Specified",
        "inputs": {
            "typeOfTable": "Web tables (HTML tables)",
            "tableSources": [
                "web",
                "wiki"
            ]
        },
        "kg": {
            "tripleStore": "DBpedia; Wikidata",
            "index": "FactBase generic index; DBpedia Lookup"
        },
        "output": "",
        "applicationPurpose": "Unsupervised annotation of web tables and empirical benchmarking of methods for KB augmentation/search. ",
        "userInterfaceTool": "",
        "checkedByAuthor": "",
        "checkedByAi": true,
        "doi": "https://doi.org/10.1007/978-3-319-68288-4_16",
        "citations": [
            {
                "ref": "2015_ritze_matching",
                "title": "Matching HTML tables to DBpedia"
            },
            {
                "ref": "2010_limaye_annotating",
                "title": "Annotating and searching web tables using entities, types and relationships"
            },
            {
                "ref": "2015_bhagavatula_tabel",
                "title": "TabEL: entity linking in web tables"
            },
            {
                "ref": "2016_zwicklbauer_doser",
                "title": "DoSeR - a knowledge-base-agnostic framework for entity disambiguation using semantic embeddings"
            },
            {
                "ref": "jimenez-ruiz2011logmap",
                "title": "LogMap: logic-based and scalable ontology matching"
            },
            {
                "ref": "2011_suchanek_paris",
                "title": "PARIS: probabilistic alignment of relations, instances, and schema"
            }
        ],
        "uncertainFields": [
            {
                "field": "nameOfApproach",
                "reason": "Paper evaluates multiple methods (lookup, embeddings, ontology matching) and two hybrids; selecting only “FactBase lookup” may not represent the whole contribution."
            },
            {
                "field": "kg.tripleStore",
                "reason": "Both DBpedia and Wikidata are used; the exact primary KB per experiment varies."
            },
            {
                "field": "code",
                "reason": "The provided URL hosts datasets/implementation details; it may not be a traditional source-code repository."
            },
            {
                "field": "output",
                "reason": "No explicit serialisation format (e.g., RDF/JSON-LD) is stated; the work reports annotations and metrics rather than an exported file format."
            },
            {
                "field": "license",
                "reason": "No explicit software licence is stated for the implementations."
            },
            {
                "field": "supportTasks.columnClassification",
                "reason": "Their heuristics target label/reference column detection rather than a full NE vs LIT column classifier."
            }
        ]
    },
    {
        "id": "2017_ell_towards",
        "added": "",
        "year": 2017,
        "firstAuthor": "Ell",
        "authors": [
            "Basil Ell",
            "Sherzod Hakimov",
            "Philipp Braukmann",
            "Lorenzo Cazzoli",
            "Fabian Kaupmann",
            "Amerigo Mancino",
            "Junaid Altaf Memon",
            "Kai Rother",
            "Abhishek Saini",
            "Philipp Cimiano"
        ],
        "title": "Towards a Large Corpus of Richly Annotated Web Tables for Knowledge Base Population",
        "venue": {
            "type": "conference",
            "acronym": "ISWC"
        },
        "nameOfApproach": "",
        "techniqueTags": [
            "rule-based",
            "ontology-driven"
        ],
        "coreTasks": {
            "cta": false,
            "cpa": false,
            "cea": true,
            "cnea": false
        },
        "supportTasks": {
            "dataPreparation": {
                "description": "Language detection and table normalisation (dates, numbers, and units) producing JSON hypotheses for cells. Plain hypotheses are always created to preserve original strings.",
                "spellChecker": "",
                "unitsOfMeasurements": "Values converted to base units (e.g., kg, km)."
            },
            "columnClassification": "",
            "subjectDetection": "",
            "datatypeAnnotation": "",
            "typeAnnotation": "",
            "predicateAnnotation": "",
            "nilAnnotation": "",
            "entityLinking": {
                "description": "Links plain cell strings to DBpedia resources and records top candidates with confidences.",
                "candidateGeneration": "Per-language indices of DBpedia entity, class, and property labels; retrieve top-N by frequency.",
                "entityDisambiguation": "Rank candidates by normalised frequency; no supervised disambiguation."
            }
        },
        "mainMethod": {
            "type": "unsupervised",
            "technique": "rule-based"
        },
        "revision": {
            "type": "fully automated",
            "description": "A scheduled pipeline applies tasks sequentially; no manual review during processing."
        },
        "domain": {
            "domain": "independent",
            "type": ""
        },
        "validation": {
            "goldStandard": "1,000,000 tables from the WDC Web Table Corpus 2015 (WTC).",
            "metrics": []
        },
        "code": "https://github.com/isywtu/code",
        "license": "Not Specified",
        "inputs": {
            "typeOfTable": "HTML tables",
            "tableSources": [
                "web"
            ]
        },
        "kg": {
            "tripleStore": "DBpedia",
            "index": "Per-language string indices over DBpedia labels for entities, classes, and properties with frequency counts."
        },
        "output": "JSON",
        "applicationPurpose": "Enable knowledge base population and support higher-level table understanding on web tables.",
        "userInterfaceTool": "",
        "checkedByAuthor": "",
        "checkedByAi": true,
        "doi": "",
        "citations": [
            {
                "ref": "2012_wang_understanding",
                "title": "Understanding Tables on the Web"
            },
            {
                "ref": "2015_bhagavatula_tabel",
                "title": "TabEL: Entity Linking in Web Tables"
            },
            {
                "ref": "2015_ritze_matching",
                "title": "Matching HTML Tables to DBpedia"
            },
            {
                "ref": "2007_pivk_transforming",
                "title": "Transforming Arbitrary Tables into F-Logic Frames with TARTAR"
            }
        ],
        "uncertainFields": [
            {
                "field": "venue.acronym",
                "reason": "Assumed from the filename; not explicitly stated in the paper header."
            },
            {
                "field": "doi",
                "reason": "A DOI for the paper was not found in the provided text; only a dataset DOI was mentioned."
            },
            {
                "field": "techniqueTags[1]",
                "reason": "Classified as ontology-driven because the approach relies on DBpedia; the paper does not use this exact label."
            },
            {
                "field": "kg.index",
                "reason": "High-level description inferred; precise indexing implementation details are not fully specified."
            }
        ]
    },
    {
        "id": "2017_lehmberg_stitching",
        "added": "",
        "year": 2017,
        "firstAuthor": "Lehmberg",
        "authors": [
            "Oliver Lehmberg",
            "Christian Bizer"
        ],
        "title": "Stitching Web Tables for Improving Matching Quality",
        "venue": {
            "type": "journal",
            "acronym": "PVLDB"
        },
        "nameOfApproach": "",
        "techniqueTags": [],
        "coreTasks": {
            "cta": false,
            "cpa": true,
            "cea": false,
            "cnea": false
        },
        "supportTasks": {
            "dataPreparation": {
                "description": "De-duplicate tables, recognise entities via DBpedia label matching, and create per-host union and stitched tables with holistic correspondence refinement.",
                "spellChecker": "",
                "unitsOfMeasurements": ""
            },
            "columnClassification": "Heuristic identification of the entity label column to guide schema matching.",
            "subjectDetection": "Detects a key/subject column (entity label column) within tables from the same host.",
            "datatypeAnnotation": "",
            "typeAnnotation": "",
            "predicateAnnotation": "Schema matching from web-table columns to DBpedia properties using T2K Match/COMA with holistic refinement.",
            "nilAnnotation": "",
            "entityLinking": {
                "description": "",
                "candidateGeneration": "",
                "entityDisambiguation": ""
            }
        },
        "mainMethod": {
            "type": "hybrid",
            "technique": "Hybrid schema matching combining label-, value-, and duplicate-based matchers with holistic correspondence refinement"
        },
        "revision": {
            "type": "fully automated",
            "description": "Fully automated stitching (union and holistic stitching) followed by automated schema matching without user intervention."
        },
        "domain": {
            "domain": "independent",
            "type": ""
        },
        "validation": {
            "goldStandard": "Random sample of 1,000 WDC 2015 web tables with 427 manually created column-to-DBpedia-property correspondences; per-host evaluations.",
            "metrics": [
                "Precision",
                "Recall",
                "F1"
            ]
        },
        "code": "https://github.com/olehmberg/WebTableStitching",
        "license": "Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International",
        "inputs": {
            "typeOfTable": "HTML tables",
            "tableSources": [
                "web"
            ]
        },
        "kg": {
            "tripleStore": "DBpedia",
            "index": ""
        },
        "output": "",
        "applicationPurpose": "Knowledge base augmentation and improved schema matching on small web tables",
        "userInterfaceTool": "",
        "checkedByAuthor": "",
        "checkedByAi": true,
        "doi": "https://doi.org/10.14778/3137628.3137657",
        "citations": [
            {
                "ref": "2017_ritze_matching",
                "title": "Matching Web Tables To DBpedia - A Feature Utility Study"
            },
            {
                "ref": "2010_limaye_annotating",
                "title": "Annotating and Searching Web Tables Using Entities, Types and Relationships"
            },
            {
                "ref": "2013_ling_synthesizing",
                "title": "Synthesizing union tables from the web"
            },
            {
                "ref": "2005_aumueller_schema",
                "title": "Schema and ontology matching with COMA++"
            },
            {
                "ref": "2015_lehmann_dbpedia",
                "title": "DBpedia - A Large-scale, Multilingual Knowledge Base Extracted from Wikipedia"
            }
        ],
        "uncertainFields": [
            {
                "field": "nameOfApproach",
                "reason": "The paper does not introduce a branded system name; it presents a stitching procedure and evaluation."
            },
            {
                "field": "techniqueTags",
                "reason": "None of the allowed technique tags precisely fit classical schema matching and stitching; left empty to avoid misclassification."
            },
            {
                "field": "supportTasks.columnClassification",
                "reason": "Entity label/key column detection is implied in the procedure but not formalised as a distinct module."
            },
            {
                "field": "supportTasks.subjectDetection",
                "reason": "Subject/key column identification is heuristic and not explicitly labelled as 'subject detection' in the paper."
            },
            {
                "field": "kg.index",
                "reason": "Specific KG indexing structures are not described beyond label lookups; details are unclear."
            },
            {
                "field": "output",
                "reason": "The exported result format is not specified; results are reported as correspondences and metrics."
            },
            {
                "field": "userInterfaceTool",
                "reason": "No UI is described; usage may rely on libraries/tools (e.g., WInte.r) but a specific UI is not stated."
            },
            {
                "field": "validation.goldStandard",
                "reason": "The description summarises the sampling and manual mapping; no official GS name is given for this new sample."
            },
            {
                "field": "mainMethod.type",
                "reason": "Classified as 'hybrid' due to combining several matchers and holistic refinement; some readers might label it 'unsupervised'."
            }
        ]
    },
    {
        "id": "2017_zhang_effective",
        "added": "",
        "year": 2017,
        "firstAuthor": "Zhang",
        "authors": [
            "Ziqi Zhang"
        ],
        "title": "Effective and Efficient Semantic Table Interpretation using TableMiner+",
        "venue": {
            "type": "journal",
            "acronym": "SWJ"
        },
        "nameOfApproach": "TableMiner+",
        "techniqueTags": [
            "ontology-driven"
        ],
        "coreTasks": {
            "cta": true,
            "cpa": true,
            "cea": true,
            "cnea": false
        },
        "supportTasks": {
            "dataPreparation": {
                "description": "Normalises content and collects in-table/out-of-table context (titles, captions, Microdata) and caches KB lookups to reduce latency. ",
                "spellChecker": "",
                "unitsOfMeasurements": ""
            },
            "columnClassification": "Identifies NE vs literal columns and classifies columns using KB-derived evidence. ",
            "subjectDetection": "Detects a subject (reference) column used to anchor relations to other columns. ",
            "datatypeAnnotation": "",
            "typeAnnotation": "Assigns KG concepts to NE-columns via bootstrapped inference and message passing with KB features. ",
            "predicateAnnotation": "Enumerates relations between the subject column and other columns (binary CPA). ",
            "nilAnnotation": "",
            "entityLinking": {
                "description": "Links cell mentions to KB entities using Freebase candidates and contextual features from table and page. ",
                "candidateGeneration": "Retrieves candidates via Freebase Search/MQL APIs, with local caching. ",
                "entityDisambiguation": "Scores candidates with in-table and out-of-table context; refines via iterative message passing. "
            }
        },
        "mainMethod": {
            "type": "unsupervised",
            "technique": "Incremental bootstrapping with semantic message passing over KB features"
        },
        "revision": {
            "type": "fully automated",
            "description": "System performs iterative inference without human-in-the-loop; annotations are refined via message passing. "
        },
        "domain": {
            "domain": "independent",
            "type": "generic"
        },
        "validation": {
            "goldStandard": "Limaye200 (200 tables), LimayeAll (6,310 tables; 227,046 NE cells), IMDB (7,416 tables), MusicBrainz (1,406 tables). ",
            "metrics": [
                "Precision",
                "Recall",
                "F1"
            ]
        },
        "code": "https://github.com/ziqizhang/sti",
        "license": "Not Specified",
        "inputs": {
            "typeOfTable": "Web tables (HTML)",
            "tableSources": [
                "web",
                "wiki"
            ]
        },
        "kg": {
            "tripleStore": "Freebase",
            "index": "Freebase Search/MQL APIs; local cache; later DBpedia interface noted. "
        },
        "output": "RDF",
        "applicationPurpose": "Semantic indexing/search of tables and creation of Linked Open Data/KB population. ",
        "userInterfaceTool": "",
        "checkedByAuthor": "",
        "checkedByAi": true,
        "doi": "https://doi.org/10.3233/SW-160242",
        "citations": [
            {
                "ref": "2010_limaye_annotating",
                "title": "Annotating and searching web tables using entities, types and relationships"
            },
            {
                "ref": "2011_venetis_recovering",
                "title": "Recovering semantics of tables on the Web"
            },
            {
                "ref": "2013_mulwad_semantic",
                "title": "Semantic message passing for generating linked data from tables"
            },
            {
                "ref": "2014_munoz_using",
                "title": "Using linked data to mine RDF from Wikipedia’s tables"
            },
            {
                "ref": "2012_wang_understanding",
                "title": "Understanding tables on the Web"
            }
        ],
        "uncertainFields": [
            {
                "field": "venue.acronym",
                "reason": "Used the common 'SWJ' acronym for Semantic Web Journal; some datasets use 'Semantic Web'."
            },
            {
                "field": "kg.tripleStore",
                "reason": "Primary experiments use Freebase, but the paper notes an interface/migration to DBpedia/Google KG; Freebase chosen to reflect evaluation. "
            },
            {
                "field": "output",
                "reason": "The paper states enabling LOD creation but does not explicitly specify an export format; 'RDF' inferred. "
            },
            {
                "field": "supportTasks.datatypeAnnotation",
                "reason": "Approach handles literal columns for CPA, but explicit mapping to datatype vocabularies is not clearly described."
            },
            {
                "field": "techniqueTags[0]",
                "reason": "Tagged as ontology-driven due to heavy KB use; other tags (e.g., rule-based/clustering) do not neatly apply."
            },
            {
                "field": "citations[2].ref",
                "reason": "Slug for the ISWC 2013 'Semantic message passing' paper may vary in exact first word; format approximated."
            }
        ]
    },
    {
        "id": "2018_kacprzak_making",
        "added": "",
        "year": 2018,
        "firstAuthor": "Kacprzak",
        "authors": [
            "Emilia Kacprzak",
            "José M. Giménez-García",
            "Alessandro Piscopo",
            "Laura Koesten",
            "Luis-Daniel Ibáñez",
            "Jeni Tennison",
            "Elena Simperl"
        ],
        "title": "Making Sense of Numerical Data - Semantic Labelling of Web Tables",
        "venue": {
            "type": "conference",
            "acronym": "EKAW"
        },
        "nameOfApproach": "NUMER",
        "techniqueTags": [
            "rule-based",
            "ontology-driven"
        ],
        "coreTasks": {
            "cta": false,
            "cpa": true,
            "cea": false,
            "cnea": false
        },
        "supportTasks": {
            "dataPreparation": {
                "description": "Partition columns into numerical vs textual, identify a subject column, disambiguate its cells to KB entities, and strip units/non-numeric characters from numeric cells.",
                "spellChecker": "",
                "unitsOfMeasurements": "Units (e.g., Km, %) are removed during preprocessing to keep only numeric values."
            },
            "columnClassification": "Classify columns as numerical or textual to focus annotation.",
            "subjectDetection": "Identify the subject column (textual NE-column) using support/connectivity heuristics from prior work.",
            "datatypeAnnotation": "Consider owl:DatatypeProperty candidates linked to subject-entity types for numeric columns.",
            "typeAnnotation": "",
            "predicateAnnotation": "Rank KB datatype properties (e.g., dbo:populationTotal) for each numeric column via KS-test distribution matching and row-wise relative difference.",
            "nilAnnotation": "",
            "entityLinking": {
                "description": "",
                "candidateGeneration": "",
                "entityDisambiguation": ""
            }
        },
        "mainMethod": {
            "type": "unsupervised",
            "technique": "rule-based"
        },
        "revision": {
            "type": "fully automated",
            "description": "Produces a ranked list of KB properties per numeric column without manual post-editing."
        },
        "domain": {
            "domain": "independent",
            "type": ""
        },
        "validation": {
            "goldStandard": "NumDB (synthetic tables from DBpedia; multiple sizes and error deviations)",
            "metrics": [
                "Top-1 Accuracy",
                "Top-k Accuracy"
            ]
        },
        "code": "https://github.com/chabrowa/semantification",
        "license": "Not Specified",
        "inputs": {
            "typeOfTable": "Web tables",
            "tableSources": [
                "wiki"
            ]
        },
        "kg": {
            "tripleStore": "DBpedia",
            "index": ""
        },
        "output": "",
        "applicationPurpose": "Assign semantic labels to numerical columns to aid data discovery and KB integration.",
        "userInterfaceTool": "",
        "usesLLM": null,
        "checkedByAuthor": "",
        "checkedByAi": true,
        "doi": "",
        "citations": [
            {
                "ref": "2016_neumaier_multi",
                "title": "Multi-level semantic labelling of numerical values"
            },
            {
                "ref": "2011_venetis_recovering",
                "title": "Recovering semantics of tables on the web"
            },
            {
                "ref": "2015_ramnandan_assigning",
                "title": "Assigning semantic labels to data sources"
            },
            {
                "ref": "2016_ermilov_taipan",
                "title": "TAIPAN: Automatic Property Mapping for Tabular Data"
            },
            {
                "ref": "2018_piscopo_numdb",
                "title": "NumDB"
            }
        ],
        "uncertainFields": [
            {
                "field": "doi",
                "reason": "The DOI of the paper is not stated in the provided text excerpt."
            },
            {
                "field": "output",
                "reason": "The paper reports ranked predictions but does not specify an export serialisation (e.g., RDF/CSV)."
            },
            {
                "field": "userInterfaceTool",
                "reason": "No UI or tool front-end is described; unclear if a CLI/Web UI exists."
            },
            {
                "field": "techniqueTags",
                "reason": "Mapped to 'rule-based' and 'ontology-driven' based on KB-driven matching and heuristics; no explicit ML/embeddings mentioned."
            },
            {
                "field": "inputs.tableSources",
                "reason": "Benchmark tables are derived from DBpedia (wiki); applicability to other sources is discussed but not validated."
            }
        ]
    },
    {
        "id": "2018_luo_cross-lingual",
        "added": "",
        "year": 2018,
        "firstAuthor": "Luo",
        "authors": [
            "Xusheng Luo",
            "Kangqi Luo",
            "Xianyang Chen",
            "Kenny Q. Zhu"
        ],
        "title": "Cross-Lingual Entity Linking for Web Tables",
        "venue": {
            "type": "conference",
            "acronym": "AAAI"
        },
        "nameOfApproach": "",
        "techniqueTags": [
            "embeddings"
        ],
        "coreTasks": {
            "cta": false,
            "cpa": false,
            "cea": true,
            "cnea": false
        },
        "supportTasks": {
            "dataPreparation": {
                "description": "Stop-word removal on translations/anchors and simple text normalisation used during candidate generation.",
                "spellChecker": "",
                "unitsOfMeasurements": ""
            },
            "columnClassification": "",
            "subjectDetection": "",
            "datatypeAnnotation": "",
            "typeAnnotation": "",
            "predicateAnnotation": "",
            "nilAnnotation": "",
            "entityLinking": {
                "description": "Joint neural model links all table mentions simultaneously with mention, context, and column-coherence features.",
                "candidateGeneration": "Translate mentions via multiple MT services; generate candidates by exact/anchor/fuzzy matches with heuristics (e.g., Jaccard/edit distance).",
                "entityDisambiguation": "Pairwise ranking (RankNet) with bilingual embedding transformation and local-search descent to select globally coherent entities."
            }
        },
        "mainMethod": {
            "type": "supervised",
            "technique": "neural network ranking (joint model with RankNet)",
            "supervision": {
                "type": "supervised"
            }
        },
        "revision": {
            "type": "fully automated",
            "description": "System automatically scores and selects entities using a learned model and local search; no human-in-the-loop post-editing."
        },
        "domain": {
            "domain": "independent",
            "type": "generic web tables"
        },
        "validation": {
            "goldStandard": "Cross-lingual table linking dataset (150 tables, 2883 linkable cells; Chinese→English Wikipedia).",
            "metrics": [
                "Accuracy"
            ]
        },
        "code": "",
        "license": "Not Specified",
        "inputs": {
            "typeOfTable": "Web tables",
            "tableSources": [
                "web",
                "wiki"
            ]
        },
        "kg": {
            "tripleStore": "Wikipedia",
            "index": ""
        },
        "output": "",
        "applicationPurpose": "KB enrichment and fact discovery from non-English web tables.",
        "userInterfaceTool": "",
        "checkedByAuthor": "",
        "checkedByAi": true,
        "doi": "https://doi.org/10.1609/aaai.v32i1.11252",
        "citations": [
            {
                "ref": "2015_bhagavatula_tabel",
                "title": "Tabel: Entity Linking in Web Tables"
            },
            {
                "ref": "2016_wu_entity",
                "title": "Entity Linking in Web Tables with Multiple Linked Knowledge Bases"
            },
            {
                "ref": "2010_limaye_annotating",
                "title": "Annotating and Searching Web Tables Using Entities, Types and Relationships"
            },
            {
                "ref": "2011_mcnamee_cross",
                "title": "Cross-Language Entity Linking"
            },
            {
                "ref": "2016_tsai_cross",
                "title": "Cross-lingual Wikification Using Multilingual Embeddings"
            },
            {
                "ref": "2013_zhang_cross",
                "title": "Cross Lingual Entity Linking with Bilingual Topic Model"
            },
            {
                "ref": "2013_socher_reasoning",
                "title": "Reasoning with Neural Tensor Networks for Knowledge Base Completion"
            }
        ],
        "uncertainFields": [
            {
                "field": "nameOfApproach",
                "reason": "No specific system name or acronym is stated; described as a joint neural model."
            },
            {
                "field": "kg.tripleStore",
                "reason": "They use Wikipedia articles as the KB rather than a conventional triple store like DBpedia or Wikidata."
            },
            {
                "field": "validation.goldStandard",
                "reason": "Dataset is described but not given a formal GS name."
            },
            {
                "field": "output",
                "reason": "The paper does not specify an exported output format for annotations."
            },
            {
                "field": "userInterfaceTool",
                "reason": "No UI or tool front-end is mentioned."
            },
            {
                "field": "code",
                "reason": "No repository or code link is provided in the paper."
            }
        ]
    },
    {
        "id": "2018_zhang_ad",
        "added": "",
        "year": 2018,
        "firstAuthor": "Zhang",
        "authors": [
            "Shuo Zhang",
            "Krisztian Balog"
        ],
        "title": "Ad Hoc Table Retrieval using Semantic Similarity",
        "venue": {
            "type": "conference",
            "acronym": "WWW"
        },
        "nameOfApproach": "Semantic Table Retrieval (STR)",
        "techniqueTags": [
            "embeddings"
        ],
        "coreTasks": {
            "cta": false,
            "cpa": false,
            "cea": false,
            "cnea": false
        },
        "supportTasks": {
            "dataPreparation": {
                "description": "WikiTables corpus with links in table bodies replaced by DBpedia entity identifiers (version 2015-10).",
                "spellChecker": "",
                "unitsOfMeasurements": ""
            },
            "columnClassification": "",
            "subjectDetection": "",
            "datatypeAnnotation": "",
            "typeAnnotation": "",
            "predicateAnnotation": "",
            "nilAnnotation": "",
            "entityLinking": {
                "description": "",
                "candidateGeneration": "",
                "entityDisambiguation": ""
            }
        },
        "mainMethod": {
            "type": "supervised",
            "technique": "Learning-to-rank (Random Forest) with semantic similarity features",
            "supervision": {
                "type": "supervised"
            }
        },
        "revision": {
            "type": "fully automated",
            "description": "Produces a ranked list of tables automatically; no user editing phase is described."
        },
        "domain": {
            "domain": "independent",
            "type": "general (web tables)"
        },
        "validation": {
            "goldStandard": "Purpose-built test collection of 1.6M Wikipedia tables with 60 queries and graded relevance (3120 query–table pairs). ",
            "metrics": [
                "NDCG@5",
                "NDCG@10",
                "NDCG@15",
                "NDCG@20"
            ]
        },
        "code": "https://github.com/iai-group/www2018-table",
        "license": "Not Specified",
        "inputs": {
            "typeOfTable": "Web tables",
            "tableSources": [
                "wiki"
            ]
        },
        "kg": {
            "tripleStore": "DBpedia",
            "index": ""
        },
        "output": "",
        "applicationPurpose": "Ad hoc table retrieval / table search. ",
        "userInterfaceTool": "",
        "checkedByAuthor": "",
        "checkedByAi": true,
        "doi": "https://doi.org/10.1145/3178876.3186067",
        "citations": [
            {
                "ref": "2008_cafarella_webtables",
                "title": "WebTables: Exploring the Power of Tables on the Web"
            },
            {
                "ref": "2012_pimplikar_answering",
                "title": "Answering Table Queries on the Web Using Column Keywords"
            },
            {
                "ref": "2013_bhagavatula_methods",
                "title": "Methods for Exploring and Mining Tables on Wikipedia"
            },
            {
                "ref": "2017_hasibi_dbpedia",
                "title": "DBpedia-Entity V2: A Test Collection for Entity Search"
            },
            {
                "ref": "2013_mikolov_distributed",
                "title": "Distributed Representations of Words and Phrases and Their Compositionality"
            },
            {
                "ref": "2016_ristoski_rdf2vec",
                "title": "RDF2vec: RDF Graph Embeddings for Data Mining"
            },
            {
                "ref": "2003_ogilvie_combining",
                "title": "Combining Document Representations for Known-item Search"
            },
            {
                "ref": "2015_balakrishnan_applying",
                "title": "Applying WebTables in Practice"
            },
            {
                "ref": "2011_venetis_recovering",
                "title": "Recovering Semantics of Tables on the Web"
            }
        ],
        "uncertainFields": [
            {
                "field": "nameOfApproach",
                "reason": "The paper labels the method as 'STR' in results tables, but it is not clearly presented as a formal system name. "
            },
            {
                "field": "license",
                "reason": "The article states a CC BY 4.0 publication licence; the software licence for the repository is not specified in the paper text. "
            },
            {
                "field": "output",
                "reason": "No serialisation/format of outputs is described; the result is a ranked list rather than an export format."
            },
            {
                "field": "kg.index",
                "reason": "An explicit KB indexing component is not described; only that entity retrieval uses a fielded representation and external resources."
            },
            {
                "field": "inputs.typeOfTable",
                "reason": "Tables are from Wikipedia (HTML on the Web); either 'Web tables' or 'HTML tables' could be appropriate. "
            },
            {
                "field": "techniqueTags",
                "reason": "Besides 'embeddings', one could argue 'ontology-driven' since entities/categories from DBpedia are leveraged; the paper does not frame it that way."
            },
            {
                "field": "venue.acronym",
                "reason": "Venue is 'The Web Conference (WWW)'; we normalised to 'WWW'. "
            },
            {
                "field": "validation.goldStandard",
                "reason": "The test collection is described but not given a formal name in the paper. "
            }
        ]
    },
    {
        "id": "2019_chabot_dagobah",
        "added": "",
        "year": 2019,
        "firstAuthor": "Chabot",
        "authors": [
            "Yoan Chabot",
            "Thomas Labbé",
            "Jixiong Liu",
            "Raphaël Troncy"
        ],
        "title": "DAGOBAH: An End-to-End Context-Free Tabular Data Semantic Annotation System",
        "venue": {
            "type": "workshop",
            "acronym": "SemTab"
        },
        "nameOfApproach": "DAGOBAH",
        "techniqueTags": [
            "rule-based",
            "clustering",
            "embeddings",
            "ontology-driven"
        ],
        "coreTasks": {
            "cta": true,
            "cpa": true,
            "cea": true,
            "cnea": false
        },
        "supportTasks": {
            "dataPreparation": {
                "description": "Pre-processing chain: orientation detection, header extraction, key column detection, and string cleaning.",
                "spellChecker": "",
                "unitsOfMeasurements": ""
            },
            "columnClassification": "Identify Object/Number/Date/Unit columns and the key column.",
            "subjectDetection": "Key column detection used to infer the subject column for triple generation.",
            "datatypeAnnotation": "",
            "typeAnnotation": "Column typing via lookup counts with relative/specificity scores; alternative embedding-based clustering with DBpedia hierarchy scoring.",
            "predicateAnnotation": "CPA by searching relations between CEA-linked entity pairs and majority voting; early version used header lookup.",
            "nilAnnotation": "",
            "entityLinking": {
                "description": "Cell candidates from multiple lookup services (Wikidata/DBpedia/Wikipedia APIs and an internal ES index) with occurrence-based voting and type-aware disambiguation; embedding variant clusters candidates and scores them.",
                "candidateGeneration": "Query labels/aliases using regex and Levenshtein ≥0.75 across services and an Elasticsearch index.",
                "entityDisambiguation": "Select entities consistent with the predicted column type or its parents using scoring."
            }
        },
        "mainMethod": {
            "type": "hybrid",
            "technique": "rule-based and clustering"
        },
        "revision": {
            "type": "fully automated",
            "description": "Automatic pipeline for CEA/CTA/CPA with no interactive user validation described."
        },
        "domain": {
            "domain": "independent",
            "type": "generic"
        },
        "validation": {
            "goldStandard": "SemTab 2019 challenge test datasets (AICrowd evaluator)",
            "metrics": [
                "Precision",
                "F1"
            ]
        },
        "code": "",
        "license": "Not Specified",
        "inputs": {
            "typeOfTable": "Web tables",
            "tableSources": []
        },
        "kg": {
            "tripleStore": "Wikidata and DBpedia",
            "index": "Elasticsearch index over Wikidata labels, aliases and types"
        },
        "output": "RDF",
        "applicationPurpose": "Annotate tables to enrich/extend knowledge graphs and support dataset search.",
        "userInterfaceTool": "",
        "checkedByAuthor": "",
        "checkedByAi": true,
        "doi": "",
        "citations": [
            {
                "ref": "2019_hassanzadeh_semtab2019",
                "title": "SemTab2019: Semantic Web Challenge on Tabular Data to Knowledge Graph Matching - Data Sets"
            },
            {
                "ref": "2018_chen_colnet",
                "title": "ColNet: Embedding the Semantics of Web Tables for Column Type Prediction"
            },
            {
                "ref": "2018_han_openke",
                "title": "OpenKE: An open toolkit for knowledge embedding"
            },
            {
                "ref": "2015_farber_a",
                "title": "A Comparative Survey of DBpedia, Freebase, OpenCyc, Wikidata, and YAGO"
            },
            {
                "ref": "2019_chapman_dataset",
                "title": "Dataset search: a survey"
            },
            {
                "ref": "2016_sarkar_junitmz",
                "title": "JUNITMZ at SemEval-2016 Task 1: Identifying semantic similarity using Levenshtein ratio"
            }
        ],
        "uncertainFields": [
            {
                "field": "venue.acronym",
                "reason": "The paper appears in SemTab 2019 materials, but the exact proceedings/workshop acronym is not explicitly stated in the text."
            },
            {
                "field": "doi",
                "reason": "A DOI for the system paper is not visible; CEUR-WS style papers often lack a DOI."
            },
            {
                "field": "code",
                "reason": "No repository URL is provided; unclear whether code is publicly available."
            },
            {
                "field": "license",
                "reason": "Paper text notes CC BY 4.0 for the manuscript, but the software licence for the approach is not specified."
            },
            {
                "field": "inputs.typeOfTable",
                "reason": "The system targets generic tabular data; 'Web tables' is inferred from SemTab but not explicitly fixed."
            },
            {
                "field": "kg.tripleStore",
                "reason": "Both Wikidata and DBpedia are used; representing both in a single string may not reflect a single backing store."
            },
            {
                "field": "output",
                "reason": "They mention transforming table knowledge into triples; 'RDF' is inferred rather than explicitly formatted output."
            },
            {
                "field": "validation.metrics",
                "reason": "CTA evaluation uses primary/secondary scores not listed among the allowed metrics; 'Precision' and 'F1' are reported for other tasks."
            },
            {
                "field": "userInterfaceTool",
                "reason": "The paper describes a pipeline but does not mention a UI or tool interface."
            }
        ]
    },
    {
        "id": "2019_chen_learning",
        "added": "",
        "year": 2019,
        "firstAuthor": "Chen",
        "authors": [
            "Jiaoyan Chen",
            "Ernesto Jiménez-Ruiz",
            "Ian Horrocks",
            "Charles Sutton"
        ],
        "title": "Learning Semantic Annotations for Tabular Data",
        "venue": {
            "type": "conference",
            "acronym": "IJCAI"
        },
        "nameOfApproach": "HNN + P2Vec",
        "techniqueTags": [
            "embeddings",
            "ontology-driven"
        ],
        "coreTasks": {
            "cta": true,
            "cpa": false,
            "cea": false,
            "cnea": false
        },
        "supportTasks": {
            "dataPreparation": {
                "description": "Samples are extracted as fixed-size micro tables; cell text is tokenised and embedded (word2vec/Att-BiRNN), with cropping/padding and parsing of dates/numbers.",
                "spellChecker": "",
                "unitsOfMeasurements": ""
            },
            "columnClassification": "",
            "subjectDetection": "",
            "datatypeAnnotation": "",
            "typeAnnotation": "Predicts the DBpedia class (type) for a target NE-column using HNN features and KB-derived property features.",
            "predicateAnnotation": "",
            "nilAnnotation": "",
            "entityLinking": {
                "description": "",
                "candidateGeneration": "",
                "entityDisambiguation": ""
            }
        },
        "mainMethod": {
            "type": "hybrid",
            "technique": "Hybrid Neural Network (Att-BiRNN + CNN) combined with KB lookup and query answering (P2Vec)"
        },
        "revision": {
            "type": "fully automated",
            "description": "System produces predictions automatically; no manual post-editing is required."
        },
        "domain": {
            "domain": "independent",
            "type": "general web"
        },
        "validation": {
            "goldStandard": "T2Dv2, Limaye, Efthymiou (DBpedia)",
            "metrics": [
                "Accuracy"
            ]
        },
        "code": "https://github.com/alan-turing-institute/SemAIDA",
        "license": "Not Specified",
        "inputs": {
            "typeOfTable": "Web tables",
            "tableSources": [
                "web",
                "wiki"
            ]
        },
        "kg": {
            "tripleStore": "DBpedia",
            "index": "DBpedia Lookup service and SPARQL endpoint"
        },
        "output": "",
        "applicationPurpose": "Column type prediction for web tables using DBpedia.",
        "userInterfaceTool": "",
        "checkedByAuthor": "",
        "checkedByAi": true,
        "doi": "https://doi.org/10.24963/ijcai.2019/289",
        "citations": [
            {
                "ref": "2010_limaye_annotating",
                "title": "Annotating and searching web tables using entities, types and relationships"
            },
            {
                "ref": "2015_ritze_matching",
                "title": "Matching HTML tables to DBpedia"
            },
            {
                "ref": "2017_efthymiou_matching",
                "title": "Matching web tables with knowledge base entities: from entity lookups to entity embeddings"
            },
            {
                "ref": "2011_mendes_dbpedia",
                "title": "DBpedia Spotlight: shedding light on the web of documents"
            },
            {
                "ref": "2019_chen_colnet",
                "title": "ColNet: Embedding the Semantics of Web Tables for Column Type Prediction"
            },
            {
                "ref": "2018_luo_cross",
                "title": "Cross-lingual entity linking for web tables"
            },
            {
                "ref": "2017_zhang_effective",
                "title": "Effective and efficient semantic table interpretation using TableMiner+"
            }
        ],
        "uncertainFields": [
            {
                "field": "nameOfApproach",
                "reason": "The paper does not brand the system with a formal name; 'HNN + P2Vec' is descriptive."
            },
            {
                "field": "mainMethod.type",
                "reason": "Method is supervised but also integrates KB lookup features; classified as 'hybrid'."
            },
            {
                "field": "license",
                "reason": "The repository/license for the referenced code is not specified in the paper."
            },
            {
                "field": "inputs.tableSources",
                "reason": "Sources include T2Dv2 (general web) and Wikipedia tables; 'wiki' is inferred from datasets."
            },
            {
                "field": "kg.index",
                "reason": "Described generically as DBpedia Lookup and SPARQL; specific indexing details are not given."
            },
            {
                "field": "output",
                "reason": "Output serialisation format is not specified; the system outputs predicted classes."
            },
            {
                "field": "userInterfaceTool",
                "reason": "No UI or tool interface is described."
            },
            {
                "field": "code",
                "reason": "The SemAIDA link is given in the paper but may refer to a project umbrella rather than this specific implementation."
            }
        ]
    },
    {
        "id": "2019_chen_colnet",
        "added": "",
        "year": 2019,
        "firstAuthor": "Chen",
        "authors": [
            "Jiaoyan Chen",
            "Ernesto Jiménez-Ruiz",
            "Ian Horrocks",
            "Charles Sutton"
        ],
        "title": "ColNet: Embedding the Semantics of Web Tables for Column Type Prediction",
        "venue": {
            "type": "conference",
            "acronym": "AAAI"
        },
        "nameOfApproach": "ColNet",
        "techniqueTags": [
            "embeddings",
            "ontology-driven"
        ],
        "coreTasks": {
            "cta": true,
            "cpa": false,
            "cea": false,
            "cnea": false
        },
        "supportTasks": {
            "dataPreparation": {
                "description": "",
                "spellChecker": "",
                "unitsOfMeasurements": ""
            },
            "columnClassification": "",
            "subjectDetection": "",
            "datatypeAnnotation": "",
            "typeAnnotation": "Column-to-class mapping using CNN-based prediction combined with KB lookup/ensemble.",
            "predicateAnnotation": "",
            "nilAnnotation": "",
            "entityLinking": {
                "description": "",
                "candidateGeneration": "",
                "entityDisambiguation": ""
            }
        },
        "mainMethod": {
            "type": "hybrid",
            "technique": "CNN-based supervised learning with KB lookup/ensemble"
        },
        "revision": {
            "type": "fully automated",
            "description": "Automatic pipeline of lookup, prediction and ensemble; no manual validation stage reported."
        },
        "domain": {
            "domain": "independent",
            "type": "generic web tables"
        },
        "validation": {
            "goldStandard": "T2Dv2; Limaye",
            "metrics": [
                "Precision",
                "Recall",
                "F1"
            ]
        },
        "code": "https://github.com/alan-turing-institute/SemAIDA",
        "license": "Not Specified",
        "inputs": {
            "typeOfTable": "Web tables",
            "tableSources": [
                "web",
                "wiki"
            ]
        },
        "kg": {
            "tripleStore": "DBpedia",
            "index": "Lexical index over KB entity labels/anchors; DBpedia Lookup/SPARQL."
        },
        "output": "column-to-class annotations",
        "applicationPurpose": "Accurate column type prediction for web tables; supports KB population and table understanding.",
        "userInterfaceTool": "",
        "checkedByAuthor": "",
        "checkedByAi": true,
        "doi": "https://doi.org/10.1609/aaai.v33i01.330129",
        "citations": [
            {
                "ref": "2007_auer_dbpedia",
                "title": "DBpedia: A Nucleus for a Web of Open Data"
            },
            {
                "ref": "2008_cafarella_webtables",
                "title": "Webtables: exploring the power of tables on the web"
            },
            {
                "ref": "2016_lehmberg_a",
                "title": "A large public corpus of web tables containing time and context metadata"
            },
            {
                "ref": "2010_limaye_annotating",
                "title": "Annotating and searching web tables using entities, types and relationships"
            },
            {
                "ref": "2014_kim_convolutional",
                "title": "Convolutional Neural Networks for Sentence Classification"
            },
            {
                "ref": "2017_efthymiou_matching",
                "title": "Matching web tables with knowledge base entities: from entity lookups to entity embeddings"
            },
            {
                "ref": "2015_bhagavatula_tabel",
                "title": "Tabel: entity linking in web tables"
            }
        ],
        "uncertainFields": [
            {
                "field": "license",
                "reason": "The paper references a GitHub repository but does not state the code licence."
            },
            {
                "field": "inputs.tableSources",
                "reason": "Evaluations use general Web and Wikipedia tables; exact source mix beyond these is not explicitly enumerated."
            },
            {
                "field": "kg.index",
                "reason": "A lexical index and DBpedia lookup are mentioned, but implementation details are brief."
            },
            {
                "field": "output",
                "reason": "No explicit serialisation format is specified; the output is conceptually column-to-class annotations."
            },
            {
                "field": "mainMethod.type",
                "reason": "Could be interpreted as supervised (auto-labelled training) or hybrid due to ensemble with KB lookup."
            }
        ]
    },
    {
        "id": "2019_cremaschi_mantistable",
        "added": "",
        "year": 2019,
        "firstAuthor": "Cremaschi",
        "authors": [
            "Marco Cremaschi",
            "Roberto Avogadro",
            "David Chieregato"
        ],
        "title": "MantisTable: an Automatic Approach for the Semantic Table Interpretation",
        "venue": {
            "type": "workshop",
            "acronym": "SemTab"
        },
        "nameOfApproach": "MantisTable",
        "techniqueTags": [
            "rule-based",
            "ontology-driven"
        ],
        "coreTasks": {
            "cta": true,
            "cpa": true,
            "cea": true,
            "cnea": false
        },
        "supportTasks": {
            "dataPreparation": {
                "description": "Cleans and normalises table text (lowercasing, removing HTML/brackets), resolves acronyms/abbreviations, and standardises units via regular expressions.",
                "spellChecker": "",
                "unitsOfMeasurements": "Normalises many units (e.g., area, currency, density, energy, length, mass, speed, temperature, time, voltage) using extended regex rules."
            },
            "columnClassification": "Regex-based detection of L-columns vs NE-columns using frequency thresholds over predefined Regextypes.",
            "subjectDetection": "Scores NE-columns using features (unique content, average words, empty cells, distance from first NE-column) and selects the highest-scoring S-column.",
            "datatypeAnnotation": "Maps literal columns to KG datatypes leveraging information from linked entities and headers.",
            "typeAnnotation": "Builds per-column concept distributions from rdf:type of linked entities and selects a best path in the concept hierarchy maximising a component score.",
            "predicateAnnotation": "Chooses the property between the subject and other columns with maximum frequency among candidates discovered during entity linking.",
            "nilAnnotation": "",
            "entityLinking": {
                "description": "Row-wise candidate graph built from entities whose labels contain the cell text/tokens; literals (dates, numbers, strings) are matched and paths scored.",
                "candidateGeneration": "SPARQL label-contains queries over tokens and redirects to collect eligible entities for each cell.",
                "entityDisambiguation": "Selects the path with maximum score combining path length and Levenshtein edit distance between cell text and entity labels."
            }
        },
        "mainMethod": {
            "type": "unsupervised",
            "technique": "rule-based"
        },
        "revision": {
            "type": "fully automated",
            "description": "All STI steps execute without user intervention; a Web UI offers guidance but outputs are computed automatically."
        },
        "domain": {
            "domain": "independent",
            "type": ""
        },
        "validation": {
            "goldStandard": "SemTab 2019 (Rounds 1–4)",
            "metrics": [
                "F1",
                "Precision"
            ]
        },
        "code": "https://bitbucket.org/disco_unimib/mantistable-tool.py",
        "license": "CC BY 4.0",
        "inputs": {
            "typeOfTable": "CSV",
            "tableSources": []
        },
        "kg": {
            "tripleStore": "DBpedia",
            "index": ""
        },
        "output": "JSON",
        "applicationPurpose": "End-to-end STI to make table semantics accessible for search, querying and KG enrichment.",
        "userInterfaceTool": "Web UI",
        "checkedByAuthor": "",
        "checkedByAi": true,
        "doi": "",
        "citations": [
            {
                "ref": "2013_deng_scalable",
                "title": "Scalable column concept determination for web tables using large knowledge bases"
            },
            {
                "ref": "2012_knoblock_semi",
                "title": "Semi-automatically Mapping Structured Sources into the Semantic Web"
            },
            {
                "ref": "2010_limaye_annotating",
                "title": "Annotating and searching web tables using entities, types and relationships"
            },
            {
                "ref": "2013_mulwad_semantic",
                "title": "Semantic message passing for generating linked data from tables"
            },
            {
                "ref": "2016_pham_semantic",
                "title": "Semantic Labeling: A Domain-Independent Approach"
            },
            {
                "ref": "2013_quercini_entity",
                "title": "Entity discovery and annotation in tables"
            },
            {
                "ref": "2015_ramnandan_assigning",
                "title": "Assigning Semantic Labels to Data Sources"
            },
            {
                "ref": "2015_ritze_matching",
                "title": "Matching html tables to dbpedia"
            },
            {
                "ref": "2010_syed_exploiting",
                "title": "Exploiting a web of semantic data for interpreting tables"
            },
            {
                "ref": "2016_taheriyan_learning",
                "title": "Learning the semantics of structured data sources"
            },
            {
                "ref": "2011_venetis_recovering",
                "title": "Recovering semantics of tables on the web"
            },
            {
                "ref": "2012_wang_understanding",
                "title": "Understanding tables on the web"
            },
            {
                "ref": "2017_zhang_effective",
                "title": "Effective and efficient semantic table interpretation using TableMiner+"
            }
        ],
        "uncertainFields": [
            {
                "field": "venue.acronym",
                "reason": "The document is a SemTab challenge system paper; exact official acronym formatting is not explicitly stated."
            },
            {
                "field": "kg.tripleStore",
                "reason": "Examples use DBpedia, and Wikidata is mentioned as a potential resource; primary KG may vary by run."
            },
            {
                "field": "inputs.tableSources",
                "reason": "Sources of the challenge tables are not specified in the paper; they may mix wiki/web origins."
            },
            {
                "field": "doi",
                "reason": "Workshop/system description appears to have no DOI (typical for CEUR-WS); left empty."
            },
            {
                "field": "output",
                "reason": "Tool originally exported JSON, but challenge submissions also involved CSV; JSON chosen here."
            },
            {
                "field": "validation.metrics",
                "reason": "Paper reports 'F1' and another score labelled 'F2' which in places corresponds to Precision; mapped conservatively to Precision."
            }
        ]
    },
    {
        "id": "2019_hulsebos_sherlock",
        "added": "",
        "year": 2019,
        "firstAuthor": "Hulsebos",
        "authors": [
            "Madelon Hulsebos",
            "Kevin Hu",
            "Michiel Bakker",
            "Emanuel Zgraggen",
            "Arvind Satyanarayan",
            "Tim Kraska",
            "Çağatay Demiralp",
            "César Hidalgo"
        ],
        "title": "Sherlock: A Deep Learning Approach to Semantic Data Type Detection",
        "venue": {
            "type": "conference",
            "acronym": "KDD"
        },
        "nameOfApproach": "Sherlock",
        "techniqueTags": [
            "embeddings"
        ],
        "coreTasks": {
            "cta": true,
            "cpa": false,
            "cea": false,
            "cnea": false
        },
        "supportTasks": {
            "dataPreparation": {
                "description": "Extracts statistics, character distributions, word embeddings, and paragraph vectors from column values; imputes missing feature values and filters types based on frequency/coverage criteria.",
                "spellChecker": "",
                "unitsOfMeasurements": ""
            },
            "columnClassification": "",
            "subjectDetection": "",
            "datatypeAnnotation": "",
            "typeAnnotation": "Predicts semantic types for columns via a multi-input deep neural network trained on labelled columns.",
            "predicateAnnotation": "",
            "nilAnnotation": "",
            "entityLinking": {
                "description": "",
                "candidateGeneration": "",
                "entityDisambiguation": ""
            }
        },
        "mainMethod": {
            "type": "supervised",
            "technique": "multi-input deep neural network",
            "supervision": {
                "type": "supervised"
            }
        },
        "revision": {
            "type": "fully automated",
            "description": "Predictions are produced automatically; authors discuss using confidence-based rejection to hand-review low-confidence cases."
        },
        "domain": {
            "domain": "independent",
            "type": ""
        },
        "validation": {
            "goldStandard": "VizNet corpus with T2Dv2-derived types (686,765 columns; 78 types)",
            "metrics": [
                "Precision",
                "Recall",
                "F1"
            ]
        },
        "code": "https://sherlock.media.mit.edu",
        "license": "Not Specified",
        "inputs": {
            "typeOfTable": "Web tables",
            "tableSources": [
                "web",
                "gov-open-data"
            ]
        },
        "kg": {
            "tripleStore": "DBpedia",
            "index": ""
        },
        "output": "",
        "applicationPurpose": "Semantic type detection to support data cleaning, schema matching, and data discovery.",
        "userInterfaceTool": "Python library",
        "checkedByAuthor": false,
        "checkedByAi": true,
        "doi": "https://doi.org/10.1145/3292500.3330993",
        "citations": [
            {
                "ref": "2008_cafarella_webtables",
                "title": "WebTables: Exploring the Power of Tables on the Web"
            },
            {
                "ref": "2007_auer_dbpedia",
                "title": "DBpedia: A nucleus for a web of open data"
            },
            {
                "ref": "2019_hu_viznet",
                "title": "VizNet: Towards a large-scale visualization learning and benchmarking repository"
            },
            {
                "ref": "2014_pennington_glove",
                "title": "GloVe: Global vectors for word representation"
            },
            {
                "ref": "2016_pham_semantic",
                "title": "Semantic labeling: a domain-independent approach"
            },
            {
                "ref": "2011_venetis_recovering",
                "title": "Recovering semantics of tables on the web"
            },
            {
                "ref": "2010_limaye_annotating",
                "title": "Annotating and searching web tables using entities, types and relationships"
            },
            {
                "ref": "2016_bartoli_inference",
                "title": "Inference of regular expressions for text extraction from examples"
            }
        ],
        "uncertainFields": [
            {
                "field": "kg.tripleStore",
                "reason": "DBpedia is used to define semantic types; the system does not appear to query a KG during inference."
            },
            {
                "field": "inputs.tableSources",
                "reason": "VizNet aggregates multiple sources; exact proportions and additional categories beyond 'web' and 'gov-open-data' are not specified."
            },
            {
                "field": "revision.type",
                "reason": "A human-in-the-loop is suggested via rejection thresholds but not part of the default pipeline."
            },
            {
                "field": "output",
                "reason": "The paper does not specify an export format for predictions."
            },
            {
                "field": "validation.goldStandard",
                "reason": "Evaluation is on a dataset split rather than a separate external gold standard; summary string combines dataset and type source."
            },
            {
                "field": "kg.index",
                "reason": "No indexing mechanism for the KG is described."
            }
        ]
    },
    {
        "id": "2019_kruit_extracting",
        "added": "",
        "year": 2019,
        "firstAuthor": "Kruit",
        "authors": [
            "Benno Kruit",
            "Peter Boncz",
            "Jacopo Urbani"
        ],
        "title": "Extracting Novel Facts from Tables for Knowledge Graph Completion",
        "venue": {
            "type": "conference",
            "acronym": "ISWC"
        },
        "nameOfApproach": "TAKCO",
        "techniqueTags": [
            "embeddings"
        ],
        "coreTasks": {
            "cta": false,
            "cpa": true,
            "cea": true,
            "cnea": false
        },
        "supportTasks": {
            "dataPreparation": {
                "description": "Heuristic key-column detection; build a label index including redirects and disambiguation pages; token-based string matching and TF-IDF ranking.",
                "spellChecker": "",
                "unitsOfMeasurements": ""
            },
            "columnClassification": "",
            "subjectDetection": "Key-column identification via most-unique non-numeric values (leftmost on ties).",
            "datatypeAnnotation": "",
            "typeAnnotation": "",
            "predicateAnnotation": "Map attribute columns to KG relations using column likelihoods aggregated over rows (ColScore) and disambiguation.",
            "nilAnnotation": "",
            "entityLinking": {
                "description": "Row–entity assignments scored from label/attribute matches and refined for table-wide coherence using a probabilistic graphical model.",
                "candidateGeneration": "Lookup over KG label index (incl. titles, redirects, disambiguation); length-normalised smoothed TF-IDF; keep top-1 or top-3 per heuristic.",
                "entityDisambiguation": "Loopy Belief Propagation over entity similarity graph to maximise coherence; final slot-filling re-ranked with TransE embeddings."
            }
        },
        "mainMethod": {
            "type": "unsupervised",
            "technique": "Probabilistic graphical model with Loopy Belief Propagation for table interpretation; KG embeddings (TransE) for slot-filling re-ranking"
        },
        "revision": {
            "type": "fully automated",
            "description": "End-to-end automated inference and extraction with thresholding to tune precision–recall; no user edits required after the core run."
        },
        "domain": {
            "domain": "independent",
            "type": "open-domain"
        },
        "validation": {
            "goldStandard": "Evaluated on T2D-v2 (web tables) and Webaroo (YAGO/DBpedia-mapped) plus a large Wikipedia tables run.",
            "metrics": [
                "Precision",
                "Recall",
                "F1",
                "P@1",
                "P@3"
            ]
        },
        "code": "https://github.com/karmaresearch/takco",
        "license": "Not Specified",
        "inputs": {
            "typeOfTable": "HTML tables",
            "tableSources": [
                "web",
                "wiki"
            ]
        },
        "kg": {
            "tripleStore": "DBpedia; Wikidata",
            "index": "Label index over KG labels, redirects and disambiguation pages; TF-IDF retrieval"
        },
        "output": "RDF",
        "applicationPurpose": "Knowledge graph completion by extracting novel facts from web tables",
        "userInterfaceTool": "",
        "checkedByAuthor": false,
        "checkedByAi": true,
        "doi": "https://doi.org/10.1007/978-3-030-30793-6_21",
        "citations": [
            {
                "ref": "2015_ritze_matching",
                "title": "Matching HTML tables to DBpedia"
            },
            {
                "ref": "2017_zhang_effective",
                "title": "Effective and efficient semantic table interpretation using TableMiner+"
            },
            {
                "ref": "2010_limaye_annotating",
                "title": "Annotating and searching web tables using entities, types and relationships"
            },
            {
                "ref": "2015_bhagavatula_tabel",
                "title": "TabEL: entity linking in web tables"
            },
            {
                "ref": "2013_bordes_translating",
                "title": "Translating embeddings for modeling multi-relational data"
            },
            {
                "ref": "2019_kruit_extracting",
                "title": "Extracting novel facts from tables for knowledge graph completion (extended version)"
            }
        ],
        "uncertainFields": [
            {
                "field": "coreTasks.cta",
                "reason": "CTA is mentioned as optional and was not explicitly evaluated; the focus is on CEA and CPA."
            },
            {
                "field": "output",
                "reason": "The exported serialisation is not stated; triples/RDF are assumed from the KG context."
            },
            {
                "field": "userInterfaceTool",
                "reason": "No user interface or tool front-end is described; likely CLI only, but unspecified."
            },
            {
                "field": "license",
                "reason": "The paper references code but does not specify a licence."
            },
            {
                "field": "kg.tripleStore",
                "reason": "The system supports multiple KGs (DBpedia and Wikidata); a single-string field was used to list both."
            },
            {
                "field": "inputs.tableSources[1]",
                "reason": "Both generic web tables and Wikipedia tables are used; classification overlap may apply."
            },
            {
                "field": "supportTasks.columnClassification",
                "reason": "Explicit column type classification is not described; method relies mainly on key-column detection."
            }
        ]
    },
    {
        "id": "2019_morikawa_semantic",
        "added": "",
        "year": 2019,
        "firstAuthor": "Morikawa",
        "authors": [
            "Hiroaki Morikawa"
        ],
        "title": "Semantic Table Interpretation using LOD4ALL",
        "venue": {
            "type": "workshop",
            "acronym": "SemTab"
        },
        "nameOfApproach": "LOD4ALL",
        "techniqueTags": [
            "rule-based",
            "ontology-driven"
        ],
        "coreTasks": {
            "cta": true,
            "cpa": true,
            "cea": true,
            "cnea": false
        },
        "supportTasks": {
            "dataPreparation": {
                "description": "Builds a Score DB (BM25 over classes) and a Keyword Store from the target KG to support prediction. Enhances literal search with keyword variants and approximate matching.",
                "spellChecker": "",
                "unitsOfMeasurements": ""
            },
            "columnClassification": "",
            "subjectDetection": "",
            "datatypeAnnotation": "",
            "typeAnnotation": "Predicts column semantic types using coverage ratios of candidate entities and BM25 class scores.",
            "predicateAnnotation": "For each row, queries predicates between entity pairs and selects the most frequent relation as the column-pair property.",
            "nilAnnotation": "",
            "entityLinking": {
                "description": "Links cells to KG entities using enhanced literal/keyword search and type-constrained selection.",
                "candidateGeneration": "Direct URI match, keyword search over labels/names, and approximate string matching (SimString) via Elasticsearch/LOD4ALL.",
                "entityDisambiguation": "Ranks candidates by combined search-similarity score and selects one consistent with the predicted column type."
            }
        },
        "mainMethod": {
            "type": "unsupervised",
            "technique": "rule-based"
        },
        "revision": {
            "type": "fully automated",
            "description": "End-to-end pipeline produces CTA/CEA/CPA without manual intervention."
        },
        "domain": {
            "domain": "independent",
            "type": "generic"
        },
        "validation": {
            "goldStandard": "SemTab 2019 (Round1–4)",
            "metrics": [
                "F1",
                "Precision"
            ]
        },
        "code": "https://github.com/lod4all/semanticTableInterpretation",
        "license": "CC BY 4.0",
        "inputs": {
            "typeOfTable": "CSV",
            "tableSources": [
                "web",
                "wiki"
            ]
        },
        "kg": {
            "tripleStore": "DBpedia",
            "index": "LOD4ALL keyword store with Elasticsearch and SimString; BM25-based Score DB for classes"
        },
        "output": "",
        "applicationPurpose": "Knowledge Graph construction from web tables",
        "userInterfaceTool": "",
        "checkedByAuthor": false,
        "checkedByAi": true,
        "doi": "",
        "citations": [
            {
                "ref": "2016_lehmberg_a",
                "title": "A large public corpus of web tables containing time and context metadata."
            },
            {
                "ref": "2019_kruit_extracting",
                "title": "Extracting Novel Facts from Tables for Knowledge Graph Completion."
            },
            {
                "ref": "2014_naseer_lod",
                "title": "LOD for all: Unlocking infinite opportunities."
            },
            {
                "ref": "",
                "title": "Semantic Web Challenge on Tabular Data to Knowledge Graph Matching"
            },
            {
                "ref": "2017_efthymiou_matching",
                "title": "Matching web tables with knowledge base entities: from entity lookups to entity embeddings."
            },
            {
                "ref": "2013_zwicklbauer_towards",
                "title": "Towards Disambiguating Web Tables."
            },
            {
                "ref": "2009_robertson_the",
                "title": "The probabilistic relevance framework: BM25 and beyond."
            },
            {
                "ref": "2010_okazaki_simple",
                "title": "Simple and efficient algorithm for approximate dictionary matching."
            },
            {
                "ref": "2016_fang_dbpedia",
                "title": "DBpedia Entity Type Inference Using Categories."
            }
        ],
        "uncertainFields": [
            {
                "field": "venue.acronym",
                "reason": "Assumed workshop acronym is 'SemTab' for the SemTab 2019 challenge paper; some records list only CEUR-WS."
            },
            {
                "field": "inputs.typeOfTable",
                "reason": "Example shows a CSV file, but the approach targets generic web tables; the exact default input format is not explicitly fixed."
            },
            {
                "field": "inputs.tableSources",
                "reason": "The system targets web tables and examples are from Wikipedia; other sources might be supported but are not stated."
            },
            {
                "field": "output",
                "reason": "Submission/serialisation format is not specified in the text."
            },
            {
                "field": "validation.goldStandard",
                "reason": "Described as participation across SemTab rounds; the precise dataset names per round are not enumerated."
            }
        ]
    },
    {
        "id": "2019_nguyen_mtab",
        "added": "",
        "year": 2019,
        "firstAuthor": "Nguyen",
        "authors": [
            "Phuc Nguyen",
            "Natthawut Kertkeidkachorn",
            "Ryutaro Ichise",
            "Hideaki Takeda"
        ],
        "title": "MTab: Matching Tabular Data to Knowledge Graph using Probability Models",
        "venue": {
            "type": "workshop",
            "acronym": "SemTab"
        },
        "nameOfApproach": "MTab",
        "techniqueTags": [
            "embeddings"
        ],
        "coreTasks": {
            "cta": true,
            "cpa": true,
            "cea": true,
            "cnea": false
        },
        "supportTasks": {
            "dataPreparation": {
                "description": "Pre-processing includes text decoding, language prediction, data type and entity type prediction, and multi-source entity lookup.",
                "spellChecker": "ftfy",
                "unitsOfMeasurements": ""
            },
            "columnClassification": "Majority voting over data type/entity tags to separate entity vs numerical columns.",
            "subjectDetection": "",
            "datatypeAnnotation": "",
            "typeAnnotation": "Aggregates signals (from numerical columns, lookups, NER types, and headers) to estimate DBpedia classes.",
            "predicateAnnotation": "Estimates relations via SPARQL links between entity candidates and value-similarity for entity–literal pairs; aggregates scores.",
            "nilAnnotation": "",
            "entityLinking": {
                "description": "Generates entity candidates from multiple lookup services and re-estimates probabilities using column, cell, and row context.",
                "candidateGeneration": "DBpedia Lookup/SPARQL plus Wikipedia/Wikidata redirects with language-aware queries.",
                "entityDisambiguation": "Probability aggregation with learnable weights over lookup rank, type consistency, string match ratios, and row-wise relation evidence."
            }
        },
        "mainMethod": {
            "type": "hybrid",
            "technique": "Probabilistic aggregation with embedding-based numerical column labelling (EmbNum) and heuristic similarity measures"
        },
        "revision": {
            "type": "fully automated",
            "description": "Outputs are selected by automated re-estimation and majority voting without user intervention."
        },
        "domain": {
            "domain": "independent",
            "type": ""
        },
        "validation": {
            "goldStandard": "SemTab 2019 datasets (Rounds 1–4)",
            "metrics": [
                "F1"
            ]
        },
        "code": "https://github.com/phucty/MTab",
        "license": "Not Specified",
        "inputs": {
            "typeOfTable": "Vertical relational tables",
            "tableSources": []
        },
        "kg": {
            "tripleStore": "DBpedia",
            "index": "DBpedia Lookup; DBpedia SPARQL endpoint; Wikipedia/Wikidata redirects"
        },
        "output": "",
        "applicationPurpose": "SemTab 2019 challenge system for matching tables to DBpedia",
        "userInterfaceTool": "",
        "checkedByAuthor": false,
        "checkedByAi": true,
        "doi": "",
        "citations": [
            {
                "ref": "2010_limaye_annotating",
                "title": "Annotating and searching web tables using entities, types and relationships"
            },
            {
                "ref": "2019_speer_ftfy",
                "title": "ftfy"
            },
            {
                "ref": "2017_joulin_bag",
                "title": "Bag of tricks for efficient text classification"
            },
            {
                "ref": "2017_honnibal_spacy",
                "title": "spaCy 2: Natural language understanding with Bloom embeddings, convolutional neural networks and incremental parsing"
            },
            {
                "ref": "2018_nguyen_embnum",
                "title": "Embnum: Semantic labeling for numerical values with deep metric learning"
            },
            {
                "ref": "2019_hassanzadeh_semtab2019",
                "title": "SemTab2019: Semantic Web Challenge on Tabular Data to Knowledge Graph Matching - 2019 Data Sets"
            },
            {
                "ref": "2017_zhang_effective",
                "title": "Effective and efficient semantic table interpretation using tableminer+"
            },
            {
                "ref": "2017_nishida_understanding",
                "title": "Understanding the semantic structures of tables with a hybrid deep neural network architecture"
            },
            {
                "ref": "2017_lehmberg_stitching",
                "title": "Stitching web tables for improving matching quality"
            },
            {
                "ref": "2017_ritze_web",
                "title": "Web-scale web table to knowledge base matching"
            }
        ],
        "uncertainFields": [
            {
                "field": "techniqueTags[0]",
                "reason": "EmbNum relies on deep metric learning embeddings; other components are heuristic/probabilistic rather than explicit rule-based or transformer."
            },
            {
                "field": "validation.metrics[0]",
                "reason": "CTA results are reported primarily with an average hierarchical score (AH); only Round 1 explicitly shows F1 for CTA, so listing F1 may not uniformly reflect all tasks."
            },
            {
                "field": "inputs.typeOfTable",
                "reason": "Paper assumes vertical relational tables but does not constrain specific file formats (e.g., HTML/CSV/PDF)."
            },
            {
                "field": "inputs.tableSources",
                "reason": "The provenance of evaluation tables is via SemTab datasets, but specific source categories (web/wiki/gov-open-data) are not detailed in the paper."
            },
            {
                "field": "output",
                "reason": "No explicit export format for annotations is described."
            },
            {
                "field": "license",
                "reason": "Paper states CC BY 4.0 for the publication; the software licence for MTab itself is not specified in the text."
            }
        ]
    },
    {
        "id": "2019_oliveira_adog",
        "added": "",
        "year": 2019,
        "firstAuthor": "Oliveira",
        "authors": [
            "Daniela Oliveira",
            "Mathieu d'Aquin"
        ],
        "title": "ADOG - Annotating Data with Ontologies and Graphs",
        "venue": {
            "type": "workshop",
            "acronym": "SemTab"
        },
        "nameOfApproach": "ADOG",
        "techniqueTags": [
            "rule-based",
            "ontology-driven"
        ],
        "coreTasks": {
            "cta": true,
            "cpa": true,
            "cea": true,
            "cnea": false
        },
        "supportTasks": {
            "dataPreparation": {
                "description": "String normalisation (punctuation removal, bracketed words ignored) and indexing of KG labels and categories; weights include tf-idf.",
                "spellChecker": "",
                "unitsOfMeasurements": ""
            },
            "columnClassification": "",
            "subjectDetection": "",
            "datatypeAnnotation": "",
            "typeAnnotation": "Assign DBpedia ontology classes to columns using ontology graph depth and shortest paths.",
            "predicateAnnotation": "Relations between matched entities extracted via KG object properties to assign column properties.",
            "nilAnnotation": "",
            "entityLinking": {
                "description": "Link cells to DBpedia entities via ElasticSearch search with scoring.",
                "candidateGeneration": "Label lookup over indexed KG entities.",
                "entityDisambiguation": "Levenshtein similarity, property frequency and weighted final score."
            }
        },
        "mainMethod": {
            "type": "unsupervised",
            "technique": "rule-based"
        },
        "revision": {
            "type": "fully automated",
            "description": "Annotations are computed automatically using graph-based scoring with no user post-editing described."
        },
        "domain": {
            "domain": "independent",
            "type": ""
        },
        "validation": {
            "goldStandard": "SemTab 2019 challenge ground truths (Rounds 1–4).",
            "metrics": [
                "Precision",
                "Recall",
                "F1"
            ]
        },
        "code": "https://github.com/danielapoliveira/iswc-annotation-challenge",
        "license": "Not Specified",
        "inputs": {
            "typeOfTable": "structured and semi-structured tables",
            "tableSources": []
        },
        "kg": {
            "tripleStore": "DBpedia",
            "index": "ElasticSearch index of labels; categories/types with tf-idf weighting."
        },
        "output": "",
        "applicationPurpose": "Semantic annotation of tables to a KG (CTA/CEA/CPA) and evaluation in the SemTab challenge.",
        "userInterfaceTool": "",
        "checkedByAuthor": false,
        "checkedByAi": true,
        "doi": "",
        "citations": [
            {
                "ref": "2019_oliveira_leveraging",
                "title": "Leveraging Ontologies for Knowledge Graph Schemas."
            }
        ],
        "uncertainFields": [
            {
                "field": "venue.acronym",
                "reason": "The acronym 'SemTab' is inferred from the file name and challenge name rather than explicitly stated in the text."
            },
            {
                "field": "validation.metrics",
                "reason": "CTA was also evaluated with AH-Score and AP-Score, which are not in the allowed list; only common metrics are recorded."
            },
            {
                "field": "inputs.typeOfTable",
                "reason": "The paper mentions structured and semi-structured data but not a specific table format (e.g., HTML, CSV)."
            },
            {
                "field": "inputs.tableSources",
                "reason": "Sources of tables (web, wiki, etc.) are not explicitly specified."
            },
            {
                "field": "output",
                "reason": "The output format of the annotations is not described."
            },
            {
                "field": "userInterfaceTool",
                "reason": "No UI or tool interface is mentioned."
            },
            {
                "field": "license",
                "reason": "The approach/repository licence is not stated in the paper."
            },
            {
                "field": "mainMethod.technique",
                "reason": "Approach relies on graph-based heuristics; labelled as rule-based, but the exact categorisation is not explicitly given."
            },
            {
                "field": "coreTasks.cpa",
                "reason": "CPA results were derived from CEA in later rounds; unclear whether CPA is a primary target of the core algorithm."
            },
            {
                "field": "kg.index",
                "reason": "Indexing details are summarised (labels, categories with tf-idf) without full configuration specifics."
            }
        ]
    },
    {
        "id": "2019_steenwinckel_csv2kg",
        "added": "",
        "year": 2019,
        "firstAuthor": "Steenwinckel",
        "authors": [
            "Bram Steenwinckel",
            "Gilles Vandewiele",
            "Filip De Turck",
            "Femke Ongenae"
        ],
        "title": "CSV2KG: Transforming Tabular Data into Semantic Knowledge",
        "venue": {
            "type": "workshop",
            "acronym": "SemTab"
        },
        "nameOfApproach": "CSV2KG",
        "techniqueTags": [
            "rule-based",
            "ontology-driven"
        ],
        "coreTasks": {
            "cta": true,
            "cpa": true,
            "cea": true,
            "cnea": false
        },
        "supportTasks": {
            "dataPreparation": {
                "description": "Cell value normalisation (e.g., trimming text before brackets, removing specific characters) to reduce noisy strings for matching.",
                "spellChecker": "",
                "unitsOfMeasurements": ""
            },
            "columnClassification": "",
            "subjectDetection": "Treats the first column as the head/subject column and uses inferred predicates to refine head/non-head annotations.",
            "datatypeAnnotation": "",
            "typeAnnotation": "Infers column types via majority voting over the DBpedia class hierarchy with an entropy-based stopping rule; adds ancestors and equivalent classes.",
            "predicateAnnotation": "Selects predicates linking column pairs by counting observed (s,p,o) across annotated cell pairs; breaks ties using domain/range depth.",
            "nilAnnotation": "",
            "entityLinking": {
                "description": "Generates candidate entities and disambiguates to DBpedia resources.",
                "candidateGeneration": "Tries direct resource IRIs from cleaned strings; uses DBpedia Lookup; falls back to DBpedia Spotlight.",
                "entityDisambiguation": "Chooses candidates with minimal Levenshtein distance; later iterations incorporate column-type and row-wise predicate constraints."
            }
        },
        "mainMethod": {
            "type": "unsupervised",
            "technique": "rule-based"
        },
        "revision": {
            "type": "fully automated",
            "description": "Six-phase pipeline executes automatically without manual intervention during inference."
        },
        "domain": {
            "domain": "independent",
            "type": ""
        },
        "validation": {
            "goldStandard": "SemTab2019 (ISWC) challenge datasets, rounds 1–4",
            "metrics": [
                "Precision",
                "Recall",
                "F1"
            ]
        },
        "code": "https://github.com/IBCNServices/CSV2KG",
        "license": "Not Specified",
        "inputs": {
            "typeOfTable": "CSV",
            "tableSources": []
        },
        "kg": {
            "tripleStore": "DBpedia",
            "index": "DBpedia Lookup API; DBpedia Spotlight; SPARQL queries for domain/range"
        },
        "output": "",
        "applicationPurpose": "Semantic annotation of CSV tables and KG construction/linking for DBpedia; SemTab 2019 participation.",
        "userInterfaceTool": "",
        "checkedByAuthor": false,
        "checkedByAi": true,
        "doi": "",
        "citations": [
            {
                "ref": "2007_auer_dbpedia",
                "title": "Dbpedia: A nucleus for a web of open data"
            },
            {
                "ref": "2015_bhagavatula_tabel",
                "title": "Tabel: entity linking in web tables"
            },
            {
                "ref": "2019_chen_colnet",
                "title": "Colnet: Embedding the semantics of web tables for column type prediction"
            },
            {
                "ref": "2014_dimou_rml",
                "title": "RML: A generic language for integrated RDF mappings of heterogeneous data"
            },
            {
                "ref": "2017_efthymiou_matching",
                "title": "Matching web tables with knowledge base entities: from entity lookups to entity embeddings"
            },
            {
                "ref": "2019_chen_semtab2019",
                "title": "Semtab2019: Semantic web challenge on tabular data to knowledge graph matching - 2019 data sets"
            },
            {
                "ref": "2015_ritze_matching",
                "title": "Matching HTML tables to DBpedia"
            },
            {
                "ref": "2017_zhang_effective",
                "title": "Effective and efficient semantic table interpretation using TableMiner+"
            },
            {
                "ref": "2013_zwicklbauer_towards",
                "title": "Towards disambiguating web tables"
            }
        ],
        "uncertainFields": [
            {
                "field": "doi",
                "reason": "No DOI is indicated in the paper; CEUR-WS challenge papers sometimes lack DOIs."
            },
            {
                "field": "license",
                "reason": "The article text shows CC BY 4.0 for the paper, but the software licence of CSV2KG is not stated in the text."
            },
            {
                "field": "output",
                "reason": "The exact exported format (e.g., RDF, JSON-LD) is not explicitly specified."
            },
            {
                "field": "inputs.tableSources",
                "reason": "Tables are described as CSV from the SemTab datasets, but their upstream source category (web/wiki/gov-open-data, etc.) is not stated."
            },
            {
                "field": "userInterfaceTool",
                "reason": "No graphical UI or CLI details are described; only a Python implementation is mentioned."
            },
            {
                "field": "kg.index",
                "reason": "APIs (Lookup/Spotlight) and SPARQL are used, but it is unclear whether a dedicated index beyond these services is maintained."
            },
            {
                "field": "supportTasks.subjectDetection",
                "reason": "The method treats the first column as the head/subject; it is not clear if a general subject-detection algorithm is applied."
            },
            {
                "field": "venue.acronym",
                "reason": "The venue is the SemTab challenge at ISWC 2019; acronym could also appear as 'ISWC SemTab' in other sources."
            }
        ]
    },
    {
        "id": "2019_takeoka_meimei",
        "added": "",
        "year": 2019,
        "firstAuthor": "Takeoka",
        "authors": [
            "Kunihiro Takeoka",
            "Masafumi Oyamada",
            "Shinji Nakadai",
            "Takeshi Okadome"
        ],
        "title": "Meimei: An Efficient Probabilistic Approach for Semantically Annotating Tables",
        "venue": {
            "type": "conference",
            "acronym": "AAAI"
        },
        "nameOfApproach": "Meimei",
        "techniqueTags": [
            "embeddings"
        ],
        "coreTasks": {
            "cta": true,
            "cpa": false,
            "cea": false,
            "cnea": false
        },
        "supportTasks": {
            "dataPreparation": {
                "description": "Extracts features from columns (textual similarity to KG lemmas for NE-columns; numeric statistics and simple textual features for literal-columns). ",
                "spellChecker": "",
                "unitsOfMeasurements": "Robustness to differing units via unit-invariant features; no explicit unit normalisation step described. "
            },
            "columnClassification": "Handles NE-columns and literal-columns with distinct feature extractors and classifiers. ",
            "subjectDetection": "",
            "datatypeAnnotation": "",
            "typeAnnotation": "Assigns KG concepts to columns via a Markov random field with multi-label classifier potentials and title/column interactions. ",
            "predicateAnnotation": "",
            "nilAnnotation": "",
            "entityLinking": {
                "description": "",
                "candidateGeneration": "",
                "entityDisambiguation": ""
            }
        },
        "mainMethod": {
            "type": "supervised",
            "technique": "Multi-label classification with Markov random field potentials (column–content, column–column, title–column) and KG embeddings.",
            "supervision": {
                "type": "supervised"
            }
        },
        "revision": {
            "type": "fully automated",
            "description": "Fully automated inference (Gibbs sampling) to maximise potentials; no human-in-the-loop revision described. "
        },
        "domain": {
            "domain": "independent",
            "type": ""
        },
        "validation": {
            "goldStandard": "183 human-annotated tables from the UCI Machine Learning Repository. ",
            "metrics": [
                "MAP@5",
                "NDCG@5"
            ]
        },
        "code": "",
        "license": "Not Specified",
        "inputs": {
            "typeOfTable": "Tabular data (UCI tables)",
            "tableSources": [
                "scientific"
            ]
        },
        "kg": {
            "tripleStore": "WordNet",
            "index": ""
        },
        "output": "Column-level semantic labels",
        "applicationPurpose": "Improve search, joining, and semantic operations on tables by unifying ambiguous column semantics. ",
        "userInterfaceTool": "",
        "checkedByAuthor": "",
        "checkedByAi": true,
        "doi": "",
        "citations": [
            {
                "ref": "2010_limaye_annotating",
                "title": "Annotating and searching web tables using entities, types and relationships"
            },
            {
                "ref": "2016_pham_semantic",
                "title": "Semantic labeling: a domain-independent approach"
            },
            {
                "ref": "2016_neumaier_multi",
                "title": "Multi-level semantic labelling of numerical values"
            },
            {
                "ref": "2017_nickel_poincare",
                "title": "Poincaré embeddings for learning hierarchical representations"
            },
            {
                "ref": "2016_trouillon_complex",
                "title": "ComplEx embeddings for simple link prediction"
            },
            {
                "ref": "2013_bordes_translating",
                "title": "Translating embeddings for modeling multi-relational data"
            },
            {
                "ref": "2017_zhang_effective",
                "title": "Effective and efficient semantic table interpretation using TableMiner+"
            },
            {
                "ref": "2011_venetis_recovering",
                "title": "Recovering semantics of tables on the web"
            },
            {
                "ref": "2015_chu_katara",
                "title": "Katara: A data cleaning system powered by knowledge bases and crowdsourcing"
            },
            {
                "ref": "2013_zhang_infogather",
                "title": "InfoGather+: Semantic matching and annotation of numeric and time-varying attributes in web tables"
            }
        ],
        "uncertainFields": [
            {
                "field": "doi",
                "reason": "The DOI for the AAAI-19 paper was not present in the provided text; leaving it empty to avoid speculation. "
            },
            {
                "field": "code",
                "reason": "No code repository or URL was mentioned in the paper excerpt. "
            },
            {
                "field": "userInterfaceTool",
                "reason": "No UI or tool front-end is described; the work focuses on methodology and experiments. "
            },
            {
                "field": "kg.index",
                "reason": "The paper uses KG embeddings (Poincaré) but does not describe a specific index structure for lookup. "
            },
            {
                "field": "inputs.typeOfTable",
                "reason": "Tables are from UCI datasets, but exact file formats (e.g., CSV, spreadsheet) are not explicitly specified. "
            }
        ]
    },
    {
        "id": "2019_thawani_entity",
        "added": "",
        "year": 2019,
        "firstAuthor": "Thawani",
        "authors": [
            "Avijit Thawani",
            "Minda Hu",
            "Erdong Hu",
            "Husain Zafar",
            "Naren Teja Divvala",
            "Amandeep Singh",
            "Ehsan Qasemi",
            "Pedro Szekely",
            "Jay Pujara"
        ],
        "title": "Entity Linking to Knowledge Graphs to Infer Column Types and Properties",
        "venue": {
            "type": "workshop",
            "acronym": "SemTab"
        },
        "nameOfApproach": "",
        "techniqueTags": [
            "rule-based",
            "ontology-driven"
        ],
        "coreTasks": {
            "cta": true,
            "cpa": true,
            "cea": true,
            "cnea": false
        },
        "supportTasks": {
            "dataPreparation": {
                "description": "Input cleaning (headers, empty lines, encodings) and building auxiliary indices (e.g., name-abbreviation index).",
                "spellChecker": "",
                "unitsOfMeasurements": ""
            },
            "columnClassification": "",
            "subjectDetection": "",
            "datatypeAnnotation": "Transforms string, date, and numeric literals to align with KG values; no explicit datatype mapping reported.",
            "typeAnnotation": "Computes column class via hierarchical voting over DBpedia class tree using thresholded frequencies.",
            "predicateAnnotation": "Selects the most frequent DBpedia property between candidate pairs across rows (with synonym mapping).",
            "nilAnnotation": "",
            "entityLinking": {
                "description": "Two-stage pipeline: candidate generation (Wikidata API + Elasticsearch over Wikidata/DBpedia + abbreviation index) and candidate selection (heuristics and learned ranker).",
                "candidateGeneration": "Combines Wikidata API with Elasticsearch indexes for labels/aliases/descriptions and DBpedia-to-Wikidata mappings; includes special handling for abbreviated person names.",
                "entityDisambiguation": "Heuristic linear combination (TF-IDF-like semantic features + string similarities) and a 2-layer neural ranking model trained on T2Dv2."
            }
        },
        "mainMethod": {
            "type": "hybrid",
            "technique": "Heuristic scoring (TF-IDF + string similarity) combined with a neural network ranking model"
        },
        "revision": {
            "type": "fully automated",
            "description": "Automatic pipeline with no manual post-editing reported."
        },
        "domain": {
            "domain": "independent",
            "type": "generic"
        },
        "validation": {
            "goldStandard": "SemTab 2019 (Round 2); T2Dv2",
            "metrics": [
                "Precision",
                "F1"
            ]
        },
        "code": "",
        "license": "Not Specified",
        "inputs": {
            "typeOfTable": "Web tables",
            "tableSources": [
                "web"
            ]
        },
        "kg": {
            "tripleStore": "DBpedia; Wikidata",
            "index": "Elasticsearch indexes over Wikidata (labels/aliases/descriptions) and DBpedia labels mapped to Wikidata; Name Abbreviations Index"
        },
        "output": "",
        "applicationPurpose": "Linking tabular data to knowledge graphs (CEA/CTA/CPA) for the SemTab challenge.",
        "userInterfaceTool": "",
        "checkedByAuthor": "",
        "checkedByAi": true,
        "doi": "",
        "citations": [
            {
                "ref": "2006_hadsell_dimensionality",
                "title": "Dimensionality reduction by learning an invariant mapping"
            },
            {
                "ref": "2010_nair_rectified",
                "title": "Rectified linear units improve restricted boltzmann machines"
            },
            {
                "ref": "2015_ritze_t2dv2",
                "title": "T2dv2 gold standard for matching web tables to DBpedia"
            }
        ],
        "uncertainFields": [
            {
                "field": "venue.acronym",
                "reason": "Paper is part of the ISWC SemTab challenge; exact workshop acronym used in the proceedings may vary."
            },
            {
                "field": "code",
                "reason": "No repository or download link is mentioned in the text provided."
            },
            {
                "field": "doi",
                "reason": "CEUR-WS challenge papers often lack DOIs; none is stated in the text."
            },
            {
                "field": "inputs.tableSources",
                "reason": "Datasets include SemTab and T2Dv2; exact original table sources are not explicitly detailed."
            },
            {
                "field": "output",
                "reason": "Submission/output format (e.g., CSV, RDF) is not specified in the text."
            },
            {
                "field": "kg.tripleStore",
                "reason": "Both DBpedia and Wikidata are used; field expects a single string so both are listed."
            },
            {
                "field": "nameOfApproach",
                "reason": "No specific system name is given; approach is described generically."
            },
            {
                "field": "techniqueTags",
                "reason": "A neural model is used but tags do not include 'neural network'; selected tags reflect heuristics and ontology features."
            }
        ]
    },
    {
        "id": "2019_zhang_sato",
        "added": "",
        "year": 2019,
        "firstAuthor": "Zhang",
        "authors": [
            "Dan Zhang",
            "Yoshihiko Suhara",
            "Jinfeng Li",
            "Madelon Hulsebos",
            "Çağatay Demiralp",
            "Wang-Chiew Tan"
        ],
        "title": "Sato: Contextual Semantic Type Detection in Tables",
        "venue": {
            "type": "conference",
            "acronym": "VLDB"
        },
        "nameOfApproach": "Sato",
        "techniqueTags": [
            "embeddings",
            "CRF",
            "transformer"
        ],
        "coreTasks": {
            "cta": true,
            "cpa": false,
            "cea": false,
            "cnea": false
        },
        "supportTasks": {
            "dataPreparation": {
                "description": "Feature extraction from column values and creation of a table-level topic vector from all table values via LDA; no explicit normalisation steps are detailed.",
                "spellChecker": "",
                "unitsOfMeasurements": ""
            },
            "columnClassification": "",
            "subjectDetection": "",
            "datatypeAnnotation": "",
            "typeAnnotation": "Predicts column semantic types using a deep neural network augmented with table-topic features and a linear-chain CRF for structured prediction.",
            "predicateAnnotation": "",
            "nilAnnotation": "",
            "entityLinking": {
                "description": "",
                "candidateGeneration": "",
                "entityDisambiguation": ""
            }
        },
        "mainMethod": {
            "type": "hybrid",
            "technique": "Neural network with LDA topic features and linear-chain CRF"
        },
        "revision": {
            "type": "fully automated",
            "description": "Predictions are produced automatically by the model without human intervention."
        },
        "domain": {
            "domain": "independent",
            "type": "generic"
        },
        "validation": {
            "goldStandard": "VizNet WebTables subset with 78 semantic types (derived from T2Dv2); ~80K tables with canonicalised headers.",
            "metrics": [
                "Macro-F1",
                "Weighted-F1"
            ]
        },
        "code": "https://github.com/megagonlabs/sato",
        "license": "Not Specified",
        "inputs": {
            "typeOfTable": "Web tables",
            "tableSources": [
                "web"
            ]
        },
        "kg": {
            "tripleStore": "",
            "index": ""
        },
        "output": "",
        "applicationPurpose": "Semantic typing of table columns to support data cleaning, schema matching, and data discovery.",
        "userInterfaceTool": "Web UI (demo)",
        "usesLLM": null,
        "checkedByAuthor": "",
        "checkedByAi": true,
        "doi": "https://doi.org/10.48550/arXiv.1911.06311",
        "citations": [
            {
                "ref": "2019_hulsebos_sherlock",
                "title": "Sherlock: A deep learning approach to semantic data type detection"
            },
            {
                "ref": "2019_hu_viznet",
                "title": "VizNet: Towards a large-scale visualization learning and benchmarking repository"
            },
            {
                "ref": "2003_blei_latent",
                "title": "Latent Dirichlet Allocation"
            },
            {
                "ref": "2001_lafferty_conditional",
                "title": "Conditional Random Fields: Probabilistic Models for Segmenting and Labeling Sequence Data"
            },
            {
                "ref": "2008_cafarella_webtables",
                "title": "WebTables: Exploring the Power of Tables on the Web"
            },
            {
                "ref": "2011_venetis_recovering",
                "title": "Recovering Semantics of Tables on the Web"
            },
            {
                "ref": "2019_devlin_bert",
                "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"
            }
        ],
        "uncertainFields": [
            {
                "field": "venue.type",
                "reason": "The PDF appears to be an arXiv preprint; the final publication venue may be PVLDB (journal) rather than a conference."
            },
            {
                "field": "venue.acronym",
                "reason": "Set to 'VLDB' based on the file name; the official acronym could be 'PVLDB'."
            },
            {
                "field": "doi",
                "reason": "Using the arXiv DataCite DOI inferred from the arXiv identifier; a different publisher DOI may exist."
            },
            {
                "field": "kg.tripleStore",
                "reason": "The approach does not rely on a knowledge graph; no triple store is specified."
            },
            {
                "field": "output",
                "reason": "Output serialisation format is not stated; the system returns predicted types, not a specific file format."
            },
            {
                "field": "userInterfaceTool",
                "reason": "An online demo is mentioned but not formally described."
            },
            {
                "field": "techniqueTags[2]",
                "reason": "‘Transformer’ is included because BERT is discussed as an alternative single-column model, not the main one."
            },
            {
                "field": "citations",
                "reason": "Only key references are listed; the paper contains many more citations."
            }
        ]
    }
]